From d95d1a33244be055b1199dcf8d9ccecb4018d5cd Mon Sep 17 00:00:00 2001
From: Gabriel Russell <gabriel.russell@mongodb.com>
Date: Thu, 19 Dec 2019 16:54:11 +0000
Subject: [PATCH 4/4] all

---
 logv1tologv2                                  |   2 +-
 run.sh                                        |   9 +-
 scons.sh                                      |   2 +-
 src/mongo/SConscript                          |   2 +-
 src/mongo/bson/bson_validate_test.cpp         |  11 +-
 src/mongo/bson/bsonelement.cpp                |   3 +-
 src/mongo/bson/bsonobjbuilder.cpp             |   5 +-
 src/mongo/bson/json.cpp                       |   4 +-
 src/mongo/client/authenticate.cpp             |   5 +-
 .../client/connection_string_connect.cpp      |   8 +-
 src/mongo/client/connpool.cpp                 |   9 +-
 src/mongo/client/dbclient_base.cpp            |   8 +-
 src/mongo/client/dbclient_connection.cpp      |  20 +-
 src/mongo/client/dbclient_cursor.cpp          |   9 +-
 src/mongo/client/dbclient_cursor_test.cpp     |   3 +-
 src/mongo/client/dbclient_rs.cpp              |  66 ++---
 src/mongo/client/mongo_uri_test.cpp           |  13 +-
 .../remote_command_retry_scheduler_test.cpp   |   3 +-
 .../client/remote_command_targeter_rs.cpp     |   6 +-
 .../client/replica_set_change_notifier.cpp    |   9 +-
 src/mongo/client/replica_set_monitor.cpp      |  44 ++--
 .../client/replica_set_monitor_manager.cpp    |   9 +-
 .../client/replica_set_monitor_scan_test.cpp  |   6 +-
 .../replica_set_monitor_test_concurrent.cpp   |  11 +-
 .../client/sasl_client_authenticate_impl.cpp  |   5 +-
 .../client/sdam/topology_description_test.cpp |   4 +-
 .../client/sdam/topology_state_machine.cpp    |  19 +-
 .../db/auth/authorization_manager_impl.cpp    |  29 +--
 .../db/auth/authorization_session_impl.cpp    |  27 +--
 ...z_session_external_state_server_common.cpp |   6 +-
 src/mongo/db/auth/sasl_commands.cpp           |   5 +-
 src/mongo/db/auth/sasl_mechanism_registry.cpp |   4 +-
 src/mongo/db/auth/sasl_scram_test.cpp         |   5 +-
 src/mongo/db/auth/security_key.cpp            |   3 +-
 .../db/auth/user_cache_invalidator_job.cpp    |   1 +
 src/mongo/db/catalog/catalog_control.cpp      |  23 +-
 src/mongo/db/catalog/coll_mod.cpp             |   3 +-
 src/mongo/db/catalog/collection_catalog.cpp   |  12 +-
 src/mongo/db/catalog/collection_compact.cpp   |   7 +-
 src/mongo/db/catalog/collection_impl.cpp      |  15 +-
 .../db/catalog/collection_validation.cpp      |  34 +--
 src/mongo/db/catalog/create_collection.cpp    |   9 +-
 src/mongo/db/catalog/database_holder_impl.cpp |   5 +-
 src/mongo/db/catalog/database_impl.cpp        |  37 ++-
 src/mongo/db/catalog/drop_collection.cpp      |  13 +-
 src/mongo/db/catalog/drop_database.cpp        |  29 +--
 src/mongo/db/catalog/drop_indexes.cpp         |   3 +-
 src/mongo/db/catalog/index_build_block.cpp    |   3 +-
 src/mongo/db/catalog/index_builds_manager.cpp |   6 +-
 .../db/catalog/index_catalog_entry_impl.cpp   |  10 +-
 src/mongo/db/catalog/index_catalog_impl.cpp   |  25 +-
 .../db/catalog/index_timestamp_helper.cpp     |   8 +-
 src/mongo/db/catalog/multi_index_block.cpp    |  34 ++-
 src/mongo/db/catalog/rename_collection.cpp    |  19 +-
 src/mongo/db/catalog/validate_adaptor.cpp     |   3 +-
 src/mongo/db/catalog/validate_state.cpp       |  21 +-
 src/mongo/db/catalog_raii_test.cpp            |   3 +-
 src/mongo/db/cloner.cpp                       |  26 +-
 .../db/collection_index_builds_tracker.cpp    |   5 +-
 src/mongo/db/commands.cpp                     |  10 +-
 .../db/commands/authentication_commands.cpp   |   9 +-
 src/mongo/db/commands/create_indexes.cpp      |  45 ++--
 src/mongo/db/commands/dbcheck.cpp             |   3 +-
 src/mongo/db/commands/dbcommands_d.cpp        |   7 +-
 src/mongo/db/commands/dbhash.cpp              |   3 +-
 src/mongo/db/commands/drop_indexes.cpp        |   5 +-
 .../feature_compatibility_version.cpp         |   8 +-
 src/mongo/db/commands/fsync.cpp               |  15 +-
 src/mongo/db/commands/generic_servers.cpp     |   3 +-
 src/mongo/db/commands/get_last_error.cpp      |   4 +-
 src/mongo/db/commands/getmore_cmd.cpp         |   5 +-
 .../db/commands/index_filter_commands.cpp     |   7 +-
 src/mongo/db/commands/kill_op.cpp             |   3 +-
 src/mongo/db/commands/mr.cpp                  |  24 +-
 src/mongo/db/commands/oplog_note.cpp          |   3 +-
 src/mongo/db/commands/resize_oplog.cpp        |   3 +-
 .../db/commands/restart_catalog_command.cpp   |   5 +-
 src/mongo/db/commands/server_status.cpp       |   3 +-
 ..._feature_compatibility_version_command.cpp |   9 +-
 src/mongo/db/commands/sleep_command.cpp       |   3 +-
 src/mongo/db/commands/test_commands.cpp       |   3 +-
 .../db/commands/traffic_recording_cmds.cpp    |   5 +-
 src/mongo/db/commands/txn_cmds.cpp            |   7 +-
 .../db/commands/user_management_commands.cpp  |   3 +-
 src/mongo/db/commands/validate.cpp            |   4 +-
 .../db/concurrency/d_concurrency_test.cpp     |   5 +-
 src/mongo/db/concurrency/deferred_writer.cpp  |   6 +-
 .../concurrency/flow_control_ticketholder.cpp |   7 +-
 src/mongo/db/concurrency/lock_manager.cpp     |   5 +-
 src/mongo/db/concurrency/lock_state.cpp       |   5 +-
 src/mongo/db/curop.cpp                        |   3 +-
 src/mongo/db/cursor_manager.cpp               |   9 +-
 .../db/database_index_builds_tracker.cpp      |   5 +-
 src/mongo/db/db.cpp                           | 100 ++++----
 src/mongo/db/db_raii.cpp                      |   7 +-
 src/mongo/db/exec/cached_plan.cpp             |  22 +-
 src/mongo/db/exec/collection_scan.cpp         |   3 +-
 .../document_value/document_value_test.cpp    |   5 +-
 src/mongo/db/exec/multi_plan.cpp              |  28 +--
 src/mongo/db/exec/subplan.cpp                 |  14 +-
 src/mongo/db/exec/trial_stage.cpp             |   1 +
 src/mongo/db/exec/update_stage.cpp            |   3 +-
 src/mongo/db/free_mon/free_mon_controller.cpp |   5 +-
 .../db/free_mon/free_mon_controller_test.cpp  |  12 +-
 src/mongo/db/free_mon/free_mon_processor.cpp  |  11 +-
 src/mongo/db/ftdc/controller.cpp              |   8 +-
 src/mongo/db/ftdc/file_manager.cpp            |  17 +-
 src/mongo/db/ftdc/file_manager_test.cpp       |   3 +-
 src/mongo/db/ftdc/util.cpp                    |  21 +-
 src/mongo/db/geo/r2_region_coverer.cpp        |   7 +-
 src/mongo/db/geo/r2_region_coverer_test.cpp   |  11 +-
 src/mongo/db/index/2d_key_generator_test.cpp  |   7 +-
 .../db/index/btree_key_generator_test.cpp     |   7 +-
 src/mongo/db/index/duplicate_key_tracker.cpp  |   8 +-
 .../db/index/hash_key_generator_test.cpp      |   7 +-
 src/mongo/db/index/haystack_access_method.cpp |   4 +-
 .../index_access_method_factory_impl.cpp      |   3 +-
 .../db/index/index_build_interceptor.cpp      |  11 +-
 src/mongo/db/index/s2_key_generator_test.cpp  |   7 +-
 .../db/index/wildcard_key_generator_test.cpp  |   7 +-
 src/mongo/db/index_builds_coordinator.cpp     |  74 +++---
 .../db/initialize_server_global_state.cpp     |   5 +-
 src/mongo/db/introspect.cpp                   |   6 +-
 .../db/keys_collection_client_direct.cpp      |   5 +-
 src/mongo/db/keys_collection_manager.cpp      |   3 +-
 src/mongo/db/kill_sessions_common.cpp         |   4 +-
 src/mongo/db/kill_sessions_local.cpp          |  12 +-
 src/mongo/db/log_process_details.cpp          |  16 +-
 src/mongo/db/logical_clock.cpp                |   5 +-
 src/mongo/db/logical_time_validator.cpp       |   7 +-
 src/mongo/db/matcher/rewrite_expr.cpp         |   7 +-
 .../db/matcher/schema/json_schema_parser.cpp  |   6 +-
 src/mongo/db/mongod_options.cpp               |  13 +-
 src/mongo/db/operation_context.cpp            |   5 +-
 src/mongo/db/ops/update_result.cpp            |   3 +-
 src/mongo/db/ops/write_ops_exec.cpp           |  23 +-
 ..._runner_job_abort_expired_transactions.cpp |   4 +-
 ...r_job_decrease_snapshot_cache_pressure.cpp |   6 +-
 src/mongo/db/pipeline/accumulator_test.cpp    |   3 +-
 .../db/pipeline/document_source_cursor.cpp    |   3 +-
 .../db/pipeline/document_source_exchange.cpp  |   5 +-
 .../document_source_exchange_test.cpp         |   3 +-
 .../pipeline/document_source_match_test.cpp   |   3 +-
 .../db/pipeline/document_source_merge.cpp     |   4 +-
 src/mongo/db/pipeline/document_source_out.cpp |   7 +-
 ...ument_source_sample_from_random_cursor.cpp |   4 +-
 src/mongo/db/pipeline/expression_test.cpp     |   3 +-
 .../pipeline/process_interface_standalone.cpp |   3 +-
 src/mongo/db/pipeline/sharded_agg_helpers.cpp |  18 +-
 src/mongo/db/query/collection_query_info.cpp  |   3 +-
 src/mongo/db/query/find.cpp                   |  23 +-
 src/mongo/db/query/find_common.cpp            |   4 +-
 src/mongo/db/query/get_executor.cpp           |  33 +--
 src/mongo/db/query/index_bounds_builder.cpp   |   5 +-
 src/mongo/db/query/plan_cache.cpp             |  33 +--
 src/mongo/db/query/plan_enumerator.cpp        |   5 +-
 src/mongo/db/query/plan_executor_impl.cpp     |   5 +-
 src/mongo/db/query/plan_ranker.cpp            |  21 +-
 src/mongo/db/query/planner_access.cpp         |   4 +-
 src/mongo/db/query/planner_analysis.cpp       |   8 +-
 src/mongo/db/query/planner_ixselect.cpp       |   6 +-
 .../db/query/planner_wildcard_helpers.cpp     |   5 +-
 src/mongo/db/query/query_planner.cpp          |  55 ++---
 .../db/query/query_planner_test_fixture.cpp   |   3 +-
 src/mongo/db/read_concern_mongod.cpp          |  34 +--
 src/mongo/db/record_id.h                      |   9 +
 src/mongo/db/repair_database.cpp              |   5 +-
 .../db/repair_database_and_check_version.cpp  |  51 ++--
 src/mongo/db/repl/abstract_oplog_fetcher.cpp  |  16 +-
 .../db/repl/abstract_oplog_fetcher_test.cpp   |  25 +-
 .../abstract_oplog_fetcher_test_fixture.cpp   |   9 +-
 src/mongo/db/repl/all_database_cloner.cpp     |  14 +-
 .../db/repl/all_database_cloner_test.cpp      |   7 +-
 src/mongo/db/repl/apply_ops.cpp               |   3 +-
 src/mongo/db/repl/base_cloner.cpp             |  39 ++-
 src/mongo/db/repl/bgsync.cpp                  |  87 +++----
 .../db/repl/collection_bulk_loader_impl.cpp   |   5 +-
 src/mongo/db/repl/collection_cloner.cpp       |  16 +-
 .../data_replicator_external_state_impl.cpp   |  13 +-
 src/mongo/db/repl/database_cloner.cpp         |   7 +-
 .../repl/drop_pending_collection_reaper.cpp   |   7 +-
 src/mongo/db/repl/idempotency_test.cpp        |   3 +-
 src/mongo/db/repl/initial_syncer.cpp          | 101 ++++----
 src/mongo/db/repl/initial_syncer_test.cpp     |  38 +--
 src/mongo/db/repl/insert_group.cpp            |   3 +-
 src/mongo/db/repl/isself.cpp                  |   5 +-
 src/mongo/db/repl/member_data.cpp             |  18 +-
 src/mongo/db/repl/noop_writer.cpp             |  14 +-
 src/mongo/db/repl/oplog.cpp                   |  48 ++--
 src/mongo/db/repl/oplog_applier.cpp           |   7 +-
 src/mongo/db/repl/oplog_applier_impl.cpp      |  22 +-
 src/mongo/db/repl/oplog_fetcher.cpp           |  11 +-
 src/mongo/db/repl/repl_client_info.cpp        |   7 +-
 src/mongo/db/repl/repl_set_commands.cpp       |  26 +-
 .../replication_consistency_markers_impl.cpp  |  39 ++-
 ...cation_coordinator_external_state_impl.cpp |  28 +--
 .../db/repl/replication_coordinator_impl.cpp  | 226 +++++++-----------
 .../replication_coordinator_impl_elect_v1.cpp |  45 ++--
 ...ication_coordinator_impl_elect_v1_test.cpp |  43 ++--
 ...replication_coordinator_impl_heartbeat.cpp |  27 +--
 ...ion_coordinator_impl_heartbeat_v1_test.cpp |  10 +-
 .../replication_coordinator_impl_test.cpp     |  35 +--
 .../replication_coordinator_test_fixture.cpp  |  25 +-
 src/mongo/db/repl/replication_process.cpp     |   9 +-
 src/mongo/db/repl/replication_recovery.cpp    |  47 ++--
 src/mongo/db/repl/reporter.cpp                |  15 +-
 .../db/repl/roll_back_local_operations.cpp    |   3 +-
 .../repl/roll_back_local_operations_test.cpp  |   7 +-
 src/mongo/db/repl/rollback_impl.cpp           | 113 ++++-----
 src/mongo/db/repl/rollback_impl_test.cpp      |  16 +-
 src/mongo/db/repl/rs_rollback.cpp             | 203 ++++++----------
 src/mongo/db/repl/scatter_gather_runner.cpp   |   4 +-
 src/mongo/db/repl/storage_interface_impl.cpp  |  12 +-
 src/mongo/db/repl/storage_interface_mock.cpp  |   7 +-
 src/mongo/db/repl/sync_source_feedback.cpp    |  13 +-
 src/mongo/db/repl/sync_source_resolver.cpp    |  31 +--
 src/mongo/db/repl/task_runner.cpp             |   3 +-
 src/mongo/db/repl/topology_coordinator.cpp    | 170 +++++--------
 .../db/repl/topology_coordinator_v1_test.cpp  |   7 +-
 .../db/repl/transaction_oplog_application.cpp |   5 +-
 src/mongo/db/s/balancer/balancer.cpp          |  52 ++--
 .../balancer_chunk_selection_policy_impl.cpp  |   1 +
 src/mongo/db/s/balancer/balancer_policy.cpp   |  20 +-
 .../db/s/balancer/cluster_statistics_impl.cpp |   4 +-
 src/mongo/db/s/balancer/migration_manager.cpp |  19 +-
 .../s/balancer/scoped_migration_request.cpp   |  12 +-
 src/mongo/db/s/chunk_splitter.cpp             |  31 +--
 src/mongo/db/s/cleanup_orphaned_cmd.cpp       |  13 +-
 src/mongo/db/s/collection_range_deleter.cpp   |  53 ++--
 .../db/s/collection_sharding_runtime.cpp      |  13 +-
 src/mongo/db/s/collection_sharding_state.cpp  |   1 +
 .../s/config/configsvr_add_shard_command.cpp  |   4 +-
 .../config/configsvr_move_primary_command.cpp |   4 +-
 ...vr_refine_collection_shard_key_command.cpp |   3 +-
 .../config/configsvr_remove_shard_command.cpp |   3 +-
 ..._catalog_manager_collection_operations.cpp |  62 ++---
 ...ng_catalog_manager_database_operations.cpp |   8 +-
 ...rding_catalog_manager_shard_operations.cpp |  20 +-
 src/mongo/db/s/database_sharding_state.cpp    |   4 +-
 .../flush_database_cache_updates_command.cpp  |   3 +-
 ...sh_routing_table_cache_updates_command.cpp |   3 +-
 src/mongo/db/s/merge_chunks_command.cpp       |   4 +-
 src/mongo/db/s/metadata_manager.cpp           |  31 +--
 .../migration_chunk_cloner_source_legacy.cpp  |  11 +-
 .../db/s/migration_destination_manager.cpp    |  33 ++-
 ...on_destination_manager_legacy_commands.cpp |   5 +-
 src/mongo/db/s/migration_source_manager.cpp   |  29 +--
 src/mongo/db/s/migration_util.cpp             |  35 ++-
 .../db/s/move_primary_source_manager.cpp      |  12 +-
 .../s/periodic_balancer_config_refresher.cpp  |   3 +-
 ..._operation_completion_sharding_actions.cpp |  10 +-
 src/mongo/db/s/set_shard_version_command.cpp  |   5 +-
 .../db/s/shard_filtering_metadata_refresh.cpp |  20 +-
 src/mongo/db/s/shard_metadata_util.cpp        |   7 +-
 .../s/shard_server_catalog_cache_loader.cpp   |  24 +-
 src/mongo/db/s/sharded_connection_info.cpp    |   3 +-
 .../db/s/sharding_initialization_mongod.cpp   |  15 +-
 src/mongo/db/s/sharding_logging.cpp           |   7 +-
 src/mongo/db/s/sharding_state.cpp             |   3 +-
 src/mongo/db/s/sharding_state_recovery.cpp    |  17 +-
 src/mongo/db/s/shardsvr_rename_collection.cpp |   3 +-
 src/mongo/db/s/shardsvr_shard_collection.cpp  |   8 +-
 src/mongo/db/s/split_chunk_command.cpp        |   3 +-
 src/mongo/db/s/split_chunk_test.cpp           |   5 +-
 src/mongo/db/s/split_vector.cpp               |  19 +-
 src/mongo/db/s/transaction_coordinator.cpp    |  12 +-
 .../db/s/transaction_coordinator_catalog.cpp  |  16 +-
 .../transaction_coordinator_futures_util.cpp  |   5 +-
 .../db/s/transaction_coordinator_service.cpp  |  11 +-
 .../db/s/transaction_coordinator_test.cpp     |  17 +-
 .../db/s/transaction_coordinator_util.cpp     |  52 ++--
 src/mongo/db/s/txn_two_phase_commit_cmds.cpp  |  17 +-
 src/mongo/db/s/wait_for_majority_service.cpp  |   3 +-
 .../db/server_options_server_helpers.cpp      |   3 +-
 src/mongo/db/service_entry_point_common.cpp   |  60 ++---
 src/mongo/db/service_entry_point_mongod.cpp   |   8 +-
 src/mongo/db/session_catalog.cpp              |   3 +-
 src/mongo/db/session_catalog_mongod.cpp       |   9 +-
 src/mongo/db/sorter/sorter_test.cpp           |   4 +-
 src/mongo/db/startup_warnings_common.cpp      |  90 +++----
 src/mongo/db/startup_warnings_mongod.cpp      | 119 ++++-----
 src/mongo/db/stats/counters.cpp               |   3 +-
 src/mongo/db/storage/durable_catalog_impl.cpp |  22 +-
 .../ephemeral_for_test_recovery_unit.cpp      |   3 +-
 src/mongo/db/storage/flow_control.cpp         |  29 +--
 src/mongo/db/storage/key_string_test.cpp      |  29 +--
 .../kv/kv_drop_pending_ident_reaper.cpp       |   4 +-
 .../db/storage/mobile/mobile_kv_engine.cpp    |  23 +-
 .../db/storage/mobile/mobile_session_pool.cpp |  11 +-
 src/mongo/db/storage/mobile/mobile_util.cpp   |   3 +-
 .../storage/oplog_cap_maintainer_thread.cpp   |   7 +-
 src/mongo/db/storage/recovery_unit.cpp        |   5 +-
 src/mongo/db/storage/storage_engine_impl.cpp  |  52 ++--
 src/mongo/db/storage/storage_engine_init.cpp  |   5 +-
 .../storage_engine_lock_file_posix.cpp        |  18 +-
 .../storage_engine_lock_file_windows.cpp      |   5 +-
 .../db/storage/storage_engine_metadata.cpp    |  14 +-
 src/mongo/db/storage/storage_file_util.cpp    |   3 +-
 .../storage/storage_repair_observer_test.cpp  |   5 +-
 .../wiredtiger/wiredtiger_global_options.cpp  |   7 +-
 .../db/storage/wiredtiger/wiredtiger_init.cpp |  24 +-
 .../wiredtiger/wiredtiger_kv_engine.cpp       |  89 ++++---
 .../wiredtiger/wiredtiger_kv_engine_test.cpp  |   4 +-
 .../wiredtiger/wiredtiger_oplog_manager.cpp   |  15 +-
 .../wiredtiger/wiredtiger_parameters.cpp      |   5 +-
 .../wiredtiger_prepare_conflict.cpp           |   6 +-
 .../wiredtiger/wiredtiger_record_store.cpp    |  60 ++---
 .../wiredtiger/wiredtiger_recovery_unit.cpp   |  18 +-
 .../wiredtiger/wiredtiger_session_cache.cpp   |   7 +-
 .../wiredtiger/wiredtiger_size_storer.cpp     |  11 +-
 .../wiredtiger_snapshot_manager.cpp           |   3 +-
 .../db/storage/wiredtiger/wiredtiger_util.cpp |  11 +-
 src/mongo/db/system_index.cpp                 |   4 +-
 src/mongo/db/transaction_participant.cpp      |  19 +-
 src/mongo/db/ttl.cpp                          |  20 +-
 src/mongo/db/views/durable_view_catalog.cpp   |   5 +-
 src/mongo/db/views/view_catalog.cpp           |   6 +-
 src/mongo/db/write_concern.cpp                |   7 +-
 src/mongo/dbtests/commandtests.cpp            |  15 +-
 src/mongo/dbtests/framework_options.cpp       |   5 +-
 src/mongo/dbtests/jsobjtests.cpp              |   3 +-
 src/mongo/dbtests/jsontests.cpp               |  15 +-
 src/mongo/dbtests/repltests.cpp               |   6 +-
 src/mongo/dbtests/storage_timestamp_tests.cpp |  26 +-
 src/mongo/dbtests/threadedtests.cpp           |   3 +-
 .../wildcard_multikey_persistence_test.cpp    |   5 +-
 src/mongo/embedded/embedded.cpp               |   7 +-
 .../mongoc_embedded/mongoc_embedded_test.cpp  |   5 +-
 src/mongo/executor/connection_pool_tl.cpp     |   9 +-
 .../network_interface_integration_fixture.cpp |   5 +-
 src/mongo/executor/network_interface_mock.cpp |   5 +-
 .../executor/network_interface_perf_test.cpp  |   3 +-
 src/mongo/executor/network_interface_tl.cpp   |  24 +-
 src/mongo/executor/thread_pool_mock.cpp       |  11 +-
 .../executor/thread_pool_task_executor.cpp    |   6 +-
 src/mongo/logger/logv2_appender.h             |   2 +-
 src/mongo/logv2/log_test_v2.cpp               |  13 +
 src/mongo/platform/decimal128_bson_test.cpp   |   5 +-
 src/mongo/platform/random_test.cpp            |   5 +-
 src/mongo/platform/shared_library_posix.cpp   |   5 +-
 src/mongo/platform/shared_library_windows.cpp |   5 +-
 src/mongo/platform/source_location_test.cpp   |  33 +--
 src/mongo/rpc/metadata/client_metadata.cpp    |   4 +-
 src/mongo/rpc/op_msg.cpp                      |   4 +-
 src/mongo/rpc/op_msg_integration_test.cpp     |   5 +-
 src/mongo/rpc/op_msg_test.cpp                 |  11 +-
 src/mongo/s/async_requests_sender.cpp         |   9 +-
 src/mongo/s/balancer_configuration.cpp        |   7 +-
 .../s/catalog/replset_dist_lock_manager.cpp   |  61 ++---
 .../catalog/sharding_catalog_client_impl.cpp  |   5 +-
 src/mongo/s/catalog_cache.cpp                 |  17 +-
 .../s/chunk_manager_index_bounds_test.cpp     |   5 +-
 src/mongo/s/client/parallel.cpp               |  47 ++--
 src/mongo/s/client/shard.cpp                  |  13 +-
 src/mongo/s/client/shard_connection.cpp       |   4 +-
 src/mongo/s/client/shard_registry.cpp         |  27 +--
 src/mongo/s/client/shard_remote.cpp           |   5 +-
 .../s/client/sharding_connection_hook.cpp     |   3 +-
 .../s/commands/cluster_coll_stats_cmd.cpp     |   3 +-
 .../s/commands/cluster_collection_mod_cmd.cpp |   3 +-
 .../s/commands/cluster_create_indexes_cmd.cpp |   3 +-
 .../s/commands/cluster_drop_indexes_cmd.cpp   |   3 +-
 .../s/commands/cluster_get_last_error_cmd.cpp |   5 +-
 .../cluster_get_shard_version_cmd.cpp         |   3 +-
 src/mongo/s/commands/cluster_kill_op.cpp      |   3 +-
 .../s/commands/cluster_move_chunk_cmd.cpp     |   3 +-
 ...luster_refine_collection_shard_key_cmd.cpp |   3 +-
 .../cluster_set_index_commit_quorum_cmd.cpp   |   4 +-
 src/mongo/s/commands/cluster_split_cmd.cpp    |   6 +-
 src/mongo/s/commands/cluster_write_cmd.cpp    |   3 +-
 .../document_shard_key_update_util.cpp        |   3 +-
 .../s/commands/flush_router_config_cmd.cpp    |   7 +-
 src/mongo/s/commands/strategy.cpp             |  33 ++-
 src/mongo/s/grid.cpp                          |   7 +-
 src/mongo/s/query/cluster_cursor_manager.cpp  |   6 +-
 src/mongo/s/query/cluster_find.cpp            |   7 +-
 src/mongo/s/server.cpp                        |  27 +--
 src/mongo/s/service_entry_point_mongos.cpp    |  10 +-
 src/mongo/s/shard_util.cpp                    |   3 +-
 src/mongo/s/sharding_task_executor.cpp        |   5 +-
 src/mongo/s/sharding_uptime_reporter.cpp      |   3 +-
 src/mongo/s/transaction_router.cpp            |  60 ++---
 src/mongo/s/version_mongos.cpp                |   5 +-
 src/mongo/s/write_ops/batch_write_exec.cpp    |  31 +--
 .../s/write_ops/chunk_manager_targeter.cpp    |  10 +-
 src/mongo/scripting/engine.cpp                |   3 +-
 src/mongo/scripting/mozjs/cursor_handle.cpp   |   3 +-
 src/mongo/scripting/mozjs/engine.cpp          |   9 +-
 src/mongo/scripting/mozjs/implscope.cpp       |   4 +-
 src/mongo/scripting/mozjs/session.cpp         |   3 +-
 src/mongo/shell/bench.cpp                     |  22 +-
 src/mongo/shell/shell_options.cpp             |   7 +-
 src/mongo/shell/shell_utils_launcher.cpp      |  32 ++-
 src/mongo/tools/bridge.cpp                    |  22 +-
 .../transport/message_compressor_manager.cpp  |  33 ++-
 .../transport/service_entry_point_impl.cpp    |  18 +-
 .../transport/service_entry_point_utils.cpp   |   3 +-
 .../transport/service_executor_adaptive.cpp   |  24 +-
 .../service_executor_adaptive_test.cpp        |  37 +--
 .../transport/service_executor_reserved.cpp   |   7 +-
 .../service_executor_synchronous.cpp          |   5 +-
 src/mongo/transport/service_executor_test.cpp |   3 +-
 src/mongo/transport/service_state_machine.cpp |  18 +-
 .../transport/service_state_machine_test.cpp  |  35 ++-
 src/mongo/transport/transport_layer_asio.cpp  |  18 +-
 .../transport_layer_asio_integration_test.cpp |   9 +-
 .../transport/transport_layer_asio_test.cpp   |  35 +--
 src/mongo/unittest/benchmark_main.cpp         |   5 +-
 src/mongo/unittest/death_test.cpp             |  11 +-
 src/mongo/unittest/integration_test_main.cpp  |   3 +-
 src/mongo/unittest/temp_dir.cpp               |   3 +-
 src/mongo/unittest/unittest.cpp               |  34 ++-
 src/mongo/unittest/unittest_test.cpp          |   3 +-
 src/mongo/util/alarm_test.cpp                 |   7 +-
 src/mongo/util/assert_util.cpp                |   3 +-
 src/mongo/util/background.cpp                 |   5 +-
 src/mongo/util/concurrency/spin_lock_test.cpp |   3 +-
 src/mongo/util/concurrency/thread_name.cpp    |   5 +-
 src/mongo/util/concurrency/thread_pool.cpp    |  16 +-
 src/mongo/util/concurrency/ticketholder.cpp   |   3 +-
 src/mongo/util/concurrency/with_lock_test.cpp |   3 +-
 src/mongo/util/diagnostic_info.cpp            |  15 +-
 src/mongo/util/duration.cpp                   | 135 ++---------
 src/mongo/util/duration.h                     |  76 +++---
 src/mongo/util/exception_filter_win32.cpp     |  10 +-
 src/mongo/util/exit.cpp                       |   3 +-
 src/mongo/util/file.cpp                       |  57 ++---
 src/mongo/util/heap_profiler.cpp              |   9 +-
 src/mongo/util/log.cpp                        |   7 +-
 src/mongo/util/lru_cache_test.cpp             |   3 +-
 .../util/net/hostname_canonicalization.cpp    |   6 +-
 src/mongo/util/net/openssl_init.cpp           |   3 +-
 src/mongo/util/net/sock.cpp                   |  35 ++-
 src/mongo/util/net/sockaddr.cpp               |   6 +-
 src/mongo/util/net/socket_utils.cpp           |   5 +-
 src/mongo/util/net/ssl_manager.cpp            |  13 +-
 src/mongo/util/net/ssl_manager_apple.cpp      |   3 +-
 src/mongo/util/net/ssl_manager_openssl.cpp    |  10 +-
 src/mongo/util/net/ssl_manager_test.cpp       |  10 +-
 src/mongo/util/net/ssl_manager_windows.cpp    |   3 +-
 src/mongo/util/net/ssl_options_server.cpp     |   5 +-
 src/mongo/util/ntservice.cpp                  |  67 +++---
 .../util/options_parser/options_parser.cpp    |   5 +-
 src/mongo/util/perfctr_collect_test.cpp       |   1 +
 src/mongo/util/periodic_runner_impl.cpp       |   5 +-
 src/mongo/util/platform_init.cpp              |   4 +-
 src/mongo/util/processinfo.cpp                |  10 +-
 src/mongo/util/processinfo_freebsd.cpp        |  17 +-
 src/mongo/util/processinfo_linux.cpp          |  12 +-
 src/mongo/util/processinfo_openbsd.cpp        |  21 +-
 src/mongo/util/processinfo_osx.cpp            |  12 +-
 src/mongo/util/processinfo_solaris.cpp        |   9 +-
 src/mongo/util/procparser_test.cpp            |  13 +-
 src/mongo/util/signal_handlers.cpp            |  23 +-
 src/mongo/util/stacktrace_libunwind_test.cpp  |   3 +-
 src/mongo/util/version.cpp                    |  15 +-
 src/mongo/watchdog/watchdog.cpp               |  12 +-
 src/mongo/watchdog/watchdog_test.cpp          |   9 +-
 458 files changed, 3122 insertions(+), 3904 deletions(-)

diff --git a/logv1tologv2 b/logv1tologv2
index 2f67f6d85a..b1350be3bd 100755
--- a/logv1tologv2
+++ b/logv1tologv2
@@ -1,7 +1,7 @@
 #!/usr/bin/perl
 use warnings;
 sub convert {
-    my $ramlogs = { 'startupWarningsLog' => 'kStartupWarnings', 'rsLog' => 'kRSLog', 'warnings' => 'kWarnings'};
+    my $ramlogs = { 'startupWarningsLog' => 'kStartupWarnings', 'rsLog' => 'kRS', 'warnings' => 'kWarnings'};
     my $expression = shift(@_);
     my $severity = shift(@_);
     return "$expression;" if ($expression =~ /str::stream\(\)/);
diff --git a/run.sh b/run.sh
index 77a3f659e2..34fee2625f 100755
--- a/run.sh
+++ b/run.sh
@@ -1,8 +1,11 @@
 #!/bin/sh
 set -e
+# save any work that we may be working on on these files
 git add logv1tologv2 run.sh scons.sh logging_cpp_files.txt
+# freshen our working directory
 git checkout-index -f -a
-xargs < logging_cpp_files.txt ./logv1tologv2 
-./scons.sh 2> scons.out.txt
-perl -n -e 'm/\[with T = (.*?);/ and print "$1\n"' scons.out.txt  | sort -n | uniq -c | sort -n > report.txt
+# covert the files listed in logging_cpp_files
+xargs < logging_cpp_files.txt ./logv1tologv2
+( ./scons.sh 2> scons.out.txt ) || true
+perl -n -e 'm/\[with T = (.*?);/ and print "$1\n"' scons.out.txt  | sort | uniq -c | sort -n > report.txt
 cat report.txt
diff --git a/scons.sh b/scons.sh
index 9ff63873ab..a8ec6958e2 100755
--- a/scons.sh
+++ b/scons.sh
@@ -5,4 +5,4 @@
     --variables-files=etc/scons/mongodbtoolchain_v3_gcc.vars \
     CPPDEFINES=MONGO_CONFIG_LOGV2_DEFAULT \
     -k \
-    mongod
+    mongod mongo mongos
diff --git a/src/mongo/SConscript b/src/mongo/SConscript
index 361151df1b..d5fb1e289c 100644
--- a/src/mongo/SConscript
+++ b/src/mongo/SConscript
@@ -113,9 +113,9 @@ baseEnv.Library(
         'logv2/bson_formatter.cpp',
         'logv2/console.cpp',
         'logv2/json_formatter.cpp',
-        'logv2/log_detail.cpp',
         'logv2/log_component.cpp',
         'logv2/log_component_settings.cpp',
+        'logv2/log_detail.cpp',
         'logv2/log_domain.cpp',
         'logv2/log_domain_global.cpp',
         'logv2/log_domain_internal.cpp',
diff --git a/src/mongo/bson/bson_validate_test.cpp b/src/mongo/bson/bson_validate_test.cpp
index e7d8e14ad7..63878738d2 100644
--- a/src/mongo/bson/bson_validate_test.cpp
+++ b/src/mongo/bson/bson_validate_test.cpp
@@ -34,6 +34,7 @@
 #include "mongo/base/data_view.h"
 #include "mongo/bson/bson_validate.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
@@ -94,9 +95,7 @@ TEST(BSONValidate, RandomData) {
         delete[] x;
     }
 
-    log() << "RandomData: didn't crash valid/total: " << numValid << "/" << numToRun
-          << " (want few valid ones)"
-          << " jsonSize: " << jsonSize << endl;
+    LOGV2("RandomData: didn't crash valid/total: {}/{} (want few valid ones) jsonSize: {}", "numValid"_attr = numValid, "numToRun"_attr = numToRun, "jsonSize"_attr = jsonSize);
 }
 
 TEST(BSONValidate, MuckingData1) {
@@ -140,14 +139,12 @@ TEST(BSONValidate, MuckingData1) {
         }
     }
 
-    log() << "MuckingData1: didn't crash valid/total: " << numValid << "/" << numToRun
-          << " (want few valid ones) "
-          << " jsonSize: " << jsonSize << endl;
+    LOGV2("MuckingData1: didn't crash valid/total: {}/{} (want few valid ones)  jsonSize: {}", "numValid"_attr = numValid, "numToRun"_attr = numToRun, "jsonSize"_attr = jsonSize);
 }
 
 TEST(BSONValidate, Fuzz) {
     int64_t seed = time(nullptr);
-    log() << "BSONValidate Fuzz random seed: " << seed << endl;
+    LOGV2("BSONValidate Fuzz random seed: {}", "seed"_attr = seed);
     PseudoRandom randomSource(seed);
 
     BSONObj original =
diff --git a/src/mongo/bson/bsonelement.cpp b/src/mongo/bson/bsonelement.cpp
index b2746f1ddf..097dad1108 100644
--- a/src/mongo/bson/bsonelement.cpp
+++ b/src/mongo/bson/bsonelement.cpp
@@ -43,6 +43,7 @@
 #include "mongo/bson/generator_extended_relaxed_2_0_0.h"
 #include "mongo/bson/generator_legacy_strict.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/strnlen.h"
 #include "mongo/util/base64.h"
 #include "mongo/util/duration.h"
@@ -840,7 +841,7 @@ std::string BSONElement::_asCode() const {
             return std::string(codeWScopeCode(),
                                ConstDataView(valuestr()).read<LittleEndian<int>>() - 1);
         default:
-            log() << "can't convert type: " << (int)(type()) << " to code" << std::endl;
+            LOGV2("can't convert type: {} to code", "int_type"_attr = (int)(type()));
     }
     uassert(10062, "not code", 0);
     return "";
diff --git a/src/mongo/bson/bsonobjbuilder.cpp b/src/mongo/bson/bsonobjbuilder.cpp
index 369f307beb..f59ca16c9a 100644
--- a/src/mongo/bson/bsonobjbuilder.cpp
+++ b/src/mongo/bson/bsonobjbuilder.cpp
@@ -34,6 +34,7 @@
 #include <boost/lexical_cast.hpp>
 
 #include "mongo/bson/timestamp.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -107,7 +108,7 @@ BSONObjBuilder& BSONObjBuilder::appendMinForType(StringData fieldName, int t) {
             appendCodeWScope(fieldName, "", BSONObj());
             return *this;
     };
-    log() << "type not supported for appendMinElementForType: " << t;
+    LOGV2("type not supported for appendMinElementForType: {}", "t"_attr = t);
     uassert(10061, "type not supported for appendMinElementForType", false);
 }
 
@@ -176,7 +177,7 @@ BSONObjBuilder& BSONObjBuilder::appendMaxForType(StringData fieldName, int t) {
             appendMinForType(fieldName, MaxKey);
             return *this;
     }
-    log() << "type not supported for appendMaxElementForType: " << t;
+    LOGV2("type not supported for appendMaxElementForType: {}", "t"_attr = t);
     uassert(14853, "type not supported for appendMaxElementForType", false);
 }
 
diff --git a/src/mongo/bson/json.cpp b/src/mongo/bson/json.cpp
index b6fbdf9454..27212fa6ea 100644
--- a/src/mongo/bson/json.cpp
+++ b/src/mongo/bson/json.cpp
@@ -36,6 +36,7 @@
 
 #include "mongo/base/parse_number.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/decimal128.h"
 #include "mongo/platform/strtoll.h"
 #include "mongo/util/base64.h"
@@ -54,8 +55,7 @@ using namespace fmt::literals;
 
 #if 0
 #define MONGO_JSON_DEBUG(message)                                                          \
-    log() << "JSON DEBUG @ " << __FILE__ << ":" << __LINE__ << " " << __FUNCTION__ << ": " \
-          << message << endl;
+    LOGV2("JSON DEBUG @ {}:{} {}{}{}", "__FILE__"_attr = __FILE__, "__LINE__"_attr = __LINE__, "__FUNCTION__"_attr = __FUNCTION__, ""_attr = ": " \, "message"_attr = message);
 #else
 #define MONGO_JSON_DEBUG(message)
 #endif
diff --git a/src/mongo/client/authenticate.cpp b/src/mongo/client/authenticate.cpp
index e76f72035a..7a5deba93e 100644
--- a/src/mongo/client/authenticate.cpp
+++ b/src/mongo/client/authenticate.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/auth/authorization_manager.h"
 #include "mongo/db/auth/sasl_command_constants.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/op_msg_rpc_impls.h"
@@ -150,8 +151,8 @@ Future<void> authenticateClient(const BSONObj& params,
     auto errorHandler = [](Status status) {
         if (serverGlobalParams.transitionToAuth && !ErrorCodes::isNetworkError(status)) {
             // If auth failed in transitionToAuth, just pretend it succeeded.
-            log() << "Failed to authenticate in transitionToAuth, falling back to no "
-                     "authentication.";
+            LOGV2("Failed to authenticate in transitionToAuth, falling back to no "
+                     "authentication.");
 
             return Status::OK();
         }
diff --git a/src/mongo/client/connection_string_connect.cpp b/src/mongo/client/connection_string_connect.cpp
index c60770e2f3..c4a15d5103 100644
--- a/src/mongo/client/connection_string_connect.cpp
+++ b/src/mongo/client/connection_string_connect.cpp
@@ -38,6 +38,7 @@
 
 #include "mongo/client/dbclient_rs.h"
 #include "mongo/client/mongo_uri.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -61,11 +62,11 @@ std::unique_ptr<DBClientBase> ConnectionString::connect(StringData applicationNa
                 auto c = std::make_unique<DBClientConnection>(true, 0, newURI);
 
                 c->setSoTimeout(socketTimeout);
-                LOG(1) << "creating new connection to:" << server;
+                LOGV2_DEBUG(1, "creating new connection to:{}", "server"_attr = server);
                 if (!c->connect(server, applicationName, errmsg)) {
                     continue;
                 }
-                LOG(1) << "connected connection!";
+                LOGV2_DEBUG(1, "connected connection!");
                 return std::move(c);
             }
             return nullptr;
@@ -96,8 +97,7 @@ std::unique_ptr<DBClientBase> ConnectionString::connect(StringData applicationNa
             // Double-checked lock, since this will never be active during normal operation
             auto replacementConn = _connectHook->connect(*this, errmsg, socketTimeout);
 
-            log() << "replacing connection to " << this->toString() << " with "
-                  << (replacementConn ? replacementConn->getServerAddress() : "(empty)");
+            LOGV2("replacing connection to {} with {}", "this_toString"_attr = this->toString(), "replacementConn_replacementConn_getServerAddress_empty"_attr = (replacementConn ? replacementConn->getServerAddress() : "(empty)"));
 
             return replacementConn;
         }
diff --git a/src/mongo/client/connpool.cpp b/src/mongo/client/connpool.cpp
index 7e1aa48e9c..443326f660 100644
--- a/src/mongo/client/connpool.cpp
+++ b/src/mongo/client/connpool.cpp
@@ -44,6 +44,7 @@
 #include "mongo/client/global_conn_pool.h"
 #include "mongo/client/replica_set_monitor.h"
 #include "mongo/executor/connection_pool_stats.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/chrono.h"
 #include "mongo/util/exit.h"
 #include "mongo/util/log.h"
@@ -352,9 +353,7 @@ DBClientBase* DBConnectionPool::_finishCreate(const string& ident,
         throw;
     }
 
-    log() << "Successfully connected to " << ident << " (" << openConnections(ident, socketTimeout)
-          << " connections now open to " << ident << " with a " << socketTimeout
-          << " second timeout)";
+    LOGV2("Successfully connected to {} ({} connections now open to {} with a {} second timeout)", "ident"_attr = ident, "openConnections_ident_socketTimeout"_attr = openConnections(ident, socketTimeout), "ident"_attr = ident, "socketTimeout"_attr = socketTimeout);
 
     return conn;
 }
@@ -462,7 +461,7 @@ void DBConnectionPool::flush() {
 
 void DBConnectionPool::clear() {
     stdx::lock_guard<Latch> L(_mutex);
-    LOG(2) << "Removing connections on all pools owned by " << _name << endl;
+    LOGV2_DEBUG(2, "Removing connections on all pools owned by {}", "_name"_attr = _name);
     for (PoolMap::iterator iter = _pools.begin(); iter != _pools.end(); ++iter) {
         iter->second.clear();
     }
@@ -470,7 +469,7 @@ void DBConnectionPool::clear() {
 
 void DBConnectionPool::removeHost(const string& host) {
     stdx::lock_guard<Latch> L(_mutex);
-    LOG(2) << "Removing connections from all pools for host: " << host << endl;
+    LOGV2_DEBUG(2, "Removing connections from all pools for host: {}", "host"_attr = host);
     for (PoolMap::iterator i = _pools.begin(); i != _pools.end(); ++i) {
         const string& poolHost = i->first.ident;
         if (!serverNameCompare()(host, poolHost) && !serverNameCompare()(poolHost, host)) {
diff --git a/src/mongo/client/dbclient_base.cpp b/src/mongo/client/dbclient_base.cpp
index 3654b2f89c..4cf3d5dc9d 100644
--- a/src/mongo/client/dbclient_base.cpp
+++ b/src/mongo/client/dbclient_base.cpp
@@ -56,6 +56,7 @@
 #include "mongo/db/wire_version.h"
 #include "mongo/executor/remote_command_request.h"
 #include "mongo/executor/remote_command_response.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/factory.h"
 #include "mongo/rpc/get_status_from_command_result.h"
@@ -469,7 +470,7 @@ Status DBClientBase::authenticateInternalUser() {
     ScopedMetadataWriterRemover remover{this};
     if (!auth::isInternalAuthSet()) {
         if (!serverGlobalParams.quiet.load()) {
-            log() << "ERROR: No authentication parameters set for internal user";
+            LOGV2("ERROR: No authentication parameters set for internal user");
         }
         return {ErrorCodes::AuthenticationFailed,
                 "No authentication parameters set for internal user"};
@@ -491,8 +492,7 @@ Status DBClientBase::authenticateInternalUser() {
     }
 
     if (serverGlobalParams.quiet.load()) {
-        log() << "can't authenticate to " << toString()
-              << " as internal user, error: " << status.reason();
+        LOGV2("can't authenticate to {} as internal user, error: {}", "toString"_attr = toString(), "status_reason"_attr = status.reason());
     }
 
     return status;
@@ -892,7 +892,7 @@ void DBClientBase::dropIndex(const string& ns, const string& indexName) {
     if (!runCommand(nsToDatabase(ns),
                     BSON("dropIndexes" << nsToCollectionSubstring(ns) << "index" << indexName),
                     info)) {
-        LOG(_logLevel) << "dropIndex failed: " << info << endl;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "dropIndex failed: {}", "info"_attr = info);
         uassert(10007, "dropIndex failed", 0);
     }
 }
diff --git a/src/mongo/client/dbclient_connection.cpp b/src/mongo/client/dbclient_connection.cpp
index cc22ee388d..3dbfdd1432 100644
--- a/src/mongo/client/dbclient_connection.cpp
+++ b/src/mongo/client/dbclient_connection.cpp
@@ -62,6 +62,7 @@
 #include "mongo/db/wire_version.h"
 #include "mongo/executor/remote_command_request.h"
 #include "mongo/executor/remote_command_response.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/client_metadata.h"
@@ -347,7 +348,7 @@ Status DBClientConnection::connectSocketOnly(const HostAndPort& serverAddress) {
     _lastConnectivityCheck = Date_t::now();
     _session->setTimeout(_socketTimeout);
     _session->setTags(_tagMask);
-    LOG(1) << "connected to server " << toString();
+    LOGV2_DEBUG(1, "connected to server {}", "toString"_attr = toString());
     return Status::OK();
 }
 
@@ -469,12 +470,12 @@ void DBClientConnection::_checkConnection() {
     // Don't hammer reconnects, backoff if needed
     sleepFor(_autoReconnectBackoff.nextSleep());
 
-    LOG(_logLevel) << "trying reconnect to " << toString() << endl;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "trying reconnect to {}", "toString"_attr = toString());
     string errmsg;
     auto connectStatus = connect(_serverAddress, _applicationName);
     if (!connectStatus.isOK()) {
         _markFailed(kSetFlag);
-        LOG(_logLevel) << "reconnect " << toString() << " failed " << errmsg << endl;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "reconnect {} failed {}", "toString"_attr = toString(), "errmsg"_attr = errmsg);
         if (connectStatus == ErrorCodes::IncompatibleCatalogManager) {
             uassertStatusOK(connectStatus);  // Will always throw
         } else {
@@ -482,7 +483,7 @@ void DBClientConnection::_checkConnection() {
         }
     }
 
-    LOG(_logLevel) << "reconnect " << toString() << " ok" << endl;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "reconnect {} ok", "toString"_attr = toString());
     if (_internalAuthOnReconnect) {
         uassertStatusOK(authenticateInternalUser());
     } else {
@@ -490,10 +491,7 @@ void DBClientConnection::_checkConnection() {
             try {
                 DBClientConnection::_auth(kv.second);
             } catch (ExceptionFor<ErrorCodes::AuthenticationFailed>& ex) {
-                LOG(_logLevel) << "reconnect: auth failed "
-                               << kv.second[auth::getSaslCommandUserDBFieldName()]
-                               << kv.second[auth::getSaslCommandUserFieldName()] << ' ' << ex.what()
-                               << std::endl;
+                LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "reconnect: auth failed {}{} {}", "kv_second_auth_getSaslCommandUserDBFieldName"_attr = kv.second[auth::getSaslCommandUserDBFieldName()], "kv_second_auth_getSaslCommandUserFieldName"_attr = kv.second[auth::getSaslCommandUserFieldName()], "ex_what"_attr = ex.what());
             }
         }
     }
@@ -646,8 +644,7 @@ bool DBClientConnection::call(Message& toSend,
 
     auto sinkStatus = _session->sinkMessage(swm.getValue());
     if (!sinkStatus.isOK()) {
-        log() << "DBClientConnection failed to send message to " << getServerAddress() << " - "
-              << redact(sinkStatus);
+        LOGV2("DBClientConnection failed to send message to {} - {}", "getServerAddress"_attr = getServerAddress(), "redact_sinkStatus"_attr = redact(sinkStatus));
         return maybeThrow(sinkStatus);
     }
 
@@ -655,8 +652,7 @@ bool DBClientConnection::call(Message& toSend,
     if (swm.isOK()) {
         response = std::move(swm.getValue());
     } else {
-        log() << "DBClientConnection failed to receive message from " << getServerAddress() << " - "
-              << redact(swm.getStatus());
+        LOGV2("DBClientConnection failed to receive message from {} - {}", "getServerAddress"_attr = getServerAddress(), "redact_swm_getStatus"_attr = redact(swm.getStatus()));
         return maybeThrow(swm.getStatus());
     }
 
diff --git a/src/mongo/client/dbclient_cursor.cpp b/src/mongo/client/dbclient_cursor.cpp
index df26ca3e9c..5d978b1b1e 100644
--- a/src/mongo/client/dbclient_cursor.cpp
+++ b/src/mongo/client/dbclient_cursor.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/query/cursor_response.h"
 #include "mongo/db/query/getmore_request.h"
 #include "mongo/db/query/query_request.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/factory.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata.h"
@@ -187,13 +188,13 @@ bool DBClientCursor::init() {
         _client->call(toSend, reply, true, &_originalHost);
     } catch (const DBException&) {
         // log msg temp?
-        log() << "DBClientCursor::init call() failed" << endl;
+        LOGV2("DBClientCursor::init call() failed");
         // We always want to throw on network exceptions.
         throw;
     }
     if (reply.empty()) {
         // log msg temp?
-        log() << "DBClientCursor::init message from call() was empty" << endl;
+        LOGV2("DBClientCursor::init message from call() was empty");
         return false;
     }
     dataReceived(reply);
@@ -219,9 +220,9 @@ bool DBClientCursor::initLazyFinish(bool& retry) {
     // If we get a bad response, return false
     if (!recvStatus.isOK() || reply.empty()) {
         if (!recvStatus.isOK())
-            log() << "DBClientCursor::init lazy say() failed: " << redact(recvStatus) << endl;
+            LOGV2("DBClientCursor::init lazy say() failed: {}", "redact_recvStatus"_attr = redact(recvStatus));
         if (reply.empty())
-            log() << "DBClientCursor::init message from say() was empty" << endl;
+            LOGV2("DBClientCursor::init message from say() was empty");
 
         _client->checkResponse({}, true, &retry, &_lazyHost);
 
diff --git a/src/mongo/client/dbclient_cursor_test.cpp b/src/mongo/client/dbclient_cursor_test.cpp
index d9f42d1ae7..3f112f2923 100644
--- a/src/mongo/client/dbclient_cursor_test.cpp
+++ b/src/mongo/client/dbclient_cursor_test.cpp
@@ -30,6 +30,7 @@
 #include "mongo/client/dbclient_connection.h"
 #include "mongo/client/dbclient_cursor.h"
 #include "mongo/db/query/cursor_response.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/assert_util.h"
 
@@ -78,7 +79,7 @@ public:
 
     // No-op.
     void killCursor(const NamespaceString& ns, long long cursorID) override {
-        unittest::log() << "Killing cursor in DBClientConnectionForTest";
+        unittest::LOGV2("Killing cursor in DBClientConnectionForTest");
     }
 
     void setSupportedProtocols(rpc::ProtocolSet protocols) {
diff --git a/src/mongo/client/dbclient_rs.cpp b/src/mongo/client/dbclient_rs.cpp
index e241efc05e..6bcd09cb0e 100644
--- a/src/mongo/client/dbclient_rs.cpp
+++ b/src/mongo/client/dbclient_rs.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/auth/sasl_command_constants.h"
 #include "mongo/db/dbmessage.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -416,7 +417,7 @@ Status DBClientReplicaSet::_runAuthLoop(Authenticate authCb) {
     const auto readPref =
         std::make_shared<ReadPreferenceSetting>(ReadPreference::PrimaryPreferred, TagSet());
 
-    LOG(3) << "dbclient_rs authentication of " << _getMonitor()->getName();
+    LOGV2_DEBUG(3, "dbclient_rs authentication of {}", "_getMonitor_getName"_attr = _getMonitor()->getName());
 
     // NOTE that we retry MAX_RETRY + 1 times, since we're always primary preferred we don't
     // fallback to the primary.
@@ -533,14 +534,8 @@ unique_ptr<DBClientCursor> DBClientReplicaSet::query(const NamespaceStringOrUUID
     invariant(nsOrUuid.nss());
     const string ns = nsOrUuid.nss()->ns();
     if (_isSecondaryQuery(ns, query.obj, *readPref)) {
-        LOG(3) << "dbclient_rs query using secondary or tagged node selection in "
-               << _getMonitor()->getName() << ", read pref is " << readPref->toString()
-               << " (primary : "
-               << (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]")
-               << ", lastTagged : "
-               << (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
-                                                     : "[not cached]")
-               << ")" << endl;
+        LOGV2_DEBUG(3, "dbclient_rs query using secondary or tagged node selection in {}, read pref is {} (primary : {}, lastTagged : {})", "_getMonitor_getName"_attr = _getMonitor()->getName(), "readPref_toString"_attr = readPref->toString(), "_master_get_nullptr__master_getServerAddress_not_cached"_attr = (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]"), "_lastSlaveOkConn_get_nullptr__lastSlaveOkConn_getServerAddress_not_cached"_attr = (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
+                                                     : "[not cached]"));
 
         string lastNodeErrMsg;
 
@@ -573,7 +568,7 @@ unique_ptr<DBClientCursor> DBClientReplicaSet::query(const NamespaceStringOrUUID
         uasserted(16370, assertMsg.str());
     }
 
-    LOG(3) << "dbclient_rs query to primary node in " << _getMonitor()->getName() << endl;
+    LOGV2_DEBUG(3, "dbclient_rs query to primary node in {}", "_getMonitor_getName"_attr = _getMonitor()->getName());
 
     return checkMaster()->query(
         nsOrUuid, query, nToReturn, nToSkip, fieldsToReturn, queryOptions, batchSize);
@@ -585,14 +580,8 @@ BSONObj DBClientReplicaSet::findOne(const string& ns,
                                     int queryOptions) {
     shared_ptr<ReadPreferenceSetting> readPref(_extractReadPref(query.obj, queryOptions));
     if (_isSecondaryQuery(ns, query.obj, *readPref)) {
-        LOG(3) << "dbclient_rs findOne using secondary or tagged node selection in "
-               << _getMonitor()->getName() << ", read pref is " << readPref->toString()
-               << " (primary : "
-               << (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]")
-               << ", lastTagged : "
-               << (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
-                                                     : "[not cached]")
-               << ")" << endl;
+        LOGV2_DEBUG(3, "dbclient_rs findOne using secondary or tagged node selection in {}, read pref is {} (primary : {}, lastTagged : {})", "_getMonitor_getName"_attr = _getMonitor()->getName(), "readPref_toString"_attr = readPref->toString(), "_master_get_nullptr__master_getServerAddress_not_cached"_attr = (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]"), "_lastSlaveOkConn_get_nullptr__lastSlaveOkConn_getServerAddress_not_cached"_attr = (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
+                                                     : "[not cached]"));
 
         string lastNodeErrMsg;
 
@@ -622,7 +611,7 @@ BSONObj DBClientReplicaSet::findOne(const string& ns,
         uasserted(16379, assertMsg.str());
     }
 
-    LOG(3) << "dbclient_rs findOne to primary node in " << _getMonitor()->getName() << endl;
+    LOGV2_DEBUG(3, "dbclient_rs findOne to primary node in {}", "_getMonitor_getName"_attr = _getMonitor()->getName());
 
     return checkMaster()->findOne(ns, query, fieldsToReturn, queryOptions);
 }
@@ -682,7 +671,7 @@ void DBClientReplicaSet::isntSecondary() {
 DBClientConnection* DBClientReplicaSet::selectNodeUsingTags(
     shared_ptr<ReadPreferenceSetting> readPref) {
     if (checkLastHost(readPref.get())) {
-        LOG(3) << "dbclient_rs selecting compatible last used node " << _lastSlaveOkHost;
+        LOGV2_DEBUG(3, "dbclient_rs selecting compatible last used node {}", "_lastSlaveOkHost"_attr = _lastSlaveOkHost);
 
         return _lastSlaveOkConn.get();
     }
@@ -691,8 +680,7 @@ DBClientConnection* DBClientReplicaSet::selectNodeUsingTags(
 
     auto selectedNodeStatus = monitor->getHostOrRefresh(*readPref).getNoThrow();
     if (!selectedNodeStatus.isOK()) {
-        LOG(3) << "dbclient_rs no compatible node found"
-               << causedBy(redact(selectedNodeStatus.getStatus()));
+        LOGV2_DEBUG(3, "dbclient_rs no compatible node found{}", "causedBy_redact_selectedNodeStatus_getStatus"_attr = causedBy(redact(selectedNodeStatus.getStatus())));
         return nullptr;
     }
 
@@ -712,7 +700,7 @@ DBClientConnection* DBClientReplicaSet::selectNodeUsingTags(
     if (monitor->isPrimary(selectedNode)) {
         checkMaster();
 
-        LOG(3) << "dbclient_rs selecting primary node " << selectedNode << endl;
+        LOGV2_DEBUG(3, "dbclient_rs selecting primary node {}", "selectedNode"_attr = selectedNode);
 
         _lastSlaveOkConn = _master;
 
@@ -746,7 +734,7 @@ DBClientConnection* DBClientReplicaSet::selectNodeUsingTags(
         // Mongos pooled connections are authenticated through ShardingConnectionHook::onCreate()
     }
 
-    LOG(3) << "dbclient_rs selecting node " << _lastSlaveOkHost << endl;
+    LOGV2_DEBUG(3, "dbclient_rs selecting node {}", "_lastSlaveOkHost"_attr = _lastSlaveOkHost);
 
     return _lastSlaveOkConn.get();
 }
@@ -764,14 +752,8 @@ void DBClientReplicaSet::say(Message& toSend, bool isRetry, string* actualServer
 
         shared_ptr<ReadPreferenceSetting> readPref(_extractReadPref(qm.query, qm.queryOptions));
         if (_isSecondaryQuery(qm.ns, qm.query, *readPref)) {
-            LOG(3) << "dbclient_rs say using secondary or tagged node selection in "
-                   << _getMonitor()->getName() << ", read pref is " << readPref->toString()
-                   << " (primary : "
-                   << (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]")
-                   << ", lastTagged : "
-                   << (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
-                                                         : "[not cached]")
-                   << ")" << endl;
+            LOGV2_DEBUG(3, "dbclient_rs say using secondary or tagged node selection in {}, read pref is {} (primary : {}, lastTagged : {})", "_getMonitor_getName"_attr = _getMonitor()->getName(), "readPref_toString"_attr = readPref->toString(), "_master_get_nullptr__master_getServerAddress_not_cached"_attr = (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]"), "_lastSlaveOkConn_get_nullptr__lastSlaveOkConn_getServerAddress_not_cached"_attr = (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
+                                                         : "[not cached]"));
 
             string lastNodeErrMsg;
 
@@ -816,7 +798,7 @@ void DBClientReplicaSet::say(Message& toSend, bool isRetry, string* actualServer
         }
     }
 
-    LOG(3) << "dbclient_rs say to primary node in " << _getMonitor()->getName() << endl;
+    LOGV2_DEBUG(3, "dbclient_rs say to primary node in {}", "_getMonitor_getName"_attr = _getMonitor()->getName());
 
     DBClientConnection* master = checkMaster();
     if (actualServer)
@@ -838,8 +820,7 @@ Status DBClientReplicaSet::recv(Message& m, int lastRequestId) {
     try {
         return _lazyState._lastClient->recv(m, lastRequestId);
     } catch (DBException& e) {
-        log() << "could not receive data from " << _lazyState._lastClient->toString()
-              << causedBy(redact(e));
+        LOGV2("could not receive data from {}{}", "_lazyState__lastClient_toString"_attr = _lazyState._lastClient->toString(), "causedBy_redact_e"_attr = causedBy(redact(e)));
         return e.toStatus();
     }
 }
@@ -898,8 +879,7 @@ void DBClientReplicaSet::checkResponse(const std::vector<BSONObj>& batch,
                 _lazyState._retries++;
                 *retry = true;
             } else {
-                log() << "too many retries (" << _lazyState._retries
-                      << "), could not get data from replica set" << endl;
+                LOGV2("too many retries ({}), could not get data from replica set", "_lazyState__retries"_attr = _lazyState._retries);
             }
         }
     } else if (_lazyState._lastOp == dbQuery) {
@@ -995,14 +975,8 @@ bool DBClientReplicaSet::call(Message& toSend,
 
         shared_ptr<ReadPreferenceSetting> readPref(_extractReadPref(qm.query, qm.queryOptions));
         if (_isSecondaryQuery(ns, qm.query, *readPref)) {
-            LOG(3) << "dbclient_rs call using secondary or tagged node selection in "
-                   << _getMonitor()->getName() << ", read pref is " << readPref->toString()
-                   << " (primary : "
-                   << (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]")
-                   << ", lastTagged : "
-                   << (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
-                                                         : "[not cached]")
-                   << ")" << endl;
+            LOGV2_DEBUG(3, "dbclient_rs call using secondary or tagged node selection in {}, read pref is {} (primary : {}, lastTagged : {})", "_getMonitor_getName"_attr = _getMonitor()->getName(), "readPref_toString"_attr = readPref->toString(), "_master_get_nullptr__master_getServerAddress_not_cached"_attr = (_master.get() != nullptr ? _master->getServerAddress() : "[not cached]"), "_lastSlaveOkConn_get_nullptr__lastSlaveOkConn_getServerAddress_not_cached"_attr = (_lastSlaveOkConn.get() != nullptr ? _lastSlaveOkConn->getServerAddress()
+                                                         : "[not cached]"));
 
             for (size_t retry = 0; retry < MAX_RETRY; retry++) {
                 try {
@@ -1032,7 +1006,7 @@ bool DBClientReplicaSet::call(Message& toSend,
         }
     }
 
-    LOG(3) << "dbclient_rs call to primary node in " << _getMonitor()->getName() << endl;
+    LOGV2_DEBUG(3, "dbclient_rs call to primary node in {}", "_getMonitor_getName"_attr = _getMonitor()->getName());
 
     DBClientConnection* m = checkMaster();
     if (actualServer)
diff --git a/src/mongo/client/mongo_uri_test.cpp b/src/mongo/client/mongo_uri_test.cpp
index e80abbf5e6..b2144e46e1 100644
--- a/src/mongo/client/mongo_uri_test.cpp
+++ b/src/mongo/client/mongo_uri_test.cpp
@@ -37,6 +37,7 @@
 #include "mongo/bson/json.h"
 #include "mongo/client/mongo_uri.h"
 #include "mongo/db/service_context_test_fixture.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 
 #include <boost/filesystem/operations.hpp>
@@ -84,11 +85,7 @@ void compareOptions(size_t lineNumber,
 
     for (std::size_t i = 0; i < std::min(options.size(), expectedOptions.size()); ++i) {
         if (options[i] != expectedOptions[i]) {
-            unittest::log() << "Option: \"tolower(" << options[i].first.original()
-                            << ")=" << options[i].second << "\" doesn't equal: \"tolower("
-                            << expectedOptions[i].first.original()
-                            << ")=" << expectedOptions[i].second << "\""
-                            << " data on line: " << lineNumber << std::endl;
+            unittest::LOGV2("Option: \"tolower({})={}\" doesn't equal: \"tolower({})={}\" data on line: {}", "options_i_first_original"_attr = options[i].first.original(), "options_i_second"_attr = options[i].second, "expectedOptions_i_first_original"_attr = expectedOptions[i].first.original(), "expectedOptions_i_second"_attr = expectedOptions[i].second, "lineNumber"_attr = lineNumber);
             std::cerr << "Failing URI: \"" << uri << "\""
                       << " data on line: " << lineNumber << std::endl;
             ASSERT(false);
@@ -594,7 +591,7 @@ std::string returnStringFromElementOrNull(BSONElement element) {
 
 // Helper method to take a valid test case, parse() it, and assure the output is correct
 void testValidURIFormat(URITestCase testCase) {
-    unittest::log() << "Testing URI: " << testCase.URI << '\n';
+    unittest::LOGV2("Testing URI: {}{}", "testCase_URI"_attr = testCase.URI, "n"_attr = '\n');
     std::string errMsg;
     const auto cs_status = MongoURI::parse(testCase.URI);
     ASSERT_OK(cs_status);
@@ -622,7 +619,7 @@ TEST(MongoURI, InvalidURIs) {
 
     for (size_t i = 0; i != numCases; ++i) {
         const InvalidURITestCase testCase = invalidCases[i];
-        unittest::log() << "Testing URI: " << testCase.URI << '\n';
+        unittest::LOGV2("Testing URI: {}{}", "testCase_URI"_attr = testCase.URI, "n"_attr = '\n');
         auto cs_status = MongoURI::parse(testCase.URI);
         ASSERT_NOT_OK(cs_status);
         if (testCase.code) {
@@ -704,7 +701,7 @@ TEST(MongoURI, specTests) {
             if (!valid) {
                 // This uri string is invalid --> parse the uri and ensure it fails
                 const InvalidURITestCase testCase = InvalidURITestCase{uri};
-                unittest::log() << "Testing URI: " << testCase.URI << '\n';
+                unittest::LOGV2("Testing URI: {}{}", "testCase_URI"_attr = testCase.URI, "n"_attr = '\n');
                 auto cs_status = MongoURI::parse(testCase.URI);
                 ASSERT_NOT_OK(cs_status);
             } else {
diff --git a/src/mongo/client/remote_command_retry_scheduler_test.cpp b/src/mongo/client/remote_command_retry_scheduler_test.cpp
index 6393207206..d7efe35f52 100644
--- a/src/mongo/client/remote_command_retry_scheduler_test.cpp
+++ b/src/mongo/client/remote_command_retry_scheduler_test.cpp
@@ -39,6 +39,7 @@
 #include "mongo/executor/remote_command_response.h"
 #include "mongo/executor/task_executor.h"
 #include "mongo/executor/thread_pool_task_executor_test_fixture.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/task_executor_proxy.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/assert_util.h"
@@ -535,7 +536,7 @@ TEST_F(RemoteCommandRetrySchedulerTest,
         request,
         [&result,
          sharedCallbackData](const executor::TaskExecutor::RemoteCommandCallbackArgs& rcba) {
-            unittest::log() << "setting result to " << rcba.response.status;
+            unittest::LOGV2("setting result to {}", "rcba_response_status"_attr = rcba.response.status);
             result = rcba.response.status;
         },
         std::move(policy));
diff --git a/src/mongo/client/remote_command_targeter_rs.cpp b/src/mongo/client/remote_command_targeter_rs.cpp
index 97eae89da0..ee1cb48ce8 100644
--- a/src/mongo/client/remote_command_targeter_rs.cpp
+++ b/src/mongo/client/remote_command_targeter_rs.cpp
@@ -38,6 +38,7 @@
 #include "mongo/client/read_preference.h"
 #include "mongo/client/replica_set_monitor.h"
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/hostandport.h"
@@ -52,9 +53,8 @@ RemoteCommandTargeterRS::RemoteCommandTargeterRS(const std::string& rsName,
     std::set<HostAndPort> seedServers(seedHosts.begin(), seedHosts.end());
     _rsMonitor = ReplicaSetMonitor::createIfNeeded(rsName, seedServers);
 
-    LOG(1) << "Started targeter for "
-           << ConnectionString::forReplicaSet(
-                  rsName, std::vector<HostAndPort>(seedServers.begin(), seedServers.end()));
+    LOGV2_DEBUG(1, "Started targeter for {}", "ConnectionString_forReplicaSet_rsName_std_vector_HostAndPort_seedServers_begin_seedServers_end"_attr = ConnectionString::forReplicaSet(
+                  rsName, std::vector<HostAndPort>(seedServers.begin(), seedServers.end())));
 }
 
 ConnectionString RemoteCommandTargeterRS::connectionString() {
diff --git a/src/mongo/client/replica_set_change_notifier.cpp b/src/mongo/client/replica_set_change_notifier.cpp
index 5edd6d9ec4..ccc6317325 100644
--- a/src/mongo/client/replica_set_change_notifier.cpp
+++ b/src/mongo/client/replica_set_change_notifier.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/client/replica_set_change_notifier.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 #include "mongo/util/stacktrace.h"
@@ -54,7 +55,7 @@ void ReplicaSetChangeNotifier::_removeListener(Listener* listener) {
 }
 
 void ReplicaSetChangeNotifier::onFoundSet(const std::string& name) {
-    LOG(2) << "Signaling found set " << name;
+    LOGV2_DEBUG(2, "Signaling found set {}", "name"_attr = name);
 
     stdx::unique_lock<Latch> lk(_mutex);
 
@@ -69,7 +70,7 @@ void ReplicaSetChangeNotifier::onFoundSet(const std::string& name) {
 }
 
 void ReplicaSetChangeNotifier::onPossibleSet(ConnectionString connectionString) {
-    LOG(2) << "Signaling possible set " << connectionString;
+    LOGV2_DEBUG(2, "Signaling possible set {}", "connectionString"_attr = connectionString);
 
     const auto& name = connectionString.getSetName();
 
@@ -96,7 +97,7 @@ void ReplicaSetChangeNotifier::onPossibleSet(ConnectionString connectionString)
 void ReplicaSetChangeNotifier::onConfirmedSet(ConnectionString connectionString,
                                               HostAndPort primary,
                                               std::set<HostAndPort> passives) {
-    LOG(2) << "Signaling confirmed set " << connectionString << " with primary " << primary;
+    LOGV2_DEBUG(2, "Signaling confirmed set {} with primary {}", "connectionString"_attr = connectionString, "primary"_attr = primary);
 
     const auto& name = connectionString.getSetName();
     stdx::unique_lock<Latch> lk(_mutex);
@@ -121,7 +122,7 @@ void ReplicaSetChangeNotifier::onConfirmedSet(ConnectionString connectionString,
 }
 
 void ReplicaSetChangeNotifier::onDroppedSet(const std::string& name) {
-    LOG(2) << "Signaling dropped set " << name;
+    LOGV2_DEBUG(2, "Signaling dropped set {}", "name"_attr = name);
 
     stdx::unique_lock<Latch> lk(_mutex);
 
diff --git a/src/mongo/client/replica_set_monitor.cpp b/src/mongo/client/replica_set_monitor.cpp
index 9d24576d31..fcc2321d25 100644
--- a/src/mongo/client/replica_set_monitor.cpp
+++ b/src/mongo/client/replica_set_monitor.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/repl/bson_extract_optime.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/stdx/condition_variable.h"
@@ -245,7 +246,7 @@ void ReplicaSetMonitor::SetState::rescheduleRefresh(SchedulingStrategy strategy)
     }
 
     if (isDropped) {  // already removed so no need to refresh
-        LOG(1) << "Stopping refresh for replica set " << name << " because it's removed";
+        LOGV2_DEBUG(1, "Stopping refresh for replica set {} because it's removed", "name"_attr = name);
         return;
     }
 
@@ -270,7 +271,7 @@ void ReplicaSetMonitor::SetState::rescheduleRefresh(SchedulingStrategy strategy)
     }
 
     nextScanTime = possibleNextScanTime;
-    LOG(1) << "Next replica set scan scheduled for " << nextScanTime;
+    LOGV2_DEBUG(1, "Next replica set scan scheduled for {}", "nextScanTime"_attr = nextScanTime);
     auto swHandle = scheduleWorkAt(nextScanTime, [this](const CallbackArgs& cbArgs) {
         if (cbArgs.myHandle != refresherHandle)
             return;  // We've been replaced!
@@ -286,7 +287,7 @@ void ReplicaSetMonitor::SetState::rescheduleRefresh(SchedulingStrategy strategy)
     });
 
     if (ErrorCodes::isShutdownError(swHandle.getStatus().code())) {
-        LOG(1) << "Cant schedule refresh for " << name << ". Executor shutdown in progress";
+        LOGV2_DEBUG(1, "Cant schedule refresh for {}. Executor shutdown in progress", "name"_attr = name);
         return;
     }
 
@@ -681,10 +682,7 @@ Refresher::NextStep Refresher::getNextStep() {
         } else {
             auto nScans = _set->consecutiveFailedScans++;
             if (nScans <= 10 || nScans % 10 == 0) {
-                log() << "Cannot reach any nodes for set " << _set->name
-                      << ". Please check network connectivity and the status of the set. "
-                      << "This has happened for " << _set->consecutiveFailedScans
-                      << " checks in a row.";
+                LOGV2("Cannot reach any nodes for set {}. Please check network connectivity and the status of the set. This has happened for {} checks in a row.", "_set_name"_attr = _set->name, "_set_consecutiveFailedScans"_attr = _set->consecutiveFailedScans);
             }
         }
 
@@ -692,8 +690,7 @@ Refresher::NextStep Refresher::getNextStep() {
         _set->currentScan.reset();
         _set->notify();
 
-        LOG(1) << "Refreshing replica set " << _set->name << " took " << _scan->timer.millis()
-               << "ms";
+        LOGV2_DEBUG(1, "Refreshing replica set {} took {}ms", "_set_name"_attr = _set->name, "_scan_timer_millis"_attr = _scan->timer.millis());
 
         return NextStep(NextStep::DONE);
     }
@@ -860,8 +857,7 @@ Status Refresher::receivedIsMasterFromMaster(const HostAndPort& from, const IsMa
     // REMINDER: both _set->nodes and reply.members are sorted.
     if (_set->nodes.size() != reply.members.size() ||
         !std::equal(_set->nodes.begin(), _set->nodes.end(), reply.members.begin(), hostsEqual)) {
-        LOG(2) << "Adjusting nodes in our view of replica set " << _set->name
-               << " based on master reply: " << redact(reply.raw);
+        LOGV2_DEBUG(2, "Adjusting nodes in our view of replica set {} based on master reply: {}", "_set_name"_attr = _set->name, "redact_reply_raw"_attr = redact(reply.raw));
 
         // remove non-members from _set->nodes
         _set->nodes.erase(
@@ -899,7 +895,7 @@ Status Refresher::receivedIsMasterFromMaster(const HostAndPort& from, const IsMa
 
         // LogLevel can be pretty low, since replica set reconfiguration should be pretty rare
         // and we want to record our changes
-        log() << "Confirmed replica set for " << _set->name << " is " << _set->seedConnStr;
+        LOGV2("Confirmed replica set for {} is {}", "_set_name"_attr = _set->name, "_set_seedConnStr"_attr = _set->seedConnStr);
 
         _set->notifier->onConfirmedSet(_set->seedConnStr, reply.host, reply.passives);
     }
@@ -970,7 +966,7 @@ void IsMasterReply::parse(const BSONObj& obj) {
         }
     } catch (const std::exception& e) {
         ok = false;
-        log() << "exception while parsing isMaster reply: " << e.what() << " " << obj;
+        LOGV2("exception while parsing isMaster reply: {} {}", "e_what"_attr = e.what(), "obj"_attr = obj);
     }
 }
 
@@ -978,7 +974,7 @@ Node::Node(const HostAndPort& host) : host(host), latencyMicros(unknownLatency)
 
 void Node::markFailed(const Status& status) {
     if (isUp) {
-        log() << "Marking host " << host << " as failed" << causedBy(redact(status));
+        LOGV2("Marking host {} as failed{}", "host"_attr = host, "causedBy_redact_status"_attr = causedBy(redact(status)));
 
         isUp = false;
     }
@@ -988,11 +984,11 @@ void Node::markFailed(const Status& status) {
 
 bool Node::matches(const ReadPreference pref) const {
     if (!isUp) {
-        LOG(3) << "Host " << host << " is not up";
+        LOGV2_DEBUG(3, "Host {} is not up", "host"_attr = host);
         return false;
     }
 
-    LOG(3) << "Host " << host << " is " << (isMaster ? "primary" : "not primary");
+    LOGV2_DEBUG(3, "Host {} is {}", "host"_attr = host, "isMaster_primary_not_primary"_attr = (isMaster ? "primary" : "not primary"));
     if (pref == ReadPreference::PrimaryOnly) {
         return isMaster;
     }
@@ -1019,7 +1015,7 @@ void Node::update(const IsMasterReply& reply) {
     invariant(host == reply.host);
     invariant(reply.ok);
 
-    LOG(3) << "Updating host " << host << " based on ismaster reply: " << reply.raw;
+    LOGV2_DEBUG(3, "Updating host {} based on ismaster reply: {}", "host"_attr = host, "reply_raw"_attr = reply.raw);
 
     // Nodes that are hidden or neither master or secondary are considered down since we can't
     // send any operations to them.
@@ -1042,10 +1038,10 @@ void Node::update(const IsMasterReply& reply) {
         }
     }
 
-    LOG(3) << "Updating " << host << " lastWriteDate to " << reply.lastWriteDate;
+    LOGV2_DEBUG(3, "Updating {} lastWriteDate to {}", "host"_attr = host, "reply_lastWriteDate"_attr = reply.lastWriteDate);
     lastWriteDate = reply.lastWriteDate;
 
-    LOG(3) << "Updating " << host << " opTime to " << reply.opTime;
+    LOGV2_DEBUG(3, "Updating {} opTime to {}", "host"_attr = host, "reply_opTime"_attr = reply.opTime);
     opTime = reply.opTime;
     lastWriteDateUpdateTime = Date_t::now();
 }
@@ -1264,7 +1260,7 @@ Node* SetState::findOrCreateNode(const HostAndPort& host) {
     // to consider alternate algorithms.
     Nodes::iterator it = std::lower_bound(nodes.begin(), nodes.end(), host, compareHosts);
     if (it == nodes.end() || it->host != host) {
-        LOG(2) << "Adding node " << host << " to our view of replica set " << name;
+        LOGV2_DEBUG(2, "Adding node {} to our view of replica set {}", "host"_attr = host, "name"_attr = name);
         it = nodes.insert(it, Node(host));
     }
     return &(*it);
@@ -1273,8 +1269,7 @@ Node* SetState::findOrCreateNode(const HostAndPort& host) {
 void SetState::updateNodeIfInNodes(const IsMasterReply& reply) {
     Node* node = findNode(reply.host);
     if (!node) {
-        LOG(2) << "Skipping application of ismaster reply from " << reply.host
-               << " since it isn't a confirmed member of set " << name;
+        LOGV2_DEBUG(2, "Skipping application of ismaster reply from {} since it isn't a confirmed member of set {}", "reply_host"_attr = reply.host, "name"_attr = name);
         return;
     }
 
@@ -1320,12 +1315,11 @@ void SetState::notify() {
             it->promise.emplaceValue(std::move(match));
             waiters.erase(it++);
         } else if (it->deadline <= cachedNow) {
-            LOG(1) << "Unable to statisfy read preference " << it->criteria << " by deadline "
-                   << it->deadline;
+            LOGV2_DEBUG(1, "Unable to statisfy read preference {} by deadline {}", "it_criteria"_attr = it->criteria, "it_deadline"_attr = it->deadline);
             it->promise.setError(makeUnsatisfedReadPrefError(it->criteria));
             waiters.erase(it++);
         } else if (shouldQuickFail) {
-            LOG(1) << "Unable to statisfy read preference because tests fail quickly";
+            LOGV2_DEBUG(1, "Unable to statisfy read preference because tests fail quickly");
             it->promise.setError(makeUnsatisfedReadPrefError(it->criteria));
             waiters.erase(it++);
         } else {
diff --git a/src/mongo/client/replica_set_monitor_manager.cpp b/src/mongo/client/replica_set_monitor_manager.cpp
index 96d270a5e4..c380c8ee94 100644
--- a/src/mongo/client/replica_set_monitor_manager.cpp
+++ b/src/mongo/client/replica_set_monitor_manager.cpp
@@ -45,6 +45,7 @@
 #include "mongo/executor/task_executor.h"
 #include "mongo/executor/task_executor_pool.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/metadata/egress_metadata_hook_list.h"
 #include "mongo/util/log.h"
@@ -121,7 +122,7 @@ shared_ptr<ReplicaSetMonitor> ReplicaSetMonitorManager::getOrCreateMonitor(const
         return monitor;
     }
 
-    log() << "Starting new replica set monitor for " << uri.toString();
+    LOGV2("Starting new replica set monitor for {}", "uri_toString"_attr = uri.toString());
 
     auto newMonitor = std::make_shared<ReplicaSetMonitor>(uri);
     _monitors[setName] = newMonitor;
@@ -149,7 +150,7 @@ void ReplicaSetMonitorManager::removeMonitor(StringData setName) {
             monitor->drop();
         }
         _monitors.erase(it);
-        log() << "Removed ReplicaSetMonitor for replica set " << setName;
+        LOGV2("Removed ReplicaSetMonitor for replica set {}", "setName"_attr = setName);
     }
 }
 
@@ -172,12 +173,12 @@ void ReplicaSetMonitorManager::shutdown() {
     }
 
     if (taskExecutor) {
-        LOG(1) << "Shutting down task executor used for monitoring replica sets";
+        LOGV2_DEBUG(1, "Shutting down task executor used for monitoring replica sets");
         taskExecutor->shutdown();
     }
 
     if (monitors.size()) {
-        log() << "Dropping all ongoing scans against replica sets";
+        LOGV2("Dropping all ongoing scans against replica sets");
     }
     for (auto& [name, monitor] : monitors) {
         auto anchor = monitor.lock();
diff --git a/src/mongo/client/replica_set_monitor_scan_test.cpp b/src/mongo/client/replica_set_monitor_scan_test.cpp
index 80d5a576b4..4af7d83629 100644
--- a/src/mongo/client/replica_set_monitor_scan_test.cpp
+++ b/src/mongo/client/replica_set_monitor_scan_test.cpp
@@ -34,6 +34,7 @@
 #include "mongo/client/replica_set_monitor_test_fixture.h"
 
 #include "mongo/client/mongo_uri.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -1416,11 +1417,10 @@ TEST_F(MinOpTimeTest, MinOpTimeIgnored) {
 class Listener : public ReplicaSetChangeNotifier::Listener {
 public:
     void logEvent(StringData name, const Key& key) {
-        log() << name << ": " << key;
+        LOGV2("{}: {}", "name"_attr = name, "key"_attr = key);
     }
     void logEvent(StringData name, const State& state) {
-        log() << name << ": "
-              << "(" << state.generation << ") " << state.connStr << " | " << state.primary;
+        LOGV2("{}: ({}) {} | {}", "name"_attr = name, "state_generation"_attr = state.generation, "state_connStr"_attr = state.connStr, "state_primary"_attr = state.primary);
     }
 
     void onFoundSet(const Key& key) override {
diff --git a/src/mongo/client/replica_set_monitor_test_concurrent.cpp b/src/mongo/client/replica_set_monitor_test_concurrent.cpp
index 55ac5e4716..4620c6f424 100644
--- a/src/mongo/client/replica_set_monitor_test_concurrent.cpp
+++ b/src/mongo/client/replica_set_monitor_test_concurrent.cpp
@@ -38,6 +38,7 @@
 #include "mongo/executor/thread_pool_mock.h"
 #include "mongo/executor/thread_pool_task_executor.h"
 #include "mongo/executor/thread_pool_task_executor_test_fixture.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/duration.h"
 #include "mongo/util/log.h"
@@ -102,15 +103,15 @@ protected:
         const auto net = getNet();
         const auto request = noi->getRequest();
         _numChecks[request.target]++;
-        LOG(2) << "at " << elapsed() << " got mock net operation " << request.toString();
+        LOGV2_DEBUG(2, "at {} got mock net operation {}", "elapsed"_attr = elapsed(), "request_toString"_attr = request.toString());
         const auto node = replSet.getNode(request.target.toString());
         if (node->isRunning()) {
             const auto opmsg = OpMsgRequest::fromDBAndBody(request.dbname, request.cmdObj);
             const auto reply = node->runCommand(request.id, opmsg)->getCommandReply();
-            LOG(2) << "replying " << reply;
+            LOGV2_DEBUG(2, "replying {}", "reply"_attr = reply);
             net->scheduleSuccessfulResponse(noi, RemoteCommandResponse(reply, Milliseconds(0)));
         } else {
-            LOG(2) << "black hole";
+            LOGV2_DEBUG(2, "black hole");
             net->blackHole(noi);
         }
         net->runReadyNetworkOperations();
@@ -122,9 +123,9 @@ protected:
         InNetworkGuard guard(net);
 
         // Operations can happen inline with advanceTime(), so log before and after the call.
-        LOG(3) << "Advancing time from " << elapsed() << " to " << (elapsed() + d);
+        LOGV2_DEBUG(3, "Advancing time from {} to {}", "elapsed"_attr = elapsed(), "elapsed_d"_attr = (elapsed() + d));
         net->advanceTime(net->now() + d);
-        LOG(3) << "Advanced to " << elapsed();
+        LOGV2_DEBUG(3, "Advanced to {}", "elapsed"_attr = elapsed());
     }
 
     int getNumChecks(HostAndPort host) {
diff --git a/src/mongo/client/sasl_client_authenticate_impl.cpp b/src/mongo/client/sasl_client_authenticate_impl.cpp
index 8a5794f95e..66c3c88b99 100644
--- a/src/mongo/client/sasl_client_authenticate_impl.cpp
+++ b/src/mongo/client/sasl_client_authenticate_impl.cpp
@@ -48,6 +48,7 @@
 #include "mongo/client/sasl_client_authenticate.h"
 #include "mongo/client/sasl_client_session.h"
 #include "mongo/db/auth/sasl_command_constants.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/util/base64.h"
 #include "mongo/util/log.h"
@@ -186,7 +187,7 @@ Future<void> asyncSaslConversation(auth::RunCommandHook runCommand,
     if (!status.isOK())
         return status;
 
-    LOG(saslLogLevel) << "sasl client input: " << base64::encode(payload) << endl;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(saslLogLevel).toInt(), "sasl client input: {}", "base64_encode_payload"_attr = base64::encode(payload));
 
     // Create new payload for our response
     std::string responsePayload;
@@ -194,7 +195,7 @@ Future<void> asyncSaslConversation(auth::RunCommandHook runCommand,
     if (!status.isOK())
         return status;
 
-    LOG(saslLogLevel) << "sasl client output: " << base64::encode(responsePayload) << endl;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(saslLogLevel).toInt(), "sasl client output: {}", "base64_encode_responsePayload"_attr = base64::encode(responsePayload));
 
     // Build command using our new payload and conversationId
     BSONObjBuilder commandBuilder;
diff --git a/src/mongo/client/sdam/topology_description_test.cpp b/src/mongo/client/sdam/topology_description_test.cpp
index e12a85836e..c5415a73e1 100644
--- a/src/mongo/client/sdam/topology_description_test.cpp
+++ b/src/mongo/client/sdam/topology_description_test.cpp
@@ -34,6 +34,7 @@
 #include "mongo/client/sdam/server_description.h"
 #include "mongo/client/sdam/server_description_builder.h"
 #include "mongo/db/wire_version.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/death_test.h"
 
 namespace mongo {
@@ -143,8 +144,7 @@ TEST_F(TopologyDescriptionTestFixture, ShouldOnlyAllowSingleAndRsNoPrimaryWithSe
                         topologyTypes.end());
 
     for (const auto topologyType : topologyTypes) {
-        unittest::log() << "Check TopologyType " << toString(topologyType)
-                        << " with setName value.";
+        unittest::LOGV2("Check TopologyType {} with setName value.", "toString_topologyType"_attr = toString(topologyType));
         ASSERT_THROWS_CODE(
             SdamConfiguration(kOneServer, topologyType, mongo::Seconds(10), kSetName),
             DBException,
diff --git a/src/mongo/client/sdam/topology_state_machine.cpp b/src/mongo/client/sdam/topology_state_machine.cpp
index dc793595b5..c38b9e4063 100644
--- a/src/mongo/client/sdam/topology_state_machine.cpp
+++ b/src/mongo/client/sdam/topology_state_machine.cpp
@@ -33,6 +33,7 @@
 #include <ostream>
 
 #include "mongo/client/sdam/sdam_test_base.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo::sdam {
@@ -149,8 +150,7 @@ void mongo::sdam::TopologyStateMachine::initTransitionTable() {
 void TopologyStateMachine::onServerDescription(TopologyDescription& topologyDescription,
                                                const ServerDescriptionPtr& serverDescription) {
     if (!topologyDescription.containsServerAddress(serverDescription->getAddress())) {
-        LOG(0) << kLogPrefix << "ignoring ismaster reply from server that is not in the topology: "
-               << serverDescription->getAddress() << std::endl;
+        LOGV2("{}ignoring ismaster reply from server that is not in the topology: {}", "kLogPrefix"_attr = kLogPrefix, "serverDescription_getAddress"_attr = serverDescription->getAddress());
         return;
     }
 
@@ -364,40 +364,37 @@ void TopologyStateMachine::setTopologyTypeAndUpdateRSWithoutPrimary(
 void TopologyStateMachine::removeServerDescription(TopologyDescription& topologyDescription,
                                                    const ServerAddress serverAddress) {
     topologyDescription.removeServerDescription(serverAddress);
-    LOG(0) << kLogPrefix << "server '" << serverAddress << "' was removed from the topology."
-           << std::endl;
+    LOGV2("{}server '{}' was removed from the topology.", "kLogPrefix"_attr = kLogPrefix, "serverAddress"_attr = serverAddress);
 }
 
 void TopologyStateMachine::modifyTopologyType(TopologyDescription& topologyDescription,
                                               TopologyType topologyType) {
     topologyDescription._type = topologyType;
-    LOG(0) << kLogPrefix << "the topology type was set to " << toString(topologyType) << std::endl;
+    LOGV2("{}the topology type was set to {}", "kLogPrefix"_attr = kLogPrefix, "toString_topologyType"_attr = toString(topologyType));
 }
 
 void TopologyStateMachine::modifySetName(TopologyDescription& topologyDescription,
                                          const boost::optional<std::string>& setName) {
     topologyDescription._setName = setName;
-    LOG(0) << kLogPrefix << "the topology setName was set to " << ((setName) ? *setName : "[null]")
-           << std::endl;
+    LOGV2("{}the topology setName was set to {}", "kLogPrefix"_attr = kLogPrefix, "setName_setName_null"_attr = ((setName) ? *setName : "[null]"));
 }
 
 void TopologyStateMachine::installServerDescription(TopologyDescription& topologyDescription,
                                                     ServerDescriptionPtr newServerDescription,
                                                     bool newServer) {
     topologyDescription.installServerDescription(newServerDescription);
-    LOG(1) << kLogPrefix << ((newServer) ? "installed new" : "updated existing")
-           << " server description: " << newServerDescription->toString() << std::endl;
+    LOGV2_DEBUG(1, "{}{} server description: {}", "kLogPrefix"_attr = kLogPrefix, "newServer_installed_new_updated_existing"_attr = ((newServer) ? "installed new" : "updated existing"), "newServerDescription_toString"_attr = newServerDescription->toString());
 }
 
 void TopologyStateMachine::modifyMaxElectionId(TopologyDescription& topologyDescription,
                                                const OID& newMaxElectionId) {
     topologyDescription._maxElectionId = newMaxElectionId;
-    LOG(0) << kLogPrefix << "topology max election id set to " << newMaxElectionId << std::endl;
+    LOGV2("{}topology max election id set to {}", "kLogPrefix"_attr = kLogPrefix, "newMaxElectionId"_attr = newMaxElectionId);
 }
 
 void TopologyStateMachine::modifyMaxSetVersion(TopologyDescription& topologyDescription,
                                                int& newMaxSetVersion) {
     topologyDescription._maxSetVersion = newMaxSetVersion;
-    LOG(0) << kLogPrefix << "topology max set version set to " << newMaxSetVersion << std::endl;
+    LOGV2("{}topology max set version set to {}", "kLogPrefix"_attr = kLogPrefix, "newMaxSetVersion"_attr = newMaxSetVersion);
 }
 }  // namespace mongo::sdam
diff --git a/src/mongo/db/auth/authorization_manager_impl.cpp b/src/mongo/db/auth/authorization_manager_impl.cpp
index 54bae468e3..c152a86ad2 100644
--- a/src/mongo/db/auth/authorization_manager_impl.cpp
+++ b/src/mongo/db/auth/authorization_manager_impl.cpp
@@ -62,6 +62,7 @@
 #include "mongo/db/global_settings.h"
 #include "mongo/db/jsobj.h"
 #include "mongo/db/mongod_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/compiler.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/stdx/unordered_map.h"
@@ -503,7 +504,7 @@ Status AuthorizationManagerImpl::getRoleDescriptionsForDB(
 }
 
 void AuthorizationManagerImpl::UserCacheInvalidator::operator()(User* user) {
-    LOG(1) << "Invalidating user " << user->getName().toString();
+    LOGV2_DEBUG(1, "Invalidating user {}", "user_getName_toString"_attr = user->getName().toString());
     user->_invalidate();
 }
 
@@ -518,7 +519,7 @@ StatusWith<UserHandle> AuthorizationManagerImpl::acquireUser(OperationContext* o
         auto ret = *cachedUser;
         fassert(16914, ret.get());
 
-        LOG(1) << "Returning user " << userName << " from cache";
+        LOGV2_DEBUG(1, "Returning user {} from cache", "userName"_attr = userName);
         return ret;
     };
 
@@ -543,7 +544,7 @@ StatusWith<UserHandle> AuthorizationManagerImpl::acquireUser(OperationContext* o
 
     guard.beginFetchPhase();
     // If there's still no user in the cache, then we need to go to disk. Take the slow path.
-    LOG(1) << "Getting user " << userName << " from disk";
+    LOGV2_DEBUG(1, "Getting user {} from disk", "userName"_attr = userName);
 
     int authzVersion = _version;
 
@@ -654,7 +655,7 @@ void AuthorizationManagerImpl::updatePinnedUsersList(std::vector<UserName> names
     bool noUsersToPin = _usersToPin->empty();
     _pinnedUsersCond.notify_one();
     if (noUsersToPin) {
-        LOG(1) << "There were no users to pin, not starting tracker thread";
+        LOGV2_DEBUG(1, "There were no users to pin, not starting tracker thread");
         return;
     }
 
@@ -668,7 +669,7 @@ void AuthorizationManagerImpl::_pinnedUsersThreadRoutine() noexcept try {
     Client::initThread("PinnedUsersTracker");
     std::list<UserHandle> pinnedUsers;
     std::vector<UserName> usersToPin;
-    LOG(1) << "Starting pinned users tracking thread";
+    LOGV2_DEBUG(1, "Starting pinned users tracking thread");
     while (true) {
         auto opCtx = cc().makeOperationContext();
 
@@ -697,13 +698,13 @@ void AuthorizationManagerImpl::_pinnedUsersThreadRoutine() noexcept try {
 
             if (!user->isValid() || !shouldPin) {
                 if (!shouldPin) {
-                    LOG(2) << "Unpinning user " << user->getName();
+                    LOGV2_DEBUG(2, "Unpinning user {}", "user_getName"_attr = user->getName());
                 } else {
-                    LOG(2) << "Pinned user no longer valid, will re-pin " << user->getName();
+                    LOGV2_DEBUG(2, "Pinned user no longer valid, will re-pin {}", "user_getName"_attr = user->getName());
                 }
                 it = pinnedUsers.erase(it);
             } else {
-                LOG(3) << "Pinned user is still valid and pinned " << user->getName();
+                LOGV2_DEBUG(3, "Pinned user is still valid and pinned {}", "user_getName"_attr = user->getName());
                 ++it;
             }
         }
@@ -718,7 +719,7 @@ void AuthorizationManagerImpl::_pinnedUsersThreadRoutine() noexcept try {
             auto swUser = acquireUser(opCtx.get(), userName);
 
             if (swUser.isOK()) {
-                LOG(2) << "Pinned user " << userName;
+                LOGV2_DEBUG(2, "Pinned user {}", "userName"_attr = userName);
                 pinnedUsers.emplace_back(std::move(swUser.getValue()));
             } else {
                 const auto& status = swUser.getStatus();
@@ -728,13 +729,13 @@ void AuthorizationManagerImpl::_pinnedUsersThreadRoutine() noexcept try {
                     warning() << "Unable to fetch pinned user " << userName.toString() << ": "
                               << status;
                 } else {
-                    LOG(2) << "Pinned user not found: " << userName;
+                    LOGV2_DEBUG(2, "Pinned user not found: {}", "userName"_attr = userName);
                 }
             }
         }
     }
 } catch (const ExceptionFor<ErrorCodes::InterruptedAtShutdown>&) {
-    LOG(1) << "Ending pinned users tracking thread";
+    LOGV2_DEBUG(1, "Ending pinned users tracking thread");
     return;
 }
 
@@ -742,21 +743,21 @@ void AuthorizationManagerImpl::invalidateUserByName(OperationContext* opCtx,
                                                     const UserName& userName) {
     CacheGuard guard(opCtx, this);
     _updateCacheGeneration_inlock(guard);
-    LOG(2) << "Invalidating user " << userName;
+    LOGV2_DEBUG(2, "Invalidating user {}", "userName"_attr = userName);
     _userCache.invalidate(userName);
 }
 
 void AuthorizationManagerImpl::invalidateUsersFromDB(OperationContext* opCtx, StringData dbname) {
     CacheGuard guard(opCtx, this);
     _updateCacheGeneration_inlock(guard);
-    LOG(2) << "Invalidating all users from database " << dbname;
+    LOGV2_DEBUG(2, "Invalidating all users from database {}", "dbname"_attr = dbname);
     _userCache.invalidateIf(
         [&](const UserName& user, const User*) { return user.getDB() == dbname; });
 }
 
 void AuthorizationManagerImpl::invalidateUserCache(OperationContext* opCtx) {
     CacheGuard guard(opCtx, this);
-    LOG(2) << "Invalidating user cache";
+    LOGV2_DEBUG(2, "Invalidating user cache");
     _invalidateUserCache_inlock(guard);
 }
 
diff --git a/src/mongo/db/auth/authorization_session_impl.cpp b/src/mongo/db/auth/authorization_session_impl.cpp
index 73c2feb31b..6ae8414743 100644
--- a/src/mongo/db/auth/authorization_session_impl.cpp
+++ b/src/mongo/db/auth/authorization_session_impl.cpp
@@ -53,6 +53,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/pipeline/aggregation_request.h"
 #include "mongo/db/pipeline/lite_parsed_pipeline.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -139,8 +140,7 @@ Status AuthorizationSessionImpl::addAndAuthorizeUser(OperationContext* opCtx,
     Status restrictionStatus =
         restrictionSet.validate(RestrictionEnvironment::get(*opCtx->getClient()));
     if (!restrictionStatus.isOK()) {
-        log() << "Failed to acquire user '" << userName
-              << "' because of unmet authentication restrictions: " << restrictionStatus.reason();
+        LOGV2("Failed to acquire user '{}' because of unmet authentication restrictions: {}", "userName"_attr = userName, "restrictionStatus_reason"_attr = restrictionStatus.reason());
         return AuthorizationManager::authenticationFailedStatus;
     }
 
@@ -551,9 +551,8 @@ bool AuthorizationSessionImpl::isAuthorizedToCreateRole(
                 return true;
             }
         }
-        log() << "Not authorized to create the first role in the system '" << args.roleName
-              << "' using the localhost exception. The user needs to acquire the role through "
-                 "external authentication first.";
+        LOGV2("Not authorized to create the first role in the system '{}' using the localhost exception. The user needs to acquire the role through "
+                 "external authentication first.", "args_roleName"_attr = args.roleName);
     }
 
     return false;
@@ -750,37 +749,29 @@ void AuthorizationSessionImpl::_refreshUserInfoAsNeeded(OperationContext* opCtx)
                         Status restrictionStatus = restrictionSet.validate(
                             RestrictionEnvironment::get(*opCtx->getClient()));
                         if (!restrictionStatus.isOK()) {
-                            log() << "Removed user " << name
-                                  << " with unmet authentication restrictions from session cache of"
-                                  << " user information. Restriction failed because: "
-                                  << restrictionStatus.reason();
+                            LOGV2("Removed user {} with unmet authentication restrictions from session cache of user information. Restriction failed because: {}", "name"_attr = name, "restrictionStatus_reason"_attr = restrictionStatus.reason());
                             // If we remove from the UserSet, we cannot increment the iterator.
                             continue;
                         }
                     } catch (...) {
-                        log() << "Evaluating authentication restrictions for " << name
-                              << " resulted in an unknown exception. Removing user from the"
-                              << " session cache.";
+                        LOGV2("Evaluating authentication restrictions for {} resulted in an unknown exception. Removing user from the session cache.", "name"_attr = name);
                         continue;
                     }
 
                     // Success! Replace the old User object with the updated one.
                     removeGuard.dismiss();
                     _authenticatedUsers.replaceAt(it, std::move(updatedUser));
-                    LOG(1) << "Updated session cache of user information for " << name;
+                    LOGV2_DEBUG(1, "Updated session cache of user information for {}", "name"_attr = name);
                     break;
                 }
                 case ErrorCodes::UserNotFound: {
                     // User does not exist anymore; remove it from _authenticatedUsers.
-                    log() << "Removed deleted user " << name
-                          << " from session cache of user information.";
+                    LOGV2("Removed deleted user {} from session cache of user information.", "name"_attr = name);
                     continue;  // No need to advance "it" in this case.
                 }
                 case ErrorCodes::UnsupportedFormat: {
                     // An auth subsystem has explicitly indicated a failure.
-                    log() << "Removed user " << name
-                          << " from session cache of user information because of refresh failure:"
-                          << " '" << status << "'.";
+                    LOGV2("Removed user {} from session cache of user information because of refresh failure: '{}'.", "name"_attr = name, "status"_attr = status);
                     continue;  // No need to advance "it" in this case.
                 }
                 default:
diff --git a/src/mongo/db/auth/authz_session_external_state_server_common.cpp b/src/mongo/db/auth/authz_session_external_state_server_common.cpp
index b9829fde37..10f545ca6b 100644
--- a/src/mongo/db/auth/authz_session_external_state_server_common.cpp
+++ b/src/mongo/db/auth/authz_session_external_state_server_common.cpp
@@ -38,6 +38,7 @@
 #include "mongo/base/status.h"
 #include "mongo/db/auth/enable_localhost_auth_bypass_parameter_gen.h"
 #include "mongo/db/client.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/debug_util.h"
 #include "mongo/util/log.h"
 
@@ -70,9 +71,8 @@ void AuthzSessionExternalStateServerCommon::_checkShouldAllowLocalhost(Operation
     _allowLocalhost = !_authzManager->hasAnyPrivilegeDocuments(opCtx);
     if (_allowLocalhost) {
         std::call_once(checkShouldAllowLocalhostOnceFlag, []() {
-            log() << "note: no users configured in admin.system.users, allowing localhost "
-                     "access"
-                  << std::endl;
+            LOGV2("note: no users configured in admin.system.users, allowing localhost "
+                     "access");
         });
     }
 }
diff --git a/src/mongo/db/auth/sasl_commands.cpp b/src/mongo/db/auth/sasl_commands.cpp
index 8106f5930f..82163b7984 100644
--- a/src/mongo/db/auth/sasl_commands.cpp
+++ b/src/mongo/db/auth/sasl_commands.cpp
@@ -51,6 +51,7 @@
 #include "mongo/db/commands.h"
 #include "mongo/db/commands/authentication_commands.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/base64.h"
 #include "mongo/util/log.h"
 #include "mongo/util/sequence_util.h"
@@ -208,9 +209,7 @@ Status doSaslStep(OperationContext* opCtx,
         }
 
         if (!serverGlobalParams.quiet.load()) {
-            log() << "Successfully authenticated as principal " << mechanism.getPrincipalName()
-                  << " on " << mechanism.getAuthenticationDatabase() << " from client "
-                  << opCtx->getClient()->session()->remote();
+            LOGV2("Successfully authenticated as principal {} on {} from client {}", "mechanism_getPrincipalName"_attr = mechanism.getPrincipalName(), "mechanism_getAuthenticationDatabase"_attr = mechanism.getAuthenticationDatabase(), "opCtx_getClient_session_remote"_attr = opCtx->getClient()->session()->remote());
         }
     }
     return Status::OK();
diff --git a/src/mongo/db/auth/sasl_mechanism_registry.cpp b/src/mongo/db/auth/sasl_mechanism_registry.cpp
index 741dde3912..44b74f83aa 100644
--- a/src/mongo/db/auth/sasl_mechanism_registry.cpp
+++ b/src/mongo/db/auth/sasl_mechanism_registry.cpp
@@ -35,6 +35,7 @@
 #include "mongo/base/init.h"
 #include "mongo/db/auth/sasl_options.h"
 #include "mongo/db/auth/user.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/icu.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/socket_utils.h"
@@ -108,8 +109,7 @@ void SASLServerMechanismRegistry::advertiseMechanismNamesForUser(OperationContex
         if (!swUser.isOK()) {
             auto& status = swUser.getStatus();
             if (status.code() == ErrorCodes::UserNotFound) {
-                log() << "Supported SASL mechanisms requested for unknown user '" << userName
-                      << "'";
+                LOGV2("Supported SASL mechanisms requested for unknown user '{}'", "userName"_attr = userName);
                 return;
             }
             uassertStatusOK(status);
diff --git a/src/mongo/db/auth/sasl_scram_test.cpp b/src/mongo/db/auth/sasl_scram_test.cpp
index 23c6c548f3..5537b6042e 100644
--- a/src/mongo/db/auth/sasl_scram_test.cpp
+++ b/src/mongo/db/auth/sasl_scram_test.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/auth/sasl_mechanism_registry.h"
 #include "mongo/db/auth/sasl_scram_server_conversation.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/base64.h"
 #include "mongo/util/log.h"
@@ -270,12 +271,12 @@ protected:
 
 public:
     void run() {
-        log() << "SCRAM-SHA-1 variant";
+        LOGV2("SCRAM-SHA-1 variant");
         saslServerSession = std::make_unique<SaslSCRAMSHA1ServerMechanism>("test");
         _digestPassword = true;
         Test::run();
 
-        log() << "SCRAM-SHA-256 variant";
+        LOGV2("SCRAM-SHA-256 variant");
         saslServerSession = std::make_unique<SaslSCRAMSHA256ServerMechanism>("test");
         _digestPassword = false;
         Test::run();
diff --git a/src/mongo/db/auth/security_key.cpp b/src/mongo/db/auth/security_key.cpp
index fe310befdf..c4f4d3c925 100644
--- a/src/mongo/db/auth/security_key.cpp
+++ b/src/mongo/db/auth/security_key.cpp
@@ -52,6 +52,7 @@
 #include "mongo/db/auth/security_file.h"
 #include "mongo/db/auth/user.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/icu.h"
 #include "mongo/util/log.h"
 #include "mongo/util/password_digest.h"
@@ -128,7 +129,7 @@ using std::string;
 bool setUpSecurityKey(const string& filename) {
     auto swKeyStrings = mongo::readSecurityFile(filename);
     if (!swKeyStrings.isOK()) {
-        log() << swKeyStrings.getStatus().reason();
+        LOGV2("{}", "swKeyStrings_getStatus_reason"_attr = swKeyStrings.getStatus().reason());
         return false;
     }
 
diff --git a/src/mongo/db/auth/user_cache_invalidator_job.cpp b/src/mongo/db/auth/user_cache_invalidator_job.cpp
index b483b8e4d4..5d8eba3e7d 100644
--- a/src/mongo/db/auth/user_cache_invalidator_job.cpp
+++ b/src/mongo/db/auth/user_cache_invalidator_job.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/auth/user_cache_invalidator_job_parameters_gen.h"
 #include "mongo/db/client.h"
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/compiler.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/get_status_from_command_result.h"
diff --git a/src/mongo/db/catalog/catalog_control.cpp b/src/mongo/db/catalog/catalog_control.cpp
index 351d709b5d..2e0b798374 100644
--- a/src/mongo/db/catalog/catalog_control.cpp
+++ b/src/mongo/db/catalog/catalog_control.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/index_builds_coordinator.h"
 #include "mongo/db/namespace_string.h"
 #include "mongo/db/repair_database.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -72,8 +73,7 @@ MinVisibleTimestampMap closeCatalog(OperationContext* opCtx) {
             // If there's a minimum visible, invariant there's also a UUID.
             invariant(!minVisible || uuid);
             if (uuid && minVisible) {
-                LOG(1) << "closeCatalog: preserving min visible timestamp. Collection: "
-                       << coll->ns() << " UUID: " << uuid << " TS: " << minVisible;
+                LOGV2_DEBUG(1, "closeCatalog: preserving min visible timestamp. Collection: {} UUID: {} TS: {}", "coll_ns"_attr = coll->ns(), "uuid"_attr = uuid, "minVisible"_attr = minVisible);
                 minVisibleTimestampMap[*uuid] = *minVisible;
             }
         }
@@ -87,14 +87,14 @@ MinVisibleTimestampMap closeCatalog(OperationContext* opCtx) {
     // to work before acquiring locks, and might otherwise spuriously regard a UUID as unknown
     // while reloading the catalog.
     CollectionCatalog::get(opCtx).onCloseCatalog(opCtx);
-    LOG(1) << "closeCatalog: closing collection catalog";
+    LOGV2_DEBUG(1, "closeCatalog: closing collection catalog");
 
     // Close all databases.
-    log() << "closeCatalog: closing all databases";
+    LOGV2("closeCatalog: closing all databases");
     databaseHolder->closeAll(opCtx);
 
     // Close the storage engine's catalog.
-    log() << "closeCatalog: closing storage engine catalog";
+    LOGV2("closeCatalog: closing storage engine catalog");
     opCtx->getServiceContext()->getStorageEngine()->closeCatalog(opCtx);
 
     reopenOnFailure.dismiss();
@@ -105,11 +105,11 @@ void openCatalog(OperationContext* opCtx, const MinVisibleTimestampMap& minVisib
     invariant(opCtx->lockState()->isW());
 
     // Load the catalog in the storage engine.
-    log() << "openCatalog: loading storage engine catalog";
+    LOGV2("openCatalog: loading storage engine catalog");
     auto storageEngine = opCtx->getServiceContext()->getStorageEngine();
     storageEngine->loadCatalog(opCtx);
 
-    log() << "openCatalog: reconciling catalog and idents";
+    LOGV2("openCatalog: reconciling catalog and idents");
     auto reconcileResult = fassert(40688, storageEngine->reconcileCatalogAndIdents(opCtx));
 
     // Determine which indexes need to be rebuilt. rebuildIndexesOnCollection() requires that all
@@ -149,8 +149,7 @@ void openCatalog(OperationContext* opCtx, const MinVisibleTimestampMap& minVisib
         invariant(collection, str::stream() << "couldn't get collection " << collNss.toString());
 
         for (const auto& indexName : entry.second.first) {
-            log() << "openCatalog: rebuilding index: collection: " << collNss.toString()
-                  << ", index: " << indexName;
+            LOGV2("openCatalog: rebuilding index: collection: {}, index: {}", "collNss_toString"_attr = collNss.toString(), "indexName"_attr = indexName);
         }
 
         std::vector<BSONObj> indexSpecs = entry.second.second;
@@ -165,7 +164,7 @@ void openCatalog(OperationContext* opCtx, const MinVisibleTimestampMap& minVisib
         opCtx, reconcileResult.indexBuildsToRestart);
 
     // Open all databases and repopulate the CollectionCatalog.
-    log() << "openCatalog: reopening all databases";
+    LOGV2("openCatalog: reopening all databases");
     auto databaseHolder = DatabaseHolder::get(opCtx);
     std::vector<std::string> databasesToOpen = storageEngine->listDatabases();
     for (auto&& dbName : databasesToOpen) {
@@ -189,7 +188,7 @@ void openCatalog(OperationContext* opCtx, const MinVisibleTimestampMap& minVisib
             // If this is the oplog collection, re-establish the replication system's cached pointer
             // to the oplog.
             if (collNss.isOplog()) {
-                log() << "openCatalog: updating cached oplog pointer";
+                LOGV2("openCatalog: updating cached oplog pointer");
                 collection->establishOplogCollectionForLogging(opCtx);
             }
         }
@@ -199,7 +198,7 @@ void openCatalog(OperationContext* opCtx, const MinVisibleTimestampMap& minVisib
     // catalog. Clear the pre-closing state.
     CollectionCatalog::get(opCtx).onOpenCatalog(opCtx);
     opCtx->getServiceContext()->incrementCatalogGeneration();
-    log() << "openCatalog: finished reloading collection catalog";
+    LOGV2("openCatalog: finished reloading collection catalog");
 }
 }  // namespace catalog
 }  // namespace mongo
diff --git a/src/mongo/db/catalog/coll_mod.cpp b/src/mongo/db/catalog/coll_mod.cpp
index 49a666c9c6..3adeac0a90 100644
--- a/src/mongo/db/catalog/coll_mod.cpp
+++ b/src/mongo/db/catalog/coll_mod.cpp
@@ -56,6 +56,7 @@
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/storage/recovery_unit.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 
@@ -376,7 +377,7 @@ Status _collModInternal(OperationContext* opCtx,
                     std::make_unique<CollModResultChange>(oldExpireSecs, newExpireSecs, result));
 
                 if (MONGO_unlikely(assertAfterIndexUpdate.shouldFail())) {
-                    log() << "collMod - assertAfterIndexUpdate fail point enabled.";
+                    LOGV2("collMod - assertAfterIndexUpdate fail point enabled.");
                     uasserted(50970, "trigger rollback after the index update");
                 }
             }
diff --git a/src/mongo/db/catalog/collection_catalog.cpp b/src/mongo/db/catalog/collection_catalog.cpp
index 2907e940f3..4d4622882a 100644
--- a/src/mongo/db/catalog/collection_catalog.cpp
+++ b/src/mongo/db/catalog/collection_catalog.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/concurrency/lock_manager_defs.h"
 #include "mongo/db/concurrency/write_conflict_exception.h"
 #include "mongo/db/storage/recovery_unit.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/uuid.h"
@@ -384,12 +385,11 @@ void CollectionCatalog::registerCollection(CollectionUUID uuid, std::unique_ptr<
     auto ns = (*coll)->ns();
     stdx::lock_guard<Latch> lock(_catalogLock);
     if (_collections.find(ns) != _collections.end()) {
-        log() << "Conflicted creating a collection. ns: " << (*coll)->ns() << " ("
-              << (*coll)->uuid() << ").";
+        LOGV2("Conflicted creating a collection. ns: {} ({}).", "coll_ns"_attr = (*coll)->ns(), "coll_uuid"_attr = (*coll)->uuid());
         throw WriteConflictException();
     }
 
-    LOG(1) << "Registering collection " << ns << " with UUID " << uuid;
+    LOGV2_DEBUG(1, "Registering collection {} with UUID {}", "ns"_attr = ns, "uuid"_attr = uuid);
 
     auto dbName = ns.db().toString();
     auto dbIdPair = std::make_pair(dbName, uuid);
@@ -419,7 +419,7 @@ std::unique_ptr<Collection> CollectionCatalog::deregisterCollection(CollectionUU
     auto dbName = ns.db().toString();
     auto dbIdPair = std::make_pair(dbName, uuid);
 
-    LOG(1) << "Deregistering collection " << ns << " with UUID " << uuid;
+    LOGV2_DEBUG(1, "Deregistering collection {} with UUID {}", "ns"_attr = ns, "uuid"_attr = uuid);
 
     // Make sure collection object exists.
     invariant(_collections.find(ns) != _collections.end());
@@ -447,14 +447,14 @@ std::unique_ptr<RecoveryUnit::Change> CollectionCatalog::makeFinishDropCollectio
 void CollectionCatalog::deregisterAllCollections() {
     stdx::lock_guard<Latch> lock(_catalogLock);
 
-    LOG(0) << "Deregistering all the collections";
+    LOGV2("Deregistering all the collections");
     for (auto& entry : _catalog) {
         auto uuid = entry.first;
         auto ns = entry.second->ns();
         auto dbName = ns.db().toString();
         auto dbIdPair = std::make_pair(dbName, uuid);
 
-        LOG(1) << "Deregistering collection " << ns << " with UUID " << uuid;
+        LOGV2_DEBUG(1, "Deregistering collection {} with UUID {}", "ns"_attr = ns, "uuid"_attr = uuid);
 
         entry.second.reset();
     }
diff --git a/src/mongo/db/catalog/collection_compact.cpp b/src/mongo/db/catalog/collection_compact.cpp
index 13d91880c8..cfe38f8d1f 100644
--- a/src/mongo/db/catalog/collection_compact.cpp
+++ b/src/mongo/db/catalog/collection_compact.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/index_builds_coordinator.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -103,7 +104,7 @@ StatusWith<int64_t> compactCollection(OperationContext* opCtx,
         recordStore = collection->getRecordStore();
     }
 
-    log(LogComponent::kCommand) << "compact " << collectionNss << " begin";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kCommand).toInt(), "compact {} begin", "collectionNss"_attr = collectionNss);
 
     auto oldTotalSize = recordStore->storageSize(opCtx) + collection->getIndexSize(opCtx);
     auto indexCatalog = collection->getIndexCatalog();
@@ -119,8 +120,8 @@ StatusWith<int64_t> compactCollection(OperationContext* opCtx,
 
     auto totalSizeDiff =
         oldTotalSize - recordStore->storageSize(opCtx) - collection->getIndexSize(opCtx);
-    log() << "compact " << collectionNss << " bytes freed: " << totalSizeDiff;
-    log() << "compact " << collectionNss << " end";
+    LOGV2("compact {} bytes freed: {}", "collectionNss"_attr = collectionNss, "totalSizeDiff"_attr = totalSizeDiff);
+    LOGV2("compact {} end", "collectionNss"_attr = collectionNss);
     return totalSizeDiff;
 }
 
diff --git a/src/mongo/db/catalog/collection_impl.cpp b/src/mongo/db/catalog/collection_impl.cpp
index c5c4912b58..0221e10578 100644
--- a/src/mongo/db/catalog/collection_impl.cpp
+++ b/src/mongo/db/catalog/collection_impl.cpp
@@ -71,6 +71,7 @@
 #include "mongo/db/update/update_driver.h"
 
 #include "mongo/db/auth/user_document_parser.h"  // XXX-ANDY
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/object_check.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -110,7 +111,7 @@ Status checkFailCollectionInsertsFailPoint(const NamespaceString& ns, const BSON
             const std::string msg = str::stream()
                 << "Failpoint (failCollectionInserts) has been enabled (" << data
                 << "), so rejecting insert (first doc): " << firstDoc;
-            log() << msg;
+            LOGV2("{}", "msg"_attr = msg);
             s = {ErrorCodes::FailPointEnabled, msg};
         },
         [&](const BSONObj& data) {
@@ -138,9 +139,7 @@ std::unique_ptr<CollatorInterface> parseCollation(OperationContext* opCtx,
     // integration, shut down the server. Errors other than IncompatibleCollationVersion should not
     // be possible, so these are an invariant rather than fassert.
     if (collator == ErrorCodes::IncompatibleCollationVersion) {
-        log() << "Collection " << nss
-              << " has a default collation which is incompatible with this version: "
-              << collationSpec;
+        LOGV2("Collection {} has a default collation which is incompatible with this version: {}", "nss"_attr = nss, "collationSpec"_attr = collationSpec);
         fassertFailedNoTrace(40144);
     }
     invariant(collator.getStatus());
@@ -415,8 +414,7 @@ Status CollectionImpl::insertDocuments(OperationContext* opCtx,
                 whenFirst += " when first _id is ";
                 whenFirst += firstIdElem.str();
             }
-            log() << "hangAfterCollectionInserts fail point enabled for " << _ns << whenFirst
-                  << ". Blocking until fail point is disabled.";
+            LOGV2("hangAfterCollectionInserts fail point enabled for {}{}. Blocking until fail point is disabled.", "_ns"_attr = _ns, "whenFirst"_attr = whenFirst);
             hangAfterCollectionInserts.pauseWhileSet(opCtx);
         },
         [&](const BSONObj& data) {
@@ -468,8 +466,7 @@ Status CollectionImpl::insertDocumentForBulkLoader(OperationContext* opCtx,
     status = onRecordInserted(loc.getValue());
 
     if (MONGO_unlikely(failAfterBulkLoadDocInsert.shouldFail())) {
-        log() << "Failpoint failAfterBulkLoadDocInsert enabled for " << _ns.ns()
-              << ". Throwing WriteConflictException.";
+        LOGV2("Failpoint failAfterBulkLoadDocInsert enabled for {}. Throwing WriteConflictException.", "_ns_ns"_attr = _ns.ns());
         throw WriteConflictException();
     }
 
@@ -593,7 +590,7 @@ void CollectionImpl::deleteDocument(OperationContext* opCtx,
                                     bool noWarn,
                                     Collection::StoreDeletedDoc storeDeletedDoc) {
     if (isCapped()) {
-        log() << "failing remove on a capped ns " << _ns;
+        LOGV2("failing remove on a capped ns {}", "_ns"_attr = _ns);
         uasserted(10089, "cannot remove from a capped collection");
         return;
     }
diff --git a/src/mongo/db/catalog/collection_validation.cpp b/src/mongo/db/catalog/collection_validation.cpp
index 83feee3965..eb4d87052f 100644
--- a/src/mongo/db/catalog/collection_validation.cpp
+++ b/src/mongo/db/catalog/collection_validation.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 
@@ -92,9 +93,7 @@ std::map<std::string, int64_t> _validateIndexesInternalStructure(
         const IndexDescriptor* descriptor = entry->descriptor();
         const IndexAccessMethod* iam = entry->accessMethod();
 
-        log(LogComponent::kIndex) << "validating the internal structure of index "
-                                  << descriptor->indexName() << " on collection "
-                                  << descriptor->parentNS();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "validating the internal structure of index {} on collection {}", "descriptor_indexName"_attr = descriptor->indexName(), "descriptor_parentNS"_attr = descriptor->parentNS());
         ValidateResults& curIndexResults = (*indexNsResultsMap)[descriptor->indexName()];
 
         int64_t numValidated;
@@ -124,8 +123,7 @@ void _validateIndexes(OperationContext* opCtx,
 
         const IndexDescriptor* descriptor = index->descriptor();
 
-        log(LogComponent::kIndex) << "validating index consistency " << descriptor->indexName()
-                                  << " on collection " << descriptor->parentNS();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "validating index consistency {} on collection {}", "descriptor_indexName"_attr = descriptor->indexName(), "descriptor_parentNS"_attr = descriptor->parentNS());
 
         ValidateResults& curIndexResults = (*indexNsResultsMap)[descriptor->indexName()];
         int64_t numTraversedKeys;
@@ -183,7 +181,7 @@ void _gatherIndexEntryErrors(OperationContext* opCtx,
                              ValidateResults* result) {
     indexConsistency->setSecondPhase();
 
-    log(LogComponent::kIndex) << "Starting to traverse through all the document key sets.";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Starting to traverse through all the document key sets.");
 
     // During the second phase of validation, iterate through each documents key set and only record
     // the keys that were inconsistent during the first phase of validation.
@@ -193,8 +191,8 @@ void _gatherIndexEntryErrors(OperationContext* opCtx,
         indexValidator->traverseRecordStore(opCtx, &tempValidateResults, &tempBuilder);
     }
 
-    log(LogComponent::kIndex) << "Finished traversing through all the document key sets.";
-    log(LogComponent::kIndex) << "Starting to traverse through all the indexes.";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Finished traversing through all the document key sets.");
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Starting to traverse through all the indexes.");
 
     // Iterate through all the indexes in the collection and only record the index entry keys that
     // had inconsistencies during the first phase.
@@ -203,8 +201,7 @@ void _gatherIndexEntryErrors(OperationContext* opCtx,
 
         const IndexDescriptor* descriptor = index->descriptor();
 
-        log(LogComponent::kIndex) << "Traversing through the index entries for index "
-                                  << descriptor->indexName() << ".";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Traversing through the index entries for index {}.", "descriptor_indexName"_attr = descriptor->indexName());
 
         indexValidator->traverseIndex(opCtx,
                                       index.get(),
@@ -212,7 +209,7 @@ void _gatherIndexEntryErrors(OperationContext* opCtx,
                                       /*ValidateResults=*/nullptr);
     }
 
-    log(LogComponent::kIndex) << "Finished traversing through all the indexes.";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Finished traversing through all the indexes.");
 
     indexConsistency->addIndexEntryErrors(indexNsResultsMap, result);
 }
@@ -434,7 +431,7 @@ Status validate(OperationContext* opCtx,
         const string uuidString = str::stream() << " (UUID: " << validateState.uuid() << ")";
 
         // Validate the record store.
-        log(LogComponent::kIndex) << "validating collection " << validateState.nss() << uuidString;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "validating collection {}{}", "validateState_nss"_attr = validateState.nss(), "uuidString"_attr = uuidString);
 
         IndexConsistency indexConsistency(opCtx, &validateState);
         ValidateAdaptor indexValidator(&indexConsistency, &validateState, &indexNsResultsMap);
@@ -457,7 +454,7 @@ Status validate(OperationContext* opCtx,
 
         if (MONGO_unlikely(pauseCollectionValidationWithLock.shouldFail())) {
             _validationIsPausedForTest.store(true);
-            log() << "Failpoint 'pauseCollectionValidationWithLock' activated.";
+            LOGV2("Failpoint 'pauseCollectionValidationWithLock' activated.");
             pauseCollectionValidationWithLock.pauseWhileSet();
             _validationIsPausedForTest.store(false);
         }
@@ -473,9 +470,7 @@ Status validate(OperationContext* opCtx,
                              results);
 
             if (indexConsistency.haveEntryMismatch()) {
-                log(LogComponent::kIndex)
-                    << "Index inconsistencies were detected on collection " << validateState.nss()
-                    << ". Starting the second phase of index validation to gather concise errors.";
+                LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Index inconsistencies were detected on collection {}. Starting the second phase of index validation to gather concise errors.", "validateState_nss"_attr = validateState.nss());
                 _gatherIndexEntryErrors(opCtx,
                                         &validateState,
                                         &indexConsistency,
@@ -495,12 +490,9 @@ Status validate(OperationContext* opCtx,
             opCtx, &validateState, &indexNsResultsMap, &keysPerIndex, results, output);
 
         if (!results->valid) {
-            log(LogComponent::kIndex) << "Validation complete for collection "
-                                      << validateState.nss() << uuidString << ". Corruption found.";
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Validation complete for collection {}{}. Corruption found.", "validateState_nss"_attr = validateState.nss(), "uuidString"_attr = uuidString);
         } else {
-            log(LogComponent::kIndex)
-                << "Validation complete for collection " << validateState.nss() << uuidString
-                << ". No corruption found.";
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kIndex).toInt(), "Validation complete for collection {}{}. No corruption found.", "validateState_nss"_attr = validateState.nss(), "uuidString"_attr = uuidString);
         }
 
         output->append("ns", validateState.nss().ns());
diff --git a/src/mongo/db/catalog/create_collection.cpp b/src/mongo/db/catalog/create_collection.cpp
index dc841b95b2..311cbb8564 100644
--- a/src/mongo/db/catalog/create_collection.cpp
+++ b/src/mongo/db/catalog/create_collection.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/views/view_catalog.h"
 #include "mongo/logger/redaction.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -248,9 +249,7 @@ Status createCollectionForApplyOps(OperationContext* opCtx,
                     return Result(Status::OK());
 
                 if (currentName && currentName->isDropPendingNamespace()) {
-                    log() << "CMD: create " << newCollName
-                          << " - existing collection with conflicting UUID " << uuid
-                          << " is in a drop-pending state: " << *currentName;
+                    LOGV2("CMD: create {} - existing collection with conflicting UUID {} is in a drop-pending state: {}", "newCollName"_attr = newCollName, "uuid"_attr = uuid, "currentName"_attr = *currentName);
                     return Result(Status(ErrorCodes::NamespaceExists,
                                          str::stream()
                                              << "existing collection " << currentName->toString()
@@ -290,9 +289,7 @@ Status createCollectionForApplyOps(OperationContext* opCtx,
                     }
 
                     // It is ok to log this because this doesn't happen very frequently.
-                    log() << "CMD: create " << newCollName
-                          << " - renaming existing collection with conflicting UUID " << uuid
-                          << " to temporary collection " << tmpName;
+                    LOGV2("CMD: create {} - renaming existing collection with conflicting UUID {} to temporary collection {}", "newCollName"_attr = newCollName, "uuid"_attr = uuid, "tmpName"_attr = tmpName);
                     Status status = db->renameCollection(opCtx, newCollName, tmpName, stayTemp);
                     if (!status.isOK())
                         return Result(status);
diff --git a/src/mongo/db/catalog/database_holder_impl.cpp b/src/mongo/db/catalog/database_holder_impl.cpp
index 6ee95d92a8..1bed4790e8 100644
--- a/src/mongo/db/catalog/database_holder_impl.cpp
+++ b/src/mongo/db/catalog/database_holder_impl.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/stats/top.h"
 #include "mongo/db/storage/storage_engine.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -175,7 +176,7 @@ void DatabaseHolderImpl::dropDb(OperationContext* opCtx, Database* db) {
     // Store the name so we have if for after the db object is deleted
     auto name = db->name();
 
-    LOG(1) << "dropDatabase " << name;
+    LOGV2_DEBUG(1, "dropDatabase {}", "name"_attr = name);
 
     invariant(opCtx->lockState()->isDbLockedForMode(name, MODE_X));
 
@@ -251,7 +252,7 @@ void DatabaseHolderImpl::closeAll(OperationContext* opCtx) {
     }
 
     for (const auto& name : dbs) {
-        LOG(2) << "DatabaseHolder::closeAll name:" << name;
+        LOGV2_DEBUG(2, "DatabaseHolder::closeAll name:{}", "name"_attr = name);
 
         Database* db = _dbs[name];
         CollectionCatalog::get(opCtx).onCloseDatabase(opCtx, name);
diff --git a/src/mongo/db/catalog/database_impl.cpp b/src/mongo/db/catalog/database_impl.cpp
index 535b4abab2..176dc2a46a 100644
--- a/src/mongo/db/catalog/database_impl.cpp
+++ b/src/mongo/db/catalog/database_impl.cpp
@@ -73,6 +73,7 @@
 #include "mongo/db/storage/storage_options.h"
 #include "mongo/db/system_index.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/s/cannot_implicitly_create_collection_info.h"
 #include "mongo/util/assert_util.h"
@@ -289,8 +290,7 @@ void DatabaseImpl::getStats(OperationContext* opCtx, BSONObjBuilder* output, dou
         } else {
             output->appendNumber("fsUsedSize", -1);
             output->appendNumber("fsTotalSize", -1);
-            log() << "Failed to query filesystem disk stats (code: " << ec.value()
-                  << "): " << ec.message();
+            LOGV2("Failed to query filesystem disk stats (code: {}): {}", "ec_value"_attr = ec.value(), "ec_message"_attr = ec.message());
         }
     }
 }
@@ -340,7 +340,7 @@ Status DatabaseImpl::dropCollectionEvenIfSystem(OperationContext* opCtx,
                                                 repl::OpTime dropOpTime) const {
     invariant(opCtx->lockState()->isCollectionLockedForMode(nss, MODE_X));
 
-    LOG(1) << "dropCollection: " << nss;
+    LOGV2_DEBUG(1, "dropCollection: {}", "nss"_attr = nss);
 
     // A valid 'dropOpTime' is not allowed when writes are replicated.
     if (!dropOpTime.isNull() && opCtx->writesAreReplicated()) {
@@ -393,9 +393,7 @@ Status DatabaseImpl::dropCollectionEvenIfSystem(OperationContext* opCtx,
         _dropCollectionIndexes(opCtx, nss, collection);
 
         auto commitTimestamp = opCtx->recoveryUnit()->getCommitTimestamp();
-        log() << "dropCollection: " << nss << " (" << uuid
-              << ") - storage engine will take ownership of drop-pending collection with optime "
-              << dropOpTime << " and commit timestamp " << commitTimestamp;
+        LOGV2("dropCollection: {} ({}) - storage engine will take ownership of drop-pending collection with optime {} and commit timestamp {}", "nss"_attr = nss, "uuid"_attr = uuid, "dropOpTime"_attr = dropOpTime, "commitTimestamp"_attr = commitTimestamp);
         if (dropOpTime.isNull()) {
             // Log oplog entry for collection drop and remove the UUID.
             dropOpTime = opObserver->onDropCollection(
@@ -434,9 +432,7 @@ Status DatabaseImpl::dropCollectionEvenIfSystem(OperationContext* opCtx,
     // Rename collection using drop-pending namespace generated from drop optime.
     auto dpns = nss.makeDropPendingNamespace(dropOpTime);
     const bool stayTemp = true;
-    log() << "dropCollection: " << nss << " (" << uuid
-          << ") - renaming to drop-pending collection: " << dpns << " with drop optime "
-          << dropOpTime;
+    LOGV2("dropCollection: {} ({}) - renaming to drop-pending collection: {} with drop optime {}", "nss"_attr = nss, "uuid"_attr = uuid, "dpns"_attr = dpns, "dropOpTime"_attr = dropOpTime);
     {
         Lock::CollectionLock collLk(opCtx, dpns, MODE_X);
         fassert(40464, renameCollection(opCtx, nss, dpns, stayTemp));
@@ -453,19 +449,19 @@ void DatabaseImpl::_dropCollectionIndexes(OperationContext* opCtx,
                                           const NamespaceString& nss,
                                           Collection* collection) const {
     invariant(_name == nss.db());
-    LOG(1) << "dropCollection: " << nss << " - dropAllIndexes start";
+    LOGV2_DEBUG(1, "dropCollection: {} - dropAllIndexes start", "nss"_attr = nss);
     collection->getIndexCatalog()->dropAllIndexes(opCtx, true);
 
     invariant(DurableCatalog::get(opCtx)->getTotalIndexCount(opCtx, collection->getCatalogId()) ==
               0);
-    LOG(1) << "dropCollection: " << nss << " - dropAllIndexes done";
+    LOGV2_DEBUG(1, "dropCollection: {} - dropAllIndexes done", "nss"_attr = nss);
 }
 
 Status DatabaseImpl::_finishDropCollection(OperationContext* opCtx,
                                            const NamespaceString& nss,
                                            Collection* collection) const {
     UUID uuid = collection->uuid();
-    log() << "Finishing collection drop for " << nss << " (" << uuid << ").";
+    LOGV2("Finishing collection drop for {} ({}).", "nss"_attr = nss, "uuid"_attr = uuid);
 
     auto status = DurableCatalog::get(opCtx)->dropCollection(opCtx, collection->getCatalogId());
     if (!status.isOK())
@@ -514,8 +510,7 @@ Status DatabaseImpl::renameCollection(OperationContext* opCtx,
                           << toNss);
     }
 
-    log() << "renameCollection: renaming collection " << collToRename->uuid() << " from " << fromNss
-          << " to " << toNss;
+    LOGV2("renameCollection: renaming collection {} from {} to {}", "collToRename_uuid"_attr = collToRename->uuid(), "fromNss"_attr = fromNss, "toNss"_attr = toNss);
 
     Top::get(opCtx->getServiceContext()).collectionDropped(fromNss);
 
@@ -655,8 +650,7 @@ Collection* DatabaseImpl::createCollection(OperationContext* opCtx,
     _checkCanCreateCollection(opCtx, nss, optionsWithUUID);
     audit::logCreateCollection(&cc(), nss.ns());
 
-    log() << "createCollection: " << nss << " with " << (generatedUUID ? "generated" : "provided")
-          << " UUID: " << optionsWithUUID.uuid.get() << " and options: " << options.toBSON();
+    LOGV2("createCollection: {} with {} UUID: {} and options: {}", "nss"_attr = nss, "generatedUUID_generated_provided"_attr = (generatedUUID ? "generated" : "provided"), "optionsWithUUID_uuid_get"_attr = optionsWithUUID.uuid.get(), "options_toBSON"_attr = options.toBSON());
 
     // Create Collection object
     auto storageEngine = opCtx->getServiceContext()->getStorageEngine();
@@ -778,7 +772,7 @@ void DatabaseImpl::checkForIdIndexesAndDropPendingCollections(OperationContext*
          CollectionCatalog::get(opCtx).getAllCollectionNamesFromDb(opCtx, _name)) {
         if (nss.isDropPendingNamespace()) {
             auto dropOpTime = fassert(40459, nss.getDropPendingNamespaceOpTime());
-            log() << "Found drop-pending namespace " << nss << " with drop optime " << dropOpTime;
+            LOGV2("Found drop-pending namespace {} with drop optime {}", "nss"_attr = nss, "dropOpTime"_attr = dropOpTime);
             repl::DropPendingCollectionReaper::get(opCtx)->addDropPendingNamespace(
                 opCtx, dropOpTime, nss);
         }
@@ -793,11 +787,8 @@ void DatabaseImpl::checkForIdIndexesAndDropPendingCollections(OperationContext*
         if (coll->getIndexCatalog()->findIdIndex(opCtx))
             continue;
 
-        log() << "WARNING: the collection '" << nss << "' lacks a unique index on _id."
-              << " This index is needed for replication to function properly" << startupWarningsLog;
-        log() << "\t To fix this, you need to create a unique index on _id."
-              << " See http://dochub.mongodb.org/core/build-replica-set-indexes"
-              << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "WARNING: the collection '{}' lacks a unique index on _id. This index is needed for replication to function properly", "nss"_attr = nss);
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "\t To fix this, you need to create a unique index on _id. See http://dochub.mongodb.org/core/build-replica-set-indexes");
     }
 }
 
@@ -806,7 +797,7 @@ Status DatabaseImpl::userCreateNS(OperationContext* opCtx,
                                   CollectionOptions collectionOptions,
                                   bool createDefaultIndexes,
                                   const BSONObj& idIndex) const {
-    LOG(1) << "create collection " << nss << ' ' << collectionOptions.toBSON();
+    LOGV2_DEBUG(1, "create collection {} {}", "nss"_attr = nss, "collectionOptions_toBSON"_attr = collectionOptions.toBSON());
     if (!NamespaceString::validCollectionComponent(nss.ns()))
         return Status(ErrorCodes::InvalidNamespace, str::stream() << "invalid ns: " << nss);
 
diff --git a/src/mongo/db/catalog/drop_collection.cpp b/src/mongo/db/catalog/drop_collection.cpp
index 5c374c2d98..c5009810b3 100644
--- a/src/mongo/db/catalog/drop_collection.cpp
+++ b/src/mongo/db/catalog/drop_collection.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 
@@ -74,8 +75,8 @@ Status _dropView(OperationContext* opCtx,
     Lock::CollectionLock systemViewsLock(opCtx, db->getSystemViewsName(), MODE_X);
 
     if (MONGO_unlikely(hangDuringDropCollection.shouldFail())) {
-        log() << "hangDuringDropCollection fail point enabled. Blocking until fail point is "
-                 "disabled.";
+        LOGV2("hangDuringDropCollection fail point enabled. Blocking until fail point is "
+                 "disabled.");
         hangDuringDropCollection.pauseWhileSet();
     }
 
@@ -116,8 +117,8 @@ Status _dropCollection(OperationContext* opCtx,
     }
 
     if (MONGO_unlikely(hangDuringDropCollection.shouldFail())) {
-        log() << "hangDuringDropCollection fail point enabled. Blocking until fail point is "
-                 "disabled.";
+        LOGV2("hangDuringDropCollection fail point enabled. Blocking until fail point is "
+                 "disabled.");
         hangDuringDropCollection.pauseWhileSet();
     }
 
@@ -160,11 +161,11 @@ Status dropCollection(OperationContext* opCtx,
                       const repl::OpTime& dropOpTime,
                       DropCollectionSystemCollectionMode systemCollectionMode) {
     if (!serverGlobalParams.quiet.load()) {
-        log() << "CMD: drop " << collectionName;
+        LOGV2("CMD: drop {}", "collectionName"_attr = collectionName);
     }
 
     if (MONGO_unlikely(hangDropCollectionBeforeLockAcquisition.shouldFail())) {
-        log() << "Hanging drop collection before lock acquisition while fail point is set";
+        LOGV2("Hanging drop collection before lock acquisition while fail point is set");
         hangDropCollectionBeforeLockAcquisition.pauseWhileSet();
     }
     return writeConflictRetry(opCtx, "drop", collectionName.ns(), [&] {
diff --git a/src/mongo/db/catalog/drop_database.cpp b/src/mongo/db/catalog/drop_database.cpp
index f598148c68..4abbb12cf5 100644
--- a/src/mongo/db/catalog/drop_database.cpp
+++ b/src/mongo/db/catalog/drop_database.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/write_concern_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/duration.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -85,7 +86,7 @@ void _finishDropDatabase(OperationContext* opCtx,
     });
 
     if (MONGO_unlikely(dropDatabaseHangBeforeInMemoryDrop.shouldFail())) {
-        log() << "dropDatabase - fail point dropDatabaseHangBeforeInMemoryDrop enabled.";
+        LOGV2("dropDatabase - fail point dropDatabaseHangBeforeInMemoryDrop enabled.");
         dropDatabaseHangBeforeInMemoryDrop.pauseWhileSet();
     }
 
@@ -93,8 +94,8 @@ void _finishDropDatabase(OperationContext* opCtx,
     databaseHolder->dropDb(opCtx, db);
     dropPendingGuard.dismiss();
 
-    log() << "dropDatabase " << dbName << " - dropped " << numCollections << " collection(s)";
-    log() << "dropDatabase " << dbName << " - finished";
+    LOGV2("dropDatabase {} - dropped {} collection(s)", "dbName"_attr = dbName, "numCollections"_attr = numCollections);
+    LOGV2("dropDatabase {} - finished", "dbName"_attr = dbName);
 }
 
 }  // namespace
@@ -147,7 +148,7 @@ Status dropDatabase(OperationContext* opCtx, const std::string& dbName) {
                               << "The database is currently being dropped. Database: " << dbName);
         }
 
-        log() << "dropDatabase " << dbName << " - starting";
+        LOGV2("dropDatabase {} - starting", "dbName"_attr = dbName);
         db->setDropPending(opCtx, true);
 
         // If Database::dropCollectionEventIfSystem() fails, we should reset the drop-pending state
@@ -164,11 +165,11 @@ Status dropDatabase(OperationContext* opCtx, const std::string& dbName) {
             const auto& nss = collection->ns();
             numCollections++;
 
-            log() << "dropDatabase " << dbName << " - dropping collection: " << nss;
+            LOGV2("dropDatabase {} - dropping collection: {}", "dbName"_attr = dbName, "nss"_attr = nss);
 
             if (nss.isDropPendingNamespace() && replCoord->isReplEnabled() &&
                 opCtx->writesAreReplicated()) {
-                log() << "dropDatabase " << dbName << " - found drop-pending collection: " << nss;
+                LOGV2("dropDatabase {} - found drop-pending collection: {}", "dbName"_attr = dbName, "nss"_attr = nss);
                 latestDropPendingOpTime = std::max(
                     latestDropPendingOpTime, uassertStatusOK(nss.getDropPendingNamespaceOpTime()));
                 continue;
@@ -264,17 +265,13 @@ Status dropDatabase(OperationContext* opCtx, const std::string& dbName) {
         const WriteConcernOptions dropDatabaseWriteConcern(
             WriteConcernOptions::kMajority, WriteConcernOptions::SyncMode::UNSET, wTimeout);
 
-        log() << "dropDatabase " << dbName << " waiting for " << awaitOpTime
-              << " to be replicated at " << dropDatabaseWriteConcern.toBSON() << ". Dropping "
-              << numCollectionsToDrop << " collection(s), with last collection drop at "
-              << latestDropPendingOpTime;
+        LOGV2("dropDatabase {} waiting for {} to be replicated at {}. Dropping {} collection(s), with last collection drop at {}", "dbName"_attr = dbName, "awaitOpTime"_attr = awaitOpTime, "dropDatabaseWriteConcern_toBSON"_attr = dropDatabaseWriteConcern.toBSON(), "numCollectionsToDrop"_attr = numCollectionsToDrop, "latestDropPendingOpTime"_attr = latestDropPendingOpTime);
 
         auto result = replCoord->awaitReplication(opCtx, awaitOpTime, dropDatabaseWriteConcern);
 
         // If the user-provided write concern is weaker than majority, this is effectively a no-op.
         if (result.status.isOK() && !userWriteConcern.usedDefault) {
-            log() << "dropDatabase " << dbName << " waiting for " << awaitOpTime
-                  << " to be replicated at " << userWriteConcern.toBSON();
+            LOGV2("dropDatabase {} waiting for {} to be replicated at {}", "dbName"_attr = dbName, "awaitOpTime"_attr = awaitOpTime, "userWriteConcern_toBSON"_attr = userWriteConcern.toBSON());
             result = replCoord->awaitReplication(opCtx, awaitOpTime, userWriteConcern);
         }
 
@@ -286,14 +283,12 @@ Status dropDatabase(OperationContext* opCtx, const std::string& dbName) {
                                              << awaitOpTime.toString() << ") to replicate.");
         }
 
-        log() << "dropDatabase " << dbName << " - successfully dropped " << numCollectionsToDrop
-              << " collection(s) (most recent drop optime: " << awaitOpTime << ") after "
-              << result.duration << ". dropping database";
+        LOGV2("dropDatabase {} - successfully dropped {} collection(s) (most recent drop optime: {}) after {}. dropping database", "dbName"_attr = dbName, "numCollectionsToDrop"_attr = numCollectionsToDrop, "awaitOpTime"_attr = awaitOpTime, "result_duration"_attr = result.duration);
     }
 
     if (MONGO_unlikely(dropDatabaseHangAfterAllCollectionsDrop.shouldFail())) {
-        log() << "dropDatabase - fail point dropDatabaseHangAfterAllCollectionsDrop enabled. "
-                 "Blocking until fail point is disabled. ";
+        LOGV2("dropDatabase - fail point dropDatabaseHangAfterAllCollectionsDrop enabled. "
+                 "Blocking until fail point is disabled. ");
         dropDatabaseHangAfterAllCollectionsDrop.pauseWhileSet();
     }
 
diff --git a/src/mongo/db/catalog/drop_indexes.cpp b/src/mongo/db/catalog/drop_indexes.cpp
index 6a14fa7505..88ff593e97 100644
--- a/src/mongo/db/catalog/drop_indexes.cpp
+++ b/src/mongo/db/catalog/drop_indexes.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -204,7 +205,7 @@ Status dropIndexes(OperationContext* opCtx,
         }
 
         if (!serverGlobalParams.quiet.load()) {
-            LOG(0) << "CMD: dropIndexes " << nss << ": " << cmdObj[kIndexFieldName].toString(false);
+            LOGV2("CMD: dropIndexes {}: {}", "nss"_attr = nss, "cmdObj_kIndexFieldName_toString_false"_attr = cmdObj[kIndexFieldName].toString(false));
         }
 
         // If db/collection does not exist, short circuit and return.
diff --git a/src/mongo/db/catalog/index_build_block.cpp b/src/mongo/db/catalog/index_build_block.cpp
index 85e184b703..218be83b08 100644
--- a/src/mongo/db/catalog/index_build_block.cpp
+++ b/src/mongo/db/catalog/index_build_block.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/query/collection_query_info.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/ttl_collection_cache.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -168,7 +169,7 @@ void IndexBuildBlock::success(OperationContext* opCtx, Collection* collection) {
         invariant(_indexBuildInterceptor->areAllConstraintsChecked(opCtx));
     }
 
-    log() << "index build: done building index " << _indexName << " on ns " << _nss;
+    LOGV2("index build: done building index {} on ns {}", "_indexName"_attr = _indexName, "_nss"_attr = _nss);
 
     collection->indexBuildSuccess(opCtx, _indexCatalogEntry);
 
diff --git a/src/mongo/db/catalog/index_builds_manager.cpp b/src/mongo/db/catalog/index_builds_manager.cpp
index bbb3cf32c0..478a3dbcb3 100644
--- a/src/mongo/db/catalog/index_builds_manager.cpp
+++ b/src/mongo/db/catalog/index_builds_manager.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/concurrency/write_conflict_exception.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/storage/write_unit_of_work.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -109,8 +110,7 @@ Status IndexBuildsManager::setUpIndexBuild(OperationContext* opCtx,
         return ex.toStatus();
     }
 
-    log() << "Index build initialized: " << buildUUID << ": " << nss << " (" << collection->uuid()
-          << " ): indexes: " << indexes.size();
+    LOGV2("Index build initialized: {}: {} ({} ): indexes: {}", "buildUUID"_attr = buildUUID, "nss"_attr = nss, "collection_uuid"_attr = collection->uuid(), "indexes_size"_attr = indexes.size());
 
     return Status::OK();
 }
@@ -282,7 +282,7 @@ bool IndexBuildsManager::abortIndexBuildWithoutCleanup(OperationContext* opCtx,
         return false;
     }
 
-    log() << "Index build aborted without cleanup: " << buildUUID << ": " << reason;
+    LOGV2("Index build aborted without cleanup: {}: {}", "buildUUID"_attr = buildUUID, "reason"_attr = reason);
     std::shared_ptr<MultiIndexBlock> builder = builderIt->second;
 
     lk.unlock();
diff --git a/src/mongo/db/catalog/index_catalog_entry_impl.cpp b/src/mongo/db/catalog/index_catalog_entry_impl.cpp
index 72102857cf..f6984ecf9c 100644
--- a/src/mongo/db/catalog/index_catalog_entry_impl.cpp
+++ b/src/mongo/db/catalog/index_catalog_entry_impl.cpp
@@ -52,6 +52,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 
@@ -107,8 +108,7 @@ IndexCatalogEntryImpl::IndexCatalogEntryImpl(OperationContext* const opCtx,
                                          MatchExpressionParser::kBanAllSpecialFeatures);
         invariant(statusWithMatcher.getStatus());
         _filterExpression = std::move(statusWithMatcher.getValue());
-        LOG(2) << "have filter expression for " << ns() << " " << _descriptor->indexName() << " "
-               << redact(filter);
+        LOGV2_DEBUG(2, "have filter expression for {} {} {}", "ns"_attr = ns(), "_descriptor_indexName"_attr = _descriptor->indexName(), "redact_filter"_attr = redact(filter));
     }
 }
 
@@ -250,8 +250,7 @@ void IndexCatalogEntryImpl::setMultikey(OperationContext* opCtx,
         }
 
         if (indexMetadataHasChanged && _queryInfo) {
-            LOG(1) << ns() << ": clearing plan cache - index " << _descriptor->keyPattern()
-                   << " set to multi key.";
+            LOGV2_DEBUG(1, "{}: clearing plan cache - index {} set to multi key.", "ns"_attr = ns(), "_descriptor_keyPattern"_attr = _descriptor->keyPattern());
             _queryInfo->clearQueryCache();
         }
     };
@@ -281,8 +280,7 @@ void IndexCatalogEntryImpl::setMultikey(OperationContext* opCtx,
 
             auto status = opCtx->recoveryUnit()->setTimestamp(writeTs);
             if (status.code() == ErrorCodes::BadValue) {
-                log() << "Temporarily could not timestamp the multikey catalog write, retrying. "
-                      << status.reason();
+                LOGV2("Temporarily could not timestamp the multikey catalog write, retrying. {}", "status_reason"_attr = status.reason());
                 throw WriteConflictException();
             }
             fassert(31164, status);
diff --git a/src/mongo/db/catalog/index_catalog_impl.cpp b/src/mongo/db/catalog/index_catalog_impl.cpp
index fd48947658..f47a33931f 100644
--- a/src/mongo/db/catalog/index_catalog_impl.cpp
+++ b/src/mongo/db/catalog/index_catalog_impl.cpp
@@ -72,6 +72,7 @@
 #include "mongo/db/storage/kv/kv_engine.h"
 #include "mongo/db/storage/storage_engine_init.h"
 #include "mongo/db/ttl_collection_cache.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/represent_as.h"
@@ -753,8 +754,7 @@ Status IndexCatalogImpl::_doesSpecConflictWithExisting(OperationContext* opCtx,
         const IndexDescriptor* desc =
             findIndexByKeyPatternAndCollationSpec(opCtx, key, collation, includeUnfinishedIndexes);
         if (desc) {
-            LOG(2) << "Index already exists with a different name: " << name << " pattern: " << key
-                   << " collation: " << collation;
+            LOGV2_DEBUG(2, "Index already exists with a different name: {} pattern: {} collation: {}", "name"_attr = name, "key"_attr = key, "collation"_attr = collation);
 
             IndexDescriptor temp(_collection, _getAccessMethodName(key), spec);
             if (!desc->areIndexOptionsEquivalent(&temp))
@@ -772,7 +772,7 @@ Status IndexCatalogImpl::_doesSpecConflictWithExisting(OperationContext* opCtx,
     if (numIndexesTotal(opCtx) >= kMaxNumIndexesAllowed) {
         string s = str::stream() << "add index fails, too many indexes for " << _collection->ns()
                                  << " key:" << key;
-        log() << s;
+        LOGV2("{}", "s"_attr = s);
         return Status(ErrorCodes::CannotCreateIndex, s);
     }
 
@@ -840,7 +840,7 @@ void IndexCatalogImpl::dropAllIndexes(OperationContext* opCtx,
         string indexName = indexNamesToDrop[i];
         const IndexDescriptor* desc = findIndexByName(opCtx, indexName, true);
         invariant(desc);
-        LOG(1) << "\t dropAllIndexes dropping: " << desc->toString();
+        LOGV2_DEBUG(1, "\t dropAllIndexes dropping: {}", "desc_toString"_attr = desc->toString());
         IndexCatalogEntry* entry = _readyIndexes.find(desc);
         invariant(entry);
 
@@ -1035,7 +1035,7 @@ int IndexCatalogImpl::numIndexesTotal(OperationContext* opCtx) const {
             dassert(DurableCatalog::get(opCtx)->getTotalIndexCount(
                         opCtx, _collection->getCatalogId()) == count);
         } catch (const WriteConflictException& ex) {
-            log() << " Skipping dassert check due to: " << ex;
+            LOGV2(" Skipping dassert check due to: {}", "ex"_attr = ex);
         }
     }
 
@@ -1056,17 +1056,17 @@ int IndexCatalogImpl::numIndexesReady(OperationContext* opCtx) const {
         // There is a potential inconistency where the index information in the collection catalog
         // entry and the index catalog differ. Log as much information as possible here.
         if (itIndexes.size() != completedIndexes.size()) {
-            log() << "index catalog reports: ";
+            LOGV2("index catalog reports: ");
             for (const IndexDescriptor* i : itIndexes) {
-                log() << "  index: " << i->toString();
+                LOGV2("  index: {}", "i_toString"_attr = i->toString());
             }
 
-            log() << "collection catalog reports: ";
+            LOGV2("collection catalog reports: ");
             for (auto const& i : completedIndexes) {
-                log() << "  index: " << i;
+                LOGV2("  index: {}", "i"_attr = i);
             }
 
-            log() << "collection uuid: " << _collection->uuid();
+            LOGV2("collection uuid: {}", "_collection_uuid"_attr = _collection->uuid());
 
             invariant(itIndexes.size() == completedIndexes.size(),
                       "The number of ready indexes reported in the collection metadata catalog did "
@@ -1440,8 +1440,7 @@ void IndexCatalogImpl::_unindexKeys(OperationContext* opCtx,
     Status status = index->accessMethod()->removeKeys(opCtx, keys, loc, options, &removed);
 
     if (!status.isOK()) {
-        log() << "Couldn't unindex record " << redact(obj) << " from collection "
-              << _collection->ns() << ". Status: " << redact(status);
+        LOGV2("Couldn't unindex record {} from collection {}. Status: {}", "redact_obj"_attr = redact(obj), "_collection_ns"_attr = _collection->ns(), "redact_status"_attr = redact(status));
     }
 
     if (keysDeletedOut) {
@@ -1561,7 +1560,7 @@ Status IndexCatalogImpl::compactIndexes(OperationContext* opCtx) {
          ++it) {
         IndexCatalogEntry* entry = it->get();
 
-        LOG(1) << "compacting index: " << entry->descriptor()->toString();
+        LOGV2_DEBUG(1, "compacting index: {}", "entry_descriptor_toString"_attr = entry->descriptor()->toString());
         Status status = entry->accessMethod()->compact(opCtx);
         if (!status.isOK()) {
             error() << "failed to compact index: " << entry->descriptor()->toString();
diff --git a/src/mongo/db/catalog/index_timestamp_helper.cpp b/src/mongo/db/catalog/index_timestamp_helper.cpp
index 8686e7af8f..6900b3130e 100644
--- a/src/mongo/db/catalog/index_timestamp_helper.cpp
+++ b/src/mongo/db/catalog/index_timestamp_helper.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/logical_clock.h"
 #include "mongo/db/repl/member_state.h"
 #include "mongo/db/repl/replication_coordinator.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -94,10 +95,10 @@ void IndexTimestampHelper::setGhostCommitTimestampForWrite(OperationContext* opC
 
     auto status = opCtx->recoveryUnit()->setTimestamp(commitTimestamp);
     if (status.code() == ErrorCodes::BadValue) {
-        log() << "Temporarily could not apply ghost commit timestamp. " << status.reason();
+        LOGV2("Temporarily could not apply ghost commit timestamp. {}", "status_reason"_attr = status.reason());
         throw WriteConflictException();
     }
-    LOG(1) << "assigning ghost commit timestamp: " << commitTimestamp.toString();
+    LOGV2_DEBUG(1, "assigning ghost commit timestamp: {}", "commitTimestamp_toString"_attr = commitTimestamp.toString());
 
     fassert(51053, status);
 }
@@ -153,8 +154,7 @@ bool IndexTimestampHelper::setGhostCommitTimestampForCatalogWrite(OperationConte
     auto status = opCtx->recoveryUnit()->setTimestamp(
         LogicalClock::get(opCtx)->getClusterTime().asTimestamp());
     if (status.code() == ErrorCodes::BadValue) {
-        log() << "Temporarily could not timestamp the index build commit, retrying. "
-              << status.reason();
+        LOGV2("Temporarily could not timestamp the index build commit, retrying. {}", "status_reason"_attr = status.reason());
         throw WriteConflictException();
     }
     fassert(50701, status);
diff --git a/src/mongo/db/catalog/multi_index_block.cpp b/src/mongo/db/catalog/multi_index_block.cpp
index 6ee21034ef..2c7efc8be3 100644
--- a/src/mongo/db/catalog/multi_index_block.cpp
+++ b/src/mongo/db/catalog/multi_index_block.cpp
@@ -54,6 +54,7 @@
 #include "mongo/db/storage/storage_options.h"
 #include "mongo/db/storage/write_unit_of_work.h"
 #include "mongo/logger/redaction.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -142,7 +143,7 @@ void MultiIndexBlock::cleanUpAfterBuild(OperationContext* opCtx,
                 // Simply get a timestamp to write with here; we can't write to the oplog.
                 repl::UnreplicatedWritesBlock uwb(opCtx);
                 if (!IndexTimestampHelper::setGhostCommitTimestampForCatalogWrite(opCtx, nss)) {
-                    log() << "Did not timestamp index abort write.";
+                    LOGV2("Did not timestamp index abort write.");
                 }
             }
 
@@ -242,9 +243,8 @@ StatusWith<std::vector<BSONObj>> MultiIndexBlock::init(OperationContext* opCtx,
             BSONObj info = indexSpecs[i];
             if (enableHybrid) {
                 if (info["background"].isBoolean() && !info["background"].Bool()) {
-                    log()
-                        << "ignoring obselete { background: false } index build option because all "
-                           "indexes are built in the background with the hybrid method";
+                    LOGV2("ignoring obselete { background: false } index build option because all "
+                           "indexes are built in the background with the hybrid method");
                 }
                 continue;
             }
@@ -325,11 +325,9 @@ StatusWith<std::vector<BSONObj>> MultiIndexBlock::init(OperationContext* opCtx,
             }
             index.options.fromIndexBuilder = true;
 
-            log() << "index build: starting on " << ns << " properties: " << descriptor->toString()
-                  << " using method: " << _method;
+            LOGV2("index build: starting on {} properties: {} using method: {}", "ns"_attr = ns, "descriptor_toString"_attr = descriptor->toString(), "_method"_attr = (int)_method);
             if (index.bulk)
-                log() << "build may temporarily use up to "
-                      << eachIndexBuildMaxMemoryUsageBytes / 1024 / 1024 << " megabytes of RAM";
+                LOGV2("build may temporarily use up to {} megabytes of RAM", "eachIndexBuildMaxMemoryUsageBytes_1024_1024"_attr = eachIndexBuildMaxMemoryUsageBytes / 1024 / 1024);
 
             index.filterExpression = index.block->getEntry()->getFilterExpression();
 
@@ -371,7 +369,7 @@ void failPointHangDuringBuild(FailPoint* fp, StringData where, const BSONObj& do
     fp->executeIf(
         [&](const BSONObj& data) {
             int i = doc.getIntField("i");
-            log() << "Hanging " << where << " index build of i=" << i;
+            LOGV2("Hanging {} index build of i={}", "where"_attr = where, "i"_attr = i);
             fp->pauseWhileSet();
         },
         [&](const BSONObj& data) {
@@ -409,13 +407,13 @@ Status MultiIndexBlock::insertAllDocumentsInCollection(OperationContext* opCtx,
 
     if (MONGO_unlikely(hangAfterSettingUpIndexBuild.shouldFail())) {
         // Hang the build after the BackgroundOperation and curOP info is set up.
-        log() << "Hanging index build due to failpoint 'hangAfterSettingUpIndexBuild'";
+        LOGV2("Hanging index build due to failpoint 'hangAfterSettingUpIndexBuild'");
         hangAfterSettingUpIndexBuild.pauseWhileSet();
     }
 
     if (MONGO_unlikely(hangAndThenFailIndexBuild.shouldFail())) {
         // Hang the build after the BackgroundOperation and curOP info is set up.
-        log() << "Hanging index build due to failpoint 'hangAndThenFailIndexBuild'";
+        LOGV2("Hanging index build due to failpoint 'hangAndThenFailIndexBuild'");
         hangAndThenFailIndexBuild.pauseWhileSet();
         return {ErrorCodes::InternalError,
                 "Failed index build because of failpoint 'hangAndThenFailIndexBuild'"};
@@ -522,8 +520,8 @@ Status MultiIndexBlock::insertAllDocumentsInCollection(OperationContext* opCtx,
     }
 
     if (MONGO_unlikely(leaveIndexBuildUnfinishedForShutdown.shouldFail())) {
-        log() << "Index build interrupted due to 'leaveIndexBuildUnfinishedForShutdown' failpoint. "
-                 "Mimicking shutdown error code.";
+        LOGV2("Index build interrupted due to 'leaveIndexBuildUnfinishedForShutdown' failpoint. "
+                 "Mimicking shutdown error code.");
         return Status(
             ErrorCodes::InterruptedAtShutdown,
             "background index build interrupted due to failpoint. returning a shutdown error.");
@@ -534,8 +532,8 @@ Status MultiIndexBlock::insertAllDocumentsInCollection(OperationContext* opCtx,
         Locker::LockSnapshot lockInfo;
         invariant(opCtx->lockState()->saveLockStateAndUnlock(&lockInfo));
 
-        log() << "Hanging index build with no locks due to "
-                 "'hangAfterStartingIndexBuildUnlocked' failpoint";
+        LOGV2("Hanging index build with no locks due to "
+                 "'hangAfterStartingIndexBuildUnlocked' failpoint");
         hangAfterStartingIndexBuildUnlocked.pauseWhileSet();
 
         if (isBackgroundBuilding()) {
@@ -550,8 +548,7 @@ Status MultiIndexBlock::insertAllDocumentsInCollection(OperationContext* opCtx,
 
     progress->finished();
 
-    log() << "index build: collection scan done. scanned " << n << " total records in "
-          << t.seconds() << " seconds";
+    LOGV2("index build: collection scan done. scanned {} total records in {} seconds", "n"_attr = n, "t_seconds"_attr = t.seconds());
 
     Status ret = dumpInsertsFromBulk(opCtx);
     if (!ret.isOK())
@@ -618,8 +615,7 @@ Status MultiIndexBlock::dumpInsertsFromBulk(OperationContext* opCtx,
                                         : _indexes[i].options.dupsAllowed;
 
         IndexCatalogEntry* entry = _indexes[i].block->getEntry();
-        LOG(1) << "index build: inserting from external sorter into index: "
-               << entry->descriptor()->indexName();
+        LOGV2_DEBUG(1, "index build: inserting from external sorter into index: {}", "entry_descriptor_indexName"_attr = entry->descriptor()->indexName());
 
         // SERVER-41918 This call to commitBulk() results in file I/O that may result in an
         // exception.
diff --git a/src/mongo/db/catalog/rename_collection.cpp b/src/mongo/db/catalog/rename_collection.cpp
index 99bc4f5656..ce0a58f77e 100644
--- a/src/mongo/db/catalog/rename_collection.cpp
+++ b/src/mongo/db/catalog/rename_collection.cpp
@@ -58,6 +58,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -174,9 +175,7 @@ Status renameTargetCollectionToTmp(OperationContext* opCtx,
 
         wunit.commit();
 
-        log() << "Successfully renamed the target " << targetNs << " (" << targetUUID << ") to "
-              << tmpName << " so that the source " << sourceNs << " (" << sourceUUID
-              << ") could be renamed to " << targetNs;
+        LOGV2("Successfully renamed the target {} ({}) to {} so that the source {} ({}) could be renamed to {}", "targetNs"_attr = targetNs, "targetUUID"_attr = targetUUID, "tmpName"_attr = tmpName, "sourceNs"_attr = sourceNs, "sourceUUID"_attr = sourceUUID, "targetNs"_attr = targetNs);
 
         return Status::OK();
     });
@@ -549,8 +548,7 @@ Status renameBetweenDBs(OperationContext* opCtx,
     }
     const auto& tmpName = tmpNameResult.getValue();
 
-    log() << "Attempting to create temporary collection: " << tmpName
-          << " with the contents of collection: " << source;
+    LOGV2("Attempting to create temporary collection: {} with the contents of collection: {}", "tmpName"_attr = tmpName, "source"_attr = source);
 
     Collection* tmpColl = nullptr;
     {
@@ -584,8 +582,7 @@ Status renameBetweenDBs(OperationContext* opCtx,
         if (!status.isOK()) {
             // Ignoring failure case when dropping the temporary collection during cleanup because
             // the rename operation has already failed for another reason.
-            log() << "Unable to drop temporary collection " << tmpName << " while renaming from "
-                  << source << " to " << target << ": " << status;
+            LOGV2("Unable to drop temporary collection {} while renaming from {} to {}: {}", "tmpName"_attr = tmpName, "source"_attr = source, "target"_attr = target, "status"_attr = status);
         }
     });
 
@@ -842,7 +839,7 @@ Status renameCollection(OperationContext* opCtx,
 
     const std::string dropTargetMsg =
         options.dropTarget ? " and drop " + target.toString() + "." : ".";
-    log() << "renameCollectionForCommand: rename " << source << " to " << target << dropTargetMsg;
+    LOGV2("renameCollectionForCommand: rename {} to {}{}", "source"_attr = source, "target"_attr = target, "dropTargetMsg"_attr = dropTargetMsg);
 
     if (source.db() == target.db())
         return renameCollectionWithinDB(opCtx, source, target, options);
@@ -938,8 +935,7 @@ Status renameCollectionForApplyOps(OperationContext* opCtx,
     const std::string dropTargetMsg =
         uuidToDrop ? " and drop " + uuidToDrop->toString() + "." : ".";
     const std::string uuidString = uuidToRename ? uuidToRename->toString() : "UUID unknown";
-    log() << "renameCollectionForApplyOps: rename " << sourceNss << " (" << uuidString << ") to "
-          << targetNss << dropTargetMsg;
+    LOGV2("renameCollectionForApplyOps: rename {} ({}) to {}{}", "sourceNss"_attr = sourceNss, "uuidString"_attr = uuidString, "targetNss"_attr = targetNss, "dropTargetMsg"_attr = dropTargetMsg);
 
     if (sourceNss.db() == targetNss.db()) {
         return renameCollectionWithinDBForApplyOps(
@@ -960,8 +956,7 @@ Status renameCollectionForRollback(OperationContext* opCtx,
                                "have the same database. source: "
                             << *source << ". target: " << target);
 
-    log() << "renameCollectionForRollback: rename " << *source << " (" << uuid << ") to " << target
-          << ".";
+    LOGV2("renameCollectionForRollback: rename {} ({}) to {}.", "source"_attr = *source, "uuid"_attr = uuid, "target"_attr = target);
 
     return renameCollectionWithinDB(opCtx, *source, target, {});
 }
diff --git a/src/mongo/db/catalog/validate_adaptor.cpp b/src/mongo/db/catalog/validate_adaptor.cpp
index 75fa4f96a5..b37bbf6abe 100644
--- a/src/mongo/db/catalog/validate_adaptor.cpp
+++ b/src/mongo/db/catalog/validate_adaptor.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/storage/key_string.h"
 #include "mongo/db/storage/record_store.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/object_check.h"
 #include "mongo/util/log.h"
 
@@ -277,7 +278,7 @@ void ValidateAdaptor::traverseRecordStore(OperationContext* opCtx,
                 ss << "Reason: Validated size of " << validatedSize
                    << " bytes does not equal the record size of " << dataSize << " bytes";
             }
-            log() << std::string(ss);
+            LOGV2("{}", "std_string_ss"_attr = std::string(ss));
 
             // Only log once
             if (results->valid) {
diff --git a/src/mongo/db/catalog/validate_state.cpp b/src/mongo/db/catalog/validate_state.cpp
index f1924d254f..38e018d083 100644
--- a/src/mongo/db/catalog/validate_state.cpp
+++ b/src/mongo/db/catalog/validate_state.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 
@@ -172,8 +173,7 @@ void ValidateState::initializeCursors(OperationContext* opCtx) {
     } catch (const ExceptionFor<ErrorCodes::CursorNotFound>& ex) {
         invariant(_background);
         // End the validation if we can't open a checkpoint cursor on the collection.
-        log() << "Skipping background validation on collection '" << _nss
-              << "' because the collection is not yet in a checkpoint: " << ex;
+        LOGV2("Skipping background validation on collection '{}' because the collection is not yet in a checkpoint: {}", "_nss"_attr = _nss, "ex"_attr = ex);
         throw;
     }
 
@@ -183,8 +183,7 @@ void ValidateState::initializeCursors(OperationContext* opCtx) {
             opCtx, _collection->getCatalogId(), &readyDurableIndexes);
     } catch (const ExceptionFor<ErrorCodes::CursorNotFound>& ex) {
         invariant(_background);
-        log() << "Skipping background validation on collection '" << _nss
-              << "' because the data is not yet in a checkpoint: " << ex;
+        LOGV2("Skipping background validation on collection '{}' because the data is not yet in a checkpoint: {}", "_nss"_attr = _nss, "ex"_attr = ex);
         throw;
     }
 
@@ -202,8 +201,7 @@ void ValidateState::initializeCursors(OperationContext* opCtx) {
             std::find(readyDurableIndexes.begin(), readyDurableIndexes.end(), desc->indexName()) !=
             readyDurableIndexes.end();
         if (_background && !isIndexDurable) {
-            log() << "Skipping validation on index '" << desc->indexName() << "' in collection '"
-                  << _nss << "' because the index is not yet in a checkpoint.";
+            LOGV2("Skipping validation on index '{}' in collection '{}' because the index is not yet in a checkpoint.", "desc_indexName"_attr = desc->indexName(), "_nss"_attr = _nss);
             continue;
         }
 
@@ -216,8 +214,7 @@ void ValidateState::initializeCursors(OperationContext* opCtx) {
             opCtx->getServiceContext()->getStorageEngine()->getCatalog()->getIndexIdent(
                 opCtx, _collection->getCatalogId(), desc->indexName());
         if (entry->getIdent() != diskIndexIdent) {
-            log() << "Skipping validation on index '" << desc->indexName() << "' in collection '"
-                  << _nss << "' because the index was recreated and is not yet in a checkpoint.";
+            LOGV2("Skipping validation on index '{}' in collection '{}' because the index was recreated and is not yet in a checkpoint.", "desc_indexName"_attr = desc->indexName(), "_nss"_attr = _nss);
             continue;
         }
 
@@ -229,8 +226,7 @@ void ValidateState::initializeCursors(OperationContext* opCtx) {
             invariant(_background);
             // This can only happen if the checkpoint has the MDB catalog entry for the index, but
             // not the corresponding index table.
-            log() << "Skipping validation on index '" << desc->indexName() << "' in collection '"
-                  << _nss << "' because the index data is not in a checkpoint: " << ex;
+            LOGV2("Skipping validation on index '{}' in collection '{}' because the index data is not in a checkpoint: {}", "desc_indexName"_attr = desc->indexName(), "_nss"_attr = _nss, "ex"_attr = ex);
             continue;
         }
 
@@ -240,8 +236,7 @@ void ValidateState::initializeCursors(OperationContext* opCtx) {
             opCtx->getServiceContext()->getStorageEngine()->isInIndividuallyCheckpointedIndexesList(
                 diskIndexIdent)) {
             _indexCursors.erase(desc->indexName());
-            log() << "Skipping validation on index '" << desc->indexName() << "' in collection '"
-                  << _nss << "' because the index data is not yet consistent in the checkpoint.";
+            LOGV2("Skipping validation on index '{}' in collection '{}' because the index data is not yet consistent in the checkpoint.", "desc_indexName"_attr = desc->indexName(), "_nss"_attr = _nss);
             continue;
         }
 
@@ -266,7 +261,7 @@ void ValidateState::_relockDatabaseAndCollection(OperationContext* opCtx) {
     _databaseLock.reset();
 
     if (MONGO_unlikely(hangDuringYieldingLocksForValidation.shouldFail())) {
-        log() << "Hanging on fail point 'hangDuringYieldingLocksForValidation'";
+        LOGV2("Hanging on fail point 'hangDuringYieldingLocksForValidation'");
         hangDuringYieldingLocksForValidation.pauseWhileSet();
     }
 
diff --git a/src/mongo/db/catalog_raii_test.cpp b/src/mongo/db/catalog_raii_test.cpp
index 97c67cd0f2..c0839b76a9 100644
--- a/src/mongo/db/catalog_raii_test.cpp
+++ b/src/mongo/db/catalog_raii_test.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/concurrency/lock_state.h"
 #include "mongo/db/service_context_test_fixture.h"
 #include "mongo/db/storage/recovery_unit_noop.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 #include "mongo/util/time_support.h"
@@ -79,7 +80,7 @@ void failsWithLockTimeout(std::function<void()> func, Milliseconds timeoutMillis
         func();
         FAIL("Should have gotten an exception due to timeout");
     } catch (const ExceptionFor<ErrorCodes::LockTimeout>& ex) {
-        log() << ex;
+        LOGV2("{}", "ex"_attr = ex);
         Date_t t2 = Date_t::now();
         ASSERT_GTE(t2 - t1, timeoutMillis);
     }
diff --git a/src/mongo/db/cloner.cpp b/src/mongo/db/cloner.cpp
index 3c3f97cd03..5a3ae70f2b 100644
--- a/src/mongo/db/cloner.cpp
+++ b/src/mongo/db/cloner.cpp
@@ -62,6 +62,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/storage/storage_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -155,7 +156,7 @@ struct Cloner::Fun {
                 if (now - lastLog >= 60) {
                     // report progress
                     if (lastLog)
-                        log() << "clone " << to_collection << ' ' << numSeen;
+                        LOGV2("clone {} {}", "to_collection"_attr = to_collection, "numSeen"_attr = numSeen);
                     lastLog = now;
                 }
                 opCtx->checkForInterrupt();
@@ -246,7 +247,7 @@ struct Cloner::Fun {
 
             static Rarely sampler;
             if (sampler.tick() && (time(nullptr) - saveLast > 60)) {
-                log() << numSeen << " objects cloned so far from collection " << from_collection;
+                LOGV2("{} objects cloned so far from collection {}", "numSeen"_attr = numSeen, "from_collection"_attr = from_collection);
                 saveLast = time(nullptr);
             }
         }
@@ -275,8 +276,7 @@ void Cloner::copy(OperationContext* opCtx,
                   const NamespaceString& to_collection,
                   const CloneOptions& opts,
                   Query query) {
-    LOG(2) << "\t\tcloning collection " << from_collection << " to " << to_collection << " on "
-           << _conn->getServerAddress() << " with filter " << redact(query.toString());
+    LOGV2_DEBUG(2, "\t\tcloning collection {} to {} on {} with filter {}", "from_collection"_attr = from_collection, "to_collection"_attr = to_collection, "_conn_getServerAddress"_attr = _conn->getServerAddress(), "redact_query_toString"_attr = redact(query.toString()));
 
     Fun f(opCtx, toDBName);
     f.numSeen = 0;
@@ -311,8 +311,7 @@ void Cloner::copyIndexes(OperationContext* opCtx,
                          const BSONObj& from_opts,
                          const std::list<BSONObj>& from_indexes,
                          const NamespaceString& to_collection) {
-    LOG(2) << "\t\t copyIndexes " << from_collection << " to " << to_collection << " on "
-           << _conn->getServerAddress();
+    LOGV2_DEBUG(2, "\t\t copyIndexes {} to {} on {}", "from_collection"_attr = from_collection, "to_collection"_attr = to_collection, "_conn_getServerAddress"_attr = _conn->getServerAddress());
 
     uassert(ErrorCodes::PrimarySteppedDown,
             str::stream() << "Not primary while copying indexes from " << from_collection.ns()
@@ -506,8 +505,7 @@ bool Cloner::copyCollection(OperationContext* opCtx,
             return result;
         }
     } else {
-        LOG(1) << "No collection info found for ns:" << nss.toString()
-               << ", host:" << _conn->getServerAddress();
+        LOGV2_DEBUG(1, "No collection info found for ns:{}, host:{}", "nss_toString"_attr = nss.toString(), "_conn_getServerAddress"_attr = _conn->getServerAddress());
     }
 
     // main data
@@ -517,7 +515,7 @@ bool Cloner::copyCollection(OperationContext* opCtx,
 
     /* TODO : copyIndexes bool does not seem to be implemented! */
     if (!shouldCopyIndexes) {
-        log() << "ERROR copy collection shouldCopyIndexes not implemented? " << ns;
+        LOGV2("ERROR copy collection shouldCopyIndexes not implemented? {}", "ns"_attr = ns);
     }
 
     // indexes
@@ -530,7 +528,7 @@ StatusWith<std::vector<BSONObj>> Cloner::filterCollectionsForClone(
     const CloneOptions& opts, const std::list<BSONObj>& initialCollections) {
     std::vector<BSONObj> finalCollections;
     for (auto&& collection : initialCollections) {
-        LOG(2) << "\t cloner got " << collection;
+        LOGV2_DEBUG(2, "\t cloner got {}", "collection"_attr = collection);
 
         BSONElement collectionOptions = collection["options"];
         if (collectionOptions.isABSONObj()) {
@@ -551,7 +549,7 @@ StatusWith<std::vector<BSONObj>> Cloner::filterCollectionsForClone(
 
         if (ns.isSystem()) {
             if (!ns.isLegalClientSystemNS()) {
-                LOG(2) << "\t\t not cloning because system collection";
+                LOGV2_DEBUG(2, "\t\t not cloning because system collection");
                 continue;
             }
         }
@@ -785,7 +783,7 @@ Status Cloner::copyDb(OperationContext* opCtx,
                 continue;
             }
 
-            LOG(2) << "  really will clone: " << params.collectionInfo;
+            LOGV2_DEBUG(2, "  really will clone: {}", "params_collectionInfo"_attr = params.collectionInfo);
 
             const NamespaceString from_name(opts.fromDB, params.collectionName);
             const NamespaceString to_name(toDBName, params.collectionName);
@@ -794,7 +792,7 @@ Status Cloner::copyDb(OperationContext* opCtx,
                 clonedColls->insert(from_name.ns());
             }
 
-            LOG(1) << "\t\t cloning " << from_name << " -> " << to_name;
+            LOGV2_DEBUG(1, "\t\t cloning {} -> {}", "from_name"_attr = from_name, "to_name"_attr = to_name);
 
             copy(opCtx,
                  toDBName,
@@ -810,7 +808,7 @@ Status Cloner::copyDb(OperationContext* opCtx,
     // now build the secondary indexes
     if (opts.syncIndexes) {
         for (auto&& params : createCollectionParams) {
-            log() << "copying indexes for: " << params.collectionInfo;
+            LOGV2("copying indexes for: {}", "params_collectionInfo"_attr = params.collectionInfo);
 
             const NamespaceString from_name(opts.fromDB, params.collectionName);
             const NamespaceString to_name(toDBName, params.collectionName);
diff --git a/src/mongo/db/collection_index_builds_tracker.cpp b/src/mongo/db/collection_index_builds_tracker.cpp
index 40b4f292c2..b313a7f96b 100644
--- a/src/mongo/db/collection_index_builds_tracker.cpp
+++ b/src/mongo/db/collection_index_builds_tracker.cpp
@@ -34,6 +34,7 @@
 #include "mongo/db/collection_index_builds_tracker.h"
 
 #include "mongo/db/catalog/index_builds_manager.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -110,9 +111,9 @@ void CollectionIndexBuildsTracker::waitUntilNoIndexBuildsRemain(stdx::unique_loc
             return true;
         }
 
-        log() << "Waiting until the following index builds are finished:";
+        LOGV2("Waiting until the following index builds are finished:");
         for (const auto& indexBuild : _buildStateByBuildUUID) {
-            log() << "    Index build with UUID: " << indexBuild.first;
+            LOGV2("    Index build with UUID: {}", "indexBuild_first"_attr = indexBuild.first);
         }
 
         return false;
diff --git a/src/mongo/db/commands.cpp b/src/mongo/db/commands.cpp
index e67e02b8c8..340b56e090 100644
--- a/src/mongo/db/commands.cpp
+++ b/src/mongo/db/commands.cpp
@@ -54,6 +54,7 @@
 #include "mongo/db/jsobj.h"
 #include "mongo/db/namespace_string.h"
 #include "mongo/db/read_write_concern_defaults.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/factory.h"
 #include "mongo/rpc/metadata/client_metadata_ismaster.h"
 #include "mongo/rpc/op_msg_rpc_impls.h"
@@ -534,15 +535,12 @@ void CommandHelpers::evaluateFailCommandFailPoint(OperationContext* opCtx,
 
             if (closeConnection) {
                 opCtx->getClient()->session()->end();
-                log() << "Failing command '" << commandName
-                      << "' via 'failCommand' failpoint. Action: closing connection.";
+                LOGV2("Failing command '{}' via 'failCommand' failpoint. Action: closing connection.", "commandName"_attr = commandName);
                 uasserted(50985, "Failing command due to 'failCommand' failpoint");
             }
 
             if (hasErrorCode) {
-                log() << "Failing command '" << commandName
-                      << "' via 'failCommand' failpoint. Action: returning error code " << errorCode
-                      << ".";
+                LOGV2("Failing command '{}' via 'failCommand' failpoint. Action: returning error code {}.", "commandName"_attr = commandName, "errorCode"_attr = errorCode);
                 uasserted(ErrorCodes::Error(errorCode),
                           "Failing command due to 'failCommand' failpoint");
             }
@@ -604,7 +602,7 @@ void CommandInvocation::checkAuthorization(OperationContext* opCtx,
             }
         }
     } catch (const DBException& e) {
-        log(LogComponent::kAccessControl) << e.toStatus();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kAccessControl).toInt(), "{}", "e_toStatus"_attr = e.toStatus());
         CommandHelpers::auditLogAuthEvent(opCtx, this, request, e.code());
         throw;
     }
diff --git a/src/mongo/db/commands/authentication_commands.cpp b/src/mongo/db/commands/authentication_commands.cpp
index dd273d77fa..43a5b66b7e 100644
--- a/src/mongo/db/commands/authentication_commands.cpp
+++ b/src/mongo/db/commands/authentication_commands.cpp
@@ -52,6 +52,7 @@
 #include "mongo/db/commands.h"
 #include "mongo/db/commands/test_commands_enabled.h"
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/rpc/metadata/client_metadata.h"
 #include "mongo/rpc/metadata/client_metadata_ismaster.h"
@@ -254,7 +255,7 @@ bool CmdAuthenticate::run(OperationContext* opCtx,
     CommandHelpers::handleMarkKillOnClientDisconnect(opCtx);
     if (!serverGlobalParams.quiet.load()) {
         mutablebson::Document cmdToLog(cmdObj, mutablebson::Document::kInPlaceDisabled);
-        log() << " authenticate db: " << dbname << " " << cmdToLog;
+        LOGV2(" authenticate db: {} {}", "dbname"_attr = dbname, "cmdToLog"_attr = cmdToLog);
     }
     std::string mechanism = cmdObj.getStringField("mechanism");
     if (mechanism.empty()) {
@@ -283,8 +284,7 @@ bool CmdAuthenticate::run(OperationContext* opCtx,
     if (!status.isOK()) {
         if (!serverGlobalParams.quiet.load()) {
             auto const client = opCtx->getClient();
-            log() << "Failed to authenticate " << user << " from client " << client->getRemote()
-                  << " with mechanism " << mechanism << ": " << status;
+            LOGV2("Failed to authenticate {} from client {} with mechanism {}: {}", "user"_attr = user, "client_getRemote"_attr = client->getRemote(), "mechanism"_attr = mechanism, "status"_attr = status);
         }
         sleepmillis(saslGlobalParams.authFailedDelay.load());
         if (status.code() == ErrorCodes::AuthenticationFailed) {
@@ -298,8 +298,7 @@ bool CmdAuthenticate::run(OperationContext* opCtx,
     }
 
     if (!serverGlobalParams.quiet.load()) {
-        log() << "Successfully authenticated as principal " << user.getUser() << " on "
-              << user.getDB() << " from client " << opCtx->getClient()->session()->remote();
+        LOGV2("Successfully authenticated as principal {} on {} from client {}", "user_getUser"_attr = user.getUser(), "user_getDB"_attr = user.getDB(), "opCtx_getClient_session_remote"_attr = opCtx->getClient()->session()->remote());
     }
 
     result.append("dbname", user.getDB());
diff --git a/src/mongo/db/commands/create_indexes.cpp b/src/mongo/db/commands/create_indexes.cpp
index 6b2b702d38..78c5fbda0f 100644
--- a/src/mongo/db/commands/create_indexes.cpp
+++ b/src/mongo/db/commands/create_indexes.cpp
@@ -61,6 +61,7 @@
 #include "mongo/db/s/database_sharding_state.h"
 #include "mongo/db/server_options.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/compiler.h"
 #include "mongo/s/shard_key_pattern.h"
 #include "mongo/util/log.h"
@@ -464,8 +465,8 @@ BSONObj runCreateIndexesOnNewCollection(OperationContext* opCtx,
     if (MONGO_unlikely(hangBeforeCreateIndexesCollectionCreate.shouldFail())) {
         // Simulate a scenario where a conflicting collection creation occurs
         // mid-index build.
-        log() << "Hanging create collection due to failpoint "
-                 "'hangBeforeCreateIndexesCollectionCreate'";
+        LOGV2("Hanging create collection due to failpoint "
+                 "'hangBeforeCreateIndexesCollectionCreate'");
         hangBeforeCreateIndexesCollectionCreate.pauseWhileSet();
     }
 
@@ -656,7 +657,7 @@ bool runCreateIndexesForMobile(OperationContext* opCtx,
     }
 
     if (MONGO_unlikely(hangAfterIndexBuildDumpsInsertsFromBulk.shouldFail())) {
-        log() << "Hanging after dumping inserts from bulk builder";
+        LOGV2("Hanging after dumping inserts from bulk builder");
         hangAfterIndexBuildDumpsInsertsFromBulk.pauseWhileSet();
     }
 
@@ -680,7 +681,7 @@ bool runCreateIndexesForMobile(OperationContext* opCtx,
     }
 
     if (MONGO_unlikely(hangAfterIndexBuildFirstDrain.shouldFail())) {
-        log() << "Hanging after index build first drain";
+        LOGV2("Hanging after index build first drain");
         hangAfterIndexBuildFirstDrain.pauseWhileSet();
     }
 
@@ -704,7 +705,7 @@ bool runCreateIndexesForMobile(OperationContext* opCtx,
     }
 
     if (MONGO_unlikely(hangAfterIndexBuildSecondDrain.shouldFail())) {
-        log() << "Hanging after index build second drain";
+        LOGV2("Hanging after index build second drain");
         hangAfterIndexBuildSecondDrain.pauseWhileSet();
     }
 
@@ -842,7 +843,7 @@ bool runCreateIndexesWithCoordinator(OperationContext* opCtx,
     auto protocol = IndexBuildsCoordinator::supportsTwoPhaseIndexBuild()
         ? IndexBuildProtocol::kTwoPhase
         : IndexBuildProtocol::kSinglePhase;
-    log() << "Registering index build: " << buildUUID;
+    LOGV2("Registering index build: {}", "buildUUID"_attr = buildUUID);
     ReplIndexBuildState::IndexCatalogStats stats;
     IndexBuildsCoordinator::IndexBuildOptions indexBuildOptions = {commitQuorum};
 
@@ -853,17 +854,16 @@ bool runCreateIndexesWithCoordinator(OperationContext* opCtx,
         auto deadline = opCtx->getDeadline();
         // Date_t::max() means no deadline.
         if (deadline == Date_t::max()) {
-            log() << "Waiting for index build to complete: " << buildUUID;
+            LOGV2("Waiting for index build to complete: {}", "buildUUID"_attr = buildUUID);
         } else {
-            log() << "Waiting for index build to complete: " << buildUUID
-                  << " (deadline: " << deadline << ")";
+            LOGV2("Waiting for index build to complete: {} (deadline: {})", "buildUUID"_attr = buildUUID, "deadline"_attr = deadline);
         }
 
         // Throws on error.
         try {
             stats = buildIndexFuture.get(opCtx);
         } catch (const ExceptionForCat<ErrorCategory::Interruption>& interruptionEx) {
-            log() << "Index build interrupted: " << buildUUID << ": " << interruptionEx;
+            LOGV2("Index build interrupted: {}: {}", "buildUUID"_attr = buildUUID, "interruptionEx"_attr = interruptionEx);
 
             // If this node is no longer a primary, the index build will continue to run in the
             // background and will complete when this node receives a commitIndexBuild oplog entry
@@ -871,7 +871,7 @@ bool runCreateIndexesWithCoordinator(OperationContext* opCtx,
 
             if (indexBuildsCoord->supportsTwoPhaseIndexBuild() &&
                 ErrorCodes::InterruptedDueToReplStateChange == interruptionEx.code()) {
-                log() << "Index build continuing in background: " << buildUUID;
+                LOGV2("Index build continuing in background: {}", "buildUUID"_attr = buildUUID);
                 throw;
             }
 
@@ -885,18 +885,17 @@ bool runCreateIndexesWithCoordinator(OperationContext* opCtx,
                 buildUUID,
                 str::stream() << "Index build interrupted: " << buildUUID << ": "
                               << interruptionEx.toString());
-            log() << "Index build aborted: " << buildUUID;
+            LOGV2("Index build aborted: {}", "buildUUID"_attr = buildUUID);
 
             throw;
         } catch (const ExceptionForCat<ErrorCategory::NotMasterError>& ex) {
-            log() << "Index build interrupted due to change in replication state: " << buildUUID
-                  << ": " << ex;
+            LOGV2("Index build interrupted due to change in replication state: {}: {}", "buildUUID"_attr = buildUUID, "ex"_attr = ex);
 
             // The index build will continue to run in the background and will complete when this
             // node receives a commitIndexBuild oplog entry from the new primary.
 
             if (indexBuildsCoord->supportsTwoPhaseIndexBuild()) {
-                log() << "Index build continuing in background: " << buildUUID;
+                LOGV2("Index build continuing in background: {}", "buildUUID"_attr = buildUUID);
                 throw;
             }
 
@@ -905,24 +904,24 @@ bool runCreateIndexesWithCoordinator(OperationContext* opCtx,
                 buildUUID,
                 str::stream() << "Index build interrupted due to change in replication state: "
                               << buildUUID << ": " << ex.toString());
-            log() << "Index build aborted due to NotMaster error: " << buildUUID;
+            LOGV2("Index build aborted due to NotMaster error: {}", "buildUUID"_attr = buildUUID);
 
             throw;
         }
 
-        log() << "Index build completed: " << buildUUID;
+        LOGV2("Index build completed: {}", "buildUUID"_attr = buildUUID);
     } catch (DBException& ex) {
         // If the collection is dropped after the initial checks in this function (before the
         // AutoStatsTracker is created), the IndexBuildsCoordinator (either startIndexBuild() or
         // the the task running the index build) may return NamespaceNotFound. This is not
         // considered an error and the command should return success.
         if (ErrorCodes::NamespaceNotFound == ex.code()) {
-            log() << "Index build failed: " << buildUUID << ": collection dropped: " << ns;
+            LOGV2("Index build failed: {}: collection dropped: {}", "buildUUID"_attr = buildUUID, "ns"_attr = ns);
             return true;
         }
 
         // All other errors should be forwarded to the caller with index build information included.
-        log() << "Index build failed: " << buildUUID << ": " << ex.toStatus();
+        LOGV2("Index build failed: {}: {}", "buildUUID"_attr = buildUUID, "ex_toStatus"_attr = ex.toStatus());
         ex.addContext(str::stream() << "Index build failed: " << buildUUID << ": Collection " << ns
                                     << " ( " << *collectionUUID << " )");
 
@@ -1000,12 +999,8 @@ public:
                 }
                 if (shouldLogMessageOnAlreadyBuildingError) {
                     auto bsonElem = cmdObj.getField(kIndexesFieldName);
-                    log()
-                        << "Received a request to create indexes: '" << bsonElem
-                        << "', but found that at least one of the indexes is already being built, '"
-                        << ex.toStatus()
-                        << "'. This request will wait for the pre-existing index build to finish "
-                           "before proceeding.";
+                    LOGV2("Received a request to create indexes: '{}', but found that at least one of the indexes is already being built, '{}'. This request will wait for the pre-existing index build to finish "
+                           "before proceeding.", "bsonElem"_attr = bsonElem, "ex_toStatus"_attr = ex.toStatus());
                     shouldLogMessageOnAlreadyBuildingError = false;
                 }
                 // Unset the response fields so we do not write duplicate fields.
diff --git a/src/mongo/db/commands/dbcheck.cpp b/src/mongo/db/commands/dbcheck.cpp
index c933dd6ad3..df0f8359f4 100644
--- a/src/mongo/db/commands/dbcheck.cpp
+++ b/src/mongo/db/commands/dbcheck.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/repl/optime.h"
 #include "mongo/util/background.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -210,7 +211,7 @@ protected:
             }
 
             if (_done) {
-                log() << "dbCheck terminated due to stepdown";
+                LOGV2("dbCheck terminated due to stepdown");
                 return;
             }
         }
diff --git a/src/mongo/db/commands/dbcommands_d.cpp b/src/mongo/db/commands/dbcommands_d.cpp
index 63d1335159..c7bc712bcd 100644
--- a/src/mongo/db/commands/dbcommands_d.cpp
+++ b/src/mongo/db/commands/dbcommands_d.cpp
@@ -86,6 +86,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/stats/storage_stats.h"
 #include "mongo/db/write_concern.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/stale_exception.h"
 #include "mongo/scripting/engine.h"
 #include "mongo/util/fail_point.h"
@@ -277,7 +278,7 @@ public:
                     if (partialOk) {
                         break;  // skipped chunk is probably on another shard
                     }
-                    log() << "should have chunk: " << n << " have:" << myn;
+                    LOGV2("should have chunk: {} have:{}", "n"_attr = n, "myn"_attr = myn);
                     dumpChunks(opCtx, nss.ns(), query, sort);
                     uassert(10040, "chunks out of order", n == myn);
                 }
@@ -312,7 +313,7 @@ public:
                     // RELOCKED
                     ctx.reset(new AutoGetCollectionForReadCommand(opCtx, nss));
                 } catch (const StaleConfigException&) {
-                    LOG(1) << "chunk metadata changed during filemd5, will retarget and continue";
+                    LOGV2_DEBUG(1, "chunk metadata changed during filemd5, will retarget and continue");
                     break;
                 }
 
@@ -347,7 +348,7 @@ public:
         q.sort(sort);
         unique_ptr<DBClientCursor> c = client.query(NamespaceString(ns), q);
         while (c->more()) {
-            log() << c->nextSafe();
+            LOGV2("{}", "c_nextSafe"_attr = c->nextSafe());
         }
     }
 
diff --git a/src/mongo/db/commands/dbhash.cpp b/src/mongo/db/commands/dbhash.cpp
index da18168956..ed1b35ec62 100644
--- a/src/mongo/db/commands/dbhash.cpp
+++ b/src/mongo/db/commands/dbhash.cpp
@@ -50,6 +50,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/storage/storage_engine.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/util/log.h"
 #include "mongo/util/md5.hpp"
@@ -370,7 +371,7 @@ private:
             exec = InternalPlanner::collectionScan(
                 opCtx, nss.ns(), collection, PlanExecutor::NO_YIELD);
         } else {
-            log() << "can't find _id index for: " << nss;
+            LOGV2("can't find _id index for: {}", "nss"_attr = nss);
             return "no _id _index";
         }
 
diff --git a/src/mongo/db/commands/drop_indexes.cpp b/src/mongo/db/commands/drop_indexes.cpp
index 033023ec71..027e51ad0b 100644
--- a/src/mongo/db/commands/drop_indexes.cpp
+++ b/src/mongo/db/commands/drop_indexes.cpp
@@ -53,6 +53,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/quick_exit.h"
 
@@ -126,7 +127,7 @@ public:
         const NamespaceString toReIndexNss =
             CommandHelpers::parseNsCollectionRequired(dbname, jsobj);
 
-        LOG(0) << "CMD: reIndex " << toReIndexNss;
+        LOGV2("CMD: reIndex {}", "toReIndexNss"_attr = toReIndexNss);
 
         AutoGetCollection autoColl(opCtx, toReIndexNss, MODE_X);
         Collection* collection = autoColl.getCollection();
@@ -219,7 +220,7 @@ public:
         }
 
         if (MONGO_unlikely(reIndexCrashAfterDrop.shouldFail())) {
-            log() << "exiting because 'reIndexCrashAfterDrop' fail point was set";
+            LOGV2("exiting because 'reIndexCrashAfterDrop' fail point was set");
             quickExit(EXIT_ABRUPT);
         }
 
diff --git a/src/mongo/db/commands/feature_compatibility_version.cpp b/src/mongo/db/commands/feature_compatibility_version.cpp
index 8e7cf3b8d9..8716ebfef5 100644
--- a/src/mongo/db/commands/feature_compatibility_version.cpp
+++ b/src/mongo/db/commands/feature_compatibility_version.cpp
@@ -51,6 +51,7 @@
 #include "mongo/db/wire_version.h"
 #include "mongo/db/write_concern_options.h"
 #include "mongo/executor/egress_tag_closer_manager.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/grid.h"
@@ -157,8 +158,7 @@ void FeatureCompatibilityVersion::onInsertOrUpdate(OperationContext* opCtx, cons
         ? serverGlobalParams.featureCompatibility.getVersion() != newVersion
         : true;
     if (isDifferent) {
-        log() << "setting featureCompatibilityVersion to "
-              << FeatureCompatibilityVersionParser::toString(newVersion);
+        LOGV2("setting featureCompatibilityVersion to {}", "FeatureCompatibilityVersionParser_toString_newVersion"_attr = FeatureCompatibilityVersionParser::toString(newVersion));
     }
 
     opCtx->recoveryUnit()->onCommit([opCtx, newVersion](boost::optional<Timestamp>) {
@@ -178,9 +178,9 @@ void FeatureCompatibilityVersion::onInsertOrUpdate(OperationContext* opCtx, cons
 
         if (newVersion != ServerGlobalParams::FeatureCompatibility::Version::kFullyUpgradedTo44) {
             if (MONGO_unlikely(hangBeforeAbortingRunningTransactionsOnFCVDowngrade.shouldFail())) {
-                log() << "featureCompatibilityVersion - "
+                LOGV2("featureCompatibilityVersion - "
                          "hangBeforeAbortingRunningTransactionsOnFCVDowngrade fail point enabled. "
-                         "Blocking until fail point is disabled.";
+                         "Blocking until fail point is disabled.");
                 hangBeforeAbortingRunningTransactionsOnFCVDowngrade.pauseWhileSet();
             }
             // Abort all open transactions when downgrading the featureCompatibilityVersion.
diff --git a/src/mongo/db/commands/fsync.cpp b/src/mongo/db/commands/fsync.cpp
index 25bedb64ba..d5a7670413 100644
--- a/src/mongo/db/commands/fsync.cpp
+++ b/src/mongo/db/commands/fsync.cpp
@@ -49,6 +49,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/backup_cursor_hooks.h"
 #include "mongo/db/storage/storage_engine.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/condition_variable.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/background.h"
@@ -136,7 +137,7 @@ public:
         const bool sync =
             !cmdObj["async"].trueValue();  // async means do an fsync, but return immediately
         const bool lock = cmdObj["lock"].trueValue();
-        log() << "CMD fsync: sync:" << sync << " lock:" << lock;
+        LOGV2("CMD fsync: sync:{} lock:{}", "sync"_attr = sync, "lock"_attr = lock);
 
         // fsync + lock is sometimes used to block writes out of the system and does not care if
         // the `BackupCursorService::fsyncLock` call succeeds.
@@ -187,9 +188,9 @@ public:
             }
         }
 
-        log() << "mongod is locked and no writes are allowed. db.fsyncUnlock() to unlock";
-        log() << "Lock count is " << getLockCount();
-        log() << "    For more info see " << FSyncCommand::url();
+        LOGV2("mongod is locked and no writes are allowed. db.fsyncUnlock() to unlock");
+        LOGV2("Lock count is {}", "getLockCount"_attr = getLockCount());
+        LOGV2("    For more info see {}", "FSyncCommand_url"_attr = FSyncCommand::url());
         result.append("info", "now locked against writes, use db.fsyncUnlock() to unlock");
         result.append("lockCount", getLockCount());
         result.append("seeAlso", FSyncCommand::url());
@@ -298,7 +299,7 @@ public:
                    const BSONObj& cmdObj,
                    std::string& errmsg,
                    BSONObjBuilder& result) override {
-        log() << "command: unlock requested";
+        LOGV2("command: unlock requested");
 
         Lock::ExclusiveLock lk(opCtx->lockState(), commandMutex);
 
@@ -318,11 +319,11 @@ public:
             // If we're still locked then lock count is not zero.
             invariant(lockCount > 0);
             lockCount = fsyncCmd.getLockCount_inLock();
-            log() << "fsyncUnlock completed. Lock count is now " << lockCount;
+            LOGV2("fsyncUnlock completed. Lock count is now {}", "lockCount"_attr = lockCount);
         } else {
             invariant(fsyncCmd.getLockCount() == 0);
             lockCount = 0;
-            log() << "fsyncUnlock completed. mongod is now unlocked and free to accept writes";
+            LOGV2("fsyncUnlock completed. mongod is now unlocked and free to accept writes");
         }
 
         result.append("info", str::stream() << "fsyncUnlock completed");
diff --git a/src/mongo/db/commands/generic_servers.cpp b/src/mongo/db/commands/generic_servers.cpp
index 88c137982a..bbca48ac69 100644
--- a/src/mongo/db/commands/generic_servers.cpp
+++ b/src/mongo/db/commands/generic_servers.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/commands/shutdown.h"
 #include "mongo/db/commands/test_commands_enabled.h"
 #include "mongo/db/log_process_details.h"
+#include "mongo/logv2/log.h"
 #include "mongo/logv2/ramlog.h"
 #include "mongo/scripting/engine.h"
 #include "mongo/util/exit.h"
@@ -354,7 +355,7 @@ void CmdShutdown::shutdownHelper(const BSONObj& cmdObj) {
         ::abort();
     });
 
-    log() << "terminating, shutdown command received " << cmdObj;
+    LOGV2("terminating, shutdown command received {}", "cmdObj"_attr = cmdObj);
 
 #if defined(_WIN32)
     // Signal the ServiceMain thread to shutdown.
diff --git a/src/mongo/db/commands/get_last_error.cpp b/src/mongo/db/commands/get_last_error.cpp
index 1b674dd6ef..b00ac88838 100644
--- a/src/mongo/db/commands/get_last_error.cpp
+++ b/src/mongo/db/commands/get_last_error.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/repl/repl_client_info.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/write_concern.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -263,8 +264,7 @@ public:
                 }
             } else {
                 if (electionId != repl::ReplicationCoordinator::get(opCtx)->getElectionId()) {
-                    LOG(3) << "oid passed in is " << electionId << ", but our id is "
-                           << repl::ReplicationCoordinator::get(opCtx)->getElectionId();
+                    LOGV2_DEBUG(3, "oid passed in is {}, but our id is {}", "electionId"_attr = electionId, "repl_ReplicationCoordinator_get_opCtx_getElectionId"_attr = repl::ReplicationCoordinator::get(opCtx)->getElectionId());
                     errmsg = "election occurred after write";
                     result.append("code", ErrorCodes::WriteConcernFailed);
                     result.append("codeName",
diff --git a/src/mongo/db/commands/getmore_cmd.cpp b/src/mongo/db/commands/getmore_cmd.cpp
index d0129eaba5..507a7edc8e 100644
--- a/src/mongo/db/commands/getmore_cmd.cpp
+++ b/src/mongo/db/commands/getmore_cmd.cpp
@@ -57,6 +57,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/stats/counters.h"
 #include "mongo/db/stats/top.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/chunk_version.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -413,8 +414,8 @@ public:
                           ClientCursorParams::LockPolicy::kLockExternally);
 
                 if (MONGO_unlikely(GetMoreHangBeforeReadLock.shouldFail())) {
-                    log() << "GetMoreHangBeforeReadLock fail point enabled. Blocking until fail "
-                             "point is disabled.";
+                    LOGV2("GetMoreHangBeforeReadLock fail point enabled. Blocking until fail "
+                             "point is disabled.");
                     GetMoreHangBeforeReadLock.pauseWhileSet(opCtx);
                 }
 
diff --git a/src/mongo/db/commands/index_filter_commands.cpp b/src/mongo/db/commands/index_filter_commands.cpp
index 59dd614002..0c51dd46c4 100644
--- a/src/mongo/db/commands/index_filter_commands.cpp
+++ b/src/mongo/db/commands/index_filter_commands.cpp
@@ -50,6 +50,7 @@
 #include "mongo/db/matcher/extensions_callback_real.h"
 #include "mongo/db/namespace_string.h"
 #include "mongo/db/query/collection_query_info.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/unordered_set.h"
 #include "mongo/util/log.h"
 
@@ -264,7 +265,7 @@ Status ClearFilters::clear(OperationContext* opCtx,
         // Remove entry from plan cache
         planCache->remove(*cq).transitional_ignore();
 
-        LOG(0) << "Removed index filter on " << redact(cq->toStringShort());
+        LOGV2("Removed index filter on {}", "redact_cq_toStringShort"_attr = redact(cq->toStringShort()));
 
         return Status::OK();
     }
@@ -320,7 +321,7 @@ Status ClearFilters::clear(OperationContext* opCtx,
         planCache->remove(*cq).transitional_ignore();
     }
 
-    LOG(0) << "Removed all index filters for collection: " << ns;
+    LOGV2("Removed all index filters for collection: {}", "ns"_attr = ns);
 
     return Status::OK();
 }
@@ -397,7 +398,7 @@ Status SetFilter::set(OperationContext* opCtx,
     // Remove entry from plan cache.
     planCache->remove(*cq).transitional_ignore();
 
-    LOG(0) << "Index filter set on " << redact(cq->toStringShort()) << " " << indexesElt;
+    LOGV2("Index filter set on {} {}", "redact_cq_toStringShort"_attr = redact(cq->toStringShort()), "indexesElt"_attr = indexesElt);
 
     return Status::OK();
 }
diff --git a/src/mongo/db/commands/kill_op.cpp b/src/mongo/db/commands/kill_op.cpp
index 5a9b639427..6301ff092e 100644
--- a/src/mongo/db/commands/kill_op.cpp
+++ b/src/mongo/db/commands/kill_op.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/commands/kill_op_cmd_base.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 
@@ -58,7 +59,7 @@ public:
 
         // Used by tests to check if auth checks passed.
         result.append("info", "attempting to kill op");
-        log() << "going to kill op: " << opId;
+        LOGV2("going to kill op: {}", "opId"_attr = opId);
         KillOpCmdBase::killLocalOperation(opCtx, opId);
 
         // killOp always reports success once past the auth check.
diff --git a/src/mongo/db/commands/mr.cpp b/src/mongo/db/commands/mr.cpp
index df22782ff0..d4ed70dfb8 100644
--- a/src/mongo/db/commands/mr.cpp
+++ b/src/mongo/db/commands/mr.cpp
@@ -65,6 +65,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/durable_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/parallel.h"
@@ -944,7 +945,7 @@ State::~State() {
             _scope->invoke(cleanup, nullptr, nullptr, 0, true);
         } catch (const DBException&) {
             // not important because properties will be reset if scope is reused
-            LOG(1) << "MapReduce terminated during state destruction";
+            LOGV2_DEBUG(1, "MapReduce terminated during state destruction");
         }
     }
 }
@@ -1086,7 +1087,7 @@ void State::switchMode(bool jsMode) {
 }
 
 void State::bailFromJS() {
-    LOG(1) << "M/R: Switching from JS mode to mixed mode";
+    LOGV2_DEBUG(1, "M/R: Switching from JS mode to mixed mode");
 
     // reduce and reemit into c++
     switchMode(false);
@@ -1363,9 +1364,7 @@ void State::reduceAndSpillInMemoryStateIfNeeded() {
             // reduce now to lower mem usage
             Timer t;
             _scope->invoke(_reduceAll, nullptr, nullptr, 0, true);
-            LOG(3) << "  MR - did reduceAll: keys=" << keyCt << " dups=" << dupCt
-                   << " newKeys=" << _scope->getNumberInt("_keyCt") << " time=" << t.millis()
-                   << "ms";
+            LOGV2_DEBUG(3, "  MR - did reduceAll: keys={} dups={} newKeys={} time={}ms", "keyCt"_attr = keyCt, "dupCt"_attr = dupCt, "_scope_getNumberInt__keyCt"_attr = _scope->getNumberInt("_keyCt"), "t_millis"_attr = t.millis());
             return;
         }
     }
@@ -1378,13 +1377,12 @@ void State::reduceAndSpillInMemoryStateIfNeeded() {
         long oldSize = _size;
         Timer t;
         reduceInMemory();
-        LOG(3) << "  MR - did reduceInMemory: size=" << oldSize << " dups=" << _dupCount
-               << " newSize=" << _size << " time=" << t.millis() << "ms";
+        LOGV2_DEBUG(3, "  MR - did reduceInMemory: size={} dups={} newSize={} time={}ms", "oldSize"_attr = oldSize, "_dupCount"_attr = _dupCount, "_size"_attr = _size, "t_millis"_attr = t.millis());
 
         // if size is still high, or values are not reducing well, dump
         if (_onDisk && (_size > _config.maxInMemSize || _size > oldSize / 2)) {
             dumpToInc();
-            LOG(3) << "  MR - dumping to db";
+            LOGV2_DEBUG(3, "  MR - dumping to db");
         }
     }
 }
@@ -1411,7 +1409,7 @@ bool runMapReduce(OperationContext* opCtx,
 
     const Config config(dbname, cmd);
 
-    LOG(1) << "mr ns: " << config.nss;
+    LOGV2_DEBUG(1, "mr ns: {}", "config_nss"_attr = config.nss);
 
     uassert(16149, "cannot run map reduce without the js engine", getGlobalScriptEngine());
 
@@ -1632,19 +1630,19 @@ bool runMapReduce(OperationContext* opCtx,
             return false;
         }
     } catch (StaleConfigException& e) {
-        log() << "mr detected stale config, should retry" << redact(e);
+        LOGV2("mr detected stale config, should retry{}", "redact_e"_attr = redact(e));
         throw;
     }
     // TODO:  The error handling code for queries is v. fragile,
     // *requires* rethrow AssertionExceptions - should probably fix.
     catch (AssertionException& e) {
-        log() << "mr failed, removing collection" << redact(e);
+        LOGV2("mr failed, removing collection{}", "redact_e"_attr = redact(e));
         throw;
     } catch (std::exception& e) {
-        log() << "mr failed, removing collection" << causedBy(e);
+        LOGV2("mr failed, removing collection{}", "causedBy_e"_attr = causedBy(e));
         throw;
     } catch (...) {
-        log() << "mr failed for unknown reason, removing collection";
+        LOGV2("mr failed for unknown reason, removing collection");
         throw;
     }
 
diff --git a/src/mongo/db/commands/oplog_note.cpp b/src/mongo/db/commands/oplog_note.cpp
index 2899d5b602..d2b449da94 100644
--- a/src/mongo/db/commands/oplog_note.cpp
+++ b/src/mongo/db/commands/oplog_note.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/repl/oplog.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -60,7 +61,7 @@ Status _performNoopWrite(OperationContext* opCtx, BSONObj msgObj, StringData not
         opCtx, MODE_IX, Date_t::now() + Milliseconds(1), Lock::InterruptBehavior::kLeaveUnlocked);
 
     if (!lock.isLocked()) {
-        LOG(1) << "Global lock is not available skipping noopWrite";
+        LOGV2_DEBUG(1, "Global lock is not available skipping noopWrite");
         return {ErrorCodes::LockFailed, "Global lock is not available"};
     }
 
diff --git a/src/mongo/db/commands/resize_oplog.cpp b/src/mongo/db/commands/resize_oplog.cpp
index 31c2153a8d..05bb9d46b4 100644
--- a/src/mongo/db/commands/resize_oplog.cpp
+++ b/src/mongo/db/commands/resize_oplog.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/jsobj.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/storage/durable_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -107,7 +108,7 @@ public:
             uassertStatusOK(status);
             DurableCatalog::get(opCtx)->updateCappedSize(opCtx, coll->getCatalogId(), size);
             wunit.commit();
-            LOG(0) << "replSetResizeOplog success, currentSize:" << size;
+            LOGV2("replSetResizeOplog success, currentSize:{}", "size"_attr = size);
             return true;
         });
     }
diff --git a/src/mongo/db/commands/restart_catalog_command.cpp b/src/mongo/db/commands/restart_catalog_command.cpp
index 99858abf37..7edd3a4d4c 100644
--- a/src/mongo/db/commands/restart_catalog_command.cpp
+++ b/src/mongo/db/commands/restart_catalog_command.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/commands.h"
 #include "mongo/db/commands/test_commands_enabled.h"
 #include "mongo/db/concurrency/d_concurrency.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -106,10 +107,10 @@ public:
             }
         }
 
-        log() << "Closing database catalog";
+        LOGV2("Closing database catalog");
         auto state = catalog::closeCatalog(opCtx);
 
-        log() << "Reopening database catalog";
+        LOGV2("Reopening database catalog");
         catalog::openCatalog(opCtx, state);
 
         return true;
diff --git a/src/mongo/db/commands/server_status.cpp b/src/mongo/db/commands/server_status.cpp
index 685332111b..75a4642859 100644
--- a/src/mongo/db/commands/server_status.cpp
+++ b/src/mongo/db/commands/server_status.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/commands/server_status_internal.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/stats/counters.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/http_client.h"
 #include "mongo/util/net/socket_utils.h"
@@ -145,7 +146,7 @@ public:
         timeBuilder.appendNumber("at end", durationCount<Milliseconds>(runElapsed));
         if (runElapsed > Milliseconds(1000)) {
             BSONObj t = timeBuilder.obj();
-            log() << "serverStatus was very slow: " << t;
+            LOGV2("serverStatus was very slow: {}", "t"_attr = t);
 
             bool include_timing = true;
             const auto& elem = cmdObj[kTimingSection];
diff --git a/src/mongo/db/commands/set_feature_compatibility_version_command.cpp b/src/mongo/db/commands/set_feature_compatibility_version_command.cpp
index dd825f5bab..64f70cef35 100644
--- a/src/mongo/db/commands/set_feature_compatibility_version_command.cpp
+++ b/src/mongo/db/commands/set_feature_compatibility_version_command.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/s/migration_util.h"
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog/type_collection.h"
 #include "mongo/s/database_version_helpers.h"
@@ -181,7 +182,7 @@ public:
             if (serverGlobalParams.clusterRole == ClusterRole::ShardServer) {
                 const auto shardingState = ShardingState::get(opCtx);
                 if (shardingState->enabled()) {
-                    LOG(0) << "Upgrade: submitting orphaned ranges for cleanup";
+                    LOGV2("Upgrade: submitting orphaned ranges for cleanup");
                     migrationutil::submitOrphanRangesForCleanup(opCtx);
                 }
 
@@ -204,7 +205,7 @@ public:
                                      << requestedVersion)))));
 
                 if (MONGO_unlikely(pauseBeforeUpgradingConfigMetadata.shouldFail())) {
-                    log() << "Hit pauseBeforeUpgradingConfigMetadata";
+                    LOGV2("Hit pauseBeforeUpgradingConfigMetadata");
                     pauseBeforeUpgradingConfigMetadata.pauseWhileSet(opCtx);
                 }
                 ShardingCatalogManager::get(opCtx)->upgradeOrDowngradeChunksAndTags(
@@ -242,7 +243,7 @@ public:
             }
 
             if (serverGlobalParams.clusterRole == ClusterRole::ShardServer) {
-                LOG(0) << "Downgrade: dropping config.rangeDeletions collection";
+                LOGV2("Downgrade: dropping config.rangeDeletions collection");
                 migrationutil::dropRangeDeletionsCollection(opCtx);
 
                 // The primary shard sharding a collection will write the initial chunks for a
@@ -264,7 +265,7 @@ public:
                                      << requestedVersion)))));
 
                 if (MONGO_unlikely(pauseBeforeDowngradingConfigMetadata.shouldFail())) {
-                    log() << "Hit pauseBeforeDowngradingConfigMetadata";
+                    LOGV2("Hit pauseBeforeDowngradingConfigMetadata");
                     pauseBeforeDowngradingConfigMetadata.pauseWhileSet(opCtx);
                 }
                 ShardingCatalogManager::get(opCtx)->upgradeOrDowngradeChunksAndTags(
diff --git a/src/mongo/db/commands/sleep_command.cpp b/src/mongo/db/commands/sleep_command.cpp
index 877ba3eacf..2458e7d600 100644
--- a/src/mongo/db/commands/sleep_command.cpp
+++ b/src/mongo/db/commands/sleep_command.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/commands/test_commands_enabled.h"
 #include "mongo/db/concurrency/d_concurrency.h"
 #include "mongo/db/concurrency/lock_manager_defs.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -118,7 +119,7 @@ public:
              const std::string& ns,
              const BSONObj& cmdObj,
              BSONObjBuilder& result) {
-        log() << "test only command sleep invoked";
+        LOGV2("test only command sleep invoked");
         long long msToSleep = 0;
 
         if (cmdObj["secs"] || cmdObj["seconds"] || cmdObj["millis"]) {
diff --git a/src/mongo/db/commands/test_commands.cpp b/src/mongo/db/commands/test_commands.cpp
index 81b7332b31..1140173872 100644
--- a/src/mongo/db/commands/test_commands.cpp
+++ b/src/mongo/db/commands/test_commands.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/op_observer.h"
 #include "mongo/db/query/internal_plans.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -80,7 +81,7 @@ public:
                            string& errmsg,
                            BSONObjBuilder& result) {
         const NamespaceString nss(CommandHelpers::parseNsCollectionRequired(dbname, cmdObj));
-        log() << "test only command godinsert invoked coll:" << nss.coll();
+        LOGV2("test only command godinsert invoked coll:{}", "nss_coll"_attr = nss.coll());
         BSONObj obj = cmdObj["obj"].embeddedObjectUserCheck();
 
         Lock::DBLock lk(opCtx, dbname, MODE_X);
diff --git a/src/mongo/db/commands/traffic_recording_cmds.cpp b/src/mongo/db/commands/traffic_recording_cmds.cpp
index 7fd2894c9f..9648f79f99 100644
--- a/src/mongo/db/commands/traffic_recording_cmds.cpp
+++ b/src/mongo/db/commands/traffic_recording_cmds.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/commands.h"
 #include "mongo/db/traffic_recorder.h"
 #include "mongo/db/traffic_recorder_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -53,9 +54,7 @@ public:
 
         void typedRun(OperationContext* opCtx) {
             TrafficRecorder::get(opCtx->getServiceContext()).start(request());
-            log() << "** Warning: The recording file contains unencrypted user traffic."
-                  << " We recommend that you limit retention of this file and "
-                  << "store it on an encrypted filesystem volume.";
+            LOGV2("** Warning: The recording file contains unencrypted user traffic. We recommend that you limit retention of this file and store it on an encrypted filesystem volume.");
         }
 
     private:
diff --git a/src/mongo/db/commands/txn_cmds.cpp b/src/mongo/db/commands/txn_cmds.cpp
index 9f9e7afa02..3ef24866f2 100644
--- a/src/mongo/db/commands/txn_cmds.cpp
+++ b/src/mongo/db/commands/txn_cmds.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/transaction_participant.h"
 #include "mongo/db/transaction_validation.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -95,8 +96,7 @@ public:
                 "commitTransaction must be run within a transaction",
                 txnParticipant);
 
-        LOG(3) << "Received commitTransaction for transaction with txnNumber "
-               << opCtx->getTxnNumber() << " on session " << opCtx->getLogicalSessionId()->toBSON();
+        LOGV2_DEBUG(3, "Received commitTransaction for transaction with txnNumber {} on session {}", "opCtx_getTxnNumber"_attr = opCtx->getTxnNumber(), "opCtx_getLogicalSessionId_toBSON"_attr = opCtx->getLogicalSessionId()->toBSON());
 
         // commitTransaction is retryable.
         if (txnParticipant.transactionIsCommitted()) {
@@ -199,8 +199,7 @@ public:
                 "abortTransaction must be run within a transaction",
                 txnParticipant);
 
-        LOG(3) << "Received abortTransaction for transaction with txnNumber "
-               << opCtx->getTxnNumber() << " on session " << opCtx->getLogicalSessionId()->toBSON();
+        LOGV2_DEBUG(3, "Received abortTransaction for transaction with txnNumber {} on session {}", "opCtx_getTxnNumber"_attr = opCtx->getTxnNumber(), "opCtx_getLogicalSessionId_toBSON"_attr = opCtx->getLogicalSessionId()->toBSON());
 
         uassert(ErrorCodes::NoSuchTransaction,
                 "Transaction isn't in progress",
diff --git a/src/mongo/db/commands/user_management_commands.cpp b/src/mongo/db/commands/user_management_commands.cpp
index 90bec146f4..963adf5edf 100644
--- a/src/mongo/db/commands/user_management_commands.cpp
+++ b/src/mongo/db/commands/user_management_commands.cpp
@@ -67,6 +67,7 @@
 #include "mongo/db/ops/write_ops.h"
 #include "mongo/db/query/cursor_response.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/write_ops/batched_command_response.h"
@@ -579,7 +580,7 @@ public:
         }
 
         if (_authzManager->getCacheGeneration() == _cacheGeneration) {
-            LOG(1) << "User management command did not invalidate the user cache.";
+            LOGV2_DEBUG(1, "User management command did not invalidate the user cache.");
             _authzManager->invalidateUserCache(_opCtx);
         }
     }
diff --git a/src/mongo/db/commands/validate.cpp b/src/mongo/db/commands/validate.cpp
index 09594aa207..754eaf79e5 100644
--- a/src/mongo/db/commands/validate.cpp
+++ b/src/mongo/db/commands/validate.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/query/internal_plans.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/storage/record_store.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -142,8 +143,7 @@ public:
         }
 
         if (!serverGlobalParams.quiet.load()) {
-            LOG(0) << "CMD: validate " << nss.ns() << (background ? ", background:true" : "")
-                   << (fullValidate ? ", full:true" : "");
+            LOGV2("CMD: validate {}{}{}", "nss_ns"_attr = nss.ns(), "background_background_true"_attr = (background ? ", background:true" : ""), "fullValidate_full_true"_attr = (fullValidate ? ", full:true" : ""));
         }
 
         // Only one validation per collection can be in progress, the rest wait.
diff --git a/src/mongo/db/concurrency/d_concurrency_test.cpp b/src/mongo/db/concurrency/d_concurrency_test.cpp
index c19883a2b1..6a481a1f29 100644
--- a/src/mongo/db/concurrency/d_concurrency_test.cpp
+++ b/src/mongo/db/concurrency/d_concurrency_test.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/concurrency/write_conflict_exception.h"
 #include "mongo/db/service_context_d_test_fixture.h"
 #include "mongo/db/storage/recovery_unit_noop.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/future.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/unittest/unittest.h"
@@ -2042,9 +2043,7 @@ TEST_F(DConcurrencyTestFixture, CompatibleFirstStress) {
     for (auto& thread : threads)
         thread.join();
     for (int threadId = 0; threadId < numThreads; threadId++) {
-        log() << "thread " << threadId << " stats: " << acquisitionCount[threadId]
-              << " acquisitions, " << timeoutCount[threadId] << " timeouts, "
-              << busyWaitCount[threadId] / 1'000'000 << "M busy waits";
+        LOGV2("thread {} stats: {} acquisitions, {} timeouts, {}M busy waits", "threadId"_attr = threadId, "acquisitionCount_threadId"_attr = acquisitionCount[threadId], "timeoutCount_threadId"_attr = timeoutCount[threadId], "busyWaitCount_threadId_1_000_000"_attr = busyWaitCount[threadId] / 1'000'000);
     }
 }
 
diff --git a/src/mongo/db/concurrency/deferred_writer.cpp b/src/mongo/db/concurrency/deferred_writer.cpp
index 4bedbe1995..532f85b18d 100644
--- a/src/mongo/db/concurrency/deferred_writer.cpp
+++ b/src/mongo/db/concurrency/deferred_writer.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/concurrency/write_conflict_exception.h"
 #include "mongo/db/db_raii.h"
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/concurrency/thread_pool.h"
 #include "mongo/util/log.h"
@@ -47,7 +48,7 @@ auto kLogInterval = stdx::chrono::minutes(1);
 
 void DeferredWriter::_logFailure(const Status& status) {
     if (TimePoint::clock::now() - _lastLogged > kLogInterval) {
-        log() << "Unable to write to collection " << _nss.toString() << ": " << status.toString();
+        LOGV2("Unable to write to collection {}: {}", "_nss_toString"_attr = _nss.toString(), "status_toString"_attr = status.toString());
         _lastLogged = stdx::chrono::system_clock::now();
     }
 }
@@ -55,8 +56,7 @@ void DeferredWriter::_logFailure(const Status& status) {
 void DeferredWriter::_logDroppedEntry() {
     _droppedEntries += 1;
     if (TimePoint::clock::now() - _lastLoggedDrop > kLogInterval) {
-        log() << "Deferred write buffer for " << _nss.toString() << " is full. " << _droppedEntries
-              << " entries have been dropped.";
+        LOGV2("Deferred write buffer for {} is full. {} entries have been dropped.", "_nss_toString"_attr = _nss.toString(), "_droppedEntries"_attr = _droppedEntries);
         _lastLoggedDrop = stdx::chrono::system_clock::now();
         _droppedEntries = 0;
     }
diff --git a/src/mongo/db/concurrency/flow_control_ticketholder.cpp b/src/mongo/db/concurrency/flow_control_ticketholder.cpp
index b8f6217665..7fc2cbc502 100644
--- a/src/mongo/db/concurrency/flow_control_ticketholder.cpp
+++ b/src/mongo/db/concurrency/flow_control_ticketholder.cpp
@@ -34,6 +34,7 @@
 #include "mongo/db/concurrency/flow_control_ticketholder.h"
 
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/time_support.h"
 
@@ -81,7 +82,7 @@ void FlowControlTicketholder::set(ServiceContext* service,
 void FlowControlTicketholder::refreshTo(int numTickets) {
     invariant(numTickets >= 0);
     stdx::lock_guard<Latch> lk(_mutex);
-    LOG(4) << "Refreshing tickets. Before: " << _tickets << " Now: " << numTickets;
+    LOGV2_DEBUG(4, "Refreshing tickets. Before: {} Now: {}", "_tickets"_attr = _tickets, "numTickets"_attr = numTickets);
     _tickets = numTickets;
     _cv.notify_all();
 }
@@ -93,7 +94,7 @@ void FlowControlTicketholder::getTicket(OperationContext* opCtx,
         return;
     }
 
-    LOG(4) << "Taking ticket. Available: " << _tickets;
+    LOGV2_DEBUG(4, "Taking ticket. Available: {}", "_tickets"_attr = _tickets);
     if (_tickets == 0) {
         ++stats->acquireWaitCount;
     }
@@ -128,7 +129,7 @@ void FlowControlTicketholder::getTicket(OperationContext* opCtx,
 
 // Should only be called once, during shutdown.
 void FlowControlTicketholder::setInShutdown() {
-    LOG(0) << "Stopping further Flow Control ticket acquisitions.";
+    LOGV2("Stopping further Flow Control ticket acquisitions.");
     stdx::lock_guard<Latch> lk(_mutex);
     _inShutdown = true;
     _cv.notify_all();
diff --git a/src/mongo/db/concurrency/lock_manager.cpp b/src/mongo/db/concurrency/lock_manager.cpp
index a7d3671c63..482700203b 100644
--- a/src/mongo/db/concurrency/lock_manager.cpp
+++ b/src/mongo/db/concurrency/lock_manager.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/catalog/collection_catalog.h"
 #include "mongo/db/concurrency/d_concurrency.h"
 #include "mongo/db/concurrency/locker.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -826,7 +827,7 @@ LockManager::Partition* LockManager::_getPartition(LockRequest* request) const {
 }
 
 void LockManager::dump() const {
-    log() << "Dumping LockManager @ " << static_cast<const void*>(this) << '\n';
+    LOGV2("Dumping LockManager @ {}{}", "static_cast_const_void_this"_attr = reinterpret_cast<uint64_t>(this), "n"_attr = '\n');
 
     auto lockToClientMap = getLockToClientMap(getGlobalServiceContext());
     for (unsigned i = 0; i < _numLockBuckets; i++) {
@@ -963,7 +964,7 @@ void LockManager::_dumpBucket(const std::map<LockerId, BSONObj>& lockToClientMap
         }
 
         sb << "-----------------------------------------------------------\n";
-        log() << sb.str();
+        LOGV2("{}", "sb_str"_attr = sb.str());
     }
 }
 
diff --git a/src/mongo/db/concurrency/lock_state.cpp b/src/mongo/db/concurrency/lock_state.cpp
index 6cc0f0ee26..a485e5f7a5 100644
--- a/src/mongo/db/concurrency/lock_state.cpp
+++ b/src/mongo/db/concurrency/lock_state.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/namespace_string.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/flow_control.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/compiler.h"
 #include "mongo/stdx/new.h"
 #include "mongo/util/background.h"
@@ -203,7 +204,7 @@ void LockerImpl::dump() const {
     }
     _lock.unlock();
 
-    log() << ss.str();
+    LOGV2("{}", "ss_str"_attr = ss.str());
 }
 
 
@@ -1062,7 +1063,7 @@ public:
     }
 
     void taskDoWork() {
-        LOG(2) << "cleaning up unused lock buckets of the global lock manager";
+        LOGV2_DEBUG(2, "cleaning up unused lock buckets of the global lock manager");
         getGlobalLockManager()->cleanupUnusedLocks();
     }
 } unusedLockCleaner;
diff --git a/src/mongo/db/curop.cpp b/src/mongo/db/curop.cpp
index feb616ded0..7e7502e487 100644
--- a/src/mongo/db/curop.cpp
+++ b/src/mongo/db/curop.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/prepare_conflict_tracker.h"
 #include "mongo/db/query/getmore_request.h"
 #include "mongo/db/query/plan_summary_stats.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/client_metadata.h"
 #include "mongo/rpc/metadata/client_metadata_ismaster.h"
 #include "mongo/rpc/metadata/impersonated_user_metadata.h"
@@ -463,7 +464,7 @@ bool CurOp::completeAndLogOperation(OperationContext* opCtx,
         _debug.prepareConflictDurationMillis =
             duration_cast<Milliseconds>(prepareConflictDurationMicros);
 
-        log(component) << _debug.report(opCtx, (lockerInfo ? &lockerInfo->stats : nullptr));
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(component).toInt(), "{}", "_debug_report_opCtx_lockerInfo_lockerInfo_stats_nullptr"_attr = _debug.report(opCtx, (lockerInfo ? &lockerInfo->stats : nullptr)));
     }
 
     // Return 'true' if this operation should also be added to the profiler.
diff --git a/src/mongo/db/cursor_manager.cpp b/src/mongo/db/cursor_manager.cpp
index 93dd9cad7f..e040cd3eb7 100644
--- a/src/mongo/db/cursor_manager.cpp
+++ b/src/mongo/db/cursor_manager.cpp
@@ -52,6 +52,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/query/plan_executor.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/util/exit.h"
 #include "mongo/util/log.h"
@@ -90,7 +91,7 @@ std::pair<Status, int> CursorManager::killCursorsWithMatchingSessions(
     OperationContext* opCtx, const SessionKiller::Matcher& matcher) {
     auto eraser = [&](CursorManager& mgr, CursorId id) {
         uassertStatusOK(mgr.killCursor(opCtx, id, true));
-        log() << "killing cursor: " << id << " as part of killing session(s)";
+        LOGV2("killing cursor: {} as part of killing session(s)", "id"_attr = id);
     };
 
     auto bySessionCursorKiller = makeKillCursorsBySessionAdaptor(opCtx, matcher, std::move(eraser));
@@ -141,8 +142,7 @@ std::size_t CursorManager::timeoutCursors(OperationContext* opCtx, Date_t now) {
 
     // Be careful not to dispose of cursors while holding the partition lock.
     for (auto&& cursor : toDisposeWithoutMutex) {
-        log() << "Cursor id " << cursor->cursorid() << " timed out, idle since "
-              << cursor->getLastUseDate();
+        LOGV2("Cursor id {} timed out, idle since {}", "cursor_cursorid"_attr = cursor->cursorid(), "cursor_getLastUseDate"_attr = cursor->getLastUseDate());
         cursor->dispose(opCtx);
     }
     return toDisposeWithoutMutex.size();
@@ -212,8 +212,7 @@ void CursorManager::unpin(OperationContext* opCtx,
     // proactively delete the cursor. In other cases we preserve the error code so that the client
     // will see the reason the cursor was killed when asking for the next batch.
     if (interruptStatus == ErrorCodes::Interrupted || interruptStatus == ErrorCodes::CursorKilled) {
-        LOG(0) << "removing cursor " << cursor->cursorid()
-               << " after completing batch: " << interruptStatus;
+        LOGV2("removing cursor {} after completing batch: {}", "cursor_cursorid"_attr = cursor->cursorid(), "interruptStatus"_attr = interruptStatus);
         return deregisterAndDestroyCursor(std::move(partition), opCtx, std::move(cursor));
     } else if (!interruptStatus.isOK()) {
         cursor->markAsKilled(interruptStatus);
diff --git a/src/mongo/db/database_index_builds_tracker.cpp b/src/mongo/db/database_index_builds_tracker.cpp
index 4f7bb13a47..967772a6de 100644
--- a/src/mongo/db/database_index_builds_tracker.cpp
+++ b/src/mongo/db/database_index_builds_tracker.cpp
@@ -34,6 +34,7 @@
 #include "mongo/db/database_index_builds_tracker.h"
 
 #include "mongo/db/catalog/index_builds_manager.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -80,9 +81,9 @@ void DatabaseIndexBuildsTracker::waitUntilNoIndexBuildsRemain(stdx::unique_lock<
             return true;
         }
 
-        log() << "Waiting until the following index builds are finished:";
+        LOGV2("Waiting until the following index builds are finished:");
         for (const auto& indexBuild : _allIndexBuilds) {
-            log() << "    Index build with UUID: " << indexBuild.first;
+            LOGV2("    Index build with UUID: {}", "indexBuild_first"_attr = indexBuild.first);
         }
 
         return false;
diff --git a/src/mongo/db/db.cpp b/src/mongo/db/db.cpp
index 75e3321a28..bd20cda04d 100644
--- a/src/mongo/db/db.cpp
+++ b/src/mongo/db/db.cpp
@@ -187,6 +187,7 @@
 #include "mongo/watchdog/watchdog_mongod.h"
 
 #ifdef MONGO_CONFIG_SSL
+#include "mongo/logv2/log.h"
 #include "mongo/util/net/ssl_options.h"
 #endif
 
@@ -307,7 +308,7 @@ ExitCode _initAndListen(int listenPort) {
     }
 
     if (kDebugBuild)
-        log(LogComponent::kControl) << "DEBUG build (which is slower)" << endl;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kControl).toInt(), "DEBUG build (which is slower)");
 
 #if defined(_WIN32)
     VersionInfoInterface::instance().logTargetMinOS();
@@ -367,17 +368,14 @@ ExitCode _initAndListen(int listenPort) {
     // Disallow running a storage engine that doesn't support capped collections with --profile
     if (!serviceContext->getStorageEngine()->supportsCappedCollections() &&
         serverGlobalParams.defaultProfile != 0) {
-        log() << "Running " << storageGlobalParams.engine << " with profiling is not supported. "
-              << "Make sure you are not using --profile.";
+        LOGV2("Running {} with profiling is not supported. Make sure you are not using --profile.", "storageGlobalParams_engine"_attr = storageGlobalParams.engine);
         exitCleanly(EXIT_BADOPTIONS);
     }
 
     // Disallow running WiredTiger with --nojournal in a replica set
     if (storageGlobalParams.engine == "wiredTiger" && !storageGlobalParams.dur &&
         replSettings.usingReplSets()) {
-        log() << "Running wiredTiger without journaling in a replica set is not "
-              << "supported. Make sure you are not using --nojournal and that "
-              << "storage.journal.enabled is not set to 'false'.";
+        LOGV2("Running wiredTiger without journaling in a replica set is not supported. Make sure you are not using --nojournal and that storage.journal.enabled is not set to 'false'.");
         exitCleanly(EXIT_BADOPTIONS);
     }
 
@@ -442,11 +440,11 @@ ExitCode _initAndListen(int listenPort) {
     }
 
     if (gFlowControlEnabled.load()) {
-        log() << "Flow Control is enabled on this deployment.";
+        LOGV2("Flow Control is enabled on this deployment.");
     }
 
     if (storageGlobalParams.upgrade) {
-        log() << "finished checking dbs";
+        LOGV2("finished checking dbs");
         exitCleanly(EXIT_CLEAN);
     }
 
@@ -462,7 +460,7 @@ ExitCode _initAndListen(int listenPort) {
     if (globalAuthzManager->shouldValidateAuthSchemaOnStartup()) {
         Status status = verifySystemIndexes(startupOpCtx.get());
         if (!status.isOK()) {
-            log() << redact(status);
+            LOGV2("{}", "redact_status"_attr = redact(status));
             if (status == ErrorCodes::AuthSchemaIncompatible) {
                 exitCleanly(EXIT_NEED_UPGRADE);
             } else if (status == ErrorCodes::NotMaster) {
@@ -478,22 +476,15 @@ ExitCode _initAndListen(int listenPort) {
         status =
             globalAuthzManager->getAuthorizationVersion(startupOpCtx.get(), &foundSchemaVersion);
         if (!status.isOK()) {
-            log() << "Auth schema version is incompatible: "
-                  << "User and role management commands require auth data to have "
-                  << "at least schema version " << AuthorizationManager::schemaVersion26Final
-                  << " but startup could not verify schema version: " << status;
-            log() << "To manually repair the 'authSchema' document in the admin.system.version "
+            LOGV2("Auth schema version is incompatible: User and role management commands require auth data to have at least schema version {} but startup could not verify schema version: {}", "AuthorizationManager_schemaVersion26Final"_attr = AuthorizationManager::schemaVersion26Final, "status"_attr = status);
+            LOGV2("To manually repair the 'authSchema' document in the admin.system.version "
                      "collection, start up with --setParameter "
-                     "startupAuthSchemaValidation=false to disable validation.";
+                     "startupAuthSchemaValidation=false to disable validation.");
             exitCleanly(EXIT_NEED_UPGRADE);
         }
 
         if (foundSchemaVersion <= AuthorizationManager::schemaVersion26Final) {
-            log() << "This server is using MONGODB-CR, an authentication mechanism which "
-                  << "has been removed from MongoDB 4.0. In order to upgrade the auth schema, "
-                  << "first downgrade MongoDB binaries to version 3.6 and then run the "
-                  << "authSchemaUpgrade command. "
-                  << "See http://dochub.mongodb.org/core/3.0-upgrade-to-scram-sha-1";
+            LOGV2("This server is using MONGODB-CR, an authentication mechanism which has been removed from MongoDB 4.0. In order to upgrade the auth schema, first downgrade MongoDB binaries to version 3.6 and then run the authSchemaUpgrade command. See http://dochub.mongodb.org/core/3.0-upgrade-to-scram-sha-1");
             exitCleanly(EXIT_NEED_UPGRADE);
         }
     } else if (globalAuthzManager->isAuthEnabled()) {
@@ -502,13 +493,11 @@ ExitCode _initAndListen(int listenPort) {
     } else {
         // If authSchemaValidation is disabled and server is running without auth,
         // warn the user and continue startup without authSchema metadata checks.
-        log() << startupWarningsLog;
-        log() << "** WARNING: Startup auth schema validation checks are disabled for the "
-                 "database."
-              << startupWarningsLog;
-        log() << "**          This mode should only be used to manually repair corrupted auth "
-                 "data."
-              << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: Startup auth schema validation checks are disabled for the "
+                 "database.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          This mode should only be used to manually repair corrupted auth "
+                 "data.");
     }
 
     WaitForMajorityService::get(serviceContext).setUp(serviceContext);
@@ -519,8 +508,7 @@ ExitCode _initAndListen(int listenPort) {
     if (shardingInitialized) {
         auto status = waitForShardRegistryReload(startupOpCtx.get());
         if (!status.isOK()) {
-            LOG(0) << "Failed to load the shard registry as part of startup"
-                   << causedBy(redact(status));
+            LOGV2("Failed to load the shard registry as part of startup{}", "causedBy_redact_status"_attr = causedBy(redact(status)));
         }
     }
 
@@ -578,23 +566,18 @@ ExitCode _initAndListen(int listenPort) {
 
         replCoord->startup(startupOpCtx.get());
         if (getReplSetMemberInStandaloneMode(serviceContext)) {
-            log() << startupWarningsLog;
-            log() << "** WARNING: mongod started without --replSet yet document(s) are present in "
-                  << NamespaceString::kSystemReplSetNamespace << "." << startupWarningsLog;
-            log() << "**          Database contents may appear inconsistent with the oplog and may "
-                     "appear to not contain"
-                  << startupWarningsLog;
-            log() << "**          writes that were visible when this node was running as part of a "
-                     "replica set."
-                  << startupWarningsLog;
-            log() << "**          Restart with --replSet unless you are doing maintenance and no "
-                     "other clients are connected."
-                  << startupWarningsLog;
-            log() << "**          The TTL collection monitor will not start because of this."
-                  << startupWarningsLog;
-            log() << "**         ";
-            log() << " For more info see http://dochub.mongodb.org/core/ttlcollections";
-            log() << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: mongod started without --replSet yet document(s) are present in {}.", "NamespaceString_kSystemReplSetNamespace"_attr = NamespaceString::kSystemReplSetNamespace);
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          Database contents may appear inconsistent with the oplog and may "
+                     "appear to not contain");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          writes that were visible when this node was running as part of a "
+                     "replica set.");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          Restart with --replSet unless you are doing maintenance and no "
+                     "other clients are connected.");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          The TTL collection monitor will not start because of this.");
+            LOGV2("**         ");
+            LOGV2(" For more info see http://dochub.mongodb.org/core/ttlcollections");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
         } else {
             startTTLBackgroundJob(serviceContext);
         }
@@ -669,12 +652,12 @@ ExitCode _initAndListen(int listenPort) {
 #else
     if (ntservice::shouldStartService()) {
         ntservice::reportStatus(SERVICE_RUNNING);
-        log() << "Service running";
+        LOGV2("Service running");
     }
 #endif
 
     if (MONGO_unlikely(shutdownAtStartup.shouldFail())) {
-        log() << "starting clean exit via failpoint";
+        LOGV2("starting clean exit via failpoint");
         exitCleanly(EXIT_CLEAN);
     }
 
@@ -686,16 +669,16 @@ ExitCode initAndListen(int listenPort) {
     try {
         return _initAndListen(listenPort);
     } catch (DBException& e) {
-        log() << "exception in initAndListen: " << e.toString() << ", terminating";
+        LOGV2("exception in initAndListen: {}, terminating", "e_toString"_attr = e.toString());
         return EXIT_UNCAUGHT;
     } catch (std::exception& e) {
-        log() << "exception in initAndListen std::exception: " << e.what() << ", terminating";
+        LOGV2("exception in initAndListen std::exception: {}, terminating", "e_what"_attr = e.what());
         return EXIT_UNCAUGHT;
     } catch (int& n) {
-        log() << "exception in initAndListen int: " << n << ", terminating";
+        LOGV2("exception in initAndListen int: {}, terminating", "n"_attr = n);
         return EXIT_UNCAUGHT;
     } catch (...) {
-        log() << "exception in initAndListen, terminating";
+        LOGV2("exception in initAndListen, terminating");
         return EXIT_UNCAUGHT;
     }
 }
@@ -911,8 +894,7 @@ void shutdownTask(const ShutdownTaskArgs& shutdownArgs) {
             } catch (const ExceptionFor<ErrorCodes::NotMaster>&) {
                 // ignore not master errors
             } catch (const DBException& e) {
-                log() << "Failed to stepDown in non-command initiated shutdown path "
-                      << e.toString();
+                LOGV2("Failed to stepDown in non-command initiated shutdown path {}", "e_toString"_attr = e.toString());
             }
         }
     }
@@ -932,7 +914,7 @@ void shutdownTask(const ShutdownTaskArgs& shutdownArgs) {
 
     // Shutdown the TransportLayer so that new connections aren't accepted
     if (auto tl = serviceContext->getTransportLayer()) {
-        log(LogComponent::kNetwork) << "shutdown: going to close listening sockets...";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "shutdown: going to close listening sockets...");
         tl->shutdown();
     }
 
@@ -1009,8 +991,7 @@ void shutdownTask(const ShutdownTaskArgs& shutdownArgs) {
     // Shutdown the Service Entry Point and its sessions and give it a grace period to complete.
     if (auto sep = serviceContext->getServiceEntryPoint()) {
         if (!sep->shutdown(Seconds(10))) {
-            log(LogComponent::kNetwork)
-                << "Service entry point failed to shutdown within timelimit.";
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "Service entry point failed to shutdown within timelimit.");
         }
     }
 
@@ -1018,8 +999,7 @@ void shutdownTask(const ShutdownTaskArgs& shutdownArgs) {
     if (auto svcExec = serviceContext->getServiceExecutor()) {
         Status status = svcExec->shutdown(Seconds(10));
         if (!status.isOK()) {
-            log(LogComponent::kNetwork)
-                << "Service executor failed to shutdown within timelimit: " << status.reason();
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "Service executor failed to shutdown within timelimit: {}", "status_reason"_attr = status.reason());
         }
     }
 #endif
@@ -1048,7 +1028,7 @@ void shutdownTask(const ShutdownTaskArgs& shutdownArgs) {
     // the memory and makes leak sanitizer happy.
     ScriptEngine::dropScopeCache();
 
-    log(LogComponent::kControl) << "now exiting";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kControl).toInt(), "now exiting");
 
     audit::logShutdown(client);
 
diff --git a/src/mongo/db/db_raii.cpp b/src/mongo/db/db_raii.cpp
index dd98f9f5ee..69285a2604 100644
--- a/src/mongo/db/db_raii.cpp
+++ b/src/mongo/db/db_raii.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/db_raii_gen.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/s/collection_sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -185,9 +186,7 @@ AutoGetCollectionForRead::AutoGetCollectionForRead(OperationContext* opCtx,
         // waiting for the lastAppliedTimestamp to move forward. Instead we force the reader take
         // the PBWM lock and retry.
         if (lastAppliedTimestamp) {
-            LOG(0) << "tried reading at last-applied time: " << *lastAppliedTimestamp
-                   << " on ns: " << nss.ns() << ", but future catalog changes are pending at time "
-                   << *minSnapshot << ". Trying again without reading at last-applied time.";
+            LOGV2("tried reading at last-applied time: {} on ns: {}, but future catalog changes are pending at time {}. Trying again without reading at last-applied time.", "lastAppliedTimestamp"_attr = *lastAppliedTimestamp, "nss_ns"_attr = nss.ns(), "minSnapshot"_attr = *minSnapshot);
             // Destructing the block sets _shouldConflictWithSecondaryBatchApplication back to the
             // previous value. If the previous value is false (because there is another
             // shouldNotConflictWithSecondaryBatchApplicationBlock outside of this function), this
@@ -259,7 +258,7 @@ bool AutoGetCollectionForRead::_shouldReadAtLastAppliedTimestamp(
     // This may occur when multiple collection locks are held concurrently, which is often the case
     // when DBDirectClient is used.
     if (opCtx->lockState()->isLockHeldForMode(resourceIdParallelBatchWriterMode, MODE_IS)) {
-        LOG(1) << "not reading at last-applied because the PBWM lock is held";
+        LOGV2_DEBUG(1, "not reading at last-applied because the PBWM lock is held");
         return false;
     }
 
diff --git a/src/mongo/db/exec/cached_plan.cpp b/src/mongo/db/exec/cached_plan.cpp
index 9738936f4b..4255c0526e 100644
--- a/src/mongo/db/exec/cached_plan.cpp
+++ b/src/mongo/db/exec/cached_plan.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/query/query_knobs_gen.h"
 #include "mongo/db/query/query_planner.h"
 #include "mongo/db/query/stage_builder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 #include "mongo/util/transitional_tools_do_not_use/vector_spooling.h"
@@ -141,10 +142,7 @@ Status CachedPlanStage::pickBestPlan(PlanYieldPolicy* yieldPolicy) {
             // existing cache entry nor cache the result of replanning.
             BSONObj statusObj = WorkingSetCommon::getStatusMemberDocument(*_ws, id)->toBson();
 
-            LOG(1) << "Execution of cached plan failed, falling back to replan."
-                   << " query: " << redact(_canonicalQuery->toStringShort())
-                   << " planSummary: " << Explain::getPlanSummary(child().get())
-                   << " status: " << redact(statusObj);
+            LOGV2_DEBUG(1, "Execution of cached plan failed, falling back to replan. query: {} planSummary: {} status: {}", "redact__canonicalQuery_toStringShort"_attr = redact(_canonicalQuery->toStringShort()), "Explain_getPlanSummary_child_get"_attr = Explain::getPlanSummary(child().get()), "redact_statusObj"_attr = redact(statusObj));
 
             const bool shouldCache = false;
             return replan(yieldPolicy, shouldCache);
@@ -155,11 +153,7 @@ Status CachedPlanStage::pickBestPlan(PlanYieldPolicy* yieldPolicy) {
 
     // If we're here, the trial period took more than 'maxWorksBeforeReplan' work cycles. This
     // plan is taking too long, so we replan from scratch.
-    LOG(1) << "Execution of cached plan required " << maxWorksBeforeReplan
-           << " works, but was originally cached with only " << _decisionWorks
-           << " works. Evicting cache entry and replanning query: "
-           << redact(_canonicalQuery->toStringShort())
-           << " plan summary before replan: " << Explain::getPlanSummary(child().get());
+    LOGV2_DEBUG(1, "Execution of cached plan required {} works, but was originally cached with only {} works. Evicting cache entry and replanning query: {} plan summary before replan: {}", "maxWorksBeforeReplan"_attr = maxWorksBeforeReplan, "_decisionWorks"_attr = _decisionWorks, "redact__canonicalQuery_toStringShort"_attr = redact(_canonicalQuery->toStringShort()), "Explain_getPlanSummary_child_get"_attr = Explain::getPlanSummary(child().get()));
 
     const bool shouldCache = true;
     return replan(yieldPolicy, shouldCache);
@@ -213,11 +207,7 @@ Status CachedPlanStage::replan(PlanYieldPolicy* yieldPolicy, bool shouldCache) {
         _replannedQs = std::move(solutions.back());
         solutions.pop_back();
 
-        LOG(1)
-            << "Replanning of query resulted in single query solution, which will not be cached. "
-            << redact(_canonicalQuery->toStringShort())
-            << " plan summary after replan: " << Explain::getPlanSummary(child().get())
-            << " previous cache entry evicted: " << (shouldCache ? "yes" : "no");
+        LOGV2_DEBUG(1, "Replanning of query resulted in single query solution, which will not be cached. {} plan summary after replan: {} previous cache entry evicted: {}", "redact__canonicalQuery_toStringShort"_attr = redact(_canonicalQuery->toStringShort()), "Explain_getPlanSummary_child_get"_attr = Explain::getPlanSummary(child().get()), "shouldCache_yes_no"_attr = (shouldCache ? "yes" : "no"));
         return Status::OK();
     }
 
@@ -246,9 +236,7 @@ Status CachedPlanStage::replan(PlanYieldPolicy* yieldPolicy, bool shouldCache) {
         return pickBestPlanStatus;
     }
 
-    LOG(1) << "Replanning " << redact(_canonicalQuery->toStringShort())
-           << " resulted in plan with summary: " << Explain::getPlanSummary(child().get())
-           << ", which " << (shouldCache ? "has" : "has not") << " been written to the cache";
+    LOGV2_DEBUG(1, "Replanning {} resulted in plan with summary: {}, which {} been written to the cache", "redact__canonicalQuery_toStringShort"_attr = redact(_canonicalQuery->toStringShort()), "Explain_getPlanSummary_child_get"_attr = Explain::getPlanSummary(child().get()), "shouldCache_has_has_not"_attr = (shouldCache ? "has" : "has not"));
     return Status::OK();
 }
 
diff --git a/src/mongo/db/exec/collection_scan.cpp b/src/mongo/db/exec/collection_scan.cpp
index 66711faadf..097a90d3ab 100644
--- a/src/mongo/db/exec/collection_scan.cpp
+++ b/src/mongo/db/exec/collection_scan.cpp
@@ -47,6 +47,7 @@
 #include "mongo/util/log.h"
 
 #include "mongo/db/client.h"  // XXX-ERH
+#include "mongo/logv2/log.h"
 
 namespace mongo {
 
@@ -173,7 +174,7 @@ PlanStage::StageState CollectionScan::doWork(WorkingSetID* out) {
                 boost::optional<RecordId> startLoc =
                     collection()->getRecordStore()->oplogStartHack(getOpCtx(), goal.getValue());
                 if (startLoc && !startLoc->isNull()) {
-                    LOG(3) << "Using direct oplog seek";
+                    LOGV2_DEBUG(3, "Using direct oplog seek");
                     record = _cursor->seekExact(*startLoc);
                 }
             }
diff --git a/src/mongo/db/exec/document_value/document_value_test.cpp b/src/mongo/db/exec/document_value/document_value_test.cpp
index d641b699ae..6f9a9ed26c 100644
--- a/src/mongo/db/exec/document_value/document_value_test.cpp
+++ b/src/mongo/db/exec/document_value/document_value_test.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/json.h"
 #include "mongo/db/pipeline/field_path.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 
 namespace DocumentTests {
 
@@ -236,7 +237,7 @@ public:
 
         // Remove the second field.
         md.setField("b", Value());
-        log() << md.peek().toString();
+        LOGV2("{}", "md_peek_toString"_attr = md.peek().toString());
         ASSERT_EQUALS(2U, md.peek().size());
         ASSERT(md.peek()["b"].missing());
         ASSERT_EQUALS("a", getNthField(md.peek(), 0).first.toString());
@@ -1915,7 +1916,7 @@ private:
         assertComparison(expectedResult, fromBson(a), fromBson(b));
     }
     void assertComparison(int expectedResult, const Value& a, const Value& b) {
-        mongo::unittest::log() << "testing " << a.toString() << " and " << b.toString();
+        mongo::unittest::LOGV2("testing {} and {}", "a_toString"_attr = a.toString(), "b_toString"_attr = b.toString());
 
         // reflexivity
         ASSERT_EQUALS(0, cmp(a, a));
diff --git a/src/mongo/db/exec/multi_plan.cpp b/src/mongo/db/exec/multi_plan.cpp
index 45c409c7ab..bf446bbf14 100644
--- a/src/mongo/db/exec/multi_plan.cpp
+++ b/src/mongo/db/exec/multi_plan.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/query/explain.h"
 #include "mongo/db/query/plan_cache.h"
 #include "mongo/db/query/plan_ranker.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 
@@ -117,7 +118,7 @@ PlanStage::StageState MultiPlanStage::doWork(WorkingSetID* out) {
     StageState state = bestPlan.root->work(out);
 
     if (PlanStage::FAILURE == state && hasBackupPlan()) {
-        LOG(5) << "Best plan errored out switching to backup";
+        LOGV2_DEBUG(5, "Best plan errored out switching to backup");
         // Uncache the bad solution if we fall back
         // on the backup solution.
         //
@@ -138,7 +139,7 @@ PlanStage::StageState MultiPlanStage::doWork(WorkingSetID* out) {
     }
 
     if (hasBackupPlan() && PlanStage::ADVANCED == state) {
-        LOG(5) << "Best plan had a blocking stage, became unblocked";
+        LOGV2_DEBUG(5, "Best plan had a blocking stage, became unblocked");
         _backupPlanIdx = kNoSuchPlan;
     }
 
@@ -245,15 +246,15 @@ Status MultiPlanStage::pickBestPlan(PlanYieldPolicy* yieldPolicy) {
     const auto& alreadyProduced = bestCandidate.results;
     const auto& bestSolution = bestCandidate.solution;
 
-    LOG(5) << "Winning solution:\n" << redact(bestSolution->toString());
-    LOG(2) << "Winning plan: " << Explain::getPlanSummary(bestCandidate.root);
+    LOGV2_DEBUG(5, "Winning solution:\n{}", "redact_bestSolution_toString"_attr = redact(bestSolution->toString()));
+    LOGV2_DEBUG(2, "Winning plan: {}", "Explain_getPlanSummary_bestCandidate_root"_attr = Explain::getPlanSummary(bestCandidate.root));
 
     _backupPlanIdx = kNoSuchPlan;
     if (bestSolution->hasBlockingStage && (0 == alreadyProduced.size())) {
-        LOG(5) << "Winner has blocking stage, looking for backup plan...";
+        LOGV2_DEBUG(5, "Winner has blocking stage, looking for backup plan...");
         for (auto&& ix : candidateOrder) {
             if (!_candidates[ix].solution->hasBlockingStage) {
-                LOG(5) << "Candidate " << ix << " is backup child";
+                LOGV2_DEBUG(5, "Candidate {} is backup child", "ix"_attr = ix);
                 _backupPlanIdx = ix;
                 break;
             }
@@ -281,12 +282,7 @@ Status MultiPlanStage::pickBestPlan(PlanYieldPolicy* yieldPolicy) {
             size_t winnerIdx = ranking->candidateOrder[0];
             size_t runnerUpIdx = ranking->candidateOrder[1];
 
-            LOG(1) << "Winning plan tied with runner-up. Not caching."
-                   << " query: " << redact(_query->toStringShort())
-                   << " winner score: " << ranking->scores[0]
-                   << " winner summary: " << Explain::getPlanSummary(_candidates[winnerIdx].root)
-                   << " runner-up score: " << ranking->scores[1] << " runner-up summary: "
-                   << Explain::getPlanSummary(_candidates[runnerUpIdx].root);
+            LOGV2_DEBUG(1, "Winning plan tied with runner-up. Not caching. query: {} winner score: {} winner summary: {} runner-up score: {} runner-up summary: {}", "redact__query_toStringShort"_attr = redact(_query->toStringShort()), "ranking_scores_0"_attr = ranking->scores[0], "Explain_getPlanSummary__candidates_winnerIdx_root"_attr = Explain::getPlanSummary(_candidates[winnerIdx].root), "ranking_scores_1"_attr = ranking->scores[1], "Explain_getPlanSummary__candidates_runnerUpIdx_root"_attr = Explain::getPlanSummary(_candidates[runnerUpIdx].root));
         }
 
         if (alreadyProduced.empty()) {
@@ -295,10 +291,7 @@ Status MultiPlanStage::pickBestPlan(PlanYieldPolicy* yieldPolicy) {
             canCache = false;
 
             size_t winnerIdx = ranking->candidateOrder[0];
-            LOG(1) << "Winning plan had zero results. Not caching."
-                   << " query: " << redact(_query->toStringShort())
-                   << " winner score: " << ranking->scores[0]
-                   << " winner summary: " << Explain::getPlanSummary(_candidates[winnerIdx].root);
+            LOGV2_DEBUG(1, "Winning plan had zero results. Not caching. query: {} winner score: {} winner summary: {}", "redact__query_toStringShort"_attr = redact(_query->toStringShort()), "ranking_scores_0"_attr = ranking->scores[0], "Explain_getPlanSummary__candidates_winnerIdx_root"_attr = Explain::getPlanSummary(_candidates[winnerIdx].root));
         }
     }
 
@@ -324,8 +317,7 @@ Status MultiPlanStage::pickBestPlan(PlanYieldPolicy* yieldPolicy) {
         bool validSolutions = true;
         for (size_t ix = 0; ix < solutions.size(); ++ix) {
             if (nullptr == solutions[ix]->cacheData.get()) {
-                LOG(5) << "Not caching query because this solution has no cache data: "
-                       << redact(solutions[ix]->toString());
+                LOGV2_DEBUG(5, "Not caching query because this solution has no cache data: {}", "redact_solutions_ix_toString"_attr = redact(solutions[ix]->toString()));
                 validSolutions = false;
                 break;
             }
diff --git a/src/mongo/db/exec/subplan.cpp b/src/mongo/db/exec/subplan.cpp
index c6fc999118..d402e990db 100644
--- a/src/mongo/db/exec/subplan.cpp
+++ b/src/mongo/db/exec/subplan.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/query/query_planner.h"
 #include "mongo/db/query/query_planner_common.h"
 #include "mongo/db/query/stage_builder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 #include "mongo/util/transitional_tools_do_not_use/vector_spooling.h"
@@ -111,7 +112,7 @@ Status SubplanStage::planSubqueries() {
         const auto insertionRes = _indexMap.insert(std::make_pair(ie.identifier, i));
         // Be sure the key was not already in the map.
         invariant(insertionRes.second);
-        LOG(5) << "Subplanner: index " << i << " is " << ie;
+        LOGV2_DEBUG(5, "Subplanner: index {} is {}", "i"_attr = i, "ie"_attr = ie);
     }
 
     for (size_t i = 0; i < _orExpression->numChildren(); ++i) {
@@ -141,8 +142,7 @@ Status SubplanStage::planSubqueries() {
             auto planCacheKey = planCache->computeKey(*branchResult->canonicalQuery);
             if (auto cachedSol = planCache->getCacheEntryIfActive(planCacheKey)) {
                 // We have a CachedSolution. Store it for later.
-                LOG(5) << "Subplanner: cached plan found for child " << i << " of "
-                       << _orExpression->numChildren();
+                LOGV2_DEBUG(5, "Subplanner: cached plan found for child {} of {}", "i"_attr = i, "_orExpression_numChildren"_attr = _orExpression->numChildren());
 
                 branchResult->cachedSolution = std::move(cachedSol);
             }
@@ -150,7 +150,7 @@ Status SubplanStage::planSubqueries() {
 
         if (!branchResult->cachedSolution) {
             // No CachedSolution found. We'll have to plan from scratch.
-            LOG(5) << "Subplanner: planning child " << i << " of " << _orExpression->numChildren();
+            LOGV2_DEBUG(5, "Subplanner: planning child {} of {}", "i"_attr = i, "_orExpression_numChildren"_attr = _orExpression->numChildren());
 
             // We don't set NO_TABLE_SCAN because peeking at the cache data will keep us from
             // considering any plan that's a collscan.
@@ -164,7 +164,7 @@ Status SubplanStage::planSubqueries() {
             }
             branchResult->solutions = std::move(solutions.getValue());
 
-            LOG(5) << "Subplanner: got " << branchResult->solutions.size() << " solutions";
+            LOGV2_DEBUG(5, "Subplanner: got {} solutions", "branchResult_solutions_size"_attr = branchResult->solutions.size());
         }
     }
 
@@ -329,7 +329,7 @@ Status SubplanStage::choosePlanForSubqueries(PlanYieldPolicy* yieldPolicy) {
         return Status(ErrorCodes::NoQueryExecutionPlans, ss);
     }
 
-    LOG(5) << "Subplanner: fully tagged tree is " << redact(solnRoot->toString());
+    LOGV2_DEBUG(5, "Subplanner: fully tagged tree is {}", "redact_solnRoot_toString"_attr = redact(solnRoot->toString()));
 
     _compositeSolution =
         QueryPlannerAnalysis::analyzeDataAccess(*_query, _plannerParams, std::move(solnRoot));
@@ -340,7 +340,7 @@ Status SubplanStage::choosePlanForSubqueries(PlanYieldPolicy* yieldPolicy) {
         return Status(ErrorCodes::NoQueryExecutionPlans, ss);
     }
 
-    LOG(5) << "Subplanner: Composite solution is " << redact(_compositeSolution->toString());
+    LOGV2_DEBUG(5, "Subplanner: Composite solution is {}", "redact__compositeSolution_toString"_attr = redact(_compositeSolution->toString()));
 
     // Use the index tags from planning each branch to construct the composite solution,
     // and set that solution as our child stage.
diff --git a/src/mongo/db/exec/trial_stage.cpp b/src/mongo/db/exec/trial_stage.cpp
index 1e5b36fb7c..ba2b84a219 100644
--- a/src/mongo/db/exec/trial_stage.cpp
+++ b/src/mongo/db/exec/trial_stage.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/exec/or.h"
 #include "mongo/db/exec/queued_data_stage.h"
 #include "mongo/db/exec/working_set_common.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
diff --git a/src/mongo/db/exec/update_stage.cpp b/src/mongo/db/exec/update_stage.cpp
index 2ded1a54e5..7b4a84fed9 100644
--- a/src/mongo/db/exec/update_stage.cpp
+++ b/src/mongo/db/exec/update_stage.cpp
@@ -52,6 +52,7 @@
 #include "mongo/db/storage/duplicate_key_error_info.h"
 #include "mongo/db/update/path_support.h"
 #include "mongo/db/update/storage_validation.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/shard_key_pattern.h"
 #include "mongo/s/would_change_owning_shard_exception.h"
 #include "mongo/util/assert_util.h"
@@ -735,7 +736,7 @@ bool UpdateStage::checkUpdateChangesShardKeyFields(ScopedCollectionMetadata meta
 
     if (!metadata->keyBelongsToMe(newShardKey)) {
         if (MONGO_unlikely(hangBeforeThrowWouldChangeOwningShard.shouldFail())) {
-            log() << "Hit hangBeforeThrowWouldChangeOwningShard failpoint";
+            LOGV2("Hit hangBeforeThrowWouldChangeOwningShard failpoint");
             hangBeforeThrowWouldChangeOwningShard.pauseWhileSet(getOpCtx());
         }
 
diff --git a/src/mongo/db/free_mon/free_mon_controller.cpp b/src/mongo/db/free_mon/free_mon_controller.cpp
index a9de7ca4c4..4eb3325793 100644
--- a/src/mongo/db/free_mon/free_mon_controller.cpp
+++ b/src/mongo/db/free_mon/free_mon_controller.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/ftdc/collector.h"
 #include "mongo/logger/logstream_builder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -167,7 +168,7 @@ void FreeMonController::start(RegistrationType registrationType,
 
 void FreeMonController::stop() {
     // Stop the agent
-    log() << "Shutting down free monitoring";
+    LOGV2("Shutting down free monitoring");
 
     {
         stdx::lock_guard<Latch> lock(_mutex);
@@ -198,7 +199,7 @@ void FreeMonController::turnCrankForTest(size_t countMessagesToIgnore) {
         invariant(_state == State::kStarted);
     }
 
-    log() << "Turning Crank: " << countMessagesToIgnore;
+    LOGV2("Turning Crank: {}", "countMessagesToIgnore"_attr = countMessagesToIgnore);
 
     _processor->turnCrankForTest(countMessagesToIgnore);
 }
diff --git a/src/mongo/db/free_mon/free_mon_controller_test.cpp b/src/mongo/db/free_mon/free_mon_controller_test.cpp
index 296b3700b9..ffc0420d33 100644
--- a/src/mongo/db/free_mon/free_mon_controller_test.cpp
+++ b/src/mongo/db/free_mon/free_mon_controller_test.cpp
@@ -62,6 +62,7 @@
 #include "mongo/db/service_context_d_test_fixture.h"
 #include "mongo/executor/network_interface_mock.h"
 #include "mongo/executor/thread_pool_task_executor_test_fixture.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/object_check.h"
 #include "mongo/unittest/barrier.h"
 #include "mongo/unittest/temp_dir.h"
@@ -75,8 +76,7 @@ namespace {
 
 auto makeRandom() {
     auto seed = SecureRandom().nextInt64();
-    unittest::log() << "PseudoRandom(" << std::showbase << std::hex << seed << std::dec
-                    << std::noshowbase << ")";
+    unittest::LOGV2("PseudoRandom({}{}{}{})", "std_showbase"_attr = std::showbase, "std_hex"_attr = std::hex, "seed"_attr = seed, "std_noshowbase"_attr = std::noshowbase);
     return PseudoRandom(seed);
 }
 
@@ -245,7 +245,7 @@ public:
 
     Future<FreeMonRegistrationResponse> sendRegistrationAsync(
         const FreeMonRegistrationRequest& req) final {
-        log() << "Sending Registration ...";
+        LOGV2("Sending Registration ...");
 
         _registers.addAndFetch(1);
 
@@ -291,7 +291,7 @@ public:
 
 
     Future<FreeMonMetricsResponse> sendMetricsAsync(const FreeMonMetricsRequest& req) final {
-        log() << "Sending Metrics ...";
+        LOGV2("Sending Metrics ...");
 
         _metrics.addAndFetch(1);
 
@@ -508,8 +508,8 @@ TEST(FreeMonRetryTest, TestRegistration) {
     // If jitter is large as possible, we'd expect trueMin increments before false.
     const auto trueMin = characterizeJitter(Seconds{9}, Seconds{119});
 
-    // unittest::log() << "trueMin:" << trueMin;
-    // unittest::log() << "trueMax:" << trueMax;
+    // unittest::LOGV2("trueMin:{}", "trueMin"_attr = trueMin);
+    // unittest::LOGV2("trueMax:{}", "trueMax"_attr = trueMax);
 
     for (int j = 0; j < 30; j++) {
         // std::cout << "j: " << j << "\n";
diff --git a/src/mongo/db/free_mon/free_mon_processor.cpp b/src/mongo/db/free_mon/free_mon_processor.cpp
index 8cb57bda42..fd23ed1e2c 100644
--- a/src/mongo/db/free_mon/free_mon_processor.cpp
+++ b/src/mongo/db/free_mon/free_mon_processor.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/free_mon/free_mon_storage.h"
 #include "mongo/db/service_context.h"
 #include "mongo/idl/idl_parser.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -646,7 +647,7 @@ void FreeMonProcessor::doAsyncRegisterComplete(
     // Notify waiters
     notifyPendingRegisters(Status::OK());
 
-    log() << "Free Monitoring is Enabled. Frequency: " << resp.getReportingInterval() << " seconds";
+    LOGV2("Free Monitoring is Enabled. Frequency: {} seconds", "resp_getReportingInterval"_attr = resp.getReportingInterval());
 
     // Enqueue next metrics upload immediately to deliver a good experience
     enqueue(FreeMonMessage::createNow(FreeMonMessageType::MetricsSend));
@@ -670,8 +671,7 @@ void FreeMonProcessor::doAsyncRegisterFail(
         return;
     }
 
-    LOG(1) << "Free Monitoring Registration Failed with status '" << msg->getPayload()
-           << "', retrying in " << _registrationRetry->getNextDuration();
+    LOGV2_DEBUG(1, "Free Monitoring Registration Failed with status '{}', retrying in {}", "msg_getPayload"_attr = msg->getPayload(), "_registrationRetry_getNextDuration"_attr = _registrationRetry->getNextDuration());
 
     // Enqueue a register retry
     enqueue(FreeMonRegisterCommandMessage::createWithDeadline(
@@ -688,7 +688,7 @@ void FreeMonProcessor::doCommandUnregister(
 
     writeState(client);
 
-    log() << "Free Monitoring is Disabled";
+    LOGV2("Free Monitoring is Disabled");
 
     msg->setStatus(Status::OK());
 }
@@ -855,8 +855,7 @@ void FreeMonProcessor::doAsyncMetricsFail(
         return;
     }
 
-    LOG(1) << "Free Monitoring Metrics upload failed with status " << msg->getPayload()
-           << ", retrying in " << _metricsRetry->getNextDuration();
+    LOGV2_DEBUG(1, "Free Monitoring Metrics upload failed with status {}, retrying in {}", "msg_getPayload"_attr = msg->getPayload(), "_metricsRetry_getNextDuration"_attr = _metricsRetry->getNextDuration());
 
     // Enqueue next metrics upload
     enqueue(FreeMonMessage::createWithDeadline(FreeMonMessageType::MetricsSend,
diff --git a/src/mongo/db/ftdc/controller.cpp b/src/mongo/db/ftdc/controller.cpp
index 937fe0dbc7..bd0e4aff0b 100644
--- a/src/mongo/db/ftdc/controller.cpp
+++ b/src/mongo/db/ftdc/controller.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/ftdc/collector.h"
 #include "mongo/db/ftdc/util.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/stdx/condition_variable.h"
 #include "mongo/stdx/thread.h"
@@ -137,8 +138,7 @@ BSONObj FTDCController::getMostRecentPeriodicDocument() {
 }
 
 void FTDCController::start() {
-    log() << "Initializing full-time diagnostic data capture with directory '"
-          << _path.generic_string() << "'";
+    LOGV2("Initializing full-time diagnostic data capture with directory '{}'", "_path_generic_string"_attr = _path.generic_string());
 
     // Start the thread
     _thread = stdx::thread([this] { doLoop(); });
@@ -152,7 +152,7 @@ void FTDCController::start() {
 }
 
 void FTDCController::stop() {
-    log() << "Shutting down full-time diagnostic data capture";
+    LOGV2("Shutting down full-time diagnostic data capture");
 
     {
         stdx::lock_guard<Latch> lock(_mutex);
@@ -180,7 +180,7 @@ void FTDCController::stop() {
     if (_mgr) {
         auto s = _mgr->close();
         if (!s.isOK()) {
-            log() << "Failed to close full-time diagnostic data capture file manager: " << s;
+            LOGV2("Failed to close full-time diagnostic data capture file manager: {}", "s"_attr = s);
         }
     }
 }
diff --git a/src/mongo/db/ftdc/file_manager.cpp b/src/mongo/db/ftdc/file_manager.cpp
index 61ac60fcc4..1a6f3ade40 100644
--- a/src/mongo/db/ftdc/file_manager.cpp
+++ b/src/mongo/db/ftdc/file_manager.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/ftdc/constants.h"
 #include "mongo/db/ftdc/file_reader.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -227,8 +228,7 @@ Status FTDCFileManager::trimDirectory(std::vector<boost::filesystem::path>& file
         size += fileSize;
 
         if (size >= maxSize) {
-            LOG(1) << "Cleaning file over full-time diagnostic data capture quota, file: "
-                   << (*it).generic_string() << " with size " << fileSize;
+            LOGV2_DEBUG(1, "Cleaning file over full-time diagnostic data capture quota, file: {} with size {}", "it_generic_string"_attr = (*it).generic_string(), "fileSize"_attr = fileSize);
 
             boost::filesystem::remove(*it, ec);
             if (ec) {
@@ -257,8 +257,7 @@ FTDCFileManager::recoverInterimFile() {
     boost::system::error_code ec;
     size_t size = boost::filesystem::file_size(interimFile, ec);
     if (ec) {
-        log() << "Recover interim file failed as the file size could not be checked: "
-              << ec.message();
+        LOGV2("Recover interim file failed as the file size could not be checked: {}", "ec_message"_attr = ec.message());
         return docs;
     }
 
@@ -269,11 +268,10 @@ FTDCFileManager::recoverInterimFile() {
     FTDCFileReader read;
     auto s = read.open(interimFile);
     if (!s.isOK()) {
-        log() << "Unclean full-time diagnostic data capture shutdown detected, found interim file, "
+        LOGV2("Unclean full-time diagnostic data capture shutdown detected, found interim file, "
                  "but failed "
                  "to open it, some "
-                 "metrics may have been lost. "
-              << s;
+                 "metrics may have been lost. {}", "s"_attr = s);
 
         // Note: We ignore any actual errors as reading from the interim files is a best-effort
         return docs;
@@ -288,10 +286,9 @@ FTDCFileManager::recoverInterimFile() {
 
     // Warn if the interim file was corrupt or we had an unclean shutdown
     if (!m.isOK() || !docs.empty()) {
-        log() << "Unclean full-time diagnostic data capture shutdown detected, found interim file, "
+        LOGV2("Unclean full-time diagnostic data capture shutdown detected, found interim file, "
                  "some "
-                 "metrics may have been lost. "
-              << m.getStatus();
+                 "metrics may have been lost. {}", "m_getStatus"_attr = m.getStatus());
     }
 
     // Note: We ignore any actual errors as reading from the interim files is a best-effort
diff --git a/src/mongo/db/ftdc/file_manager_test.cpp b/src/mongo/db/ftdc/file_manager_test.cpp
index a6cf6c6b38..dd35b75d54 100644
--- a/src/mongo/db/ftdc/file_manager_test.cpp
+++ b/src/mongo/db/ftdc/file_manager_test.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/ftdc/file_writer.h"
 #include "mongo/db/ftdc/ftdc_test.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/temp_dir.h"
 #include "mongo/unittest/unittest.h"
 
@@ -111,7 +112,7 @@ TEST_F(FTDCFileManagerTest, TestFull) {
     for (auto& file : files) {
         int fs = boost::filesystem::file_size(file);
         ASSERT_TRUE(fs < c.maxFileSizeBytes * 1.10);
-        unittest::log() << "File " << file.generic_string() << " has size " << fs;
+        unittest::LOGV2("File {} has size {}", "file_generic_string"_attr = file.generic_string(), "fs"_attr = fs);
         if (file.generic_string().find("interim") == std::string::npos) {
             sum += fs;
         }
diff --git a/src/mongo/db/ftdc/util.cpp b/src/mongo/db/ftdc/util.cpp
index 9500bf62ec..54c9550dec 100644
--- a/src/mongo/db/ftdc/util.cpp
+++ b/src/mongo/db/ftdc/util.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/ftdc/constants.h"
 #include "mongo/db/jsobj.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -180,8 +181,8 @@ StatusWith<bool> extractMetricsFromDocument(const BSONObj& referenceDoc,
     while (itCurrent.more()) {
         // Schema mismatch if current document is longer than reference document
         if (matches && !itReference.more()) {
-            LOG(4) << "full-time diagnostic data capture schema change: currrent document is "
-                      "longer than reference document";
+            LOGV2_DEBUG(4, "full-time diagnostic data capture schema change: currrent document is "
+                      "longer than reference document");
             matches = false;
         }
 
@@ -191,10 +192,7 @@ StatusWith<bool> extractMetricsFromDocument(const BSONObj& referenceDoc,
         if (matches) {
             // Check for matching field names
             if (referenceElement.fieldNameStringData() != currentElement.fieldNameStringData()) {
-                LOG(4)
-                    << "full-time diagnostic data capture schema change: field name change - from '"
-                    << referenceElement.fieldNameStringData() << "' to '"
-                    << currentElement.fieldNameStringData() << "'";
+                LOGV2_DEBUG(4, "full-time diagnostic data capture schema change: field name change - from '{}' to '{}'", "referenceElement_fieldNameStringData"_attr = referenceElement.fieldNameStringData(), "currentElement_fieldNameStringData"_attr = currentElement.fieldNameStringData());
                 matches = false;
             }
 
@@ -205,11 +203,8 @@ StatusWith<bool> extractMetricsFromDocument(const BSONObj& referenceDoc,
             if ((currentElement.type() != referenceElement.type()) &&
                 !(referenceElement.isNumber() == true &&
                   currentElement.isNumber() == referenceElement.isNumber())) {
-                LOG(4) << "full-time diagnostic data capture  schema change: field type change for "
-                          "field '"
-                       << referenceElement.fieldNameStringData() << "' from '"
-                       << static_cast<int>(referenceElement.type()) << "' to '"
-                       << static_cast<int>(currentElement.type()) << "'";
+                LOGV2_DEBUG(4, "full-time diagnostic data capture  schema change: field type change for "
+                          "field '{}' from '{}' to '{}'", "referenceElement_fieldNameStringData"_attr = referenceElement.fieldNameStringData(), "static_cast_int_referenceElement_type"_attr = static_cast<int>(referenceElement.type()), "static_cast_int_currentElement_type"_attr = static_cast<int>(currentElement.type()));
                 matches = false;
             }
         }
@@ -261,8 +256,8 @@ StatusWith<bool> extractMetricsFromDocument(const BSONObj& referenceDoc,
 
     // schema mismatch if ref is longer than curr
     if (matches && itReference.more()) {
-        LOG(4) << "full-time diagnostic data capture schema change: reference document is longer "
-                  "then current";
+        LOGV2_DEBUG(4, "full-time diagnostic data capture schema change: reference document is longer "
+                  "then current");
         matches = false;
     }
 
diff --git a/src/mongo/db/geo/r2_region_coverer.cpp b/src/mongo/db/geo/r2_region_coverer.cpp
index 284350f62a..aa6afb24fd 100644
--- a/src/mongo/db/geo/r2_region_coverer.cpp
+++ b/src/mongo/db/geo/r2_region_coverer.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/geo/r2_region_coverer.h"
 #include "mongo/db/geo/shapes.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -108,7 +109,7 @@ void R2RegionCoverer::getCovering(const R2Region& region, vector<GeoHash>* cover
         Candidate* candidate = _candidateQueue->top().second;  // Owned
         _candidateQueue->pop();
         // REDACT?? I think this may have User info, but I'm not sure how to redact
-        LOG(3) << "Pop: " << redact(candidate->cell.toString());
+        LOGV2_DEBUG(3, "Pop: {}", "redact_candidate_cell_toString"_attr = redact(candidate->cell.toString()));
 
         // Try to expand this cell into its children
         if (candidate->cell.getBits() < _minLevel || candidate->numChildren == 1 ||
@@ -123,7 +124,7 @@ void R2RegionCoverer::getCovering(const R2Region& region, vector<GeoHash>* cover
             candidate->isTerminal = true;
             addCandidate(candidate);
         }
-        LOG(3) << "Queue: " << _candidateQueue->size();
+        LOGV2_DEBUG(3, "Queue: {}", "_candidateQueue_size"_attr = _candidateQueue->size());
     }
 
     _region = nullptr;
@@ -185,7 +186,7 @@ void R2RegionCoverer::addCandidate(Candidate* candidate) {
                          numTerminals);
         _candidateQueue->push(make_pair(priority, candidate));  // queue owns candidate
         // REDACT??
-        LOG(3) << "Push: " << redact(candidate->cell.toString()) << " (" << priority << ") ";
+        LOGV2_DEBUG(3, "Push: {} ({}) ", "redact_candidate_cell_toString"_attr = redact(candidate->cell.toString()), "priority"_attr = priority);
     }
 }
 
diff --git a/src/mongo/db/geo/r2_region_coverer_test.cpp b/src/mongo/db/geo/r2_region_coverer_test.cpp
index d569cb78ce..5e0cbe3b54 100644
--- a/src/mongo/db/geo/r2_region_coverer_test.cpp
+++ b/src/mongo/db/geo/r2_region_coverer_test.cpp
@@ -38,6 +38,7 @@
 #include "mongo/base/init.h"
 #include "mongo/bson/bsonmisc.h"
 #include "mongo/db/geo/geometry_container.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
@@ -58,7 +59,7 @@ MONGO_INITIALIZER(R2CellUnion_Test)(InitializerContext* context) {
         }
     }
     generator.seed(seed);
-    log() << "R2CellUnion Test - Random Number Generator Seed: " << seed;
+    LOGV2("R2CellUnion Test - Random Number Generator Seed: {}", "seed"_attr = seed);
     return Status::OK();
 }
 
@@ -226,8 +227,8 @@ void checkCellIdCovering(const GeoHashConverter& converter,
 
     // The covering doesn't contain this cell, so the region shouldn't contain this cell.
     if (region.fastContains(cell)) {
-        log() << "covering " << covering.toString();
-        log() << "cellId " << cellId;
+        LOGV2("covering {}", "covering_toString"_attr = covering.toString());
+        LOGV2("cellId {}", "cellId"_attr = cellId);
     }
     ASSERT_FALSE(region.fastContains(cell));
 
@@ -726,8 +727,8 @@ TEST(R2CellUnion, Normalize) {
             ASSERT_EQUALS(expected[i], cellUnion.cellIds()[i]);
         }
     }
-    log() << "Average Unnormalized Size: " << unnormalizedSum * 1.0 / kIters;
-    log() << "Average Normalized Size: " << normalizedSum * 1.0 / kIters;
+    LOGV2("Average Unnormalized Size: {}", "unnormalizedSum_1_0_kIters"_attr = unnormalizedSum * 1.0 / kIters);
+    LOGV2("Average Normalized Size: {}", "normalizedSum_1_0_kIters"_attr = normalizedSum * 1.0 / kIters);
 }
 
 void testContains(const R2CellUnion& cellUnion, GeoHash id, int num) {
diff --git a/src/mongo/db/index/2d_key_generator_test.cpp b/src/mongo/db/index/2d_key_generator_test.cpp
index 2745eb06b8..8cf33d742a 100644
--- a/src/mongo/db/index/2d_key_generator_test.cpp
+++ b/src/mongo/db/index/2d_key_generator_test.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/index/2d_common.h"
 #include "mongo/db/index/expression_params.h"
 #include "mongo/db/json.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 
@@ -61,14 +62,12 @@ std::string dumpKeyset(const KeyStringSet& keyStrings) {
 
 bool assertKeysetsEqual(const KeyStringSet& expectedKeys, const KeyStringSet& actualKeys) {
     if (expectedKeys.size() != actualKeys.size()) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
     if (!std::equal(expectedKeys.begin(), expectedKeys.end(), actualKeys.begin())) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
diff --git a/src/mongo/db/index/btree_key_generator_test.cpp b/src/mongo/db/index/btree_key_generator_test.cpp
index 811c5d41ba..97e53e4437 100644
--- a/src/mongo/db/index/btree_key_generator_test.cpp
+++ b/src/mongo/db/index/btree_key_generator_test.cpp
@@ -39,6 +39,7 @@
 #include "mongo/bson/simple_bsonobj_comparator.h"
 #include "mongo/db/json.h"
 #include "mongo/db/query/collation/collator_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 
@@ -137,15 +138,13 @@ bool testKeygen(const BSONObj& kp,
     //
     bool match = keysetsEqual(expectedKeys, actualKeys);
     if (!match) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
     match = (expectedMultikeyPaths == actualMultikeyPaths);
     if (!match) {
-        log() << "Expected: " << dumpMultikeyPaths(expectedMultikeyPaths) << ", "
-              << "Actual: " << dumpMultikeyPaths(actualMultikeyPaths);
+        LOGV2("Expected: {}, Actual: {}", "dumpMultikeyPaths_expectedMultikeyPaths"_attr = dumpMultikeyPaths(expectedMultikeyPaths), "dumpMultikeyPaths_actualMultikeyPaths"_attr = dumpMultikeyPaths(actualMultikeyPaths));
     }
 
     return match;
diff --git a/src/mongo/db/index/duplicate_key_tracker.cpp b/src/mongo/db/index/duplicate_key_tracker.cpp
index 9898415dfe..2a79072288 100644
--- a/src/mongo/db/index/duplicate_key_tracker.cpp
+++ b/src/mongo/db/index/duplicate_key_tracker.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/curop.h"
 #include "mongo/db/index/index_access_method.h"
 #include "mongo/db/keypattern.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -79,8 +80,7 @@ Status DuplicateKeyTracker::recordKeys(OperationContext* opCtx, const std::vecto
         records.emplace_back(Record{RecordId(), RecordData(obj.objdata(), obj.objsize())});
     }
 
-    LOG(1) << "recording " << records.size() << " duplicate key conflicts on unique index: "
-           << _indexCatalogEntry->descriptor()->indexName();
+    LOGV2_DEBUG(1, "recording {} duplicate key conflicts on unique index: {}", "records_size"_attr = records.size(), "_indexCatalogEntry_descriptor_indexName"_attr = _indexCatalogEntry->descriptor()->indexName());
 
     WriteUnitOfWork wuow(opCtx);
     std::vector<Timestamp> timestamps(records.size());
@@ -138,9 +138,7 @@ Status DuplicateKeyTracker::checkConstraints(OperationContext* opCtx) const {
     invariant(resolved == _duplicateCounter.load());
 
     int logLevel = (resolved > 0) ? 0 : 1;
-    LOG(logLevel) << "index build: resolved " << resolved
-                  << " duplicate key conflicts for unique index: "
-                  << _indexCatalogEntry->descriptor()->indexName();
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(logLevel).toInt(), "index build: resolved {} duplicate key conflicts for unique index: {}", "resolved"_attr = resolved, "_indexCatalogEntry_descriptor_indexName"_attr = _indexCatalogEntry->descriptor()->indexName());
     return Status::OK();
 }
 
diff --git a/src/mongo/db/index/hash_key_generator_test.cpp b/src/mongo/db/index/hash_key_generator_test.cpp
index f2babba8cb..4e08d5f02f 100644
--- a/src/mongo/db/index/hash_key_generator_test.cpp
+++ b/src/mongo/db/index/hash_key_generator_test.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/hasher.h"
 #include "mongo/db/json.h"
 #include "mongo/db/query/collation/collator_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 
@@ -64,14 +65,12 @@ std::string dumpKeyset(const KeyStringSet& keyStrings) {
 
 bool assertKeysetsEqual(const KeyStringSet& expectedKeys, const KeyStringSet& actualKeys) {
     if (expectedKeys.size() != actualKeys.size()) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
     if (!std::equal(expectedKeys.begin(), expectedKeys.end(), actualKeys.begin())) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
diff --git a/src/mongo/db/index/haystack_access_method.cpp b/src/mongo/db/index/haystack_access_method.cpp
index e309dcaebe..310c4dbe81 100644
--- a/src/mongo/db/index/haystack_access_method.cpp
+++ b/src/mongo/db/index/haystack_access_method.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/index/haystack_access_method_internal.h"
 #include "mongo/db/jsobj.h"
 #include "mongo/db/query/internal_plans.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -89,8 +90,7 @@ void HaystackAccessMethod::searchCommand(OperationContext* opCtx,
                                          unsigned limit) const {
     Timer t;
 
-    LOG(1) << "SEARCH near:" << redact(nearObj) << " maxDistance:" << maxDistance
-           << " search: " << redact(search);
+    LOGV2_DEBUG(1, "SEARCH near:{} maxDistance:{} search: {}", "redact_nearObj"_attr = redact(nearObj), "maxDistance"_attr = maxDistance, "redact_search"_attr = redact(search));
     int x, y;
     {
         BSONObjIterator i(nearObj);
diff --git a/src/mongo/db/index/index_access_method_factory_impl.cpp b/src/mongo/db/index/index_access_method_factory_impl.cpp
index 2eb06511d1..9717d9fe8c 100644
--- a/src/mongo/db/index/index_access_method_factory_impl.cpp
+++ b/src/mongo/db/index/index_access_method_factory_impl.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/index/haystack_access_method.h"
 #include "mongo/db/index/s2_access_method.h"
 #include "mongo/db/index/wildcard_access_method.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -62,7 +63,7 @@ std::unique_ptr<IndexAccessMethod> IndexAccessMethodFactoryImpl::make(
         return std::make_unique<TwoDAccessMethod>(entry, std::move(sortedDataInterface));
     else if (IndexNames::WILDCARD == type)
         return std::make_unique<WildcardAccessMethod>(entry, std::move(sortedDataInterface));
-    log() << "Can't find index for keyPattern " << desc->keyPattern();
+    LOGV2("Can't find index for keyPattern {}", "desc_keyPattern"_attr = desc->keyPattern());
     fassertFailed(31021);
 }
 
diff --git a/src/mongo/db/index/index_build_interceptor.cpp b/src/mongo/db/index/index_build_interceptor.cpp
index 47ce29006c..649f5c86e4 100644
--- a/src/mongo/db/index/index_build_interceptor.cpp
+++ b/src/mongo/db/index/index_build_interceptor.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/multi_key_path_tracker.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 #include "mongo/util/progress_meter.h"
@@ -259,10 +260,7 @@ Status IndexBuildInterceptor::drainWritesIntoIndex(OperationContext* opCtx,
     progress->finished();
 
     int logLevel = (_numApplied - appliedAtStart > 0) ? 0 : 1;
-    LOG(logLevel) << "index build: drain applied " << (_numApplied - appliedAtStart)
-                  << " side writes (inserted: " << totalInserted << ", deleted: " << totalDeleted
-                  << ") for '" << _indexCatalogEntry->descriptor()->indexName() << "' in "
-                  << timer.millis() << " ms";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(logLevel).toInt(), "index build: drain applied {} side writes (inserted: {}, deleted: {}) for '{}' in {} ms", "_numApplied_appliedAtStart"_attr = (_numApplied - appliedAtStart), "totalInserted"_attr = totalInserted, "totalDeleted"_attr = totalDeleted, "_indexCatalogEntry_descriptor_indexName"_attr = _indexCatalogEntry->descriptor()->indexName(), "timer_millis"_attr = timer.millis());
 
     return Status::OK();
 }
@@ -346,7 +344,7 @@ void IndexBuildInterceptor::_yield(OperationContext* opCtx) {
 
     hangDuringIndexBuildDrainYield.executeIf(
         [&](auto&&) {
-            log() << "Hanging index build during drain yield";
+            LOGV2("Hanging index build during drain yield");
             hangDuringIndexBuildDrainYield.pauseWhileSet();
         },
         [&](auto&& config) {
@@ -472,8 +470,7 @@ Status IndexBuildInterceptor::sideWrite(OperationContext* opCtx,
                                     RecordData(doc.objdata(), doc.objsize())});
     }
 
-    LOG(2) << "recording " << records.size() << " side write keys on index '"
-           << _indexCatalogEntry->descriptor()->indexName() << "'";
+    LOGV2_DEBUG(2, "recording {} side write keys on index '{}'", "records_size"_attr = records.size(), "_indexCatalogEntry_descriptor_indexName"_attr = _indexCatalogEntry->descriptor()->indexName());
 
     // By passing a vector of null timestamps, these inserts are not timestamped individually, but
     // rather with the timestamp of the owning operation.
diff --git a/src/mongo/db/index/s2_key_generator_test.cpp b/src/mongo/db/index/s2_key_generator_test.cpp
index 1a8432d0ff..e2974876fe 100644
--- a/src/mongo/db/index/s2_key_generator_test.cpp
+++ b/src/mongo/db/index/s2_key_generator_test.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/index/s2_common.h"
 #include "mongo/db/json.h"
 #include "mongo/db/query/collation/collator_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -79,14 +80,12 @@ std::string dumpMultikeyPaths(const MultikeyPaths& multikeyPaths) {
 
 bool areKeysetsEqual(const KeyStringSet& expectedKeys, const KeyStringSet& actualKeys) {
     if (expectedKeys.size() != actualKeys.size()) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
     if (!std::equal(expectedKeys.begin(), expectedKeys.end(), actualKeys.begin())) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
diff --git a/src/mongo/db/index/wildcard_key_generator_test.cpp b/src/mongo/db/index/wildcard_key_generator_test.cpp
index 4d5d7f9f3c..5279ff8d53 100644
--- a/src/mongo/db/index/wildcard_key_generator_test.cpp
+++ b/src/mongo/db/index/wildcard_key_generator_test.cpp
@@ -34,6 +34,7 @@
 #include "mongo/bson/json.h"
 #include "mongo/db/index/wildcard_key_generator.h"
 #include "mongo/db/query/collation/collator_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 
@@ -67,14 +68,12 @@ std::string dumpKeyset(const KeyStringSet& keyStrings) {
 
 bool assertKeysetsEqual(const KeyStringSet& expectedKeys, const KeyStringSet& actualKeys) {
     if (expectedKeys.size() != actualKeys.size()) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
     if (!std::equal(expectedKeys.begin(), expectedKeys.end(), actualKeys.begin())) {
-        log() << "Expected: " << dumpKeyset(expectedKeys) << ", "
-              << "Actual: " << dumpKeyset(actualKeys);
+        LOGV2("Expected: {}, Actual: {}", "dumpKeyset_expectedKeys"_attr = dumpKeyset(expectedKeys), "dumpKeyset_actualKeys"_attr = dumpKeyset(actualKeys));
         return false;
     }
 
diff --git a/src/mongo/db/index_builds_coordinator.cpp b/src/mongo/db/index_builds_coordinator.cpp
index 5e52d4403c..b75c0fe569 100644
--- a/src/mongo/db/index_builds_coordinator.cpp
+++ b/src/mongo/db/index_builds_coordinator.cpp
@@ -55,6 +55,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/durable_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/shard_key_pattern.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
@@ -152,7 +153,7 @@ void onCommitIndexBuild(OperationContext* opCtx,
             // oplog entry.
             repl::UnreplicatedWritesBlock uwb(opCtx);
             if (!IndexTimestampHelper::setGhostCommitTimestampForCatalogWrite(opCtx, nss)) {
-                log() << "Did not timestamp index commit write.";
+                LOGV2("Did not timestamp index commit write.");
             }
             return;
         }
@@ -239,8 +240,7 @@ void unlockRSTLForIndexCleanup(OperationContext* opCtx) {
 void logFailure(Status status,
                 const NamespaceString& nss,
                 std::shared_ptr<ReplIndexBuildState> replState) {
-    log() << "Index build failed: " << replState->buildUUID << ": " << nss << " ( "
-          << replState->collectionUUID << " ): " << status;
+    LOGV2("Index build failed: {}: {} ( {} ): {}", "replState_buildUUID"_attr = replState->buildUUID, "nss"_attr = nss, "replState_collectionUUID"_attr = replState->collectionUUID, "status"_attr = status);
 }
 
 /**
@@ -254,7 +254,7 @@ void forEachIndexBuild(
         return;
     }
 
-    log() << logPrefix << "active index builds: " << indexBuilds.size();
+    LOGV2("{}active index builds: {}", "logPrefix"_attr = logPrefix, "indexBuilds_size"_attr = indexBuilds.size());
 
     for (auto replState : indexBuilds) {
         std::string indexNamesStr;
@@ -367,9 +367,7 @@ Status IndexBuildsCoordinator::_startIndexBuildForRecovery(OperationContext* opC
             // after an abort has been rolled back.
             if (!DurableCatalog::get(opCtx)->isIndexPresent(
                     opCtx, collection->getCatalogId(), indexNames[i])) {
-                log() << "The index for build " << buildUUID
-                      << " was not found while trying to drop the index during recovery: "
-                      << indexNames[i];
+                LOGV2("The index for build {} was not found while trying to drop the index during recovery: {}", "buildUUID"_attr = buildUUID, "indexNames_i"_attr = indexNames[i]);
                 continue;
             }
 
@@ -507,7 +505,7 @@ void IndexBuildsCoordinator::signalCommitAndWait(OperationContext* opCtx, const
         replState->condVar.notify_all();
     }
     auto fut = replState->sharedPromise.getFuture();
-    log() << "Index build joined after commit: " << buildUUID << ": " << fut.waitNoThrow(opCtx);
+    LOGV2("Index build joined after commit: {}: {}", "buildUUID"_attr = buildUUID, "fut_waitNoThrow_opCtx"_attr = fut.waitNoThrow(opCtx));
 
     // Throws if there was an error building the index.
     fut.get();
@@ -522,13 +520,12 @@ void IndexBuildsCoordinator::signalAbortAndWait(OperationContext* opCtx,
     // an abort for a non-existent index build. Abort should always succeed, so suppress the error.
     auto replStateResult = _getIndexBuild(buildUUID);
     if (!replStateResult.isOK()) {
-        log() << "ignoring error while aborting index build " << buildUUID << ": "
-              << replStateResult.getStatus();
+        LOGV2("ignoring error while aborting index build {}: {}", "buildUUID"_attr = buildUUID, "replStateResult_getStatus"_attr = replStateResult.getStatus());
         return;
     }
     auto replState = replStateResult.getValue();
     auto fut = replState->sharedPromise.getFuture();
-    log() << "Index build joined after abort: " << buildUUID << ": " << fut.waitNoThrow(opCtx);
+    LOGV2("Index build joined after abort: {}: {}", "buildUUID"_attr = buildUUID, "fut_waitNoThrow_opCtx"_attr = fut.waitNoThrow(opCtx));
 }
 
 void IndexBuildsCoordinator::abortIndexBuildByBuildUUID(OperationContext* opCtx,
@@ -566,7 +563,7 @@ bool containsUniqueIndexes(const std::vector<BSONObj>& specs) {
 }  // namespace
 
 void IndexBuildsCoordinator::onStepUp(OperationContext* opCtx) {
-    log() << "IndexBuildsCoordinator::onStepUp - this node is stepping up to primary";
+    LOGV2("IndexBuildsCoordinator::onStepUp - this node is stepping up to primary");
 
     auto indexBuilds = _getIndexBuilds();
     auto onIndexBuild = [this, opCtx](std::shared_ptr<ReplIndexBuildState> replState) {
@@ -597,7 +594,7 @@ void IndexBuildsCoordinator::onStepUp(OperationContext* opCtx) {
 }
 
 IndexBuilds IndexBuildsCoordinator::onRollback(OperationContext* opCtx) {
-    log() << "IndexBuildsCoordinator::onRollback - this node is entering the rollback state";
+    LOGV2("IndexBuildsCoordinator::onRollback - this node is entering the rollback state");
 
     IndexBuilds buildsAborted;
 
@@ -639,8 +636,7 @@ void IndexBuildsCoordinator::restartIndexBuildsForRecovery(OperationContext* opC
             CollectionCatalog::get(opCtx).lookupNSSByUUID(opCtx, build.collUUID);
         invariant(nss);
 
-        log() << "Restarting index build for collection: " << *nss
-              << ", collection UUID: " << build.collUUID << ", index build UUID: " << buildUUID;
+        LOGV2("Restarting index build for collection: {}, collection UUID: {}, index build UUID: {}", "nss"_attr = *nss, "build_collUUID"_attr = build.collUUID, "buildUUID"_attr = buildUUID);
 
         IndexBuildsCoordinator::IndexBuildOptions indexBuildOptions;
         // Start the index build as if in secondary oplog application.
@@ -943,7 +939,7 @@ Status IndexBuildsCoordinator::_registerIndexBuild(
                     }
                 }
                 std::string msg = ss;
-                log() << msg;
+                LOGV2("{}", "msg"_attr = msg);
                 if (aborted) {
                     return {ErrorCodes::IndexBuildAborted, msg};
                 }
@@ -1181,7 +1177,7 @@ Status IndexBuildsCoordinator::_setUpIndexBuild(OperationContext* opCtx,
         ((status == ErrorCodes::IndexOptionsConflict ||
           status == ErrorCodes::IndexKeySpecsConflict) &&
          options.indexConstraints == IndexBuildsManager::IndexConstraints::kRelax)) {
-        LOG(1) << "Ignoring indexing error: " << redact(status);
+        LOGV2_DEBUG(1, "Ignoring indexing error: {}", "redact_status"_attr = redact(status));
 
         // The requested index (specs) are already built or are being built. Return success
         // early (this is v4.0 behavior compatible).
@@ -1433,11 +1429,7 @@ void IndexBuildsCoordinator::_runIndexBuildInner(OperationContext* opCtx,
         _indexBuildsManager.tearDownIndexBuild(
             opCtx, collection, replState->buildUUID, MultiIndexBlock::kNoopOnCleanUpFn);
 
-        log() << "Index build completed successfully: " << replState->buildUUID << ": " << nss
-              << " ( " << replState->collectionUUID
-              << " ). Index specs built: " << replState->indexSpecs.size()
-              << ". Indexes in catalog before build: " << replState->stats.numIndexesBefore
-              << ". Indexes in catalog after build: " << replState->stats.numIndexesAfter;
+        LOGV2("Index build completed successfully: {}: {} ( {} ). Index specs built: {}. Indexes in catalog before build: {}. Indexes in catalog after build: {}", "replState_buildUUID"_attr = replState->buildUUID, "nss"_attr = nss, "replState_collectionUUID"_attr = replState->collectionUUID, "replState_indexSpecs_size"_attr = replState->indexSpecs.size(), "replState_stats_numIndexesBefore"_attr = replState->stats.numIndexesBefore, "replState_stats_numIndexesAfter"_attr = replState->stats.numIndexesAfter);
         return;
     }
 
@@ -1512,9 +1504,8 @@ void IndexBuildsCoordinator::_buildIndexTwoPhase(
         if (!replSetAndNotPrimary) {
             throw;
         }
-        log() << "Index build failed before final phase during oplog application. "
-                 "Waiting for abort: "
-              << replState->buildUUID << ": " << ex;
+        LOGV2("Index build failed before final phase during oplog application. "
+                 "Waiting for abort: {}: {}", "replState_buildUUID"_attr = replState->buildUUID, "ex"_attr = ex);
         preAbortStatus = ex.toStatus();
     }
 
@@ -1571,7 +1562,7 @@ void IndexBuildsCoordinator::_scanCollectionAndInsertKeysIntoSorter(
     }
 
     if (MONGO_unlikely(hangAfterIndexBuildDumpsInsertsFromBulk.shouldFail())) {
-        log() << "Hanging after dumping inserts from bulk builder";
+        LOGV2("Hanging after dumping inserts from bulk builder");
         hangAfterIndexBuildDumpsInsertsFromBulk.pauseWhileSet();
     }
 }
@@ -1597,7 +1588,7 @@ NamespaceString IndexBuildsCoordinator::_insertKeysFromSideTablesWithoutBlocking
     }
 
     if (MONGO_unlikely(hangAfterIndexBuildFirstDrain.shouldFail())) {
-        log() << "Hanging after index build first drain";
+        LOGV2("Hanging after index build first drain");
         hangAfterIndexBuildFirstDrain.pauseWhileSet();
     }
 
@@ -1619,7 +1610,7 @@ NamespaceString IndexBuildsCoordinator::_insertKeysFromSideTablesWithoutBlocking
     }
 
     if (MONGO_unlikely(hangAfterIndexBuildSecondDrain.shouldFail())) {
-        log() << "Hanging after index build second drain";
+        LOGV2("Hanging after index build second drain");
         hangAfterIndexBuildSecondDrain.pauseWhileSet();
     }
 
@@ -1636,8 +1627,7 @@ Timestamp IndexBuildsCoordinator::_waitForCommitOrAbort(
     const Status& preAbortStatus) {
     Timestamp commitIndexBuildTimestamp;
     if (shouldWaitForCommitOrAbort(opCtx, nss, *replState)) {
-        log() << "Index build waiting for commit or abort before completing final phase: "
-              << replState->buildUUID;
+        LOGV2("Index build waiting for commit or abort before completing final phase: {}", "replState_buildUUID"_attr = replState->buildUUID);
 
         // Yield locks and storage engine resources before blocking.
         opCtx->recoveryUnit()->abandonSnapshot();
@@ -1652,9 +1642,7 @@ Timestamp IndexBuildsCoordinator::_waitForCommitOrAbort(
         opCtx->waitForConditionOrInterrupt(replState->condVar, lk, isReadyToCommitOrAbort);
 
         if (replState->isCommitReady) {
-            log() << "Committing index build: " << replState->buildUUID
-                  << ", timestamp: " << replState->commitTimestamp
-                  << ", collection UUID: " << replState->collectionUUID;
+            LOGV2("Committing index build: {}, timestamp: {}, collection UUID: {}", "replState_buildUUID"_attr = replState->buildUUID, "replState_commitTimestamp"_attr = replState->commitTimestamp, "replState_collectionUUID"_attr = replState->collectionUUID);
             commitIndexBuildTimestamp = replState->commitTimestamp;
             invariant(!replState->aborted, replState->buildUUID.toString());
             uassertStatusOK(preAbortStatus.withContext(
@@ -1662,11 +1650,7 @@ Timestamp IndexBuildsCoordinator::_waitForCommitOrAbort(
                                  "commitIndexBuild oplog entry from the primary with timestamp: "
                               << replState->commitTimestamp.toString()));
         } else if (replState->aborted) {
-            log() << "Aborting index build: " << replState->buildUUID
-                  << ", timestamp: " << replState->abortTimestamp
-                  << ", reason: " << replState->abortReason
-                  << ", collection UUID: " << replState->collectionUUID
-                  << ", local index error (if any): " << preAbortStatus;
+            LOGV2("Aborting index build: {}, timestamp: {}, reason: {}, collection UUID: {}, local index error (if any): {}", "replState_buildUUID"_attr = replState->buildUUID, "replState_abortTimestamp"_attr = replState->abortTimestamp, "replState_abortReason"_attr = replState->abortReason, "replState_collectionUUID"_attr = replState->collectionUUID, "preAbortStatus"_attr = preAbortStatus);
             invariant(!replState->isCommitReady, replState->buildUUID.toString());
         }
     }
@@ -1729,14 +1713,13 @@ void IndexBuildsCoordinator::_insertKeysFromSideTablesAndCommit(
         }
 
         if (indexBuildOptions.replSetAndNotPrimaryAtStart) {
-            LOG(1) << "Skipping createIndexes oplog entry for index build: "
-                   << replState->buildUUID;
+            LOGV2_DEBUG(1, "Skipping createIndexes oplog entry for index build: {}", "replState_buildUUID"_attr = replState->buildUUID);
             // Get a timestamp to complete the index build in the absence of a createIndexBuild
             // oplog entry.
             repl::UnreplicatedWritesBlock uwb(opCtx);
             if (!IndexTimestampHelper::setGhostCommitTimestampForCatalogWrite(opCtx,
                                                                               collection->ns())) {
-                log() << "Did not timestamp index commit write.";
+                LOGV2("Did not timestamp index commit write.");
             }
             return;
         }
@@ -1775,7 +1758,7 @@ StatusWith<std::pair<long long, long long>> IndexBuildsCoordinator::_runIndexReb
     indexCatalogStats.numIndexesBefore = getNumIndexesTotal(opCtx, collection);
 
     try {
-        log() << "Index builds manager starting: " << buildUUID << ": " << nss;
+        LOGV2("Index builds manager starting: {}: {}", "buildUUID"_attr = buildUUID, "nss"_attr = nss);
 
         std::tie(numRecords, dataSize) = uassertStatusOK(
             _indexBuildsManager.startBuildingIndexForRecovery(opCtx, collection->ns(), buildUUID));
@@ -1793,14 +1776,11 @@ StatusWith<std::pair<long long, long long>> IndexBuildsCoordinator::_runIndexReb
 
         indexCatalogStats.numIndexesAfter = getNumIndexesTotal(opCtx, collection);
 
-        log() << "Index builds manager completed successfully: " << buildUUID << ": " << nss
-              << ". Index specs requested: " << replState->indexSpecs.size()
-              << ". Indexes in catalog before build: " << indexCatalogStats.numIndexesBefore
-              << ". Indexes in catalog after build: " << indexCatalogStats.numIndexesAfter;
+        LOGV2("Index builds manager completed successfully: {}: {}. Index specs requested: {}. Indexes in catalog before build: {}. Indexes in catalog after build: {}", "buildUUID"_attr = buildUUID, "nss"_attr = nss, "replState_indexSpecs_size"_attr = replState->indexSpecs.size(), "indexCatalogStats_numIndexesBefore"_attr = indexCatalogStats.numIndexesBefore, "indexCatalogStats_numIndexesAfter"_attr = indexCatalogStats.numIndexesAfter);
     } catch (const DBException& ex) {
         status = ex.toStatus();
         invariant(status != ErrorCodes::IndexAlreadyExists);
-        log() << "Index builds manager failed: " << buildUUID << ": " << nss << ": " << status;
+        LOGV2("Index builds manager failed: {}: {}: {}", "buildUUID"_attr = buildUUID, "nss"_attr = nss, "status"_attr = status);
     }
 
     // Index build is registered in manager regardless of IndexBuildsManager::setUpIndexBuild()
diff --git a/src/mongo/db/initialize_server_global_state.cpp b/src/mongo/db/initialize_server_global_state.cpp
index 41e092f949..f6641554be 100644
--- a/src/mongo/db/initialize_server_global_state.cpp
+++ b/src/mongo/db/initialize_server_global_state.cpp
@@ -58,6 +58,7 @@
 #include "mongo/logger/rotatable_file_manager.h"
 #include "mongo/logger/rotatable_file_writer.h"
 #include "mongo/logger/syslog_appender.h"
+#include "mongo/logv2/log.h"
 #include "mongo/logv2/log_domain_global.h"
 #include "mongo/platform/process_id.h"
 #include "mongo/util/log.h"
@@ -320,7 +321,7 @@ MONGO_INITIALIZER_GENERAL(ServerLogRedirection,
                 : logv2::LogDomainGlobal::ConfigurationOptions::OpenMode::kTruncate;
 
             if (serverGlobalParams.logAppend && exists) {
-                log() << "***** SERVER RESTARTED *****";
+                LOGV2("***** SERVER RESTARTED *****");
                 // FIXME rewrite for logv2
                 // Status status = logger::RotatableFileWriter::Use(writer.getValue()).status();
                 // if (!status.isOK())
@@ -338,7 +339,7 @@ MONGO_INITIALIZER_GENERAL(ServerLogRedirection,
             javascriptAppender = std::make_unique<RotatableFileAppender<MessageEventEphemeral>>(
                 std::make_unique<MessageEventDetailsEncoder>(), writer.getValue());
             if (serverGlobalParams.logAppend && exists) {
-                log() << "***** SERVER RESTARTED *****";
+                LOGV2("***** SERVER RESTARTED *****");
                 Status status = logger::RotatableFileWriter::Use(writer.getValue()).status();
                 if (!status.isOK())
                     return status;
diff --git a/src/mongo/db/introspect.cpp b/src/mongo/db/introspect.cpp
index 82993e676c..779fcd1d53 100644
--- a/src/mongo/db/introspect.cpp
+++ b/src/mongo/db/introspect.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/curop.h"
 #include "mongo/db/db_raii.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/client_metadata.h"
 #include "mongo/rpc/metadata/client_metadata_ismaster.h"
 #include "mongo/util/log.h"
@@ -159,8 +160,7 @@ void profile(OperationContext* opCtx, NetworkOp op) {
             Database* const db = autoGetDb->getDb();
             if (!db) {
                 // Database disappeared
-                log() << "note: not profiling because db went away for "
-                      << CurOp::get(opCtx)->getNS();
+                LOGV2("note: not profiling because db went away for {}", "CurOp_get_opCtx_getNS"_attr = CurOp::get(opCtx)->getNS());
                 break;
             }
 
@@ -231,7 +231,7 @@ Status createProfileCollection(OperationContext* opCtx, Database* db) {
     }
 
     // system.profile namespace doesn't exist; create it
-    log() << "Creating profile collection: " << dbProfilingNS;
+    LOGV2("Creating profile collection: {}", "dbProfilingNS"_attr = dbProfilingNS);
 
     CollectionOptions collectionOptions;
     collectionOptions.capped = true;
diff --git a/src/mongo/db/keys_collection_client_direct.cpp b/src/mongo/db/keys_collection_client_direct.cpp
index 861440f770..8e1915fd62 100644
--- a/src/mongo/db/keys_collection_client_direct.cpp
+++ b/src/mongo/db/keys_collection_client_direct.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/logical_time.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog/sharding_catalog_client.h"
 #include "mongo/s/write_ops/batched_command_request.h"
@@ -158,9 +159,7 @@ Status KeysCollectionClientDirect::_insert(OperationContext* opCtx,
             Shard::CommandResponse::processBatchWriteResponse(swResponse, &batchResponse);
         if (retry < kOnErrorNumRetries &&
             isRetriableError(writeStatus.code(), Shard::RetryPolicy::kIdempotent)) {
-            LOG(2) << "Batch write command to " << nss.db()
-                   << "failed with retriable error and will be retried"
-                   << causedBy(redact(writeStatus));
+            LOGV2_DEBUG(2, "Batch write command to {}failed with retriable error and will be retried{}", "nss_db"_attr = nss.db(), "causedBy_redact_writeStatus"_attr = causedBy(redact(writeStatus)));
             continue;
         }
 
diff --git a/src/mongo/db/keys_collection_manager.cpp b/src/mongo/db/keys_collection_manager.cpp
index 91e8bd8f4a..13bc266e7a 100644
--- a/src/mongo/db/keys_collection_manager.cpp
+++ b/src/mongo/db/keys_collection_manager.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/logical_time.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -293,7 +294,7 @@ void KeysCollectionManager::PeriodicRunner::_doPeriodicRefresh(ServiceContext* s
                     return _inShutdown || _refreshRequest;
                 });
         } catch (const DBException& e) {
-            LOG(1) << "Unable to wait for refresh request due to: " << e;
+            LOGV2_DEBUG(1, "Unable to wait for refresh request due to: {}", "e"_attr = e);
 
             if (ErrorCodes::isShutdownError(e)) {
                 return;
diff --git a/src/mongo/db/kill_sessions_common.cpp b/src/mongo/db/kill_sessions_common.cpp
index 7a3f93e9d3..3b064f4ede 100644
--- a/src/mongo/db/kill_sessions_common.cpp
+++ b/src/mongo/db/kill_sessions_common.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/session_killer.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -56,8 +57,7 @@ SessionKiller::Result killSessionsLocalKillOps(OperationContext* opCtx,
                 if (const KillAllSessionsByPattern* pattern = matcher.match(*lsid)) {
                     ScopedKillAllSessionsByPatternImpersonator impersonator(opCtx, *pattern);
 
-                    log() << "killing op: " << opCtxToKill->getOpID()
-                          << " as part of killing session: " << lsid->toBSON();
+                    LOGV2("killing op: {} as part of killing session: {}", "opCtxToKill_getOpID"_attr = opCtxToKill->getOpID(), "lsid_toBSON"_attr = lsid->toBSON());
 
                     opCtx->getServiceContext()->killOperation(lk, opCtxToKill);
                 }
diff --git a/src/mongo/db/kill_sessions_local.cpp b/src/mongo/db/kill_sessions_local.cpp
index eb708bb97f..cf1ce8db5f 100644
--- a/src/mongo/db/kill_sessions_local.cpp
+++ b/src/mongo/db/kill_sessions_local.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/session_catalog.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -132,11 +133,8 @@ void killAllExpiredTransactions(OperationContext* opCtx) {
                            // that as aborted due to transactionLifetimeLimitSessions.
                            if (txnParticipant.transactionIsInProgress() ||
                                txnParticipant.transactionIsAborted()) {
-                               log() << "Aborting transaction with txnNumber "
-                                     << txnParticipant.getActiveTxnNumber() << " on session "
-                                     << session.getSessionId().getId()
-                                     << " because it has been running for longer than "
-                                        "'transactionLifetimeLimitSeconds'";
+                               LOGV2("Aborting transaction with txnNumber {} on session {} because it has been running for longer than "
+                                        "'transactionLifetimeLimitSeconds'", "txnParticipant_getActiveTxnNumber"_attr = txnParticipant.getActiveTxnNumber(), "session_getSessionId_getId"_attr = session.getSessionId().getId());
                                if (txnParticipant.transactionIsInProgress()) {
                                    txnParticipant.abortTransaction(opCtx);
                                }
@@ -205,9 +203,7 @@ void yieldLocksForPreparedTransactions(OperationContext* opCtx) {
                            // any new
                            // writes.
                            if (txnParticipant.transactionIsPrepared()) {
-                               LOG(3) << "Yielding locks of prepared transaction. SessionId: "
-                                      << session.getSessionId().getId()
-                                      << " TxnNumber: " << txnParticipant.getActiveTxnNumber();
+                               LOGV2_DEBUG(3, "Yielding locks of prepared transaction. SessionId: {} TxnNumber: {}", "session_getSessionId_getId"_attr = session.getSessionId().getId(), "txnParticipant_getActiveTxnNumber"_attr = txnParticipant.getActiveTxnNumber());
                                txnParticipant.refreshLocksForPreparedTransaction(killerOpCtx, true);
                            }
                        },
diff --git a/src/mongo/db/log_process_details.cpp b/src/mongo/db/log_process_details.cpp
index 8f7bd8cf5b..8e922320ac 100644
--- a/src/mongo/db/log_process_details.cpp
+++ b/src/mongo/db/log_process_details.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/server_options.h"
 #include "mongo/db/server_options_server_helpers.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/socket_utils.h"
 #include "mongo/util/processinfo.h"
@@ -50,21 +51,18 @@ bool is32bit() {
 
 void logProcessDetails() {
     auto&& vii = VersionInfoInterface::instance();
-    log() << mongodVersion(vii);
+    LOGV2("{}", "mongodVersion_vii"_attr = mongodVersion(vii));
     vii.logBuildInfo();
 
     if (ProcessInfo::getMemSizeMB() < ProcessInfo::getSystemMemSizeMB()) {
-        log() << ProcessInfo::getMemSizeMB() << " MB of memory available to the process out of "
-              << ProcessInfo::getSystemMemSizeMB() << " MB total system memory";
+        LOGV2("{} MB of memory available to the process out of {} MB total system memory", "ProcessInfo_getMemSizeMB"_attr = ProcessInfo::getMemSizeMB(), "ProcessInfo_getSystemMemSizeMB"_attr = ProcessInfo::getSystemMemSizeMB());
     }
 
     printCommandLineOpts();
 }
 
 void logProcessDetailsForLogRotate(ServiceContext* serviceContext) {
-    log() << "pid=" << ProcessId::getCurrent() << " port=" << serverGlobalParams.port
-          << (is32bit() ? " 32" : " 64") << "-bit "
-          << "host=" << getHostNameCached();
+    LOGV2("pid={} port={}{}-bit host={}", "ProcessId_getCurrent"_attr = ProcessId::getCurrent(), "serverGlobalParams_port"_attr = serverGlobalParams.port, "is32bit_32_64"_attr = (is32bit() ? " 32" : " 64"), "getHostNameCached"_attr = getHostNameCached());
 
     auto replCoord = repl::ReplicationCoordinator::get(serviceContext);
     if (replCoord != nullptr &&
@@ -72,10 +70,10 @@ void logProcessDetailsForLogRotate(ServiceContext* serviceContext) {
         auto rsConfig = replCoord->getConfig();
 
         if (rsConfig.isInitialized()) {
-            log() << "Replica Set Config: " << rsConfig.toBSON();
-            log() << "Replica Set Member State: " << (replCoord->getMemberState()).toString();
+            LOGV2("Replica Set Config: {}", "rsConfig_toBSON"_attr = rsConfig.toBSON());
+            LOGV2("Replica Set Member State: {}", "replCoord_getMemberState_toString"_attr = (replCoord->getMemberState()).toString());
         } else {
-            log() << "Node currently has no Replica Set Config.";
+            LOGV2("Node currently has no Replica Set Config.");
         }
     }
 
diff --git a/src/mongo/db/logical_clock.cpp b/src/mongo/db/logical_clock.cpp
index 5cc982465d..13ec9cce68 100644
--- a/src/mongo/db/logical_clock.cpp
+++ b/src/mongo/db/logical_clock.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/time_proof_service.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -118,8 +119,8 @@ LogicalTime LogicalClock::reserveTicks(uint64_t nTicks) {
     // second.
     else if (clusterTime.asTimestamp().getInc() > (kMaxSignedInt - nTicks)) {
 
-        log() << "Exceeded maximum allowable increment value within one second. Moving clusterTime "
-                 "forward to the next second.";
+        LOGV2("Exceeded maximum allowable increment value within one second. Moving clusterTime "
+                 "forward to the next second.");
 
         // Move time forward to the next second
         clusterTime = LogicalTime(Timestamp(clusterTime.asTimestamp().getSecs() + 1, 0));
diff --git a/src/mongo/db/logical_time_validator.cpp b/src/mongo/db/logical_time_validator.cpp
index 6d448f78a5..dc56e0ede6 100644
--- a/src/mongo/db/logical_time_validator.cpp
+++ b/src/mongo/db/logical_time_validator.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/logical_clock.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -195,7 +196,7 @@ bool LogicalTimeValidator::shouldGossipLogicalTime() {
 }
 
 void LogicalTimeValidator::resetKeyManagerCache() {
-    log() << "Resetting key manager cache";
+    LOGV2("Resetting key manager cache");
     invariant(_keyManager);
     _keyManager->clearCache();
     stdx::lock_guard<Latch> lk(_mutex);
@@ -205,7 +206,7 @@ void LogicalTimeValidator::resetKeyManagerCache() {
 
 void LogicalTimeValidator::stopKeyManager() {
     if (_keyManager) {
-        log() << "Stopping key manager";
+        LOGV2("Stopping key manager");
         _keyManager->stopMonitoring();
         _keyManager->clearCache();
 
@@ -213,7 +214,7 @@ void LogicalTimeValidator::stopKeyManager() {
         _lastSeenValidTime = SignedLogicalTime();
         _timeProofService.resetCache();
     } else {
-        log() << "Stopping key manager: no key manager exists.";
+        LOGV2("Stopping key manager: no key manager exists.");
     }
 }
 
diff --git a/src/mongo/db/matcher/rewrite_expr.cpp b/src/mongo/db/matcher/rewrite_expr.cpp
index 01e5a6e51c..f2a21d9605 100644
--- a/src/mongo/db/matcher/rewrite_expr.cpp
+++ b/src/mongo/db/matcher/rewrite_expr.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/matcher/expression_internal_expr_eq.h"
 #include "mongo/db/matcher/expression_leaf.h"
 #include "mongo/db/matcher/expression_tree.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -44,16 +45,16 @@ using CmpOp = ExpressionCompare::CmpOp;
 
 RewriteExpr::RewriteResult RewriteExpr::rewrite(const boost::intrusive_ptr<Expression>& expression,
                                                 const CollatorInterface* collator) {
-    LOG(5) << "Expression prior to rewrite: " << expression->serialize(false);
+    LOGV2_DEBUG(5, "Expression prior to rewrite: {}", "expression_serialize_false"_attr = expression->serialize(false));
 
     RewriteExpr rewriteExpr(collator);
     std::unique_ptr<MatchExpression> matchExpression;
 
     if (auto matchTree = rewriteExpr._rewriteExpression(expression)) {
         matchExpression = std::move(matchTree);
-        LOG(5) << "Post-rewrite MatchExpression: " << matchExpression->debugString();
+        LOGV2_DEBUG(5, "Post-rewrite MatchExpression: {}", "matchExpression_debugString"_attr = matchExpression->debugString());
         matchExpression = MatchExpression::optimize(std::move(matchExpression));
-        LOG(5) << "Post-rewrite/post-optimized MatchExpression: " << matchExpression->debugString();
+        LOGV2_DEBUG(5, "Post-rewrite/post-optimized MatchExpression: {}", "matchExpression_debugString"_attr = matchExpression->debugString());
     }
 
     return {std::move(matchExpression), std::move(rewriteExpr._matchExprElemStorage)};
diff --git a/src/mongo/db/matcher/schema/json_schema_parser.cpp b/src/mongo/db/matcher/schema/json_schema_parser.cpp
index a8ad976b5d..7079469557 100644
--- a/src/mongo/db/matcher/schema/json_schema_parser.cpp
+++ b/src/mongo/db/matcher/schema/json_schema_parser.cpp
@@ -60,6 +60,7 @@
 #include "mongo/db/matcher/schema/expression_internal_schema_xor.h"
 #include "mongo/db/matcher/schema/json_pointer.h"
 #include "mongo/logger/log_component_settings.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/string_map.h"
 
@@ -1610,12 +1611,11 @@ StatusWithMatchExpression JSONSchemaParser::parse(
     const boost::intrusive_ptr<ExpressionContext>& expCtx,
     BSONObj schema,
     bool ignoreUnknownKeywords) {
-    LOG(5) << "Parsing JSON Schema: " << schema.jsonString(JsonStringFormat::LegacyStrict);
+    LOGV2_DEBUG(5, "Parsing JSON Schema: {}", "schema_jsonString_JsonStringFormat_LegacyStrict"_attr = schema.jsonString(JsonStringFormat::LegacyStrict));
     try {
         auto translation = _parse(expCtx, ""_sd, schema, ignoreUnknownKeywords);
         if (shouldLog(logger::LogSeverity::Debug(5)) && translation.isOK()) {
-            LOG(5) << "Translated schema match expression: "
-                   << translation.getValue()->debugString();
+            LOGV2_DEBUG(5, "Translated schema match expression: {}", "translation_getValue_debugString"_attr = translation.getValue()->debugString());
         }
         return translation;
     } catch (const DBException& ex) {
diff --git a/src/mongo/db/mongod_options.cpp b/src/mongo/db/mongod_options.cpp
index 11a75108e9..6daa247507 100644
--- a/src/mongo/db/mongod_options.cpp
+++ b/src/mongo/db/mongod_options.cpp
@@ -53,6 +53,7 @@
 #include "mongo/db/server_options_base.h"
 #include "mongo/db/server_options_nongeneral_gen.h"
 #include "mongo/db/server_options_server_helpers.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/ssl_options.h"
 #include "mongo/util/options_parser/startup_options.h"
@@ -101,13 +102,13 @@ void printMongodHelp(const moe::OptionSection& options) {
 namespace {
 void sysRuntimeInfo() {
 #if defined(_SC_PAGE_SIZE)
-    log() << "  page size: " << (int)sysconf(_SC_PAGE_SIZE);
+    LOGV2("  page size: {}", "int_sysconf__SC_PAGE_SIZE"_attr = (int)sysconf(_SC_PAGE_SIZE));
 #endif
 #if defined(_SC_PHYS_PAGES)
-    log() << "  _SC_PHYS_PAGES: " << sysconf(_SC_PHYS_PAGES);
+    LOGV2("  _SC_PHYS_PAGES: {}", "sysconf__SC_PHYS_PAGES"_attr = sysconf(_SC_PHYS_PAGES));
 #endif
 #if defined(_SC_AVPHYS_PAGES)
-    log() << "  _SC_AVPHYS_PAGES: " << sysconf(_SC_AVPHYS_PAGES);
+    LOGV2("  _SC_AVPHYS_PAGES: {}", "sysconf__SC_AVPHYS_PAGES"_attr = sysconf(_SC_AVPHYS_PAGES));
 #endif
 }
 }  // namespace
@@ -121,7 +122,7 @@ bool handlePreValidationMongodOptions(const moe::Environment& params,
     if (params.count("version") && params["version"].as<bool>() == true) {
         setPlainConsoleLogger();
         auto&& vii = VersionInfoInterface::instance();
-        log() << mongodVersion(vii);
+        LOGV2("{}", "mongodVersion_vii"_attr = mongodVersion(vii));
         vii.logBuildInfo();
         return false;
     }
@@ -630,10 +631,10 @@ Status storeMongodOptions(const moe::Environment& params) {
     // Check if we are 32 bit and have not explicitly specified any journaling options
     if (sizeof(void*) == 4 && !params.count("storage.journal.enabled")) {
         // trying to make this stand out more like startup warnings
-        log() << endl;
+        LOGV2("");
         warning() << "32-bit servers don't have journaling enabled by default. "
                   << "Please use --journal if you want durability.";
-        log() << endl;
+        LOGV2("");
     }
 
     bool isClusterRoleShard = params.count("shardsvr");
diff --git a/src/mongo/db/operation_context.cpp b/src/mongo/db/operation_context.cpp
index 0a281d3b3b..ae459c0888 100644
--- a/src/mongo/db/operation_context.cpp
+++ b/src/mongo/db/operation_context.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/client.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/platform/random.h"
 #include "mongo/transport/baton.h"
@@ -218,7 +219,7 @@ Status OperationContext::checkForInterruptNoAssert() noexcept {
 
     checkForInterruptFail.executeIf(
         [&](auto&&) {
-            log() << "set pending kill on op " << getOpID() << ", for checkForInterruptFail";
+            LOGV2("set pending kill on op {}, for checkForInterruptFail", "getOpID"_attr = getOpID());
             markKilled();
         },
         [&](auto&& data) { return opShouldFail(getClient(), data); });
@@ -319,7 +320,7 @@ void OperationContext::markKilled(ErrorCodes::Error killCode) {
     invariant(!ErrorExtraInfo::parserFor(killCode));
 
     if (killCode == ErrorCodes::ClientDisconnect) {
-        log() << "operation was interrupted because a client disconnected";
+        LOGV2("operation was interrupted because a client disconnected");
     }
 
     if (auto status = ErrorCodes::OK; _killCode.compareAndSwap(&status, killCode)) {
diff --git a/src/mongo/db/ops/update_result.cpp b/src/mongo/db/ops/update_result.cpp
index 8765dd1dde..aec9492fc2 100644
--- a/src/mongo/db/ops/update_result.cpp
+++ b/src/mongo/db/ops/update_result.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/ops/update_result.h"
 
 #include "mongo/db/lasterror.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 
@@ -53,7 +54,7 @@ UpdateResult::UpdateResult(bool existing_,
     if (!existing && numMatched == 0 && !id.eoo()) {
         upserted = id.wrap(kUpsertedFieldName);
     }
-    LOG(4) << "UpdateResult -- " << redact(toString());
+    LOGV2_DEBUG(4, "UpdateResult -- {}", "redact_toString"_attr = redact(toString()));
 }
 
 std::string UpdateResult::toString() const {
diff --git a/src/mongo/db/ops/write_ops_exec.cpp b/src/mongo/db/ops/write_ops_exec.cpp
index 7c93bc3303..cd01d85d05 100644
--- a/src/mongo/db/ops/write_ops_exec.cpp
+++ b/src/mongo/db/ops/write_ops_exec.cpp
@@ -74,6 +74,7 @@
 #include "mongo/db/storage/duplicate_key_error_info.h"
 #include "mongo/db/transaction_participant.h"
 #include "mongo/db/write_concern.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/cannot_implicitly_create_collection_info.h"
 #include "mongo/s/would_change_owning_shard_exception.h"
@@ -128,8 +129,7 @@ void finishCurOp(OperationContext* opCtx, CurOp* curOp) {
                     curOp->getReadWriteType());
 
         if (!curOp->debug().errInfo.isOK()) {
-            LOG(3) << "Caught Assertion in " << redact(logicalOpToString(curOp->getLogicalOp()))
-                   << ": " << curOp->debug().errInfo.toString();
+            LOGV2_DEBUG(3, "Caught Assertion in {}: {}", "redact_logicalOpToString_curOp_getLogicalOp"_attr = redact(logicalOpToString(curOp->getLogicalOp())), "curOp_debug_errInfo_toString"_attr = curOp->debug().errInfo.toString());
         }
 
         // Mark the op as complete, and log it if appropriate. Returns a boolean indicating whether
@@ -147,7 +147,7 @@ void finishCurOp(OperationContext* opCtx, CurOp* curOp) {
         // We need to ignore all errors here. We don't want a successful op to fail because of a
         // failure to record stats. We also don't want to replace the error reported for an op that
         // is failing.
-        log() << "Ignoring error from finishCurOp: " << redact(ex);
+        LOGV2("Ignoring error from finishCurOp: {}", "redact_ex"_attr = redact(ex));
     }
 }
 
@@ -168,7 +168,7 @@ public:
             // guard to fire in that case. Operations on the local DB aren't replicated, so they
             // don't need to bump the lastOp.
             replClientInfo().setLastOpToSystemLastOpTime(_opCtx);
-            LOG(5) << "Set last op to system time: " << replClientInfo().getLastOp().getTimestamp();
+            LOGV2_DEBUG(5, "Set last op to system time: {}", "replClientInfo_getLastOp_getTimestamp"_attr = replClientInfo().getLastOp().getTimestamp());
         }
     }
 
@@ -375,10 +375,8 @@ bool insertBatchAndHandleErrors(OperationContext* opCtx,
         opCtx,
         "hangDuringBatchInsert",
         [&wholeOp]() {
-            log() << "batch insert - hangDuringBatchInsert fail point enabled for namespace "
-                  << wholeOp.getNamespace()
-                  << ". Blocking "
-                     "until fail point is disabled.";
+            LOGV2("batch insert - hangDuringBatchInsert fail point enabled for namespace {}. Blocking "
+                     "until fail point is disabled.", "wholeOp_getNamespace"_attr = wholeOp.getNamespace());
         },
         true,  // Check for interrupt periodically.
         wholeOp.getNamespace());
@@ -609,9 +607,8 @@ static SingleWriteResult performSingleUpdateOp(OperationContext* opCtx,
         opCtx,
         "hangDuringBatchUpdate",
         [&ns]() {
-            log() << "batch update - hangDuringBatchUpdate fail point enabled for nss " << ns
-                  << ". Blocking until "
-                     "fail point is disabled.";
+            LOGV2("batch update - hangDuringBatchUpdate fail point enabled for nss {}. Blocking until "
+                     "fail point is disabled.", "ns"_attr = ns);
         },
         false /*checkForInterrupt*/,
         ns);
@@ -862,8 +859,8 @@ static SingleWriteResult performSingleDeleteOp(OperationContext* opCtx,
         opCtx,
         "hangDuringBatchRemove",
         []() {
-            log() << "batch remove - hangDuringBatchRemove fail point enabled. Blocking "
-                     "until fail point is disabled.";
+            LOGV2("batch remove - hangDuringBatchRemove fail point enabled. Blocking "
+                     "until fail point is disabled.");
         },
         true  // Check for interrupt periodically.
     );
diff --git a/src/mongo/db/periodic_runner_job_abort_expired_transactions.cpp b/src/mongo/db/periodic_runner_job_abort_expired_transactions.cpp
index 12d931edc4..8185e093a2 100644
--- a/src/mongo/db/periodic_runner_job_abort_expired_transactions.cpp
+++ b/src/mongo/db/periodic_runner_job_abort_expired_transactions.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/transaction_participant.h"
 #include "mongo/db/transaction_participant_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/periodic_runner.h"
 
@@ -113,8 +114,7 @@ void PeriodicThreadToAbortExpiredTransactions::_init(ServiceContext* serviceCont
             try {
                 anchor->setPeriod(getPeriod(secs));
             } catch (const DBException& ex) {
-                log() << "Failed to update period of thread which aborts expired transactions "
-                      << ex.toStatus();
+                LOGV2("Failed to update period of thread which aborts expired transactions {}", "ex_toStatus"_attr = ex.toStatus());
             }
         });
 }
diff --git a/src/mongo/db/periodic_runner_job_decrease_snapshot_cache_pressure.cpp b/src/mongo/db/periodic_runner_job_decrease_snapshot_cache_pressure.cpp
index 3f9010eb08..f6d854be2a 100644
--- a/src/mongo/db/periodic_runner_job_decrease_snapshot_cache_pressure.cpp
+++ b/src/mongo/db/periodic_runner_job_decrease_snapshot_cache_pressure.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/snapshot_window_options.h"
 #include "mongo/db/snapshot_window_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/periodic_runner.h"
 
@@ -97,9 +98,8 @@ void PeriodicThreadToDecreaseSnapshotHistoryCachePressure::_init(ServiceContext*
         try {
             anchor->setPeriod(Seconds(secs));
         } catch (const DBException& ex) {
-            log() << "Failed to update the period of the thread which decreases data history cache "
-                     "target size if there is cache pressure."
-                  << ex.toStatus();
+            LOGV2("Failed to update the period of the thread which decreases data history cache "
+                     "target size if there is cache pressure.{}", "ex_toStatus"_attr = ex.toStatus());
         }
     });
 }
diff --git a/src/mongo/db/pipeline/accumulator_test.cpp b/src/mongo/db/pipeline/accumulator_test.cpp
index 373a24a415..929eb1db73 100644
--- a/src/mongo/db/pipeline/accumulator_test.cpp
+++ b/src/mongo/db/pipeline/accumulator_test.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/pipeline/expression_context_for_test.h"
 #include "mongo/db/query/collation/collator_interface_mock.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 
 namespace AccumulatorTests {
 
@@ -93,7 +94,7 @@ static void assertExpectedResults(
                 ASSERT_EQUALS(op.second.getType(), result.getType());
             }
         } catch (...) {
-            log() << "failed with arguments: " << Value(op.first);
+            LOGV2("failed with arguments: {}", "Value_op_first"_attr = Value(op.first));
             throw;
         }
     }
diff --git a/src/mongo/db/pipeline/document_source_cursor.cpp b/src/mongo/db/pipeline/document_source_cursor.cpp
index bf576960b2..483a77df4f 100644
--- a/src/mongo/db/pipeline/document_source_cursor.cpp
+++ b/src/mongo/db/pipeline/document_source_cursor.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/query/explain.h"
 #include "mongo/db/query/find_common.h"
 #include "mongo/db/storage/storage_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -80,7 +81,7 @@ void DocumentSourceCursor::loadBatch() {
     }
 
     while (MONGO_unlikely(hangBeforeDocumentSourceCursorLoadBatch.shouldFail())) {
-        log() << "Hanging aggregation due to 'hangBeforeDocumentSourceCursorLoadBatch' failpoint";
+        LOGV2("Hanging aggregation due to 'hangBeforeDocumentSourceCursorLoadBatch' failpoint");
         sleepmillis(10);
     }
 
diff --git a/src/mongo/db/pipeline/document_source_exchange.cpp b/src/mongo/db/pipeline/document_source_exchange.cpp
index 9e8e37e97c..7c9caa6010 100644
--- a/src/mongo/db/pipeline/document_source_exchange.cpp
+++ b/src/mongo/db/pipeline/document_source_exchange.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/hasher.h"
 #include "mongo/db/pipeline/document_source_exchange.h"
 #include "mongo/db/storage/key_string.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -302,7 +303,7 @@ DocumentSource::GetNextResult Exchange::getNext(OperationContext* opCtx,
 
         // There is not any document so try to load more from the source.
         if (_loadingThreadId == kInvalidThreadId) {
-            LOG(3) << "A consumer " << consumerId << " begins loading";
+            LOGV2_DEBUG(3, "A consumer {} begins loading", "consumerId"_attr = consumerId);
 
             try {
                 // This consumer won the race and will fill the buffers.
@@ -316,7 +317,7 @@ DocumentSource::GetNextResult Exchange::getNext(OperationContext* opCtx,
                 size_t fullConsumerId = loadNextBatch();
 
                 if (MONGO_unlikely(exchangeFailLoadNextBatch.shouldFail())) {
-                    log() << "exchangeFailLoadNextBatch fail point enabled.";
+                    LOGV2("exchangeFailLoadNextBatch fail point enabled.");
                     uasserted(ErrorCodes::FailPointEnabled,
                               "Asserting on loading the next batch due to failpoint.");
                 }
diff --git a/src/mongo/db/pipeline/document_source_exchange_test.cpp b/src/mongo/db/pipeline/document_source_exchange_test.cpp
index ff517ad4f9..30cf16eeb3 100644
--- a/src/mongo/db/pipeline/document_source_exchange_test.cpp
+++ b/src/mongo/db/pipeline/document_source_exchange_test.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/storage/key_string.h"
 #include "mongo/executor/network_interface_factory.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/unittest/temp_dir.h"
 #include "mongo/unittest/unittest.h"
@@ -115,7 +116,7 @@ protected:
 
     static auto getNewSeed() {
         auto seed = Date_t::now().asInt64();
-        unittest::log() << "Generated new seed is " << seed;
+        unittest::LOGV2("Generated new seed is {}", "seed"_attr = seed);
 
         return seed;
     }
diff --git a/src/mongo/db/pipeline/document_source_match_test.cpp b/src/mongo/db/pipeline/document_source_match_test.cpp
index cb4821161f..7515291b87 100644
--- a/src/mongo/db/pipeline/document_source_match_test.cpp
+++ b/src/mongo/db/pipeline/document_source_match_test.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/pipeline/document_source_match.h"
 #include "mongo/db/pipeline/document_source_mock.h"
 #include "mongo/db/pipeline/pipeline.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/death_test.h"
 #include "mongo/unittest/unittest.h"
 
@@ -59,7 +60,7 @@ TEST_F(DocumentSourceMatchTest, RedactSafePortion) {
             auto match = DocumentSourceMatch::create(fromjson(input), expCtx);
             ASSERT_BSONOBJ_EQ(match->redactSafePortion(), fromjson(safePortion));
         } catch (...) {
-            unittest::log() << "Problem with redactSafePortion() of: " << input;
+            unittest::LOGV2("Problem with redactSafePortion() of: {}", "input"_attr = input);
             throw;
         }
     };
diff --git a/src/mongo/db/pipeline/document_source_merge.cpp b/src/mongo/db/pipeline/document_source_merge.cpp
index 835d5546db..d78b9c21d9 100644
--- a/src/mongo/db/pipeline/document_source_merge.cpp
+++ b/src/mongo/db/pipeline/document_source_merge.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/curop_failpoint_helpers.h"
 #include "mongo/db/ops/write_ops.h"
 #include "mongo/db/pipeline/document_path_support.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -485,8 +486,7 @@ void DocumentSourceMerge::waitWhileFailPointEnabled() {
         pExpCtx->opCtx,
         "hangWhileBuildingDocumentSourceMergeBatch",
         []() {
-            log() << "Hanging aggregation due to 'hangWhileBuildingDocumentSourceMergeBatch' "
-                  << "failpoint";
+            LOGV2("Hanging aggregation due to 'hangWhileBuildingDocumentSourceMergeBatch' failpoint");
         });
 }
 
diff --git a/src/mongo/db/pipeline/document_source_out.cpp b/src/mongo/db/pipeline/document_source_out.cpp
index b5c1a0e3e9..1df00d0fb7 100644
--- a/src/mongo/db/pipeline/document_source_out.cpp
+++ b/src/mongo/db/pipeline/document_source_out.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/curop_failpoint_helpers.h"
 #include "mongo/db/ops/write_ops.h"
 #include "mongo/db/pipeline/document_path_support.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/util/destructor_guard.h"
 #include "mongo/util/fail_point.h"
@@ -166,8 +167,7 @@ void DocumentSourceOut::initialize() {
         pExpCtx->opCtx,
         "outWaitAfterTempCollectionCreation",
         []() {
-            log() << "Hanging aggregation due to 'outWaitAfterTempCollectionCreation' "
-                  << "failpoint";
+            LOGV2("Hanging aggregation due to 'outWaitAfterTempCollectionCreation' failpoint");
         });
     if (_originalIndexes.empty()) {
         return;
@@ -259,8 +259,7 @@ void DocumentSourceOut::waitWhileFailPointEnabled() {
         pExpCtx->opCtx,
         "hangWhileBuildingDocumentSourceOutBatch",
         []() {
-            log() << "Hanging aggregation due to 'hangWhileBuildingDocumentSourceOutBatch' "
-                  << "failpoint";
+            LOGV2("Hanging aggregation due to 'hangWhileBuildingDocumentSourceOutBatch' failpoint");
         });
 }
 
diff --git a/src/mongo/db/pipeline/document_source_sample_from_random_cursor.cpp b/src/mongo/db/pipeline/document_source_sample_from_random_cursor.cpp
index 09e4b1fc14..7c3b05ef24 100644
--- a/src/mongo/db/pipeline/document_source_sample_from_random_cursor.cpp
+++ b/src/mongo/db/pipeline/document_source_sample_from_random_cursor.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/exec/document_value/value.h"
 #include "mongo/db/pipeline/expression.h"
 #include "mongo/db/pipeline/expression_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -121,8 +122,7 @@ DocumentSource::GetNextResult DocumentSourceSampleFromRandomCursor::getNextNonDu
                 if (_seenDocs.insert(std::move(idField)).second) {
                     return nextInput;
                 }
-                LOG(1) << "$sample encountered duplicate document: "
-                       << nextInput.getDocument().toString();
+                LOGV2_DEBUG(1, "$sample encountered duplicate document: {}", "nextInput_getDocument_toString"_attr = nextInput.getDocument().toString());
                 break;  // Try again with the next document.
             }
             case GetNextResult::ReturnStatus::kPauseExecution: {
diff --git a/src/mongo/db/pipeline/expression_test.cpp b/src/mongo/db/pipeline/expression_test.cpp
index 522e2a750f..e7c13a2a8a 100644
--- a/src/mongo/db/pipeline/expression_test.cpp
+++ b/src/mongo/db/pipeline/expression_test.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/pipeline/expression_context_for_test.h"
 #include "mongo/db/query/collation/collator_interface_mock.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 
 namespace ExpressionTests {
@@ -83,7 +84,7 @@ static void assertExpectedResults(
             ASSERT_VALUE_EQ(op.second, result);
             ASSERT_EQUALS(op.second.getType(), result.getType());
         } catch (...) {
-            log() << "failed with arguments: " << ImplicitValue::convertToValue(op.first);
+            LOGV2("failed with arguments: {}", "ImplicitValue_convertToValue_op_first"_attr = ImplicitValue::convertToValue(op.first));
             throw;
         }
     }
diff --git a/src/mongo/db/pipeline/process_interface_standalone.cpp b/src/mongo/db/pipeline/process_interface_standalone.cpp
index 94e00b7955..6a20a9e93b 100644
--- a/src/mongo/db/pipeline/process_interface_standalone.cpp
+++ b/src/mongo/db/pipeline/process_interface_standalone.cpp
@@ -67,6 +67,7 @@
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/transaction_history_iterator.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/query/document_source_merge_cursors.h"
 #include "mongo/util/log.h"
@@ -268,7 +269,7 @@ std::vector<Document> MongoInterfaceStandalone::getIndexStats(OperationContext*
     Collection* collection = autoColl.getCollection();
     std::vector<Document> indexStats;
     if (!collection) {
-        LOG(2) << "Collection not found on index stats retrieval: " << ns.ns();
+        LOGV2_DEBUG(2, "Collection not found on index stats retrieval: {}", "ns_ns"_attr = ns.ns());
         return indexStats;
     }
 
diff --git a/src/mongo/db/pipeline/sharded_agg_helpers.cpp b/src/mongo/db/pipeline/sharded_agg_helpers.cpp
index b3a10e92d1..fa656a7ee8 100644
--- a/src/mongo/db/pipeline/sharded_agg_helpers.cpp
+++ b/src/mongo/db/pipeline/sharded_agg_helpers.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/pipeline/document_source_change_stream.h"
 #include "mongo/db/pipeline/document_source_out.h"
 #include "mongo/db/query/find_common.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/op_msg_rpc_impls.h"
 #include "mongo/s/catalog/type_shard.h"
@@ -201,7 +202,7 @@ std::vector<RemoteCursor> establishShardCursors(
     const std::set<ShardId>& shardIds,
     const BSONObj& cmdObj,
     const ReadPreferenceSetting& readPref) {
-    LOG(1) << "Dispatching command " << redact(cmdObj) << " to establish cursors on shards";
+    LOGV2_DEBUG(1, "Dispatching command {} to establish cursors on shards", "redact_cmdObj"_attr = redact(cmdObj));
 
     const bool mustRunOnAll = mustRunOnAllShards(nss, hasChangeStream);
     std::vector<std::pair<ShardId, BSONObj>> requests;
@@ -234,8 +235,8 @@ std::vector<RemoteCursor> establishShardCursors(
     }
 
     if (MONGO_unlikely(shardedAggregateHangBeforeEstablishingShardCursors.shouldFail())) {
-        log() << "shardedAggregateHangBeforeEstablishingShardCursors fail point enabled.  Blocking "
-                 "until fail point is disabled.";
+        LOGV2("shardedAggregateHangBeforeEstablishingShardCursors fail point enabled.  Blocking "
+                 "until fail point is disabled.");
         while (MONGO_unlikely(shardedAggregateHangBeforeEstablishingShardCursors.shouldFail())) {
             sleepsecs(1);
         }
@@ -402,7 +403,7 @@ sharded_agg_helpers::DispatchShardPipelineResults dispatchExchangeConsumerPipeli
     auto opCtx = expCtx->opCtx;
 
     if (MONGO_unlikely(shardedAggregateFailToDispatchExchangeConsumerPipeline.shouldFail())) {
-        log() << "shardedAggregateFailToDispatchExchangeConsumerPipeline fail point enabled.";
+        LOGV2("shardedAggregateFailToDispatchExchangeConsumerPipeline fail point enabled.");
         uasserted(ErrorCodes::FailPointEnabled,
                   "Asserting on exhange consumer pipeline dispatch due to failpoint.");
     }
@@ -584,10 +585,7 @@ DispatchShardPipelineResults dispatchShardPipeline(
     boost::optional<cluster_aggregation_planner::SplitPipeline> splitPipeline;
 
     if (needsSplit) {
-        LOG(5) << "Splitting pipeline: "
-               << "targeting = " << shardIds.size()
-               << " shards, needsMongosMerge = " << needsMongosMerge
-               << ", needsPrimaryShardMerge = " << needsPrimaryShardMerge;
+        LOGV2_DEBUG(5, "Splitting pipeline: targeting = {} shards, needsMongosMerge = {}, needsPrimaryShardMerge = {}", "shardIds_size"_attr = shardIds.size(), "needsMongosMerge"_attr = needsMongosMerge, "needsPrimaryShardMerge"_attr = needsPrimaryShardMerge);
         splitPipeline = cluster_aggregation_planner::splitPipeline(std::move(pipeline));
 
         exchangeSpec = cluster_aggregation_planner::checkIfEligibleForExchange(
@@ -707,7 +705,7 @@ AsyncRequestsSender::Response establishMergingShardCursor(OperationContext* opCt
                                                           const BSONObj mergeCmdObj,
                                                           const ShardId& mergingShardId) {
     if (MONGO_unlikely(shardedAggregateFailToEstablishMergingShardCursor.shouldFail())) {
-        log() << "shardedAggregateFailToEstablishMergingShardCursor fail point enabled.";
+        LOGV2("shardedAggregateFailToEstablishMergingShardCursor fail point enabled.");
         uasserted(ErrorCodes::FailPointEnabled,
                   "Asserting on establishing merging shard cursor due to failpoint.");
     }
@@ -781,7 +779,7 @@ Status dispatchMergingPipeline(
     auto mergeCmdObj = createCommandForMergingShard(
         serializedCommand, expCtx, mergingShardId, mergingShardContributesData, mergePipeline);
 
-    LOG(1) << "Dispatching merge pipeline " << redact(mergeCmdObj) << " to designated shard";
+    LOGV2_DEBUG(1, "Dispatching merge pipeline {} to designated shard", "redact_mergeCmdObj"_attr = redact(mergeCmdObj));
 
     // Dispatch $mergeCursors to the chosen shard, store the resulting cursor, and return.
     auto mergeResponse =
diff --git a/src/mongo/db/query/collection_query_info.cpp b/src/mongo/db/query/collection_query_info.cpp
index d65773a230..c79e9805b4 100644
--- a/src/mongo/db/query/collection_query_info.cpp
+++ b/src/mongo/db/query/collection_query_info.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/query/plan_cache.h"
 #include "mongo/db/query/planner_ixselect.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/clock_source.h"
 #include "mongo/util/log.h"
 
@@ -177,7 +178,7 @@ void CollectionQueryInfo::notifyOfQuery(OperationContext* opCtx,
 
 void CollectionQueryInfo::clearQueryCache() {
     const Collection* coll = get.owner(this);
-    LOG(1) << coll->ns() << ": clearing plan cache - collection info cache reset";
+    LOGV2_DEBUG(1, "{}: clearing plan cache - collection info cache reset", "coll_ns"_attr = coll->ns());
     if (nullptr != _planCache.get()) {
         _planCache->clear();
     }
diff --git a/src/mongo/db/query/find.cpp b/src/mongo/db/query/find.cpp
index 0d903bd308..8a631e5315 100644
--- a/src/mongo/db/query/find.cpp
+++ b/src/mongo/db/query/find.cpp
@@ -63,6 +63,7 @@
 #include "mongo/db/stats/top.h"
 #include "mongo/db/storage/storage_options.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/chunk_version.h"
 #include "mongo/s/stale_exception.h"
 #include "mongo/util/fail_point.h"
@@ -244,7 +245,7 @@ Message getMore(OperationContext* opCtx,
                 bool* isCursorAuthorized) {
     invariant(ntoreturn >= 0);
 
-    LOG(5) << "Running getMore, cursorid: " << cursorid;
+    LOGV2_DEBUG(5, "Running getMore, cursorid: {}", "cursorid"_attr = cursorid);
 
     CurOp& curOp = *CurOp::get(opCtx);
     curOp.ensureStarted();
@@ -523,8 +524,7 @@ Message getMore(OperationContext* opCtx,
         cursorid = 0;
         curOp.debug().cursorExhausted = true;
 
-        LOG(5) << "getMore NOT saving client cursor, ended with state "
-               << PlanExecutor::statestr(state);
+        LOGV2_DEBUG(5, "getMore NOT saving client cursor, ended with state {}", "PlanExecutor_statestr_state"_attr = PlanExecutor::statestr(state));
     } else {
         cursorFreer.dismiss();
         // Continue caching the ClientCursor.
@@ -532,7 +532,7 @@ Message getMore(OperationContext* opCtx,
         cursorPin->incNBatches();
         exec->saveState();
         exec->detachFromOperationContext();
-        LOG(5) << "getMore saving client cursor ended with state " << PlanExecutor::statestr(state);
+        LOGV2_DEBUG(5, "getMore saving client cursor ended with state {}", "PlanExecutor_statestr_state"_attr = PlanExecutor::statestr(state));
 
         *exhaust = cursorPin->queryOptions() & QueryOption_Exhaust;
 
@@ -564,7 +564,7 @@ Message getMore(OperationContext* opCtx,
     qr.setCursorId(cursorid);
     qr.setStartingFrom(startingResult);
     qr.setNReturned(numResults);
-    LOG(5) << "getMore returned " << numResults << " results\n";
+    LOGV2_DEBUG(5, "getMore returned {} results\n", "numResults"_attr = numResults);
     return Message(bb.release());
 }
 
@@ -602,8 +602,8 @@ std::string runQuery(OperationContext* opCtx,
         "Can't canonicalize query");
     invariant(cq.get());
 
-    LOG(5) << "Running query:\n" << redact(cq->toString());
-    LOG(2) << "Running query: " << redact(cq->toStringShort());
+    LOGV2_DEBUG(5, "Running query:\n{}", "redact_cq_toString"_attr = redact(cq->toString()));
+    LOGV2_DEBUG(2, "Running query: {}", "redact_cq_toStringShort"_attr = redact(cq->toStringShort()));
 
     // Parse, canonicalize, plan, transcribe, and get a plan executor.
     AutoGetCollectionForReadCommand ctx(opCtx, nss, AutoGetCollection::ViewMode::kViewsForbidden);
@@ -699,9 +699,7 @@ std::string runQuery(OperationContext* opCtx,
         ++numResults;
 
         if (FindCommon::enoughForFirstBatch(qr, numResults)) {
-            LOG(5) << "Enough for first batch, wantMore=" << qr.wantMore()
-                   << " ntoreturn=" << qr.getNToReturn().value_or(0)
-                   << " numResults=" << numResults;
+            LOGV2_DEBUG(5, "Enough for first batch, wantMore={} ntoreturn={} numResults={}", "qr_wantMore"_attr = qr.wantMore(), "qr_getNToReturn_value_or_0"_attr = qr.getNToReturn().value_or(0), "numResults"_attr = numResults);
             break;
         }
     }
@@ -741,8 +739,7 @@ std::string runQuery(OperationContext* opCtx,
             });
         ccId = pinnedCursor.getCursor()->cursorid();
 
-        LOG(5) << "caching executor with cursorid " << ccId << " after returning " << numResults
-               << " results";
+        LOGV2_DEBUG(5, "caching executor with cursorid {} after returning {} results", "ccId"_attr = ccId, "numResults"_attr = numResults);
 
         // TODO document
         if (qr.isExhaust()) {
@@ -762,7 +759,7 @@ std::string runQuery(OperationContext* opCtx,
 
         endQueryOp(opCtx, collection, *pinnedCursor.getCursor()->getExecutor(), numResults, ccId);
     } else {
-        LOG(5) << "Not caching executor but returning " << numResults << " results.";
+        LOGV2_DEBUG(5, "Not caching executor but returning {} results.", "numResults"_attr = numResults);
         endQueryOp(opCtx, collection, *exec, numResults, ccId);
     }
 
diff --git a/src/mongo/db/query/find_common.cpp b/src/mongo/db/query/find_common.cpp
index e236faccfb..0813079514 100644
--- a/src/mongo/db/query/find_common.cpp
+++ b/src/mongo/db/query/find_common.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/curop_failpoint_helpers.h"
 #include "mongo/db/query/canonical_query.h"
 #include "mongo/db/query/query_request.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -79,8 +80,7 @@ bool FindCommon::haveSpaceForNext(const BSONObj& nextDoc, long long numDocs, int
 void FindCommon::waitInFindBeforeMakingBatch(OperationContext* opCtx, const CanonicalQuery& cq) {
     auto whileWaitingFunc = [&, hasLogged = false]() mutable {
         if (!std::exchange(hasLogged, true)) {
-            log() << "Waiting in find before making batch for query - "
-                  << redact(cq.toStringShort());
+            LOGV2("Waiting in find before making batch for query - {}", "redact_cq_toStringShort"_attr = redact(cq.toStringShort()));
         }
     };
 
diff --git a/src/mongo/db/query/get_executor.cpp b/src/mongo/db/query/get_executor.cpp
index d236fd1f16..d864950f4a 100644
--- a/src/mongo/db/query/get_executor.cpp
+++ b/src/mongo/db/query/get_executor.cpp
@@ -87,6 +87,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/storage_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/engine.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -185,9 +186,7 @@ IndexEntry indexEntryFromIndexCatalogEntry(OperationContext* opCtx,
                 multikeyPathSet = accessMethod->getMultikeyPathSet(opCtx, &mkAccessStats);
             }
 
-            LOG(2) << "Multikey path metadata range index scan stats: { index: "
-                   << desc->indexName() << ", numSeeks: " << mkAccessStats.keysExamined
-                   << ", keysExamined: " << mkAccessStats.keysExamined << "}";
+            LOGV2_DEBUG(2, "Multikey path metadata range index scan stats: { index: {}, numSeeks: {}, keysExamined: {}}", "desc_indexName"_attr = desc->indexName(), "mkAccessStats_keysExamined"_attr = mkAccessStats.keysExamined, "mkAccessStats_keysExamined"_attr = mkAccessStats.keysExamined);
         }
     }
 
@@ -357,8 +356,7 @@ StatusWith<PrepareExecutionResult> prepareExecution(OperationContext* opCtx,
     // This can happen as we're called by internal clients as well.
     if (nullptr == collection) {
         const string& ns = canonicalQuery->ns();
-        LOG(2) << "Collection " << ns << " does not exist."
-               << " Using EOF plan: " << redact(canonicalQuery->toStringShort());
+        LOGV2_DEBUG(2, "Collection {} does not exist. Using EOF plan: {}", "ns"_attr = ns, "redact_canonicalQuery_toStringShort"_attr = redact(canonicalQuery->toStringShort()));
         root = std::make_unique<EOFStage>(opCtx);
         return PrepareExecutionResult(std::move(canonicalQuery), nullptr, std::move(root));
     }
@@ -379,7 +377,7 @@ StatusWith<PrepareExecutionResult> prepareExecution(OperationContext* opCtx,
 
     // If we have an _id index we can use an idhack plan.
     if (descriptor && IDHackStage::supportsQuery(collection, *canonicalQuery)) {
-        LOG(2) << "Using idhack: " << redact(canonicalQuery->toStringShort());
+        LOGV2_DEBUG(2, "Using idhack: {}", "redact_canonicalQuery_toStringShort"_attr = redact(canonicalQuery->toStringShort()));
 
         root = std::make_unique<IDHackStage>(opCtx, canonicalQuery.get(), ws, descriptor);
 
@@ -472,7 +470,7 @@ StatusWith<PrepareExecutionResult> prepareExecution(OperationContext* opCtx,
                 auto querySolution = std::move(statusWithQs.getValue());
                 if ((plannerParams.options & QueryPlannerParams::IS_COUNT) &&
                     turnIxscanIntoCount(querySolution.get())) {
-                    LOG(2) << "Using fast count: " << redact(canonicalQuery->toStringShort());
+                    LOGV2_DEBUG(2, "Using fast count: {}", "redact_canonicalQuery_toStringShort"_attr = redact(canonicalQuery->toStringShort()));
                 }
 
                 auto root =
@@ -498,7 +496,7 @@ StatusWith<PrepareExecutionResult> prepareExecution(OperationContext* opCtx,
 
     if (internalQueryPlanOrChildrenIndependently.load() &&
         SubplanStage::canUseSubplanning(*canonicalQuery)) {
-        LOG(2) << "Running query as sub-queries: " << redact(canonicalQuery->toStringShort());
+        LOGV2_DEBUG(2, "Running query as sub-queries: {}", "redact_canonicalQuery_toStringShort"_attr = redact(canonicalQuery->toStringShort()));
 
         root = std::make_unique<SubplanStage>(
             opCtx, collection, ws, plannerParams, canonicalQuery.get());
@@ -523,8 +521,7 @@ StatusWith<PrepareExecutionResult> prepareExecution(OperationContext* opCtx,
                 auto root =
                     StageBuilder::build(opCtx, collection, *canonicalQuery, *solutions[i], ws);
 
-                LOG(2) << "Using fast count: " << redact(canonicalQuery->toStringShort())
-                       << ", planSummary: " << Explain::getPlanSummary(root.get());
+                LOGV2_DEBUG(2, "Using fast count: {}, planSummary: {}", "redact_canonicalQuery_toStringShort"_attr = redact(canonicalQuery->toStringShort()), "Explain_getPlanSummary_root_get"_attr = Explain::getPlanSummary(root.get()));
 
                 return PrepareExecutionResult(
                     std::move(canonicalQuery), std::move(solutions[i]), std::move(root));
@@ -730,8 +727,7 @@ StatusWith<unique_ptr<PlanExecutor, PlanExecutor::Deleter>> getExecutorDelete(
     if (!collection) {
         // Treat collections that do not exist as empty collections. Return a PlanExecutor which
         // contains an EOF stage.
-        LOG(2) << "Collection " << nss.ns() << " does not exist."
-               << " Using EOF stage: " << redact(request->getQuery());
+        LOGV2_DEBUG(2, "Collection {} does not exist. Using EOF stage: {}", "nss_ns"_attr = nss.ns(), "redact_request_getQuery"_attr = redact(request->getQuery()));
         return PlanExecutor::make(
             opCtx, std::move(ws), std::make_unique<EOFStage>(opCtx), nullptr, policy, nss);
     }
@@ -758,7 +754,7 @@ StatusWith<unique_ptr<PlanExecutor, PlanExecutor::Deleter>> getExecutorDelete(
 
         if (descriptor && CanonicalQuery::isSimpleIdQuery(unparsedQuery) &&
             request->getProj().isEmpty() && hasCollectionDefaultCollation) {
-            LOG(2) << "Using idhack: " << redact(unparsedQuery);
+            LOGV2_DEBUG(2, "Using idhack: {}", "redact_unparsedQuery"_attr = redact(unparsedQuery));
 
             auto idHackStage = std::make_unique<IDHackStage>(
                 opCtx, unparsedQuery["_id"].wrap(), ws.get(), descriptor);
@@ -876,8 +872,7 @@ StatusWith<unique_ptr<PlanExecutor, PlanExecutor::Deleter>> getExecutorUpdate(
     // we are an explain. If the collection doesn't exist, we're not an explain, and the upsert flag
     // is true, we expect the caller to have created the collection already.
     if (!collection) {
-        LOG(2) << "Collection " << nss.ns() << " does not exist."
-               << " Using EOF stage: " << redact(request->getQuery());
+        LOGV2_DEBUG(2, "Collection {} does not exist. Using EOF stage: {}", "nss_ns"_attr = nss.ns(), "redact_request_getQuery"_attr = redact(request->getQuery()));
         return PlanExecutor::make(
             opCtx, std::move(ws), std::make_unique<EOFStage>(opCtx), nullptr, policy, nss);
     }
@@ -902,7 +897,7 @@ StatusWith<unique_ptr<PlanExecutor, PlanExecutor::Deleter>> getExecutorUpdate(
 
             if (descriptor && CanonicalQuery::isSimpleIdQuery(unparsedQuery) &&
                 request->getProj().isEmpty() && hasCollectionDefaultCollation) {
-                LOG(2) << "Using idhack: " << redact(unparsedQuery);
+                LOGV2_DEBUG(2, "Using idhack: {}", "redact_unparsedQuery"_attr = redact(unparsedQuery));
 
                 // Working set 'ws' is discarded. InternalPlanner::updateWithIdHack() makes its own
                 // WorkingSet.
@@ -1483,8 +1478,7 @@ StatusWith<std::unique_ptr<PlanExecutor, PlanExecutor::Deleter>> getExecutorForS
     auto root =
         StageBuilder::build(opCtx, collection, *parsedDistinct->getQuery(), *soln, ws.get());
 
-    LOG(2) << "Using fast distinct: " << redact(parsedDistinct->getQuery()->toStringShort())
-           << ", planSummary: " << Explain::getPlanSummary(root.get());
+    LOGV2_DEBUG(2, "Using fast distinct: {}, planSummary: {}", "redact_parsedDistinct_getQuery_toStringShort"_attr = redact(parsedDistinct->getQuery()->toStringShort()), "Explain_getPlanSummary_root_get"_attr = Explain::getPlanSummary(root.get()));
 
     return PlanExecutor::make(parsedDistinct->releaseQuery(),
                               std::move(ws),
@@ -1524,8 +1518,7 @@ getExecutorDistinctFromIndexSolutions(OperationContext* opCtx,
             auto root = StageBuilder::build(
                 opCtx, collection, *parsedDistinct->getQuery(), *currentSolution, ws.get());
 
-            LOG(2) << "Using fast distinct: " << redact(parsedDistinct->getQuery()->toStringShort())
-                   << ", planSummary: " << Explain::getPlanSummary(root.get());
+            LOGV2_DEBUG(2, "Using fast distinct: {}, planSummary: {}", "redact_parsedDistinct_getQuery_toStringShort"_attr = redact(parsedDistinct->getQuery()->toStringShort()), "Explain_getPlanSummary_root_get"_attr = Explain::getPlanSummary(root.get()));
 
             return PlanExecutor::make(parsedDistinct->releaseQuery(),
                                       std::move(ws),
diff --git a/src/mongo/db/query/index_bounds_builder.cpp b/src/mongo/db/query/index_bounds_builder.cpp
index 90983655d7..bf15aae3f0 100644
--- a/src/mongo/db/query/index_bounds_builder.cpp
+++ b/src/mongo/db/query/index_bounds_builder.cpp
@@ -49,6 +49,7 @@
 #include "mongo/db/query/planner_ixselect.h"
 #include "mongo/db/query/planner_wildcard_helpers.h"
 #include "mongo/db/query/query_knobs_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 #include "third_party/s2/s2cell.h"
@@ -1090,9 +1091,7 @@ void IndexBoundsBuilder::alignBounds(IndexBounds* bounds, const BSONObj& kp, int
     }
 
     if (!bounds->isValidFor(kp, scanDir)) {
-        log() << "INVALID BOUNDS: " << redact(bounds->toString()) << endl
-              << "kp = " << redact(kp) << endl
-              << "scanDir = " << scanDir;
+        LOGV2("INVALID BOUNDS: {}\nkp = {}\nscanDir = {}", "redact_bounds_toString"_attr = redact(bounds->toString()), "redact_kp"_attr = redact(kp), "scanDir"_attr = scanDir);
         MONGO_UNREACHABLE;
     }
 }
diff --git a/src/mongo/db/query/plan_cache.cpp b/src/mongo/db/query/plan_cache.cpp
index 9d03e0b101..507fff0075 100644
--- a/src/mongo/db/query/plan_cache.cpp
+++ b/src/mongo/db/query/plan_cache.cpp
@@ -51,6 +51,7 @@
 #include "mongo/db/query/planner_ixselect.h"
 #include "mongo/db/query/query_knobs_gen.h"
 #include "mongo/db/query/query_solution.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/hex.h"
 #include "mongo/util/log.h"
@@ -438,8 +439,7 @@ std::unique_ptr<CachedSolution> PlanCache::getCacheEntryIfActive(const PlanCache
 
     PlanCache::GetResult res = get(key);
     if (res.state == PlanCache::CacheEntryState::kPresentInactive) {
-        LOG(2) << "Not using cached entry for " << redact(res.cachedSolution->toString())
-               << " since it is inactive";
+        LOGV2_DEBUG(2, "Not using cached entry for {} since it is inactive", "redact_res_cachedSolution_toString"_attr = redact(res.cachedSolution->toString()));
         return nullptr;
     }
 
@@ -460,9 +460,7 @@ PlanCache::NewEntryState PlanCache::getNewEntryState(const CanonicalQuery& query
                                                      double growthCoefficient) {
     NewEntryState res;
     if (!oldEntry) {
-        LOG(1) << "Creating inactive cache entry for query shape " << redact(query.toStringShort())
-               << " queryHash " << unsignedIntToFixedLengthHex(queryHash) << " planCacheKey "
-               << unsignedIntToFixedLengthHex(planCacheKey) << " with works value " << newWorks;
+        LOGV2_DEBUG(1, "Creating inactive cache entry for query shape {} queryHash {} planCacheKey {} with works value {}", "redact_query_toStringShort"_attr = redact(query.toStringShort()), "unsignedIntToFixedLengthHex_queryHash"_attr = unsignedIntToFixedLengthHex(queryHash), "unsignedIntToFixedLengthHex_planCacheKey"_attr = unsignedIntToFixedLengthHex(planCacheKey), "newWorks"_attr = newWorks);
         res.shouldBeCreated = true;
         res.shouldBeActive = false;
         return res;
@@ -472,18 +470,11 @@ PlanCache::NewEntryState PlanCache::getNewEntryState(const CanonicalQuery& query
         // The new plan did better than the currently stored active plan. This case may
         // occur if many MultiPlanners are run simultaneously.
 
-        LOG(1) << "Replacing active cache entry for query " << redact(query.toStringShort())
-               << " queryHash " << unsignedIntToFixedLengthHex(queryHash) << " planCacheKey "
-               << unsignedIntToFixedLengthHex(planCacheKey) << " with works " << oldEntry->works
-               << " with a plan with works " << newWorks;
+        LOGV2_DEBUG(1, "Replacing active cache entry for query {} queryHash {} planCacheKey {} with works {} with a plan with works {}", "redact_query_toStringShort"_attr = redact(query.toStringShort()), "unsignedIntToFixedLengthHex_queryHash"_attr = unsignedIntToFixedLengthHex(queryHash), "unsignedIntToFixedLengthHex_planCacheKey"_attr = unsignedIntToFixedLengthHex(planCacheKey), "oldEntry_works"_attr = oldEntry->works, "newWorks"_attr = newWorks);
         res.shouldBeCreated = true;
         res.shouldBeActive = true;
     } else if (oldEntry->isActive) {
-        LOG(1) << "Attempt to write to the planCache for query " << redact(query.toStringShort())
-               << " queryHash " << unsignedIntToFixedLengthHex(queryHash) << " planCacheKey "
-               << unsignedIntToFixedLengthHex(planCacheKey) << " with a plan with works "
-               << newWorks << " is a noop, since there's already a plan with works value "
-               << oldEntry->works;
+        LOGV2_DEBUG(1, "Attempt to write to the planCache for query {} queryHash {} planCacheKey {} with a plan with works {} is a noop, since there's already a plan with works value {}", "redact_query_toStringShort"_attr = redact(query.toStringShort()), "unsignedIntToFixedLengthHex_queryHash"_attr = unsignedIntToFixedLengthHex(queryHash), "unsignedIntToFixedLengthHex_planCacheKey"_attr = unsignedIntToFixedLengthHex(planCacheKey), "newWorks"_attr = newWorks, "oldEntry_works"_attr = oldEntry->works);
         // There is already an active cache entry with a higher works value.
         // We do nothing.
         res.shouldBeCreated = false;
@@ -499,11 +490,7 @@ PlanCache::NewEntryState PlanCache::getNewEntryState(const CanonicalQuery& query
         const double increasedWorks = std::max(
             oldEntry->works + 1u, static_cast<size_t>(oldEntry->works * growthCoefficient));
 
-        LOG(1) << "Increasing work value associated with cache entry for query "
-               << redact(query.toStringShort()) << " queryHash "
-               << unsignedIntToFixedLengthHex(queryHash) << " planCacheKey "
-               << unsignedIntToFixedLengthHex(planCacheKey) << " from " << oldEntry->works << " to "
-               << increasedWorks;
+        LOGV2_DEBUG(1, "Increasing work value associated with cache entry for query {} queryHash {} planCacheKey {} from {} to {}", "redact_query_toStringShort"_attr = redact(query.toStringShort()), "unsignedIntToFixedLengthHex_queryHash"_attr = unsignedIntToFixedLengthHex(queryHash), "unsignedIntToFixedLengthHex_planCacheKey"_attr = unsignedIntToFixedLengthHex(planCacheKey), "oldEntry_works"_attr = oldEntry->works, "increasedWorks"_attr = increasedWorks);
         oldEntry->works = increasedWorks;
 
         // Don't create a new entry.
@@ -512,10 +499,7 @@ PlanCache::NewEntryState PlanCache::getNewEntryState(const CanonicalQuery& query
         // This plan performed just as well or better than we expected, based on the
         // inactive entry's works. We use this as an indicator that it's safe to
         // cache (as an active entry) the plan this query used for the future.
-        LOG(1) << "Inactive cache entry for query " << redact(query.toStringShort())
-               << " queryHash " << unsignedIntToFixedLengthHex(queryHash) << " planCacheKey "
-               << unsignedIntToFixedLengthHex(planCacheKey) << " with works " << oldEntry->works
-               << " is being promoted to active entry with works value " << newWorks;
+        LOGV2_DEBUG(1, "Inactive cache entry for query {} queryHash {} planCacheKey {} with works {} is being promoted to active entry with works value {}", "redact_query_toStringShort"_attr = redact(query.toStringShort()), "unsignedIntToFixedLengthHex_queryHash"_attr = unsignedIntToFixedLengthHex(queryHash), "unsignedIntToFixedLengthHex_planCacheKey"_attr = unsignedIntToFixedLengthHex(planCacheKey), "oldEntry_works"_attr = oldEntry->works, "newWorks"_attr = newWorks);
         // We'll replace the old inactive entry with an active entry.
         res.shouldBeCreated = true;
         res.shouldBeActive = true;
@@ -594,8 +578,7 @@ Status PlanCache::set(const CanonicalQuery& query,
     std::unique_ptr<PlanCacheEntry> evictedEntry = _cache.add(key, newEntry.release());
 
     if (nullptr != evictedEntry.get()) {
-        LOG(1) << query.nss() << ": plan cache maximum size exceeded - "
-               << "removed least recently used entry " << redact(evictedEntry->toString());
+        LOGV2_DEBUG(1, "{}: plan cache maximum size exceeded - removed least recently used entry {}", "query_nss"_attr = query.nss(), "redact_evictedEntry_toString"_attr = redact(evictedEntry->toString()));
     }
 
     return Status::OK();
diff --git a/src/mongo/db/query/plan_enumerator.cpp b/src/mongo/db/query/plan_enumerator.cpp
index f213e98c6c..c7edd613ac 100644
--- a/src/mongo/db/query/plan_enumerator.cpp
+++ b/src/mongo/db/query/plan_enumerator.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/query/index_tag.h"
 #include "mongo/db/query/indexability.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/string_map.h"
 
@@ -359,7 +360,7 @@ unique_ptr<MatchExpression> PlanEnumerator::getNext() {
     tagForSort(tree.get());
 
     _root->resetTag();
-    LOG(5) << "Enumerator: memo just before moving:" << endl << dumpMemo();
+    LOGV2_DEBUG(5, "Enumerator: memo just before moving:\n{}", "dumpMemo"_attr = dumpMemo());
     _done = nextMemo(memoIDForNode(_root));
     return tree;
 }
@@ -1568,7 +1569,7 @@ void PlanEnumerator::compound(const vector<MatchExpression*>& tryCompound,
 //
 
 void PlanEnumerator::tagMemo(size_t id) {
-    LOG(5) << "Tagging memoID " << id;
+    LOGV2_DEBUG(5, "Tagging memoID {}", "id"_attr = id);
     NodeAssignment* assign = _memo[id];
     verify(nullptr != assign);
 
diff --git a/src/mongo/db/query/plan_executor_impl.cpp b/src/mongo/db/query/plan_executor_impl.cpp
index cc2df08721..4c93ce599b 100644
--- a/src/mongo/db/query/plan_executor_impl.cpp
+++ b/src/mongo/db/query/plan_executor_impl.cpp
@@ -56,6 +56,7 @@
 #include "mongo/db/query/plan_yield_policy.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -628,8 +629,8 @@ PlanExecutor::ExecState PlanExecutorImpl::_getNextImpl(Snapshotted<Document>* ob
             // Fall through to yield check at end of large conditional.
         } else if (PlanStage::IS_EOF == code) {
             if (MONGO_unlikely(planExecutorHangBeforeShouldWaitForInserts.shouldFail())) {
-                log() << "PlanExecutor - planExecutorHangBeforeShouldWaitForInserts fail point "
-                         "enabled. Blocking until fail point is disabled.";
+                LOGV2("PlanExecutor - planExecutorHangBeforeShouldWaitForInserts fail point "
+                         "enabled. Blocking until fail point is disabled.");
                 planExecutorHangBeforeShouldWaitForInserts.pauseWhileSet();
             }
             if (!_shouldWaitForInserts()) {
diff --git a/src/mongo/db/query/plan_ranker.cpp b/src/mongo/db/query/plan_ranker.cpp
index 0de63fc137..f66c4a1ab5 100644
--- a/src/mongo/db/query/plan_ranker.cpp
+++ b/src/mongo/db/query/plan_ranker.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/query/query_knobs_gen.h"
 #include "mongo/db/query/query_solution.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace {
@@ -93,25 +94,21 @@ StatusWith<std::unique_ptr<PlanRankingDecision>> PlanRanker::pickBestPlan(
     // Compute score for each tree.  Record the best.
     for (size_t i = 0; i < statTrees.size(); ++i) {
         if (!candidates[i].failed) {
-            LOG(5) << "Scoring plan " << i << ":" << endl
-                   << redact(candidates[i].solution->toString()) << "Stats:\n"
-                   << redact(Explain::statsToBSON(*statTrees[i])
-                                 .jsonString(ExtendedRelaxedV2_0_0, true));
-            LOG(2) << "Scoring query plan: " << Explain::getPlanSummary(candidates[i].root)
-                   << " planHitEOF=" << statTrees[i]->common.isEOF;
+            LOGV2_DEBUG(5, "Scoring plan {}:\n{}Stats:\n{}", "i"_attr = i, "redact_candidates_i_solution_toString"_attr = redact(candidates[i].solution->toString()), "redact_Explain_statsToBSON_statTrees_i_jsonString_ExtendedRelaxedV2_0_0_true"_attr = redact(Explain::statsToBSON(*statTrees[i])
+                                 .jsonString(ExtendedRelaxedV2_0_0, true)));
+            LOGV2_DEBUG(2, "Scoring query plan: {} planHitEOF={}", "Explain_getPlanSummary_candidates_i_root"_attr = Explain::getPlanSummary(candidates[i].root), "statTrees_i_common_isEOF"_attr = statTrees[i]->common.isEOF);
 
             double score = scoreTree(statTrees[i].get());
-            LOG(5) << "score = " << score;
+            LOGV2_DEBUG(5, "score = {}", "score"_attr = score);
             if (statTrees[i]->common.isEOF) {
-                LOG(5) << "Adding +" << eofBonus << " EOF bonus to score.";
+                LOGV2_DEBUG(5, "Adding +{} EOF bonus to score.", "eofBonus"_attr = eofBonus);
                 score += 1;
             }
 
             scoresAndCandidateindices.push_back(std::make_pair(score, i));
         } else {
             failed.push_back(i);
-            LOG(2) << "Not scording plan: " << Explain::getPlanSummary(candidates[i].root)
-                   << " because the plan failed.";
+            LOGV2_DEBUG(2, "Not scording plan: {} because the plan failed.", "Explain_getPlanSummary_candidates_i_root"_attr = Explain::getPlanSummary(candidates[i].root));
         }
     }
 
@@ -265,14 +262,14 @@ double PlanRanker::scoreTree(const PlanStageStats* stats) {
        << str::convertDoubleToString(noSortBonus) << " noSortBonus + "
        << str::convertDoubleToString(noIxisectBonus)
        << " noIxisectBonus = " << str::convertDoubleToString(tieBreakers) << ")";
-    LOG(2) << sb.str();
+    LOGV2_DEBUG(2, "{}", "sb_str"_attr = sb.str());
 
     if (internalQueryForceIntersectionPlans.load()) {
         if (hasStage(STAGE_AND_HASH, stats) || hasStage(STAGE_AND_SORTED, stats)) {
             // The boost should be >2.001 to make absolutely sure the ixisect plan will win due
             // to the combination of 1) productivity, 2) eof bonus, and 3) no ixisect bonus.
             score += 3;
-            LOG(5) << "Score boosted to " << score << " due to intersection forcing.";
+            LOGV2_DEBUG(5, "Score boosted to {} due to intersection forcing.", "score"_attr = score);
         }
     }
 
diff --git a/src/mongo/db/query/planner_access.cpp b/src/mongo/db/query/planner_access.cpp
index f70427a91d..5ccfe4a1ef 100644
--- a/src/mongo/db/query/planner_access.cpp
+++ b/src/mongo/db/query/planner_access.cpp
@@ -50,6 +50,7 @@
 #include "mongo/db/query/query_knobs_gen.h"
 #include "mongo/db/query/query_planner.h"
 #include "mongo/db/query/query_planner_common.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/transitional_tools_do_not_use/vector_spooling.h"
 
@@ -1113,8 +1114,7 @@ std::unique_ptr<QuerySolutionNode> QueryPlannerAccess::buildIndexedAnd(
         } else {
             // We can't use sort-based intersection, and hash-based intersection is disabled.
             // Clean up the index scans and bail out by returning NULL.
-            LOG(5) << "Can't build index intersection solution: "
-                   << "AND_SORTED is not possible and AND_HASH is disabled.";
+            LOGV2_DEBUG(5, "Can't build index intersection solution: AND_SORTED is not possible and AND_HASH is disabled.");
             return nullptr;
         }
     }
diff --git a/src/mongo/db/query/planner_analysis.cpp b/src/mongo/db/query/planner_analysis.cpp
index 6432e1cbe4..31297b1070 100644
--- a/src/mongo/db/query/planner_analysis.cpp
+++ b/src/mongo/db/query/planner_analysis.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/matcher/expression_geo.h"
 #include "mongo/db/query/query_planner.h"
 #include "mongo/db/query/query_planner_common.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -344,7 +345,7 @@ std::unique_ptr<QuerySolutionNode> addSortKeyGeneratorStageIfNeeded(
 std::unique_ptr<ProjectionNode> analyzeProjection(const CanonicalQuery& query,
                                                   std::unique_ptr<QuerySolutionNode> solnRoot,
                                                   const bool hasSortStage) {
-    LOG(5) << "PROJECTION: Current plan is:\n" << redact(solnRoot->toString());
+    LOGV2_DEBUG(5, "PROJECTION: Current plan is:\n{}", "redact_solnRoot_toString"_attr = redact(solnRoot->toString()));
 
     // If the projection requires the entire document we add a fetch stage if not present. Otherwise
     // we add a fetch stage if we are not covered.
@@ -628,8 +629,7 @@ bool QueryPlannerAnalysis::explodeForSort(const CanonicalQuery& query,
 
     // Too many ixscans spoil the performance.
     if (totalNumScans > (size_t)internalQueryMaxScansToExplode.load()) {
-        LOG(5) << "Could expand ixscans to pull out sort order but resulting scan count"
-               << "(" << totalNumScans << ") is too high.";
+        LOGV2_DEBUG(5, "Could expand ixscans to pull out sort order but resulting scan count({}) is too high.", "totalNumScans"_attr = totalNumScans);
         return false;
     }
 
@@ -689,7 +689,7 @@ QuerySolutionNode* QueryPlannerAnalysis::analyzeSort(const CanonicalQuery& query
     BSONObj reverseSort = QueryPlannerCommon::reverseSortObj(sortObj);
     if (sorts.end() != sorts.find(reverseSort)) {
         QueryPlannerCommon::reverseScans(solnRoot);
-        LOG(5) << "Reversing ixscan to provide sort. Result: " << redact(solnRoot->toString());
+        LOGV2_DEBUG(5, "Reversing ixscan to provide sort. Result: {}", "redact_solnRoot_toString"_attr = redact(solnRoot->toString()));
         return solnRoot;
     }
 
diff --git a/src/mongo/db/query/planner_ixselect.cpp b/src/mongo/db/query/planner_ixselect.cpp
index 1e2adddbd3..7029ce91f0 100644
--- a/src/mongo/db/query/planner_ixselect.cpp
+++ b/src/mongo/db/query/planner_ixselect.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/query/indexability.h"
 #include "mongo/db/query/planner_wildcard_helpers.h"
 #include "mongo/db/query/query_planner_common.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -287,15 +288,14 @@ std::vector<IndexEntry> QueryPlannerIXSelect::findIndexesByHint(
         auto hintName = firstHintElt.valueStringData();
         for (auto&& entry : allIndices) {
             if (entry.identifier.catalogName == hintName) {
-                LOG(5) << "Hint by name specified, restricting indices to "
-                       << entry.keyPattern.toString();
+                LOGV2_DEBUG(5, "Hint by name specified, restricting indices to {}", "entry_keyPattern_toString"_attr = entry.keyPattern.toString());
                 out.push_back(entry);
             }
         }
     } else {
         for (auto&& entry : allIndices) {
             if (SimpleBSONObjComparator::kInstance.evaluate(entry.keyPattern == hintedIndex)) {
-                LOG(5) << "Hint specified, restricting indices to " << hintedIndex.toString();
+                LOGV2_DEBUG(5, "Hint specified, restricting indices to {}", "hintedIndex_toString"_attr = hintedIndex.toString());
                 out.push_back(entry);
             }
         }
diff --git a/src/mongo/db/query/planner_wildcard_helpers.cpp b/src/mongo/db/query/planner_wildcard_helpers.cpp
index edf768c75a..0f83b82ea2 100644
--- a/src/mongo/db/query/planner_wildcard_helpers.cpp
+++ b/src/mongo/db/query/planner_wildcard_helpers.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/exec/projection_executor_utils.h"
 #include "mongo/db/index/wildcard_key_generator.h"
 #include "mongo/db/query/index_bounds.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -245,9 +246,7 @@ bool validateNumericPathComponents(const MultikeyPaths& multikeyPaths,
     // all paths with and without array indices. Because this is O(2^n), we decline to answer
     // queries that traverse more than 8 levels of array indices.
     if (arrayIndices.size() > kWildcardMaxArrayIndexTraversalDepth) {
-        LOG(2) << "Declining to answer query on field '" << queryPath.dottedField()
-               << "' with $** index, as it traverses through more than "
-               << kWildcardMaxArrayIndexTraversalDepth << " nested array indices.";
+        LOGV2_DEBUG(2, "Declining to answer query on field '{}' with $** index, as it traverses through more than {} nested array indices.", "queryPath_dottedField"_attr = queryPath.dottedField(), "kWildcardMaxArrayIndexTraversalDepth"_attr = kWildcardMaxArrayIndexTraversalDepth);
         return false;
     }
 
diff --git a/src/mongo/db/query/query_planner.cpp b/src/mongo/db/query/query_planner.cpp
index d9780a699f..a622117a0c 100644
--- a/src/mongo/db/query/query_planner.cpp
+++ b/src/mongo/db/query/query_planner.cpp
@@ -54,6 +54,7 @@
 #include "mongo/db/query/planner_ixselect.h"
 #include "mongo/db/query/query_planner_common.h"
 #include "mongo/db/query/query_solution.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -472,10 +473,7 @@ StatusWith<std::unique_ptr<QuerySolution>> QueryPlanner::planFromCache(
     // Create a copy of the expression tree.  We use cachedSoln to annotate this with indices.
     unique_ptr<MatchExpression> clone = query.root()->shallowClone();
 
-    LOG(5) << "Tagging the match expression according to cache data: " << endl
-           << "Filter:" << endl
-           << redact(clone->debugString()) << "Cache data:" << endl
-           << redact(winnerCacheData.toString());
+    LOGV2_DEBUG(5, "Tagging the match expression according to cache data: \nFilter:\n{}Cache data:\n{}", "redact_clone_debugString"_attr = redact(clone->debugString()), "redact_winnerCacheData_toString"_attr = redact(winnerCacheData.toString()));
 
     stdx::unordered_set<string> fields;
     QueryPlannerIXSelect::getFields(query.root(), &fields);
@@ -489,7 +487,7 @@ StatusWith<std::unique_ptr<QuerySolution>> QueryPlanner::planFromCache(
         const auto insertionRes = indexMap.insert(std::make_pair(ie.identifier, i));
         // Be sure the key was not already in the map.
         invariant(insertionRes.second);
-        LOG(5) << "Index " << i << ": " << ie.identifier;
+        LOGV2_DEBUG(5, "Index {}: {}", "i"_attr = i, "ie_identifier"_attr = ie.identifier);
     }
 
     Status s = tagAccordingToCache(clone.get(), winnerCacheData.tree.get(), indexMap);
@@ -500,7 +498,7 @@ StatusWith<std::unique_ptr<QuerySolution>> QueryPlanner::planFromCache(
     // The MatchExpression tree is in canonical order. We must order the nodes for access planning.
     prepareForAccessPlanning(clone.get());
 
-    LOG(5) << "Tagged tree:" << endl << redact(clone->debugString());
+    LOGV2_DEBUG(5, "Tagged tree:\n{}", "redact_clone_debugString"_attr = redact(clone->debugString()));
 
     // Use the cached index assignments to build solnRoot.
     std::unique_ptr<QuerySolutionNode> solnRoot(QueryPlannerAccess::buildIndexedDataAccess(
@@ -519,21 +517,17 @@ StatusWith<std::unique_ptr<QuerySolution>> QueryPlanner::planFromCache(
                           << "Failed to analyze plan from cache. Query: " << query.toStringShort());
     }
 
-    LOG(5) << "Planner: solution constructed from the cache:\n" << redact(soln->toString());
+    LOGV2_DEBUG(5, "Planner: solution constructed from the cache:\n{}", "redact_soln_toString"_attr = redact(soln->toString()));
     return {std::move(soln)};
 }
 
 // static
 StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
     const CanonicalQuery& query, const QueryPlannerParams& params) {
-    LOG(5) << "Beginning planning..." << endl
-           << "=============================" << endl
-           << "Options = " << optionString(params.options) << endl
-           << "Canonical query:" << endl
-           << redact(query.toString()) << "=============================";
+    LOGV2_DEBUG(5, "Beginning planning...\n=============================\nOptions = {}\nCanonical query:\n{}=============================", "optionString_params_options"_attr = optionString(params.options), "redact_query_toString"_attr = redact(query.toString()));
 
     for (size_t i = 0; i < params.indices.size(); ++i) {
-        LOG(5) << "Index " << i << " is " << params.indices[i].toString();
+        LOGV2_DEBUG(5, "Index {} is {}", "i"_attr = i, "params_indices_i_toString"_attr = params.indices[i].toString());
     }
 
     const bool canTableScan = !(params.options & QueryPlannerParams::NO_TABLE_SCAN);
@@ -569,7 +563,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
         BSONElement naturalHint = dps::extractElementAtPath(hintObj, "$natural");
 
         if (naturalHint) {
-            LOG(5) << "Forcing a table scan due to hinted $natural";
+            LOGV2_DEBUG(5, "Forcing a table scan due to hinted $natural");
             if (!canTableScan) {
                 return Status(ErrorCodes::NoQueryExecutionPlans,
                               "hint $natural is not allowed, because 'notablescan' is enabled");
@@ -629,7 +623,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
     stdx::unordered_set<string> fields;
     QueryPlannerIXSelect::getFields(query.root(), &fields);
     for (auto&& field : fields) {
-        LOG(5) << "Predicate over field '" << field << "'";
+        LOGV2_DEBUG(5, "Predicate over field '{}'", "field"_attr = field);
     }
 
     fullIndexList = QueryPlannerIXSelect::expandIndexes(fields, std::move(fullIndexList));
@@ -703,7 +697,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
     }
 
     for (size_t i = 0; i < relevantIndices.size(); ++i) {
-        LOG(2) << "Relevant index " << i << " is " << relevantIndices[i].toString();
+        LOGV2_DEBUG(2, "Relevant index {} is {}", "i"_attr = i, "relevantIndices_i_toString"_attr = relevantIndices[i].toString());
     }
 
     // Figure out how useful each index is to each predicate.
@@ -725,7 +719,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
     }
 
     // query.root() is now annotated with RelevantTag(s).
-    LOG(5) << "Rated tree:" << endl << redact(query.root()->debugString());
+    LOGV2_DEBUG(5, "Rated tree:\n{}", "redact_query_root_debugString"_attr = redact(query.root()->debugString()));
 
     // If there is a GEO_NEAR it must have an index it can use directly.
     const MatchExpression* gnNode = nullptr;
@@ -733,14 +727,14 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
         // No index for GEO_NEAR?  No query.
         RelevantTag* tag = static_cast<RelevantTag*>(gnNode->getTag());
         if (!tag || (0 == tag->first.size() && 0 == tag->notFirst.size())) {
-            LOG(5) << "Unable to find index for $geoNear query.";
+            LOGV2_DEBUG(5, "Unable to find index for $geoNear query.");
             // Don't leave tags on query tree.
             query.root()->resetTag();
             return Status(ErrorCodes::NoQueryExecutionPlans,
                           "unable to find index for $geoNear query");
         }
 
-        LOG(5) << "Rated tree after geonear processing:" << redact(query.root()->debugString());
+        LOGV2_DEBUG(5, "Rated tree after geonear processing:{}", "redact_query_root_debugString"_attr = redact(query.root()->debugString()));
     }
 
     // Likewise, if there is a TEXT it must have an index it can use directly.
@@ -777,7 +771,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
         // assigned to it.
         invariant(1 == tag->first.size() + tag->notFirst.size());
 
-        LOG(5) << "Rated tree after text processing:" << redact(query.root()->debugString());
+        LOGV2_DEBUG(5, "Rated tree after text processing:{}", "redact_query_root_debugString"_attr = redact(query.root()->debugString()));
     }
 
     std::vector<std::unique_ptr<QuerySolution>> out;
@@ -795,8 +789,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
 
         unique_ptr<MatchExpression> nextTaggedTree;
         while ((nextTaggedTree = isp.getNext()) && (out.size() < params.maxIndexedSolutions)) {
-            LOG(5) << "About to build solntree from tagged tree:" << endl
-                   << redact(nextTaggedTree->debugString());
+            LOGV2_DEBUG(5, "About to build solntree from tagged tree:\n{}", "redact_nextTaggedTree_debugString"_attr = redact(nextTaggedTree->debugString()));
 
             // Store the plan cache index tree before calling prepareForAccessingPlanning(), so that
             // the PlanCacheIndexTree has the same sort as the MatchExpression used to generate the
@@ -805,8 +798,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
             std::unique_ptr<PlanCacheIndexTree> cacheData;
             auto statusWithCacheData = cacheDataFromTaggedTree(clone.get(), relevantIndices);
             if (!statusWithCacheData.isOK()) {
-                LOG(5) << "Query is not cachable: "
-                       << redact(statusWithCacheData.getStatus().reason());
+                LOGV2_DEBUG(5, "Query is not cachable: {}", "redact_statusWithCacheData_getStatus_reason"_attr = redact(statusWithCacheData.getStatus().reason()));
             } else {
                 cacheData = std::move(statusWithCacheData.getValue());
             }
@@ -825,7 +817,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
 
             auto soln = QueryPlannerAnalysis::analyzeDataAccess(query, params, std::move(solnRoot));
             if (soln) {
-                LOG(5) << "Planner: adding solution:" << endl << redact(soln->toString());
+                LOGV2_DEBUG(5, "Planner: adding solution:\n{}", "redact_soln_toString"_attr = redact(soln->toString()));
                 if (statusWithCacheData.isOK()) {
                     SolutionCacheData* scd = new SolutionCacheData();
                     scd->tree = std::move(cacheData);
@@ -839,7 +831,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
     // Don't leave tags on query tree.
     query.root()->resetTag();
 
-    LOG(5) << "Planner: outputted " << out.size() << " indexed solutions.";
+    LOGV2_DEBUG(5, "Planner: outputted {} indexed solutions.", "out_size"_attr = out.size());
 
     // Produce legible error message for failed OR planning with a TEXT child.
     // TODO: support collection scan for non-TEXT children of OR.
@@ -874,7 +866,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
             return Status(ErrorCodes::NoQueryExecutionPlans,
                           "Failed to build whole-index solution for $hint");
         }
-        LOG(5) << "Planner: outputting soln that uses hinted index as scan.";
+        LOGV2_DEBUG(5, "Planner: outputting soln that uses hinted index as scan.");
         std::vector<std::unique_ptr<QuerySolution>> out;
         out.push_back(std::move(soln));
         return {std::move(out)};
@@ -935,7 +927,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
 
                 const BSONObj kp = QueryPlannerAnalysis::getSortPattern(index.keyPattern);
                 if (providesSort(query, kp)) {
-                    LOG(5) << "Planner: outputting soln that uses index to provide sort.";
+                    LOGV2_DEBUG(5, "Planner: outputting soln that uses index to provide sort.");
                     auto soln = buildWholeIXSoln(fullIndexList[i], query, params);
                     if (soln) {
                         PlanCacheIndexTree* indexTree = new PlanCacheIndexTree();
@@ -951,8 +943,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
                     }
                 }
                 if (providesSort(query, QueryPlannerCommon::reverseSortObj(kp))) {
-                    LOG(5) << "Planner: outputting soln that uses (reverse) index "
-                           << "to provide sort.";
+                    LOGV2_DEBUG(5, "Planner: outputting soln that uses (reverse) index to provide sort.");
                     auto soln = buildWholeIXSoln(fullIndexList[i], query, params, -1);
                     if (soln) {
                         PlanCacheIndexTree* indexTree = new PlanCacheIndexTree();
@@ -987,7 +978,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
             QueryPlannerParams paramsForCoveredIxScan;
             auto soln = buildWholeIXSoln(index, query, paramsForCoveredIxScan);
             if (soln && !soln->root->fetched()) {
-                LOG(5) << "Planner: outputting soln that uses index to provide projection.";
+                LOGV2_DEBUG(5, "Planner: outputting soln that uses index to provide projection.");
                 PlanCacheIndexTree* indexTree = new PlanCacheIndexTree();
                 indexTree->setIndexEntry(index);
 
@@ -1029,7 +1020,7 @@ StatusWith<std::vector<std::unique_ptr<QuerySolution>>> QueryPlanner::plan(
                           "Failed to build collection scan soln");
         }
         if (collscan) {
-            LOG(5) << "Planner: outputting a collscan:" << endl << redact(collscan->toString());
+            LOGV2_DEBUG(5, "Planner: outputting a collscan:\n{}", "redact_collscan_toString"_attr = redact(collscan->toString()));
             SolutionCacheData* scd = new SolutionCacheData();
             scd->solnType = SolutionCacheData::COLLSCAN_SOLN;
             collscan->cacheData.reset(scd);
diff --git a/src/mongo/db/query/query_planner_test_fixture.cpp b/src/mongo/db/query/query_planner_test_fixture.cpp
index db4ae678f8..72fd1ee3b7 100644
--- a/src/mongo/db/query/query_planner_test_fixture.cpp
+++ b/src/mongo/db/query/query_planner_test_fixture.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/query/query_knobs_gen.h"
 #include "mongo/db/query/query_planner.h"
 #include "mongo/db/query/query_planner_test_lib.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/transitional_tools_do_not_use/vector_spooling.h"
 
@@ -478,7 +479,7 @@ size_t QueryPlannerTest::getNumSolutions() const {
 void QueryPlannerTest::dumpSolutions() const {
     str::stream ost;
     dumpSolutions(ost);
-    log() << std::string(ost);
+    LOGV2("{}", "std_string_ost"_attr = std::string(ost));
 }
 
 void QueryPlannerTest::dumpSolutions(str::stream& ost) const {
diff --git a/src/mongo/db/read_concern_mongod.cpp b/src/mongo/db/read_concern_mongod.cpp
index 3569bc526c..732e437427 100644
--- a/src/mongo/db/read_concern_mongod.cpp
+++ b/src/mongo/db/read_concern_mongod.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/server_options.h"
 #include "mongo/db/storage/recovery_unit.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/concurrency/notification.h"
 #include "mongo/util/log.h"
@@ -121,8 +122,7 @@ Status makeNoopWriteIfNeeded(OperationContext* opCtx, LogicalTime clusterTime) {
         auto waitStatus = replCoord->waitUntilOpTimeForReadUntil(opCtx, readConcernArgs, deadline);
         lastAppliedOpTime = LogicalTime(replCoord->getMyLastAppliedOpTime().getTimestamp());
         if (!waitStatus.isOK()) {
-            LOG(1) << "Wait for clusterTime: " << clusterTime.toString()
-                   << " until deadline: " << deadline << " failed with " << waitStatus.toString();
+            LOGV2_DEBUG(1, "Wait for clusterTime: {} until deadline: {} failed with {}", "clusterTime_toString"_attr = clusterTime.toString(), "deadline"_attr = deadline, "waitStatus_toString"_attr = waitStatus.toString());
         }
     }
 
@@ -163,8 +163,7 @@ Status makeNoopWriteIfNeeded(OperationContext* opCtx, LogicalTime clusterTime) {
         auto myWriteRequest = writeRequests.getOrCreateWriteRequest(clusterTime);
         if (std::get<0>(myWriteRequest)) {  // Its a new request
             try {
-                LOG(2) << "New appendOplogNote request on clusterTime: " << clusterTime.toString()
-                       << " remaining attempts: " << remainingAttempts;
+                LOGV2_DEBUG(2, "New appendOplogNote request on clusterTime: {} remaining attempts: {}", "clusterTime_toString"_attr = clusterTime.toString(), "remainingAttempts"_attr = remainingAttempts);
                 auto swRes = myShard.getValue()->runCommand(
                     opCtx,
                     ReadPreferenceSetting(ReadPreference::PrimaryOnly),
@@ -183,8 +182,7 @@ Status makeNoopWriteIfNeeded(OperationContext* opCtx, LogicalTime clusterTime) {
                 writeRequests.deleteWriteRequest(clusterTime);
             }
         } else {
-            LOG(2) << "Join appendOplogNote request on clusterTime: " << clusterTime.toString()
-                   << " remaining attempts: " << remainingAttempts;
+            LOGV2_DEBUG(2, "Join appendOplogNote request on clusterTime: {} remaining attempts: {}", "clusterTime_toString"_attr = clusterTime.toString(), "remainingAttempts"_attr = remainingAttempts);
             try {
                 status = std::get<1>(myWriteRequest)->get(opCtx);
             } catch (const DBException& ex) {
@@ -199,8 +197,7 @@ Status makeNoopWriteIfNeeded(OperationContext* opCtx, LogicalTime clusterTime) {
     }
     // This is when the noop write failed but the opLog caught up to clusterTime by replicating.
     if (!status.isOK()) {
-        LOG(1) << "Reached clusterTime " << lastAppliedOpTime.toString()
-               << " but failed noop write due to " << status.toString();
+        LOGV2_DEBUG(1, "Reached clusterTime {} but failed noop write due to {}", "lastAppliedOpTime_toString"_attr = lastAppliedOpTime.toString(), "status_toString"_attr = status.toString());
     }
     return Status::OK();
 }
@@ -316,8 +313,7 @@ Status waitForReadConcernImpl(OperationContext* opCtx,
 
             auto status = makeNoopWriteIfNeeded(opCtx, *targetClusterTime);
             if (!status.isOK()) {
-                LOG(0) << "Failed noop write at clusterTime: " << targetClusterTime->toString()
-                       << " due to " << status.toString();
+                LOGV2("Failed noop write at clusterTime: {} due to {}", "targetClusterTime_toString"_attr = targetClusterTime->toString(), "status_toString"_attr = status.toString());
             }
         }
 
@@ -361,15 +357,14 @@ Status waitForReadConcernImpl(OperationContext* opCtx,
 
         const int debugLevel = serverGlobalParams.clusterRole == ClusterRole::ConfigServer ? 1 : 2;
 
-        LOG(debugLevel) << "Waiting for 'committed' snapshot to be available for reading: "
-                        << readConcernArgs;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(debugLevel).toInt(), "Waiting for 'committed' snapshot to be available for reading: {}", "readConcernArgs"_attr = readConcernArgs);
 
         opCtx->recoveryUnit()->setTimestampReadSource(RecoveryUnit::ReadSource::kMajorityCommitted);
         Status status = opCtx->recoveryUnit()->obtainMajorityCommittedSnapshot();
 
         // Wait until a snapshot is available.
         while (status == ErrorCodes::ReadConcernMajorityNotAvailableYet) {
-            LOG(debugLevel) << "Snapshot not available yet.";
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(debugLevel).toInt(), "Snapshot not available yet.");
             replCoord->waitUntilSnapshotCommitted(opCtx, Timestamp());
             status = opCtx->recoveryUnit()->obtainMajorityCommittedSnapshot();
         }
@@ -378,8 +373,7 @@ Status waitForReadConcernImpl(OperationContext* opCtx,
             return status;
         }
 
-        LOG(debugLevel) << "Using 'committed' snapshot: " << CurOp::get(opCtx)->opDescription()
-                        << " with readTs: " << opCtx->recoveryUnit()->getPointInTimeReadTimestamp();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(debugLevel).toInt(), "Using 'committed' snapshot: {} with readTs: {}", "CurOp_get_opCtx_opDescription"_attr = CurOp::get(opCtx)->opDescription(), "opCtx_recoveryUnit_getPointInTimeReadTimestamp"_attr = opCtx->recoveryUnit()->getPointInTimeReadTimestamp());
     }
     return Status::OK();
 }
@@ -387,8 +381,8 @@ Status waitForReadConcernImpl(OperationContext* opCtx,
 Status waitForLinearizableReadConcernImpl(OperationContext* opCtx, const int readConcernTimeout) {
     CurOpFailpointHelpers::waitWhileFailPointEnabled(
         &hangBeforeLinearizableReadConcern, opCtx, "hangBeforeLinearizableReadConcern", [opCtx]() {
-            log() << "batch update - hangBeforeLinearizableReadConcern fail point enabled. "
-                     "Blocking until fail point is disabled.";
+            LOGV2("batch update - hangBeforeLinearizableReadConcern fail point enabled. "
+                     "Blocking until fail point is disabled.");
         });
 
     repl::ReplicationCoordinator* replCoord =
@@ -460,8 +454,7 @@ Status waitForSpeculativeMajorityReadConcernImpl(
     }
 
     // Block to make sure returned data is majority committed.
-    LOG(1) << "Servicing speculative majority read, waiting for timestamp " << waitTs
-           << " to become committed, current commit point: " << replCoord->getLastCommittedOpTime();
+    LOGV2_DEBUG(1, "Servicing speculative majority read, waiting for timestamp {} to become committed, current commit point: {}", "waitTs"_attr = waitTs, "replCoord_getLastCommittedOpTime"_attr = replCoord->getLastCommittedOpTime());
 
     if (!opCtx->hasDeadline()) {
         // This hard-coded value represents the maximum time we are willing to wait for a timestamp
@@ -476,8 +469,7 @@ Status waitForSpeculativeMajorityReadConcernImpl(
     Timer t;
     auto waitStatus = replCoord->awaitTimestampCommitted(opCtx, waitTs);
     if (waitStatus.isOK()) {
-        LOG(1) << "Timestamp " << waitTs << " became majority committed, waited " << t.millis()
-               << "ms for speculative majority read to be satisfied.";
+        LOGV2_DEBUG(1, "Timestamp {} became majority committed, waited {}ms for speculative majority read to be satisfied.", "waitTs"_attr = waitTs, "t_millis"_attr = t.millis());
     }
     return waitStatus;
 }
diff --git a/src/mongo/db/record_id.h b/src/mongo/db/record_id.h
index bc2836a1b9..cf1eed5184 100644
--- a/src/mongo/db/record_id.h
+++ b/src/mongo/db/record_id.h
@@ -36,6 +36,7 @@
 #include <ostream>
 
 #include "mongo/bson/util/builder.h"
+#include "mongo/bson/bsonobjbuilder.h"
 #include "mongo/logger/logstream_builder.h"
 #include "mongo/util/bufreader.h"
 
@@ -157,6 +158,14 @@ public:
         return *this;
     }
 
+	std::string toString() const {
+        return fmt::format("RecordId({})", repr());
+	}
+
+	void serialize(BSONObjBuilder* builder) const {
+        builder->append("RecordId"_sd, repr());
+	}
+
 private:
     int64_t _repr;
 };
diff --git a/src/mongo/db/repair_database.cpp b/src/mongo/db/repair_database.cpp
index 533e0df0c6..41ab46d559 100644
--- a/src/mongo/db/repair_database.cpp
+++ b/src/mongo/db/repair_database.cpp
@@ -55,6 +55,7 @@
 #include "mongo/db/query/query_knobs_gen.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/storage/storage_engine.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 
@@ -145,7 +146,7 @@ Status repairCollections(OperationContext* opCtx,
     for (const auto& nss : colls) {
         opCtx->checkForInterrupt();
 
-        log() << "Repairing collection " << nss;
+        LOGV2("Repairing collection {}", "nss"_attr = nss);
 
         auto collection = CollectionCatalog::get(opCtx).lookupCollectionByNamespace(opCtx, nss);
         Status status = engine->repairRecordStore(opCtx, collection->getCatalogId(), nss);
@@ -178,7 +179,7 @@ Status repairDatabase(OperationContext* opCtx, StorageEngine* engine, const std:
     invariant(opCtx->lockState()->isW());
     invariant(dbName.find('.') == std::string::npos);
 
-    log() << "repairDatabase " << dbName;
+    LOGV2("repairDatabase {}", "dbName"_attr = dbName);
 
     BackgroundOperation::assertNoBgOpInProgForDb(dbName);
 
diff --git a/src/mongo/db/repair_database_and_check_version.cpp b/src/mongo/db/repair_database_and_check_version.cpp
index 741976143e..31a8e7693d 100644
--- a/src/mongo/db/repair_database_and_check_version.cpp
+++ b/src/mongo/db/repair_database_and_check_version.cpp
@@ -56,6 +56,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/storage/storage_repair_observer.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/exit.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -88,7 +89,7 @@ Status restoreMissingFeatureCompatibilityVersionDocument(OperationContext* opCtx
     auto databaseHolder = DatabaseHolder::get(opCtx);
     auto db = databaseHolder->getDb(opCtx, fcvNss.db());
     if (!db) {
-        log() << "Re-creating admin database that was dropped.";
+        LOGV2("Re-creating admin database that was dropped.");
     }
     db = databaseHolder->openDb(opCtx, fcvNss.db());
     invariant(db);
@@ -97,8 +98,8 @@ Status restoreMissingFeatureCompatibilityVersionDocument(OperationContext* opCtx
     // create it.
     if (!CollectionCatalog::get(opCtx).lookupCollectionByNamespace(
             opCtx, NamespaceString::kServerConfigurationNamespace)) {
-        log() << "Re-creating the server configuration collection (admin.system.version) that was "
-                 "dropped.";
+        LOGV2("Re-creating the server configuration collection (admin.system.version) that was "
+                 "dropped.");
         uassertStatusOK(
             createCollection(opCtx, fcvNss.db().toString(), BSON("create" << fcvNss.coll())));
     }
@@ -113,8 +114,7 @@ Status restoreMissingFeatureCompatibilityVersionDocument(OperationContext* opCtx
                           fcvColl,
                           BSON("_id" << FeatureCompatibilityVersionParser::kParameterName),
                           featureCompatibilityVersion)) {
-        log() << "Re-creating featureCompatibilityVersion document that was deleted with version "
-              << FeatureCompatibilityVersionParser::kVersion42 << ".";
+        LOGV2("Re-creating featureCompatibilityVersion document that was deleted with version {}.", "FeatureCompatibilityVersionParser_kVersion42"_attr = FeatureCompatibilityVersionParser::kVersion42);
 
         BSONObj fcvObj = BSON("_id" << FeatureCompatibilityVersionParser::kParameterName
                                     << FeatureCompatibilityVersionParser::kVersionField
@@ -268,12 +268,11 @@ void rebuildIndexes(OperationContext* opCtx, StorageEngine* storageEngine) {
     auto reconcileResult = fassert(40593, storageEngine->reconcileCatalogAndIdents(opCtx));
 
     if (!reconcileResult.indexesToRebuild.empty() && serverGlobalParams.indexBuildRetry) {
-        log() << "note: restart the server with --noIndexBuildRetry "
-              << "to skip index rebuilds";
+        LOGV2("note: restart the server with --noIndexBuildRetry to skip index rebuilds");
     }
 
     if (!serverGlobalParams.indexBuildRetry) {
-        log() << "  not rebuilding interrupted indexes";
+        LOGV2("  not rebuilding interrupted indexes");
         return;
     }
 
@@ -308,7 +307,7 @@ void rebuildIndexes(OperationContext* opCtx, StorageEngine* storageEngine) {
 
         auto collection = CollectionCatalog::get(opCtx).lookupCollectionByNamespace(opCtx, collNss);
         for (const auto& indexName : entry.second.first) {
-            log() << "Rebuilding index. Collection: " << collNss << " Index: " << indexName;
+            LOGV2("Rebuilding index. Collection: {} Index: {}", "collNss"_attr = collNss, "indexName"_attr = indexName);
         }
 
         std::vector<BSONObj> indexSpecs = entry.second.second;
@@ -378,7 +377,7 @@ bool repairDatabasesAndCheckVersion(OperationContext* opCtx) {
         invariant(!storageGlobalParams.readOnly);
 
         if (MONGO_unlikely(exitBeforeDataRepair.shouldFail())) {
-            log() << "Exiting because 'exitBeforeDataRepair' fail point was set.";
+            LOGV2("Exiting because 'exitBeforeDataRepair' fail point was set.");
             quickExit(EXIT_ABRUPT);
         }
 
@@ -392,7 +391,7 @@ bool repairDatabasesAndCheckVersion(OperationContext* opCtx) {
         }
 
         for (const auto& dbName : dbNames) {
-            LOG(1) << "    Repairing database: " << dbName;
+            LOGV2_DEBUG(1, "    Repairing database: {}", "dbName"_attr = dbName);
             fassertNoTrace(18506, repairDatabase(opCtx, storageEngine, dbName));
         }
 
@@ -437,7 +436,7 @@ bool repairDatabasesAndCheckVersion(OperationContext* opCtx) {
 
     if (storageGlobalParams.repair) {
         if (MONGO_unlikely(exitBeforeRepairInvalidatesConfig.shouldFail())) {
-            log() << "Exiting because 'exitBeforeRepairInvalidatesConfig' fail point was set.";
+            LOGV2("Exiting because 'exitBeforeRepairInvalidatesConfig' fail point was set.");
             quickExit(EXIT_ABRUPT);
         }
         // This must be done after opening the "local" database as it modifies the replica set
@@ -460,8 +459,8 @@ bool repairDatabasesAndCheckVersion(OperationContext* opCtx) {
 
         // There were modifications, but only benign ones.
         if (repairObserver->getModifications().size() > 0 && !repairObserver->isDataInvalidated()) {
-            log() << "Repair has made modifications to unreplicated data. The data is healthy and "
-                     "the node is eligible to be returned to the replica set.";
+            LOGV2("Repair has made modifications to unreplicated data. The data is healthy and "
+                     "the node is eligible to be returned to the replica set.");
         }
     }
 
@@ -487,7 +486,7 @@ bool repairDatabasesAndCheckVersion(OperationContext* opCtx) {
         if (dbName != "local") {
             nonLocalDatabases = true;
         }
-        LOG(1) << "    Recovering database: " << dbName;
+        LOGV2_DEBUG(1, "    Recovering database: {}", "dbName"_attr = dbName);
 
         auto db = databaseHolder->openDb(opCtx, dbName);
         invariant(db);
@@ -549,23 +548,15 @@ bool repairDatabasesAndCheckVersion(OperationContext* opCtx) {
                     // warning.
                     if (version ==
                         ServerGlobalParams::FeatureCompatibility::Version::kUpgradingTo44) {
-                        log() << "** WARNING: A featureCompatibilityVersion upgrade did not "
-                              << "complete. " << startupWarningsLog;
-                        log() << "**          The current featureCompatibilityVersion is "
-                              << FeatureCompatibilityVersionParser::toString(version) << "."
-                              << startupWarningsLog;
-                        log() << "**          To fix this, use the setFeatureCompatibilityVersion "
-                              << "command to resume upgrade to 4.4." << startupWarningsLog;
+                        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: A featureCompatibilityVersion upgrade did not complete. ");
+                        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          The current featureCompatibilityVersion is {}.", "FeatureCompatibilityVersionParser_toString_version"_attr = FeatureCompatibilityVersionParser::toString(version));
+                        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          To fix this, use the setFeatureCompatibilityVersion command to resume upgrade to 4.4.");
                     } else if (version ==
                                ServerGlobalParams::FeatureCompatibility::Version::
                                    kDowngradingTo42) {
-                        log() << "** WARNING: A featureCompatibilityVersion downgrade did not "
-                              << "complete. " << startupWarningsLog;
-                        log() << "**          The current featureCompatibilityVersion is "
-                              << FeatureCompatibilityVersionParser::toString(version) << "."
-                              << startupWarningsLog;
-                        log() << "**          To fix this, use the setFeatureCompatibilityVersion "
-                              << "command to resume downgrade to 4.2." << startupWarningsLog;
+                        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: A featureCompatibilityVersion downgrade did not complete. ");
+                        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          The current featureCompatibilityVersion is {}.", "FeatureCompatibilityVersionParser_toString_version"_attr = FeatureCompatibilityVersionParser::toString(version));
+                        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          To fix this, use the setFeatureCompatibilityVersion command to resume downgrade to 4.2.");
                     }
                 }
             }
@@ -603,7 +594,7 @@ bool repairDatabasesAndCheckVersion(OperationContext* opCtx) {
         fassertFailedNoTrace(40652);
     }
 
-    LOG(1) << "done repairDatabases";
+    LOGV2_DEBUG(1, "done repairDatabases");
     return nonLocalDatabases;
 }
 
diff --git a/src/mongo/db/repl/abstract_oplog_fetcher.cpp b/src/mongo/db/repl/abstract_oplog_fetcher.cpp
index d6f4c79b29..dde1cf214d 100644
--- a/src/mongo/db/repl/abstract_oplog_fetcher.cpp
+++ b/src/mongo/db/repl/abstract_oplog_fetcher.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/commands/server_status_metric.h"
 #include "mongo/db/jsobj.h"
 #include "mongo/db/repl/repl_server_parameters_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
@@ -188,8 +189,7 @@ void AbstractOplogFetcher::_callback(const Fetcher::QueryResponseStatus& result,
     Status responseStatus =
         _checkForShutdownAndConvertStatus(result.getStatus(), "error in fetcher batch callback");
     if (ErrorCodes::CallbackCanceled == responseStatus) {
-        LOG(1) << _getComponentName() << " oplog query cancelled to " << _getSource() << ": "
-               << redact(responseStatus);
+        LOGV2_DEBUG(1, "{} oplog query cancelled to {}: {}", "_getComponentName"_attr = _getComponentName(), "_getSource"_attr = _getSource(), "redact_responseStatus"_attr = redact(responseStatus));
         _finishCallback(responseStatus);
         return;
     }
@@ -204,12 +204,9 @@ void AbstractOplogFetcher::_callback(const Fetcher::QueryResponseStatus& result,
         {
             stdx::lock_guard<Latch> lock(_mutex);
             if (_fetcherRestarts == _maxFetcherRestarts) {
-                log() << "Error returned from oplog query (no more query restarts left): "
-                      << redact(responseStatus);
+                LOGV2("Error returned from oplog query (no more query restarts left): {}", "redact_responseStatus"_attr = redact(responseStatus));
             } else {
-                log() << "Restarting oplog query due to error: " << redact(responseStatus)
-                      << ". Last fetched optime: " << _lastFetched
-                      << ". Restarts remaining: " << (_maxFetcherRestarts - _fetcherRestarts);
+                LOGV2("Restarting oplog query due to error: {}. Last fetched optime: {}. Restarts remaining: {}", "redact_responseStatus"_attr = redact(responseStatus), "_lastFetched"_attr = _lastFetched, "_maxFetcherRestarts__fetcherRestarts"_attr = (_maxFetcherRestarts - _fetcherRestarts));
                 _fetcherRestarts++;
                 // Destroying current instance in _shuttingDownFetcher will possibly block.
                 _shuttingDownFetcher.reset();
@@ -221,7 +218,7 @@ void AbstractOplogFetcher::_callback(const Fetcher::QueryResponseStatus& result,
 
                 auto scheduleStatus = _scheduleFetcher_inlock();
                 if (scheduleStatus.isOK()) {
-                    log() << "Scheduled new oplog query " << _fetcher->toString();
+                    LOGV2("Scheduled new oplog query {}", "_fetcher_toString"_attr = _fetcher->toString());
                     return;
                 }
                 error() << "Error scheduling new oplog query: " << redact(scheduleStatus)
@@ -276,8 +273,7 @@ void AbstractOplogFetcher::_callback(const Fetcher::QueryResponseStatus& result,
             return;
         }
         auto lastDoc = lastDocRes.getValue();
-        LOG(3) << _getComponentName()
-               << " setting last fetched optime ahead after batch: " << lastDoc;
+        LOGV2_DEBUG(3, "{} setting last fetched optime ahead after batch: {}", "_getComponentName"_attr = _getComponentName(), "lastDoc"_attr = lastDoc);
 
         stdx::lock_guard<Latch> lock(_mutex);
         _lastFetched = lastDoc;
diff --git a/src/mongo/db/repl/abstract_oplog_fetcher_test.cpp b/src/mongo/db/repl/abstract_oplog_fetcher_test.cpp
index 7c35e08ab7..b0a9f6602b 100644
--- a/src/mongo/db/repl/abstract_oplog_fetcher_test.cpp
+++ b/src/mongo/db/repl/abstract_oplog_fetcher_test.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/repl/abstract_oplog_fetcher_test_fixture.h"
 #include "mongo/db/repl/oplog_entry.h"
 #include "mongo/db/repl/task_executor_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/task_executor_proxy.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/scopeguard.h"
@@ -300,20 +301,20 @@ TEST_F(AbstractOplogFetcherTest, OplogFetcherStopsRestartingFetcherIfRestartLimi
 
     ASSERT_OK(oplogFetcher.startup());
 
-    unittest::log() << "processing find request from first fetcher";
+    unittest::LOGV2("processing find request from first fetcher");
 
     _assertFindCommandTimestampEquals(
         ops[0], processNetworkResponse({makeCursorResponse(1, {ops[0], ops[1], ops[2]})}, true));
 
-    unittest::log() << "sending error response to getMore request from first fetcher";
+    unittest::LOGV2("sending error response to getMore request from first fetcher");
     assertRemoteCommandNameEquals(
         "getMore", processNetworkResponse({ErrorCodes::CappedPositionLost, "fail 1"}, true));
 
-    unittest::log() << "sending error response to find request from second fetcher";
+    unittest::LOGV2("sending error response to find request from second fetcher");
     _assertFindCommandTimestampEquals(
         ops[2], processNetworkResponse({ErrorCodes::IllegalOperation, "fail 2"}, true));
 
-    unittest::log() << "sending error response to find request from third fetcher";
+    unittest::LOGV2("sending error response to find request from third fetcher");
     _assertFindCommandTimestampEquals(
         ops[2], processNetworkResponse({ErrorCodes::OperationFailed, "fail 3"}, false));
 
@@ -335,28 +336,28 @@ TEST_F(AbstractOplogFetcherTest, OplogFetcherResetsRestartCounterOnSuccessfulFet
 
     ASSERT_OK(oplogFetcher.startup());
 
-    unittest::log() << "processing find request from first fetcher";
+    unittest::LOGV2("processing find request from first fetcher");
 
     _assertFindCommandTimestampEquals(
         ops[0], processNetworkResponse({makeCursorResponse(1, {ops[0], ops[1], ops[2]})}, true));
 
-    unittest::log() << "sending error response to getMore request from first fetcher";
+    unittest::LOGV2("sending error response to getMore request from first fetcher");
     assertRemoteCommandNameEquals(
         "getMore", processNetworkResponse({ErrorCodes::CappedPositionLost, "fail 1"}, true));
 
-    unittest::log() << "processing find request from second fetcher";
+    unittest::LOGV2("processing find request from second fetcher");
     _assertFindCommandTimestampEquals(
         ops[2], processNetworkResponse({makeCursorResponse(1, {ops[2], ops[3], ops[4]})}, true));
 
-    unittest::log() << "sending error response to getMore request from second fetcher";
+    unittest::LOGV2("sending error response to getMore request from second fetcher");
     assertRemoteCommandNameEquals(
         "getMore", processNetworkResponse({ErrorCodes::IllegalOperation, "fail 2"}, true));
 
-    unittest::log() << "sending error response to find request from third fetcher";
+    unittest::LOGV2("sending error response to find request from third fetcher");
     _assertFindCommandTimestampEquals(
         ops[4], processNetworkResponse({ErrorCodes::InternalError, "fail 3"}, true));
 
-    unittest::log() << "sending error response to find request from fourth fetcher";
+    unittest::LOGV2("sending error response to find request from fourth fetcher");
     _assertFindCommandTimestampEquals(
         ops[4], processNetworkResponse({ErrorCodes::OperationFailed, "fail 4"}, false));
 
@@ -406,12 +407,12 @@ TEST_F(AbstractOplogFetcherTest,
     ASSERT_OK(oplogFetcher.startup());
     ASSERT_TRUE(oplogFetcher.isActive());
 
-    unittest::log() << "processing find request from first fetcher";
+    unittest::LOGV2("processing find request from first fetcher");
 
     _assertFindCommandTimestampEquals(
         ops[0], processNetworkResponse({makeCursorResponse(1, {ops[0], ops[1], ops[2]})}, true));
 
-    unittest::log() << "sending error response to getMore request from first fetcher";
+    unittest::LOGV2("sending error response to getMore request from first fetcher");
     shouldFailSchedule = true;
     assertRemoteCommandNameEquals(
         "getMore", processNetworkResponse({ErrorCodes::CappedPositionLost, "dead cursor"}, false));
diff --git a/src/mongo/db/repl/abstract_oplog_fetcher_test_fixture.cpp b/src/mongo/db/repl/abstract_oplog_fetcher_test_fixture.cpp
index 9f748b283c..ed9454fea2 100644
--- a/src/mongo/db/repl/abstract_oplog_fetcher_test_fixture.cpp
+++ b/src/mongo/db/repl/abstract_oplog_fetcher_test_fixture.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/db/repl/oplog_entry.h"
 #include "mongo/executor/thread_pool_task_executor_test_fixture.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 
 namespace mongo {
@@ -119,13 +120,13 @@ executor::RemoteCommandRequest AbstractOplogFetcherTest::processNetworkResponse(
 
     auto net = getNet();
     executor::NetworkInterfaceMock::InNetworkGuard guard(net);
-    unittest::log() << "scheduling response.";
+    unittest::LOGV2("scheduling response.");
     auto request = net->scheduleSuccessfulResponse(response);
-    unittest::log() << "running network ops.";
+    unittest::LOGV2("running network ops.");
     net->runReadyNetworkOperations();
-    unittest::log() << "checking for more requests";
+    unittest::LOGV2("checking for more requests");
     ASSERT_EQUALS(expectReadyRequestsAfterProcessing, net->hasReadyRequests());
-    unittest::log() << "returning consumed request";
+    unittest::LOGV2("returning consumed request");
     return request;
 }
 
diff --git a/src/mongo/db/repl/all_database_cloner.cpp b/src/mongo/db/repl/all_database_cloner.cpp
index c761d8b259..f2ad9c65aa 100644
--- a/src/mongo/db/repl/all_database_cloner.cpp
+++ b/src/mongo/db/repl/all_database_cloner.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/base/string_data.h"
 #include "mongo/db/repl/all_database_cloner.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 namespace mongo {
@@ -64,14 +65,13 @@ BaseCloner::AfterStageBehavior AllDatabaseCloner::listDatabasesStage() {
     auto databasesArray = getClient()->getDatabaseInfos(BSONObj(), true /* nameOnly */);
     for (const auto& dbBSON : databasesArray) {
         if (!dbBSON.hasField("name")) {
-            LOG(1) << "Excluding database due to the 'listDatabases' response not containing a "
-                      "'name' field for this entry: "
-                   << dbBSON;
+            LOGV2_DEBUG(1, "Excluding database due to the 'listDatabases' response not containing a "
+                      "'name' field for this entry: {}", "dbBSON"_attr = dbBSON);
             continue;
         }
         const auto& dbName = dbBSON["name"].str();
         if (dbName == "local") {
-            LOG(1) << "Excluding database from the 'listDatabases' response: " << dbBSON;
+            LOGV2_DEBUG(1, "Excluding database from the 'listDatabases' response: {}", "dbBSON"_attr = dbBSON);
             continue;
         } else {
             _databases.emplace_back(dbName);
@@ -106,7 +106,7 @@ void AllDatabaseCloner::postStage() {
         }
         auto dbStatus = _currentDatabaseCloner->run();
         if (dbStatus.isOK()) {
-            LOG(1) << "Database clone for '" << dbName << "' finished: " << dbStatus;
+            LOGV2_DEBUG(1, "Database clone for '{}' finished: {}", "dbName"_attr = dbName, "dbStatus"_attr = dbStatus);
         } else {
             warning() << "database '" << dbName << "' (" << (_stats.databasesCloned + 1) << " of "
                       << _databases.size() << ") clone failed due to " << dbStatus.toString();
@@ -114,7 +114,7 @@ void AllDatabaseCloner::postStage() {
             return;
         }
         if (StringData(dbName).equalCaseInsensitive("admin")) {
-            LOG(1) << "Finished the 'admin' db, now validating it.";
+            LOGV2_DEBUG(1, "Finished the 'admin' db, now validating it.");
             // Do special checks for the admin database because of auth. collections.
             auto adminStatus = Status(ErrorCodes::NotYetInitialized, "");
             {
@@ -127,7 +127,7 @@ void AllDatabaseCloner::postStage() {
                 adminStatus = getStorageInterface()->isAdminDbValid(opCtx);
             }
             if (!adminStatus.isOK()) {
-                LOG(1) << "Validation failed on 'admin' db due to " << adminStatus;
+                LOGV2_DEBUG(1, "Validation failed on 'admin' db due to {}", "adminStatus"_attr = adminStatus);
                 setInitialSyncFailedStatus(adminStatus);
                 return;
             }
diff --git a/src/mongo/db/repl/all_database_cloner_test.cpp b/src/mongo/db/repl/all_database_cloner_test.cpp
index ffc72c8d2f..f1de5201c0 100644
--- a/src/mongo/db/repl/all_database_cloner_test.cpp
+++ b/src/mongo/db/repl/all_database_cloner_test.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/repl/storage_interface_mock.h"
 #include "mongo/db/service_context_test_fixture.h"
 #include "mongo/dbtests/mock/mock_dbclient_connection.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/clock_source_mock.h"
 #include "mongo/util/concurrency/thread_pool.h"
@@ -114,7 +115,7 @@ TEST_F(AllDatabaseClonerTest, RetriesConnect) {
     ASSERT_EQ(2, _sharedData->getTotalRetries(WithLock::withoutLock()));
 
     // Bring the server up.
-    unittest::log() << "Bringing mock server back up.";
+    unittest::LOGV2("Bringing mock server back up.");
     _mockServer->reboot();
 
     // Allow the cloner to finish.
@@ -229,7 +230,7 @@ TEST_F(AllDatabaseClonerTest, RetriesListDatabases) {
     ASSERT_EQ(2, _sharedData->getTotalRetries(WithLock::withoutLock()));
 
     // Bring the server up.
-    unittest::log() << "Bringing mock server back up.";
+    unittest::LOGV2("Bringing mock server back up.");
     _mockServer->reboot();
 
     // Allow the cloner to finish.
@@ -277,7 +278,7 @@ TEST_F(AllDatabaseClonerTest, RetriesListDatabasesButRollBackIdChanges) {
     _mockServer->setCommandReply("replSetGetRBID", fromjson("{ok:1, rbid:2}"));
 
     // Bring the server up.
-    unittest::log() << "Bringing mock server back up.";
+    unittest::LOGV2("Bringing mock server back up.");
     _mockServer->reboot();
 
     // Allow the cloner to finish.
diff --git a/src/mongo/db/repl/apply_ops.cpp b/src/mongo/db/repl/apply_ops.cpp
index a5960b2d0e..61d3e91c4e 100644
--- a/src/mongo/db/repl/apply_ops.cpp
+++ b/src/mongo/db/repl/apply_ops.cpp
@@ -55,6 +55,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/session_catalog_mongod.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -266,7 +267,7 @@ Status _applyOps(OperationContext* opCtx,
 
         ab.append(status.isOK());
         if (!status.isOK()) {
-            log() << "applyOps error applying: " << status;
+            LOGV2("applyOps error applying: {}", "status"_attr = status);
             errors++;
         }
 
diff --git a/src/mongo/db/repl/base_cloner.cpp b/src/mongo/db/repl/base_cloner.cpp
index a9a51f891b..d0b8cfd7bd 100644
--- a/src/mongo/db/repl/base_cloner.cpp
+++ b/src/mongo/db/repl/base_cloner.cpp
@@ -32,6 +32,7 @@
 #include "mongo/platform/basic.h"
 
 #include "mongo/db/repl/base_cloner.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 
@@ -91,8 +92,7 @@ Status BaseCloner::run() {
     }
     stdx::lock_guard<InitialSyncSharedData> lk(*_sharedData);
     if (!_sharedData->getInitialSyncStatus(lk).isOK()) {
-        log() << "Failing data clone because initial sync failed outside data clone: "
-              << _sharedData->getInitialSyncStatus(lk);
+        LOGV2("Failing data clone because initial sync failed outside data clone: {}", "_sharedData_getInitialSyncStatus_lk"_attr = _sharedData->getInitialSyncStatus(lk));
     }
     return _sharedData->getInitialSyncStatus(lk);
 }
@@ -116,13 +116,12 @@ void BaseCloner::pauseForFuzzer(BaseClonerStage* stage) {
             // nb: This log message is specifically checked for in
             // initial_sync_test_fixture_test.js, so if you change it here you will need to change
             // it there.
-            log() << "Collection Cloner scheduled a remote command on the "
-                  << describeForFuzzer(stage);
-            log() << "initialSyncFuzzerSynchronizationPoint1 fail point enabled.";
+            LOGV2("Collection Cloner scheduled a remote command on the {}", "describeForFuzzer_stage"_attr = describeForFuzzer(stage));
+            LOGV2("initialSyncFuzzerSynchronizationPoint1 fail point enabled.");
             initialSyncFuzzerSynchronizationPoint1.pauseWhileSet();
 
             if (MONGO_unlikely(initialSyncFuzzerSynchronizationPoint2.shouldFail())) {
-                log() << "initialSyncFuzzerSynchronizationPoint2 fail point enabled.";
+                LOGV2("initialSyncFuzzerSynchronizationPoint2 fail point enabled.");
                 initialSyncFuzzerSynchronizationPoint2.pauseWhileSet();
             }
         }
@@ -130,15 +129,14 @@ void BaseCloner::pauseForFuzzer(BaseClonerStage* stage) {
 }
 
 BaseCloner::AfterStageBehavior BaseCloner::runStage(BaseClonerStage* stage) {
-    LOG(1) << "Cloner " << getClonerName() << " running stage " << stage->getName();
+    LOGV2_DEBUG(1, "Cloner {} running stage {}", "getClonerName"_attr = getClonerName(), "stage_getName"_attr = stage->getName());
     pauseForFuzzer(stage);
     auto isThisStageFailPoint = [this, stage](const BSONObj& data) {
         return data["stage"].str() == stage->getName() && isMyFailPoint(data);
     };
     hangBeforeClonerStage.executeIf(
         [&](const BSONObj& data) {
-            log() << "Cloner " << getClonerName() << " hanging before running stage "
-                  << stage->getName();
+            LOGV2("Cloner {} hanging before running stage {}", "getClonerName"_attr = getClonerName(), "stage_getName"_attr = stage->getName());
             while (!mustExit() && hangBeforeClonerStage.shouldFail(isThisStageFailPoint)) {
                 sleepmillis(100);
             }
@@ -147,14 +145,13 @@ BaseCloner::AfterStageBehavior BaseCloner::runStage(BaseClonerStage* stage) {
     auto afterStageBehavior = runStageWithRetries(stage);
     hangAfterClonerStage.executeIf(
         [&](const BSONObj& data) {
-            log() << "Cloner " << getClonerName() << " hanging after running stage "
-                  << stage->getName();
+            LOGV2("Cloner {} hanging after running stage {}", "getClonerName"_attr = getClonerName(), "stage_getName"_attr = stage->getName());
             while (!mustExit() && hangAfterClonerStage.shouldFail(isThisStageFailPoint)) {
                 sleepmillis(100);
             }
         },
         isThisStageFailPoint);
-    LOG(1) << "Cloner " << getClonerName() << " finished running stage " << stage->getName();
+    LOGV2_DEBUG(1, "Cloner {} finished running stage {}", "getClonerName"_attr = getClonerName(), "stage_getName"_attr = stage->getName());
     return afterStageBehavior;
 }
 
@@ -170,7 +167,7 @@ Status BaseCloner::checkRollBackIdIsUnchanged() {
         if (ErrorCodes::isNetworkError(e)) {
             auto status = e.toStatus().withContext(
                 ": failed while attempting to retrieve rollBackId after re-connect");
-            LOG(1) << status;
+            LOGV2_DEBUG(1, "{}", "status"_attr = status);
             return status;
         }
         throw;
@@ -200,16 +197,14 @@ BaseCloner::AfterStageBehavior BaseCloner::runStageWithRetries(BaseClonerStage*
                 // If lastError is set, this is a retry.
                 hangBeforeRetryingClonerStage.executeIf(
                     [&](const BSONObj& data) {
-                        log() << "Cloner " << getClonerName() << " hanging before retrying stage "
-                              << stage->getName();
+                        LOGV2("Cloner {} hanging before retrying stage {}", "getClonerName"_attr = getClonerName(), "stage_getName"_attr = stage->getName());
                         while (!mustExit() &&
                                hangBeforeRetryingClonerStage.shouldFail(isThisStageFailPoint)) {
                             sleepmillis(100);
                         }
                     },
                     isThisStageFailPoint);
-                log() << "Initial Sync retrying " << getClonerName() << " stage "
-                      << stage->getName() << " due to " << lastError;
+                LOGV2("Initial Sync retrying {} stage {} due to {}", "getClonerName"_attr = getClonerName(), "stage_getName"_attr = stage->getName(), "lastError"_attr = lastError);
                 bool shouldRetry = [&] {
                     stdx::lock_guard<InitialSyncSharedData> lk(*_sharedData);
                     return _sharedData->shouldRetryOperation(lk, &_retryableOp);
@@ -225,9 +220,7 @@ BaseCloner::AfterStageBehavior BaseCloner::runStageWithRetries(BaseClonerStage*
                 }
                 hangBeforeCheckingRollBackIdClonerStage.executeIf(
                     [&](const BSONObj& data) {
-                        log() << "Cloner " << getClonerName()
-                              << " hanging before checking rollBackId for stage "
-                              << stage->getName();
+                        LOGV2("Cloner {} hanging before checking rollBackId for stage {}", "getClonerName"_attr = getClonerName(), "stage_getName"_attr = stage->getName());
                         while (!mustExit() &&
                                hangBeforeCheckingRollBackIdClonerStage.shouldFail(
                                    isThisStageFailPoint)) {
@@ -248,12 +241,10 @@ BaseCloner::AfterStageBehavior BaseCloner::runStageWithRetries(BaseClonerStage*
         } catch (DBException& e) {
             lastError = e.toStatus();
             if (!stage->isTransientError(lastError)) {
-                log() << "Non-retryable error occured during cloner " << getClonerName()
-                      << " stage " + stage->getName() << ": " << lastError;
+                LOGV2("Non-retryable error occured during cloner {}{}: {}", "getClonerName"_attr = getClonerName(), "stage_stage_getName"_attr = " stage " + stage->getName(), "lastError"_attr = lastError);
                 throw;
             }
-            LOG(1) << "Transient error occured during cloner " << getClonerName()
-                   << " stage " + stage->getName() << ": " << lastError;
+            LOGV2_DEBUG(1, "Transient error occured during cloner {}{}: {}", "getClonerName"_attr = getClonerName(), "stage_stage_getName"_attr = " stage " + stage->getName(), "lastError"_attr = lastError);
         }
     }
 }
diff --git a/src/mongo/db/repl/bgsync.cpp b/src/mongo/db/repl/bgsync.cpp
index e08f286b5b..da5cb1b7c5 100644
--- a/src/mongo/db/repl/bgsync.cpp
+++ b/src/mongo/db/repl/bgsync.cpp
@@ -58,6 +58,7 @@
 #include "mongo/db/repl/rs_rollback.h"
 #include "mongo/db/repl/storage_interface.h"
 #include "mongo/db/s/shard_identity_rollback_notifier.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/util/log.h"
@@ -250,8 +251,8 @@ void BackgroundSync::_runProducer() {
 void BackgroundSync::_produce() {
     if (MONGO_unlikely(stopReplProducer.shouldFail())) {
         // This log output is used in js tests so please leave it.
-        log() << "bgsync - stopReplProducer fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("bgsync - stopReplProducer fail point "
+                 "enabled. Blocking until fail point is disabled.");
         mongo::sleepsecs(1);
         return;
     }
@@ -293,7 +294,7 @@ void BackgroundSync::_produce() {
         const auto requiredOpTime = (minValidSaved > _lastOpTimeFetched) ? minValidSaved : OpTime();
         lastOpTimeFetched = _lastOpTimeFetched;
         if (!_syncSourceHost.empty()) {
-            log() << "Clearing sync source " << _syncSourceHost << " to choose a new one.";
+            LOGV2("Clearing sync source {} to choose a new one.", "_syncSourceHost"_attr = _syncSourceHost);
         }
         _syncSourceHost = HostAndPort();
         _syncSourceResolver = std::make_unique<SyncSourceResolver>(
@@ -326,13 +327,12 @@ void BackgroundSync::_produce() {
         // All (accessible) sync sources are too far ahead of us.
         if (_replCoord->getMemberState().primary()) {
             warning() << "Too stale to catch up.";
-            log() << "Our newest OpTime : " << lastOpTimeFetched;
-            log() << "Earliest OpTime available is " << syncSourceResp.earliestOpTimeSeen
-                  << " from " << syncSourceResp.getSyncSource();
+            LOGV2("Our newest OpTime : {}", "lastOpTimeFetched"_attr = lastOpTimeFetched);
+            LOGV2("Earliest OpTime available is {} from {}", "syncSourceResp_earliestOpTimeSeen"_attr = syncSourceResp.earliestOpTimeSeen, "syncSourceResp_getSyncSource"_attr = syncSourceResp.getSyncSource());
             auto status = _replCoord->abortCatchupIfNeeded(
                 ReplicationCoordinator::PrimaryCatchUpConclusionReason::kFailedWithError);
             if (!status.isOK()) {
-                LOG(1) << "Aborting catch-up failed with status: " << status;
+                LOGV2_DEBUG(1, "Aborting catch-up failed with status: {}", "status"_attr = status);
             }
             return;
         }
@@ -347,9 +347,9 @@ void BackgroundSync::_produce() {
         ReplicationStateTransitionLockGuard transitionGuard(opCtx.get(), MODE_X);
 
         error() << "too stale to catch up -- entering maintenance mode";
-        log() << "Our newest OpTime : " << lastOpTimeFetched;
-        log() << "Earliest OpTime available is " << syncSourceResp.earliestOpTimeSeen;
-        log() << "See http://dochub.mongodb.org/core/resyncingaverystalereplicasetmember";
+        LOGV2("Our newest OpTime : {}", "lastOpTimeFetched"_attr = lastOpTimeFetched);
+        LOGV2("Earliest OpTime available is {}", "syncSourceResp_earliestOpTimeSeen"_attr = syncSourceResp.earliestOpTimeSeen);
+        LOGV2("See http://dochub.mongodb.org/core/resyncingaverystalereplicasetmember");
 
         // Activate maintenance mode and transition to RECOVERING.
         auto status = _replCoord->setMaintenanceMode(true);
@@ -381,22 +381,17 @@ void BackgroundSync::_produce() {
             forceBgSyncSyncSourceRetryWaitMS.execute(
                 [&](const BSONObj& data) { sleepMS = data["sleepMS"].numberInt(); });
 
-            log() << "Chose same sync source candidate as last time, " << source
-                  << ". Sleeping for " << sleepMS
-                  << "ms to avoid immediately choosing a new sync source for the same reason as "
-                     "last time.";
+            LOGV2("Chose same sync source candidate as last time, {}. Sleeping for {}ms to avoid immediately choosing a new sync source for the same reason as "
+                     "last time.", "source"_attr = source, "sleepMS"_attr = sleepMS);
             numTimesChoseSameSyncSource.increment(1);
             mongo::sleepmillis(sleepMS);
         } else {
-            log() << "Changed sync source from "
-                  << (oldSource.empty() ? std::string("empty") : oldSource.toString()) << " to "
-                  << source;
+            LOGV2("Changed sync source from {} to {}", "oldSource_empty_std_string_empty_oldSource_toString"_attr = (oldSource.empty() ? std::string("empty") : oldSource.toString()), "source"_attr = source);
             numTimesChoseDifferentSyncSource.increment(1);
         }
     } else {
         if (!syncSourceResp.isOK()) {
-            log() << "failed to find sync source, received error "
-                  << syncSourceResp.syncSourceStatus.getStatus();
+            LOGV2("failed to find sync source, received error {}", "syncSourceResp_syncSourceStatus_getStatus"_attr = syncSourceResp.syncSourceStatus.getStatus());
         }
 
         long long sleepMS = 1000;
@@ -404,8 +399,7 @@ void BackgroundSync::_produce() {
             [&](const BSONObj& data) { sleepMS = data["sleepMS"].numberInt(); });
 
         // No sync source found.
-        LOG(1) << "Could not find a sync source. Sleeping for " << sleepMS
-               << "ms before trying again.";
+        LOGV2_DEBUG(1, "Could not find a sync source. Sleeping for {}ms before trying again.", "sleepMS"_attr = sleepMS);
         numTimesCouldNotFindSyncSource.increment(1);
         mongo::sleepmillis(sleepMS);
         return;
@@ -414,7 +408,7 @@ void BackgroundSync::_produce() {
     // If we find a good sync source after having gone too stale, disable maintenance mode so we can
     // transition to SECONDARY.
     if (_tooStale.swap(false)) {
-        log() << "No longer too stale. Able to sync from " << source;
+        LOGV2("No longer too stale. Able to sync from {}", "source"_attr = source);
         auto status = _replCoord->setMaintenanceMode(false);
         if (!status.isOK()) {
             warning() << "Failed to leave maintenance mode: " << status;
@@ -481,8 +475,7 @@ void BackgroundSync::_produce() {
     }
 
     const auto logLevel = getTestCommandsEnabled() ? 0 : 1;
-    LOG(logLevel) << "scheduling fetcher to read remote oplog on " << source << " starting at "
-                  << oplogFetcher->getFindQuery_forTest()["filter"];
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(logLevel).toInt(), "scheduling fetcher to read remote oplog on {} starting at {}", "source"_attr = source, "oplogFetcher_getFindQuery_forTest_filter"_attr = oplogFetcher->getFindQuery_forTest()["filter"]);
     auto scheduleStatus = oplogFetcher->startup();
     if (!scheduleStatus.isOK()) {
         warning() << "unable to schedule fetcher to read remote oplog on " << source << ": "
@@ -491,14 +484,14 @@ void BackgroundSync::_produce() {
     }
 
     oplogFetcher->join();
-    LOG(1) << "fetcher stopped reading remote oplog on " << source;
+    LOGV2_DEBUG(1, "fetcher stopped reading remote oplog on {}", "source"_attr = source);
 
     // If the background sync is stopped after the fetcher is started, we need to
     // re-evaluate our sync source and oplog common point.
     if (getState() != ProducerState::Running) {
-        log() << "Replication producer stopped after oplog fetcher finished returning a batch from "
+        LOGV2("Replication producer stopped after oplog fetcher finished returning a batch from "
                  "our sync source.  Abandoning this batch of oplog entries and re-evaluating our "
-                 "sync source.";
+                 "sync source.");
         return;
     }
 
@@ -554,7 +547,7 @@ Status BackgroundSync::_enqueueDocuments(Fetcher::Documents::const_iterator begi
 
         // Update last fetched info.
         _lastOpTimeFetched = info.lastDocument;
-        LOG(3) << "batch resetting _lastOpTimeFetched: " << _lastOpTimeFetched;
+        LOGV2_DEBUG(3, "batch resetting _lastOpTimeFetched: {}", "_lastOpTimeFetched"_attr = _lastOpTimeFetched);
     }
 
     // Check some things periodically (whenever we run out of items in the current cursor batch).
@@ -581,7 +574,7 @@ void BackgroundSync::_runRollback(OperationContext* opCtx,
         auto status = _replCoord->abortCatchupIfNeeded(
             ReplicationCoordinator::PrimaryCatchUpConclusionReason::kFailedWithError);
         if (!status.isOK()) {
-            LOG(1) << "Aborting catch-up failed with status: " << status;
+            LOGV2_DEBUG(1, "Aborting catch-up failed with status: {}", "status"_attr = status);
         }
         return;
     }
@@ -600,8 +593,8 @@ void BackgroundSync::_runRollback(OperationContext* opCtx,
         lastOpTimeFetched = _lastOpTimeFetched;
     }
 
-    log() << "Starting rollback due to " << redact(fetcherReturnStatus);
-    log() << "Replication commit point: " << _replCoord->getLastCommittedOpTime();
+    LOGV2("Starting rollback due to {}", "redact_fetcherReturnStatus"_attr = redact(fetcherReturnStatus));
+    LOGV2("Replication commit point: {}", "_replCoord_getLastCommittedOpTime"_attr = _replCoord->getLastCommittedOpTime());
 
     // TODO: change this to call into the Applier directly to block until the applier is
     // drained.
@@ -609,8 +602,7 @@ void BackgroundSync::_runRollback(OperationContext* opCtx,
     // Wait till all buffered oplog entries have drained and been applied.
     auto lastApplied = _replCoord->getMyLastAppliedOpTime();
     if (lastApplied != lastOpTimeFetched) {
-        log() << "Waiting for all operations from " << lastApplied << " until " << lastOpTimeFetched
-              << " to be applied before starting rollback.";
+        LOGV2("Waiting for all operations from {} until {} to be applied before starting rollback.", "lastApplied"_attr = lastApplied, "lastOpTimeFetched"_attr = lastOpTimeFetched);
         while (lastOpTimeFetched > (lastApplied = _replCoord->getMyLastAppliedOpTime())) {
             sleepmillis(10);
             if (getState() != ProducerState::Running) {
@@ -621,8 +613,8 @@ void BackgroundSync::_runRollback(OperationContext* opCtx,
 
     if (MONGO_unlikely(rollbackHangBeforeStart.shouldFail())) {
         // This log output is used in js tests so please leave it.
-        log() << "rollback - rollbackHangBeforeStart fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("rollback - rollbackHangBeforeStart fail point "
+                 "enabled. Blocking until fail point is disabled.");
         while (MONGO_unlikely(rollbackHangBeforeStart.shouldFail()) && !inShutdown()) {
             mongo::sleepsecs(1);
         }
@@ -649,11 +641,11 @@ void BackgroundSync::_runRollback(OperationContext* opCtx,
 
     auto storageEngine = opCtx->getServiceContext()->getStorageEngine();
     if (!forceRollbackViaRefetch.load() && storageEngine->supportsRecoverToStableTimestamp()) {
-        log() << "Rollback using 'recoverToStableTimestamp' method.";
+        LOGV2("Rollback using 'recoverToStableTimestamp' method.");
         _runRollbackViaRecoverToCheckpoint(
             opCtx, source, &localOplog, storageInterface, getConnection);
     } else {
-        log() << "Rollback using the 'rollbackViaRefetch' method.";
+        LOGV2("Rollback using the 'rollbackViaRefetch' method.");
         _fallBackOnRollbackViaRefetch(
             opCtx, source, abortedIndexBuilds, requiredRBID, &localOplog, getConnection);
     }
@@ -685,10 +677,10 @@ void BackgroundSync::_runRollbackViaRecoverToCheckpoint(
     _rollback = std::make_unique<RollbackImpl>(
         localOplog, &remoteOplog, storageInterface, _replicationProcess, _replCoord);
 
-    log() << "Scheduling rollback (sync source: " << source << ")";
+    LOGV2("Scheduling rollback (sync source: {})", "source"_attr = source);
     auto status = _rollback->runRollback(opCtx);
     if (status.isOK()) {
-        log() << "Rollback successful.";
+        LOGV2("Rollback successful.");
     } else if (status == ErrorCodes::UnrecoverableRollbackError) {
         severe() << "Rollback failed with unrecoverable error: " << status;
         fassertFailedWithStatusNoTrace(50666, status);
@@ -726,7 +718,7 @@ HostAndPort BackgroundSync::getSyncTarget() const {
 
 void BackgroundSync::clearSyncTarget() {
     stdx::unique_lock<Latch> lock(_mutex);
-    log() << "Resetting sync source to empty, which was " << _syncSourceHost;
+    LOGV2("Resetting sync source to empty, which was {}", "_syncSourceHost"_attr = _syncSourceHost);
     _syncSourceHost = HostAndPort();
 }
 
@@ -734,13 +726,13 @@ void BackgroundSync::stop(bool resetLastFetchedOptime) {
     stdx::lock_guard<Latch> lock(_mutex);
 
     _state = ProducerState::Stopped;
-    log() << "Stopping replication producer";
+    LOGV2("Stopping replication producer");
 
     _syncSourceHost = HostAndPort();
     if (resetLastFetchedOptime) {
         invariant(_oplogApplier->getBuffer()->isEmpty());
         _lastOpTimeFetched = OpTime();
-        log() << "Resetting last fetched optimes in bgsync";
+        LOGV2("Resetting last fetched optimes in bgsync");
     }
 
     if (_syncSourceResolver) {
@@ -769,21 +761,20 @@ void BackgroundSync::start(OperationContext* opCtx) {
         // If a node steps down during drain mode, then the buffer may not be empty at the beginning
         // of secondary state.
         if (!_oplogApplier->getBuffer()->isEmpty()) {
-            log() << "going to start syncing, but buffer is not empty";
+            LOGV2("going to start syncing, but buffer is not empty");
         }
         _state = ProducerState::Running;
 
         // When a node steps down during drain mode, the last fetched optime would be newer than
         // the last applied.
         if (_lastOpTimeFetched <= lastAppliedOpTime) {
-            LOG(1) << "Setting bgsync _lastOpTimeFetched=" << lastAppliedOpTime
-                   << ". Previous _lastOpTimeFetched: " << _lastOpTimeFetched;
+            LOGV2_DEBUG(1, "Setting bgsync _lastOpTimeFetched={}. Previous _lastOpTimeFetched: {}", "lastAppliedOpTime"_attr = lastAppliedOpTime, "_lastOpTimeFetched"_attr = _lastOpTimeFetched);
             _lastOpTimeFetched = lastAppliedOpTime;
         }
         // Reload the last applied optime from disk if it has been changed.
     } while (lastAppliedOpTime != _replCoord->getMyLastAppliedOpTime());
 
-    LOG(1) << "bgsync fetch queue set to: " << _lastOpTimeFetched;
+    LOGV2_DEBUG(1, "bgsync fetch queue set to: {}", "_lastOpTimeFetched"_attr = _lastOpTimeFetched);
 }
 
 OpTime BackgroundSync::_readLastAppliedOpTime(OperationContext* opCtx) {
@@ -808,14 +799,14 @@ OpTime BackgroundSync::_readLastAppliedOpTime(OperationContext* opCtx) {
     }
 
     OplogEntry parsedEntry(oplogEntry);
-    LOG(1) << "Successfully read last entry of oplog while starting bgsync: " << redact(oplogEntry);
+    LOGV2_DEBUG(1, "Successfully read last entry of oplog while starting bgsync: {}", "redact_oplogEntry"_attr = redact(oplogEntry));
     return parsedEntry.getOpTime();
 }
 
 bool BackgroundSync::shouldStopFetching() const {
     // Check if we have been stopped.
     if (getState() != ProducerState::Running) {
-        LOG(2) << "Stopping oplog fetcher due to stop request.";
+        LOGV2_DEBUG(2, "Stopping oplog fetcher due to stop request.");
         return true;
     }
 
diff --git a/src/mongo/db/repl/collection_bulk_loader_impl.cpp b/src/mongo/db/repl/collection_bulk_loader_impl.cpp
index 944776aee8..f0d1341a2f 100644
--- a/src/mongo/db/repl/collection_bulk_loader_impl.cpp
+++ b/src/mongo/db/repl/collection_bulk_loader_impl.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/repl/collection_bulk_loader_impl.h"
 #include "mongo/db/repl/repl_server_parameters_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/destructor_guard.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -212,7 +213,7 @@ Status CollectionBulkLoaderImpl::insertDocuments(const std::vector<BSONObj>::con
 Status CollectionBulkLoaderImpl::commit() {
     return _runTaskReleaseResourcesOnFailure([&] {
         _stats.startBuildingIndexes = Date_t::now();
-        LOG(2) << "Creating indexes for ns: " << _nss.ns();
+        LOGV2_DEBUG(2, "Creating indexes for ns: {}", "_nss_ns"_attr = _nss.ns());
         UnreplicatedWritesBlock uwb(_opCtx.get());
 
         // Commit before deleting dups, so the dups will be removed from secondary indexes when
@@ -309,7 +310,7 @@ Status CollectionBulkLoaderImpl::commit() {
         }
 
         _stats.endBuildingIndexes = Date_t::now();
-        LOG(2) << "Done creating indexes for ns: " << _nss.ns() << ", stats: " << _stats.toString();
+        LOGV2_DEBUG(2, "Done creating indexes for ns: {}, stats: {}", "_nss_ns"_attr = _nss.ns(), "_stats_toString"_attr = _stats.toString());
 
         _releaseResources();
         return Status::OK();
diff --git a/src/mongo/db/repl/collection_cloner.cpp b/src/mongo/db/repl/collection_cloner.cpp
index 6a7a188dc6..3d3332ee83 100644
--- a/src/mongo/db/repl/collection_cloner.cpp
+++ b/src/mongo/db/repl/collection_cloner.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/repl/collection_cloner.h"
 #include "mongo/db/repl/database_cloner_gen.h"
 #include "mongo/db/repl/repl_server_parameters_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -113,9 +114,7 @@ BaseCloner::AfterStageBehavior CollectionCloner::CollectionClonerStage::run() {
     try {
         return ClonerStage<CollectionCloner>::run();
     } catch (const ExceptionFor<ErrorCodes::NamespaceNotFound>&) {
-        log() << "CollectionCloner ns: '" << getCloner()->getSourceNss() << "' uuid: UUID(\""
-              << getCloner()->getSourceUuid()
-              << "\") stopped because collection was dropped on source.";
+        LOGV2("CollectionCloner ns: '{}' uuid: UUID(\"{}\") stopped because collection was dropped on source.", "getCloner_getSourceNss"_attr = getCloner()->getSourceNss(), "getCloner_getSourceUuid"_attr = getCloner()->getSourceUuid());
         getCloner()->waitForDatabaseWorkToComplete();
         return kSkipRemainingStages;
     } catch (const DBException&) {
@@ -200,7 +199,7 @@ void CollectionCloner::handleNextBatch(DBClientCursorBatchIterator& iter) {
             std::string message = str::stream()
                 << "Collection cloning cancelled due to initial sync failure: "
                 << getSharedData()->getInitialSyncStatus(lk).toString();
-            log() << message;
+            LOGV2("{}", "message"_attr = message);
             uasserted(ErrorCodes::CallbackCanceled, message);
         }
     }
@@ -229,9 +228,8 @@ void CollectionCloner::handleNextBatch(DBClientCursorBatchIterator& iter) {
             while (MONGO_unlikely(
                        initialSyncHangCollectionClonerAfterHandlingBatchResponse.shouldFail()) &&
                    !mustExit()) {
-                log() << "initialSyncHangCollectionClonerAfterHandlingBatchResponse fail point "
-                         "enabled for "
-                      << _sourceNss.toString() << ". Blocking until fail point is disabled.";
+                LOGV2("initialSyncHangCollectionClonerAfterHandlingBatchResponse fail point "
+                         "enabled for {}. Blocking until fail point is disabled.", "_sourceNss_toString"_attr = _sourceNss.toString());
                 mongo::sleepsecs(1);
             }
         },
@@ -263,8 +261,8 @@ void CollectionCloner::insertDocumentsCallback(const executor::TaskExecutor::Cal
 
     initialSyncHangDuringCollectionClone.executeIf(
         [&](const BSONObj&) {
-            log() << "initial sync - initialSyncHangDuringCollectionClone fail point "
-                     "enabled. Blocking until fail point is disabled.";
+            LOGV2("initial sync - initialSyncHangDuringCollectionClone fail point "
+                     "enabled. Blocking until fail point is disabled.");
             while (MONGO_unlikely(initialSyncHangDuringCollectionClone.shouldFail()) &&
                    !mustExit()) {
                 mongo::sleepsecs(1);
diff --git a/src/mongo/db/repl/data_replicator_external_state_impl.cpp b/src/mongo/db/repl/data_replicator_external_state_impl.cpp
index 33ea1ea0d1..3cacc8c263 100644
--- a/src/mongo/db/repl/data_replicator_external_state_impl.cpp
+++ b/src/mongo/db/repl/data_replicator_external_state_impl.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/repl/replication_coordinator_external_state.h"
 #include "mongo/db/repl/replication_process.h"
 #include "mongo/db/repl/storage_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -101,16 +102,12 @@ bool DataReplicatorExternalStateImpl::shouldStopFetching(
         // If OplogQueryMetadata was provided, its values were used to determine if we should
         // change sync sources.
         if (oqMetadata) {
-            log() << "Canceling oplog query due to OplogQueryMetadata. We have to choose a new "
-                     "sync source. Current source: "
-                  << source << ", OpTime " << oqMetadata->getLastOpApplied()
-                  << ", its sync source index:" << oqMetadata->getSyncSourceIndex();
+            LOGV2("Canceling oplog query due to OplogQueryMetadata. We have to choose a new "
+                     "sync source. Current source: {}, OpTime {}, its sync source index:{}", "source"_attr = source, "oqMetadata_getLastOpApplied"_attr = oqMetadata->getLastOpApplied(), "oqMetadata_getSyncSourceIndex"_attr = oqMetadata->getSyncSourceIndex());
 
         } else {
-            log() << "Canceling oplog query due to ReplSetMetadata. We have to choose a new sync "
-                     "source. Current source: "
-                  << source << ", OpTime " << replMetadata.getLastOpVisible()
-                  << ", its sync source index:" << replMetadata.getSyncSourceIndex();
+            LOGV2("Canceling oplog query due to ReplSetMetadata. We have to choose a new sync "
+                     "source. Current source: {}, OpTime {}, its sync source index:{}", "source"_attr = source, "replMetadata_getLastOpVisible"_attr = replMetadata.getLastOpVisible(), "replMetadata_getSyncSourceIndex"_attr = replMetadata.getSyncSourceIndex());
         }
         return true;
     }
diff --git a/src/mongo/db/repl/database_cloner.cpp b/src/mongo/db/repl/database_cloner.cpp
index d896ee08d0..a703274afd 100644
--- a/src/mongo/db/repl/database_cloner.cpp
+++ b/src/mongo/db/repl/database_cloner.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/commands/list_collections_filter.h"
 #include "mongo/db/repl/database_cloner.h"
 #include "mongo/db/repl/database_cloner_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -88,10 +89,10 @@ BaseCloner::AfterStageBehavior DatabaseCloner::listCollectionsStage() {
         }
         NamespaceString collectionNamespace(_dbName, result.getName());
         if (collectionNamespace.isSystem() && !collectionNamespace.isLegalClientSystemNS()) {
-            LOG(1) << "Skipping 'system' collection: " << collectionNamespace.ns();
+            LOGV2_DEBUG(1, "Skipping 'system' collection: {}", "collectionNamespace_ns"_attr = collectionNamespace.ns());
             continue;
         }
-        LOG(2) << "Allowing cloning of collectionInfo: " << info;
+        LOGV2_DEBUG(2, "Allowing cloning of collectionInfo: {}", "info"_attr = info);
 
         bool isDuplicate = seen.insert(result.getName().toString()).second;
         uassert(51005,
@@ -137,7 +138,7 @@ void DatabaseCloner::postStage() {
         }
         auto collStatus = _currentCollectionCloner->run();
         if (collStatus.isOK()) {
-            LOG(1) << "collection clone finished: " << sourceNss;
+            LOGV2_DEBUG(1, "collection clone finished: {}", "sourceNss"_attr = sourceNss);
         } else {
             error() << "collection clone for '" << sourceNss << "' failed due to "
                     << collStatus.toString();
diff --git a/src/mongo/db/repl/drop_pending_collection_reaper.cpp b/src/mongo/db/repl/drop_pending_collection_reaper.cpp
index 4c380e4c8c..c68f5973b8 100644
--- a/src/mongo/db/repl/drop_pending_collection_reaper.cpp
+++ b/src/mongo/db/repl/drop_pending_collection_reaper.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/repl/storage_interface.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -144,8 +145,7 @@ bool DropPendingCollectionReaper::rollBackDropPendingCollection(
         _dropPendingNamespaces.erase(it);
     }
 
-    log() << "Rolling back collection drop for " << pendingNss << " with drop OpTime " << opTime
-          << " to namespace " << collectionNamespace;
+    LOGV2("Rolling back collection drop for {} with drop OpTime {} to namespace {}", "pendingNss"_attr = pendingNss, "opTime"_attr = opTime, "collectionNamespace"_attr = collectionNamespace);
 
     return true;
 }
@@ -174,8 +174,7 @@ void DropPendingCollectionReaper::dropCollectionsOlderThan(OperationContext* opC
         for (const auto& opTimeAndNamespace : toDrop) {
             const auto& dropOpTime = opTimeAndNamespace.first;
             const auto& nss = opTimeAndNamespace.second;
-            log() << "Completing collection drop for " << nss << " with drop optime " << dropOpTime
-                  << " (notification optime: " << opTime << ")";
+            LOGV2("Completing collection drop for {} with drop optime {} (notification optime: {})", "nss"_attr = nss, "dropOpTime"_attr = dropOpTime, "opTime"_attr = opTime);
             Status status = Status::OK();
             try {
                 // dropCollection could throw an interrupt exception, since it acquires db locks.
diff --git a/src/mongo/db/repl/idempotency_test.cpp b/src/mongo/db/repl/idempotency_test.cpp
index 4eacc99fb5..ecaacdd3a0 100644
--- a/src/mongo/db/repl/idempotency_test.cpp
+++ b/src/mongo/db/repl/idempotency_test.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/repl/idempotency_update_sequence.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 
 namespace mongo {
@@ -114,7 +115,7 @@ std::vector<OplogEntry> RandomizedIdempotencyTest::createUpdateSequence(
 std::string RandomizedIdempotencyTest::getStatesString(const std::vector<CollectionState>& state1,
                                                        const std::vector<CollectionState>& state2,
                                                        const std::vector<OplogEntry>& ops) {
-    unittest::log() << IdempotencyTest::getStatesString(state1, state2, ops);
+    unittest::LOGV2("{}", "IdempotencyTest_getStatesString_state1_state2_ops"_attr = IdempotencyTest::getStatesString(state1, state2, ops));
     StringBuilder sb;
     sb << "Ran update ops: ";
     sb << "[ ";
diff --git a/src/mongo/db/repl/initial_syncer.cpp b/src/mongo/db/repl/initial_syncer.cpp
index ef848d9dac..5f3cafdc2e 100644
--- a/src/mongo/db/repl/initial_syncer.cpp
+++ b/src/mongo/db/repl/initial_syncer.cpp
@@ -63,6 +63,7 @@
 #include "mongo/db/session_txn_record_gen.h"
 #include "mongo/executor/task_executor.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/destructor_guard.h"
@@ -173,13 +174,13 @@ void pauseAtInitialSyncFuzzerSyncronizationPoints(std::string msg) {
     // Set and unset by the InitialSyncTest fixture to cause initial sync to pause so that the
     // Initial Sync Fuzzer can run commands on the sync source.
     if (MONGO_unlikely(initialSyncFuzzerSynchronizationPoint1.shouldFail())) {
-        log() << msg;
-        log() << "initialSyncFuzzerSynchronizationPoint1 fail point enabled.";
+        LOGV2("{}", "msg"_attr = msg);
+        LOGV2("initialSyncFuzzerSynchronizationPoint1 fail point enabled.");
         initialSyncFuzzerSynchronizationPoint1.pauseWhileSet();
     }
 
     if (MONGO_unlikely(initialSyncFuzzerSynchronizationPoint2.shouldFail())) {
-        log() << "initialSyncFuzzerSynchronizationPoint2 fail point enabled.";
+        LOGV2("initialSyncFuzzerSynchronizationPoint2 fail point enabled.");
         initialSyncFuzzerSynchronizationPoint2.pauseWhileSet();
     }
 }
@@ -406,7 +407,7 @@ BSONObj InitialSyncer::_getInitialSyncProgress_inlock() const {
         }
         return bob.obj();
     } catch (const DBException& e) {
-        log() << "Error creating initial sync progress object: " << e.toString();
+        LOGV2("Error creating initial sync progress object: {}", "e_toString"_attr = e.toString());
     }
     BSONObjBuilder bob;
     _appendInitialSyncProgressMinimal_inlock(&bob);
@@ -434,7 +435,7 @@ void InitialSyncer::_setUp_inlock(OperationContext* opCtx, std::uint32_t initial
     _storage->setInitialDataTimestamp(serviceCtx, Timestamp::kAllowUnstableCheckpointsSentinel);
     _storage->setStableTimestamp(serviceCtx, Timestamp::min());
 
-    LOG(1) << "Creating oplogBuffer.";
+    LOGV2_DEBUG(1, "Creating oplogBuffer.");
     _oplogBuffer = _dataReplicatorExternalState->makeInitialSyncOplogBuffer(opCtx);
     _oplogBuffer->startup(opCtx);
 
@@ -500,8 +501,7 @@ void InitialSyncer::_startInitialSyncAttemptCallback(
         return;
     }
 
-    log() << "Starting initial sync (attempt " << (initialSyncAttempt + 1) << " of "
-          << initialSyncMaxAttempts << ")";
+    LOGV2("Starting initial sync (attempt {} of {})", "initialSyncAttempt_1"_attr = (initialSyncAttempt + 1), "initialSyncMaxAttempts"_attr = initialSyncMaxAttempts);
 
     // This completion guard invokes _finishInitialSyncAttempt on destruction.
     auto cancelRemainingWorkInLock = [this]() { _cancelRemainingWork_inlock(); };
@@ -517,15 +517,15 @@ void InitialSyncer::_startInitialSyncAttemptCallback(
 
     _oplogApplier = {};
 
-    LOG(2) << "Resetting sync source so a new one can be chosen for this initial sync attempt.";
+    LOGV2_DEBUG(2, "Resetting sync source so a new one can be chosen for this initial sync attempt.");
     _syncSource = HostAndPort();
 
-    LOG(2) << "Resetting all optimes before starting this initial sync attempt.";
+    LOGV2_DEBUG(2, "Resetting all optimes before starting this initial sync attempt.");
     _opts.resetOptimes();
     _lastApplied = {OpTime(), Date_t()};
     _lastFetched = {};
 
-    LOG(2) << "Resetting the oldest timestamp before starting this initial sync attempt.";
+    LOGV2_DEBUG(2, "Resetting the oldest timestamp before starting this initial sync attempt.");
     auto storageEngine = getGlobalServiceContext()->getStorageEngine();
     if (storageEngine) {
         // Set the oldestTimestamp to one because WiredTiger does not allow us to set it to zero
@@ -535,9 +535,9 @@ void InitialSyncer::_startInitialSyncAttemptCallback(
         storageEngine->setOldestTimestamp(kTimestampOne);
     }
 
-    LOG(2) << "Resetting feature compatibility version to last-stable. If the sync source is in "
+    LOGV2_DEBUG(2, "Resetting feature compatibility version to last-stable. If the sync source is in "
               "latest feature compatibility version, we will find out when we clone the "
-              "server configuration collection (admin.system.version).";
+              "server configuration collection (admin.system.version).");
     serverGlobalParams.featureCompatibility.reset();
 
     // Clear the oplog buffer.
@@ -596,9 +596,7 @@ void InitialSyncer::_chooseSyncSourceCallback(
         }
 
         auto when = _exec->now() + _opts.syncSourceRetryWait;
-        LOG(1) << "Error getting sync source: '" << syncSource.getStatus() << "', trying again in "
-               << _opts.syncSourceRetryWait << " at " << when.toString() << ". Attempt "
-               << (chooseSyncSourceAttempt + 1) << " of " << numInitialSyncConnectAttempts.load();
+        LOGV2_DEBUG(1, "Error getting sync source: '{}', trying again in {} at {}. Attempt {} of {}", "syncSource_getStatus"_attr = syncSource.getStatus(), "_opts_syncSourceRetryWait"_attr = _opts.syncSourceRetryWait, "when_toString"_attr = when.toString(), "chooseSyncSourceAttempt_1"_attr = (chooseSyncSourceAttempt + 1), "numInitialSyncConnectAttempts_load"_attr = numInitialSyncConnectAttempts.load());
         auto status = _scheduleWorkAtAndSaveHandle_inlock(
             when,
             [=](const executor::TaskExecutor::CallbackArgs& args) {
@@ -618,8 +616,8 @@ void InitialSyncer::_chooseSyncSourceCallback(
 
     if (MONGO_unlikely(initialSyncHangBeforeCreatingOplog.shouldFail())) {
         // This log output is used in js tests so please leave it.
-        log() << "initial sync - initialSyncHangBeforeCreatingOplog fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("initial sync - initialSyncHangBeforeCreatingOplog fail point "
+                 "enabled. Blocking until fail point is disabled.");
         lock.unlock();
         while (MONGO_unlikely(initialSyncHangBeforeCreatingOplog.shouldFail()) &&
                !_isShuttingDown()) {
@@ -654,8 +652,7 @@ void InitialSyncer::_chooseSyncSourceCallback(
 
 Status InitialSyncer::_truncateOplogAndDropReplicatedDatabases() {
     // truncate oplog; drop user databases.
-    LOG(1) << "About to truncate the oplog, if it exists, ns:" << _opts.localOplogNS
-           << ", and drop all user databases (so that we can clone them).";
+    LOGV2_DEBUG(1, "About to truncate the oplog, if it exists, ns:{}, and drop all user databases (so that we can clone them).", "_opts_localOplogNS"_attr = _opts.localOplogNS);
 
     auto opCtx = makeOpCtx();
 
@@ -663,13 +660,13 @@ Status InitialSyncer::_truncateOplogAndDropReplicatedDatabases() {
     UnreplicatedWritesBlock unreplicatedWritesBlock(opCtx.get());
 
     // 1.) Truncate the oplog.
-    LOG(2) << "Truncating the existing oplog: " << _opts.localOplogNS;
+    LOGV2_DEBUG(2, "Truncating the existing oplog: {}", "_opts_localOplogNS"_attr = _opts.localOplogNS);
     Timer timer;
     auto status = _storage->truncateCollection(opCtx.get(), _opts.localOplogNS);
-    log() << "Initial syncer oplog truncation finished in: " << timer.millis() << "ms";
+    LOGV2("Initial syncer oplog truncation finished in: {}ms", "timer_millis"_attr = timer.millis());
     if (!status.isOK()) {
         // 1a.) Create the oplog.
-        LOG(2) << "Creating the oplog: " << _opts.localOplogNS;
+        LOGV2_DEBUG(2, "Creating the oplog: {}", "_opts_localOplogNS"_attr = _opts.localOplogNS);
         status = _storage->createOplog(opCtx.get(), _opts.localOplogNS);
         if (!status.isOK()) {
             return status;
@@ -677,7 +674,7 @@ Status InitialSyncer::_truncateOplogAndDropReplicatedDatabases() {
     }
 
     // 2.) Drop user databases.
-    LOG(2) << "Dropping user databases";
+    LOGV2_DEBUG(2, "Dropping user databases");
     return _storage->dropReplicatedDatabases(opCtx.get());
 }
 
@@ -830,7 +827,7 @@ void InitialSyncer::_getBeginFetchingOpTimeCallback(
     pauseAtInitialSyncFuzzerSyncronizationPoints(logMsg);
 
     if (MONGO_unlikely(initialSyncHangAfterGettingBeginFetchingTimestamp.shouldFail())) {
-        log() << "initialSyncHangAfterGettingBeginFetchingTimestamp fail point enabled.";
+        LOGV2("initialSyncHangAfterGettingBeginFetchingTimestamp fail point enabled.");
         initialSyncHangAfterGettingBeginFetchingTimestamp.pauseWhileSet();
     }
 
@@ -994,10 +991,7 @@ void InitialSyncer::_fcvFetcherCallback(const StatusWith<Fetcher::QueryResponse>
                             << _initialSyncState->beginFetchingTimestamp.toBSON());
 
     invariant(!result.getValue().documents.empty());
-    LOG(2) << "Setting begin applying timestamp to " << _initialSyncState->beginApplyingTimestamp
-           << " using last oplog entry: " << redact(result.getValue().documents.front())
-           << ", ns: " << _opts.localOplogNS << " and the begin fetching timestamp to "
-           << _initialSyncState->beginFetchingTimestamp;
+    LOGV2_DEBUG(2, "Setting begin applying timestamp to {} using last oplog entry: {}, ns: {} and the begin fetching timestamp to {}", "_initialSyncState_beginApplyingTimestamp"_attr = _initialSyncState->beginApplyingTimestamp, "redact_result_getValue_documents_front"_attr = redact(result.getValue().documents.front()), "_opts_localOplogNS"_attr = _opts.localOplogNS, "_initialSyncState_beginFetchingTimestamp"_attr = _initialSyncState->beginFetchingTimestamp);
 
     const auto configResult = _dataReplicatorExternalState->getCurrentConfig();
     status = configResult.getStatus();
@@ -1027,7 +1021,7 @@ void InitialSyncer::_fcvFetcherCallback(const StatusWith<Fetcher::QueryResponse>
         initialSyncOplogFetcherBatchSize,
         OplogFetcher::StartingPoint::kEnqueueFirstDoc);
 
-    LOG(2) << "Starting OplogFetcher: " << _oplogFetcher->toString();
+    LOGV2_DEBUG(2, "Starting OplogFetcher: {}", "_oplogFetcher_toString"_attr = _oplogFetcher->toString());
 
     // _startupComponent_inlock is shutdown-aware.
     status = _startupComponent_inlock(_oplogFetcher);
@@ -1042,8 +1036,8 @@ void InitialSyncer::_fcvFetcherCallback(const StatusWith<Fetcher::QueryResponse>
         // This could have been done with a scheduleWorkAt but this is used only by JS tests where
         // we run with multiple threads so it's fine to spin on this thread.
         // This log output is used in js tests so please leave it.
-        log() << "initial sync - initialSyncHangBeforeCopyingDatabases fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("initial sync - initialSyncHangBeforeCopyingDatabases fail point "
+                 "enabled. Blocking until fail point is disabled.");
         while (MONGO_unlikely(initialSyncHangBeforeCopyingDatabases.shouldFail()) &&
                !_isShuttingDown()) {
             mongo::sleepsecs(1);
@@ -1051,7 +1045,7 @@ void InitialSyncer::_fcvFetcherCallback(const StatusWith<Fetcher::QueryResponse>
         lock.lock();
     }
 
-    LOG(2) << "Starting AllDatabaseCloner: " << _initialSyncState->allDatabaseCloner->toString();
+    LOGV2_DEBUG(2, "Starting AllDatabaseCloner: {}", "_initialSyncState_allDatabaseCloner_toString"_attr = _initialSyncState->allDatabaseCloner->toString());
 
     _initialSyncState->allDatabaseClonerFuture =
         _initialSyncState->allDatabaseCloner->runOnExecutor(_clonerExec)
@@ -1087,8 +1081,7 @@ void InitialSyncer::_fcvFetcherCallback(const StatusWith<Fetcher::QueryResponse>
 void InitialSyncer::_oplogFetcherCallback(const Status& oplogFetcherFinishStatus,
                                           std::shared_ptr<OnCompletionGuard> onCompletionGuard) {
     stdx::lock_guard<Latch> lock(_mutex);
-    log() << "Finished fetching oplog during initial sync: " << redact(oplogFetcherFinishStatus)
-          << ". Last fetched optime: " << _lastFetched.toString();
+    LOGV2("Finished fetching oplog during initial sync: {}. Last fetched optime: {}", "redact_oplogFetcherFinishStatus"_attr = redact(oplogFetcherFinishStatus), "_lastFetched_toString"_attr = _lastFetched.toString());
 
     auto status = _checkForShutdownAndConvertStatus_inlock(
         oplogFetcherFinishStatus, "error fetching oplog during initial sync");
@@ -1103,8 +1096,7 @@ void InitialSyncer::_oplogFetcherCallback(const Status& oplogFetcherFinishStatus
     // an OK status is when the 'stopReplProducer' fail point is enabled, which causes the
     // OplogFetcher to ignore the current sync source response and return early.
     if (status.isOK()) {
-        log() << "Finished fetching oplog fetching early. Last fetched optime: "
-              << _lastFetched.toString();
+        LOGV2("Finished fetching oplog fetching early. Last fetched optime: {}", "_lastFetched_toString"_attr = _lastFetched.toString());
         return;
     }
 
@@ -1120,16 +1112,15 @@ void InitialSyncer::_oplogFetcherCallback(const Status& oplogFetcherFinishStatus
 void InitialSyncer::_allDatabaseClonerCallback(
     const Status& databaseClonerFinishStatus,
     std::shared_ptr<OnCompletionGuard> onCompletionGuard) {
-    log() << "Finished cloning data: " << redact(databaseClonerFinishStatus)
-          << ". Beginning oplog replay.";
+    LOGV2("Finished cloning data: {}. Beginning oplog replay.", "redact_databaseClonerFinishStatus"_attr = redact(databaseClonerFinishStatus));
     _client->shutdownAndDisallowReconnect();
 
     if (MONGO_unlikely(initialSyncHangAfterDataCloning.shouldFail())) {
         // This could have been done with a scheduleWorkAt but this is used only by JS tests where
         // we run with multiple threads so it's fine to spin on this thread.
         // This log output is used in js tests so please leave it.
-        log() << "initial sync - initialSyncHangAfterDataCloning fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("initial sync - initialSyncHangAfterDataCloning fail point "
+                 "enabled. Blocking until fail point is disabled.");
         while (MONGO_unlikely(initialSyncHangAfterDataCloning.shouldFail()) && !_isShuttingDown()) {
             mongo::sleepsecs(1);
         }
@@ -1195,7 +1186,7 @@ void InitialSyncer::_lastOplogEntryFetcherCallbackForStopTimestamp(
         const auto& documents = result.getValue().documents;
         invariant(!documents.empty());
         const BSONObj oplogSeedDoc = documents.front();
-        LOG(2) << "Inserting oplog seed document: " << oplogSeedDoc;
+        LOGV2_DEBUG(2, "Inserting oplog seed document: {}", "oplogSeedDoc"_attr = oplogSeedDoc);
 
         auto opCtx = makeOpCtx();
         // StorageInterface::insertDocument() has to be called outside the lock because we may
@@ -1219,8 +1210,7 @@ void InitialSyncer::_lastOplogEntryFetcherCallbackForStopTimestamp(
 
     stdx::lock_guard<Latch> lock(_mutex);
     _lastApplied = resultOpTimeAndWallTime;
-    log() << "No need to apply operations. (currently at "
-          << _initialSyncState->stopTimestamp.toBSON() << ")";
+    LOGV2("No need to apply operations. (currently at {})", "_initialSyncState_stopTimestamp_toBSON"_attr = _initialSyncState->stopTimestamp.toBSON());
 
     // This sets the error in 'onCompletionGuard' and shuts down the OplogFetcher on error.
     _scheduleRollbackCheckerCheckForRollback_inlock(lock, onCompletionGuard);
@@ -1250,8 +1240,7 @@ void InitialSyncer::_getNextApplierBatchCallback(
     pauseAtInitialSyncFuzzerSyncronizationPoints(logMsg);
 
     if (MONGO_unlikely(failInitialSyncBeforeApplyingBatch.shouldFail())) {
-        log() << "initial sync - failInitialSyncBeforeApplyingBatch fail point enabled. Pausing"
-              << "until fail point is disabled, then will fail initial sync.";
+        LOGV2("initial sync - failInitialSyncBeforeApplyingBatch fail point enabled. Pausinguntil fail point is disabled, then will fail initial sync.");
         failInitialSyncBeforeApplyingBatch.pauseWhileSet();
         status = Status(ErrorCodes::CallbackCanceled,
                         "failInitialSyncBeforeApplyingBatch fail point enabled");
@@ -1295,7 +1284,7 @@ void InitialSyncer::_getNextApplierBatchCallback(
                "in the oplog buffer. Aborting this initial sync attempt. Last applied: "
             << _lastApplied.opTime.toString() << ". Last fetched: " << _lastFetched.toString()
             << ". Number of operations applied: " << _initialSyncState->appliedOps;
-        log() << msg;
+        LOGV2("{}", "msg"_attr = msg);
         status = Status(ErrorCodes::RemoteResultsUnavailable, msg);
         onCompletionGuard->setResultAndCancelRemainingWork_inlock(lock, status);
         return;
@@ -1327,7 +1316,7 @@ void InitialSyncer::_multiApplierCallback(const Status& multiApplierStatus,
     // Set to cause initial sync to fassert instead of restart if applying a batch fails, so that
     // tests can be robust to network errors but not oplog idempotency errors.
     if (MONGO_unlikely(initialSyncFassertIfApplyingBatchFails.shouldFail())) {
-        log() << "initialSyncFassertIfApplyingBatchFails fail point enabled.";
+        LOGV2("initialSyncFassertIfApplyingBatchFails fail point enabled.");
         fassert(31210, status);
     }
 
@@ -1361,7 +1350,7 @@ void InitialSyncer::_rollbackCheckerCheckForRollbackCallback(
     auto status = _checkForShutdownAndConvertStatus_inlock(result.getStatus(),
                                                            "error while getting last rollback ID");
     if (_shouldRetryNetworkError(lock, status)) {
-        LOG(1) << "Retrying rollback checker because of network error " << status;
+        LOGV2_DEBUG(1, "Retrying rollback checker because of network error {}", "status"_attr = status);
         _scheduleRollbackCheckerCheckForRollback_inlock(lock, onCompletionGuard);
         return;
     }
@@ -1412,17 +1401,17 @@ void InitialSyncer::_finishInitialSyncAttempt(const StatusWith<OpTimeAndWallTime
         }
     });
 
-    log() << "Initial sync attempt finishing up.";
+    LOGV2("Initial sync attempt finishing up.");
 
     stdx::lock_guard<Latch> lock(_mutex);
-    log() << "Initial Sync Attempt Statistics: " << redact(_getInitialSyncProgress_inlock());
+    LOGV2("Initial Sync Attempt Statistics: {}", "redact__getInitialSyncProgress_inlock"_attr = redact(_getInitialSyncProgress_inlock()));
 
     auto runTime = _initialSyncState ? _initialSyncState->timer.millis() : 0;
     _stats.initialSyncAttemptInfos.emplace_back(
         InitialSyncer::InitialSyncAttemptInfo{runTime, result.getStatus(), _syncSource});
 
     if (MONGO_unlikely(failAndHangInitialSync.shouldFail())) {
-        log() << "failAndHangInitialSync fail point enabled.";
+        LOGV2("failAndHangInitialSync fail point enabled.");
         failAndHangInitialSync.pauseWhileSet();
         result = Status(ErrorCodes::InternalError, "failAndHangInitialSync fail point enabled");
     }
@@ -1497,8 +1486,8 @@ void InitialSyncer::_finishCallback(StatusWith<OpTimeAndWallTime> lastApplied) {
 
     if (MONGO_unlikely(initialSyncHangBeforeFinish.shouldFail())) {
         // This log output is used in js tests so please leave it.
-        log() << "initial sync - initialSyncHangBeforeFinish fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("initial sync - initialSyncHangBeforeFinish fail point "
+                 "enabled. Blocking until fail point is disabled.");
         while (MONGO_unlikely(initialSyncHangBeforeFinish.shouldFail()) && !_isShuttingDown()) {
             mongo::sleepsecs(1);
         }
@@ -1580,11 +1569,7 @@ void InitialSyncer::_checkApplierProgressAndScheduleGetNextApplierBatch_inlock(
     if (_lastApplied.opTime.isNull()) {
         // Check if any ops occurred while cloning or any ops need to be fetched.
         invariant(_initialSyncState->beginFetchingTimestamp < _initialSyncState->stopTimestamp);
-        log() << "Writing to the oplog and applying operations until "
-              << _initialSyncState->stopTimestamp.toBSON()
-              << " before initial sync can complete. (started fetching at "
-              << _initialSyncState->beginFetchingTimestamp.toBSON() << " and applying at "
-              << _initialSyncState->beginApplyingTimestamp.toBSON() << ")";
+        LOGV2("Writing to the oplog and applying operations until {} before initial sync can complete. (started fetching at {} and applying at {})", "_initialSyncState_stopTimestamp_toBSON"_attr = _initialSyncState->stopTimestamp.toBSON(), "_initialSyncState_beginFetchingTimestamp_toBSON"_attr = _initialSyncState->beginFetchingTimestamp.toBSON(), "_initialSyncState_beginApplyingTimestamp_toBSON"_attr = _initialSyncState->beginApplyingTimestamp.toBSON());
         // Fall through to scheduling _getNextApplierBatchCallback().
     } else if (_lastApplied.opTime.getTimestamp() >= _initialSyncState->stopTimestamp) {
         // Check for rollback if we have applied far enough to be consistent.
diff --git a/src/mongo/db/repl/initial_syncer_test.cpp b/src/mongo/db/repl/initial_syncer_test.cpp
index 1d8a360c94..2fd4aaa89c 100644
--- a/src/mongo/db/repl/initial_syncer_test.cpp
+++ b/src/mongo/db/repl/initial_syncer_test.cpp
@@ -68,6 +68,7 @@
 #include "mongo/util/scopeguard.h"
 #include "mongo/util/str.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/barrier.h"
 #include "mongo/unittest/unittest.h"
 
@@ -164,7 +165,7 @@ public:
     void scheduleNetworkResponse(std::string cmdName, const BSONObj& obj) {
         NetworkInterfaceMock* net = getNet();
         if (!net->hasReadyRequests()) {
-            log() << "The network doesn't have a request to process for this response: " << obj;
+            LOGV2("The network doesn't have a request to process for this response: {}", "obj"_attr = obj);
         }
         verifyNextRequestCommandName(cmdName);
         scheduleNetworkResponse(net->getNextReadyRequest(), obj);
@@ -175,9 +176,9 @@ public:
         NetworkInterfaceMock* net = getNet();
         Milliseconds millis(0);
         RemoteCommandResponse response(obj, millis);
-        log() << "Sending response for network request:";
-        log() << "     req: " << noi->getRequest().dbname << "." << noi->getRequest().cmdObj;
-        log() << "     resp:" << response;
+        LOGV2("Sending response for network request:");
+        LOGV2("     req: {}.{}", "noi_getRequest_dbname"_attr = noi->getRequest().dbname, "noi_getRequest_cmdObj"_attr = noi->getRequest().cmdObj);
+        LOGV2("     resp:{}", "response"_attr = response);
 
         net->scheduleResponse(noi, net->now(), response);
     }
@@ -185,7 +186,7 @@ public:
     void scheduleNetworkResponse(std::string cmdName, Status errorStatus) {
         NetworkInterfaceMock* net = getNet();
         if (!getNet()->hasReadyRequests()) {
-            log() << "The network doesn't have a request to process for the error: " << errorStatus;
+            LOGV2("The network doesn't have a request to process for the error: {}", "errorStatus"_attr = errorStatus);
         }
         verifyNextRequestCommandName(cmdName);
         net->scheduleResponse(net->getNextReadyRequest(), net->now(), errorStatus);
@@ -223,9 +224,9 @@ public:
     void finishProcessingNetworkResponse() {
         getNet()->runReadyNetworkOperations();
         if (getNet()->hasReadyRequests()) {
-            log() << "The network has unexpected requests to process, next req:";
+            LOGV2("The network has unexpected requests to process, next req:");
             const NetworkInterfaceMock::NetworkOperation& req = *getNet()->getNextReadyRequest();
-            log() << req.getDiagnosticString();
+            LOGV2("{}", "req_getDiagnosticString"_attr = req.getDiagnosticString());
         }
         ASSERT_FALSE(getNet()->hasReadyRequests());
     }
@@ -309,7 +310,7 @@ protected:
             // Get collection info from map.
             const auto collInfo = &_collections[nss];
             if (collInfo->stats->initCalled) {
-                log() << "reusing collection during test which may cause problems, ns:" << nss;
+                LOGV2("reusing collection during test which may cause problems, ns:{}", "nss"_attr = nss);
             }
             auto localLoader = std::make_unique<CollectionBulkLoaderMock>(collInfo->stats);
             auto status = localLoader->init(secondaryIndexSpecs);
@@ -862,8 +863,7 @@ TEST_F(InitialSyncerTest,
 
     // Check number of failed attempts in stats.
     auto progress = initialSyncer->getInitialSyncProgress();
-    unittest::log() << "Progress after " << initialSyncMaxAttempts
-                    << " failed attempts: " << progress;
+    unittest::LOGV2("Progress after {} failed attempts: {}", "initialSyncMaxAttempts"_attr = initialSyncMaxAttempts, "progress"_attr = progress);
     ASSERT_EQUALS(progress.getIntField("failedInitialSyncAttempts"), int(initialSyncMaxAttempts))
         << progress;
     ASSERT_EQUALS(progress.getIntField("maxFailedInitialSyncAttempts"), int(initialSyncMaxAttempts))
@@ -4336,10 +4336,10 @@ TEST_F(InitialSyncerTest, GetInitialSyncProgressReturnsCorrectProgress) {
             net->runReadyNetworkOperations();
         }
 
-        log() << "Done playing first failed response";
+        LOGV2("Done playing first failed response");
 
         auto progress = initialSyncer->getInitialSyncProgress();
-        log() << "Progress after first failed response: " << progress;
+        LOGV2("Progress after first failed response: {}", "progress"_attr = progress);
         ASSERT_EQUALS(progress.nFields(), 7) << progress;
         ASSERT_EQUALS(progress.getIntField("failedInitialSyncAttempts"), 0) << progress;
         ASSERT_EQUALS(progress.getIntField("maxFailedInitialSyncAttempts"), 2) << progress;
@@ -4357,7 +4357,7 @@ TEST_F(InitialSyncerTest, GetInitialSyncProgressReturnsCorrectProgress) {
 
     getInitialSyncer().waitForCloner_forTest();
 
-    log() << "Done playing failed responses";
+    LOGV2("Done playing failed responses");
 
     {
         FailPointEnableBlock clonerFailpoint("hangBeforeClonerStage", kListDatabasesFailPointData);
@@ -4391,10 +4391,10 @@ TEST_F(InitialSyncerTest, GetInitialSyncProgressReturnsCorrectProgress) {
             processSuccessfulFCVFetcherResponseLastStable();
         }
 
-        log() << "Done playing first successful response";
+        LOGV2("Done playing first successful response");
 
         auto progress = initialSyncer->getInitialSyncProgress();
-        log() << "Progress after failure: " << progress;
+        LOGV2("Progress after failure: {}", "progress"_attr = progress);
         ASSERT_EQUALS(progress.nFields(), 7) << progress;
         ASSERT_EQUALS(progress.getIntField("failedInitialSyncAttempts"), 1) << progress;
         ASSERT_EQUALS(progress.getIntField("maxFailedInitialSyncAttempts"), 2) << progress;
@@ -4492,10 +4492,10 @@ TEST_F(InitialSyncerTest, GetInitialSyncProgressReturnsCorrectProgress) {
         // applying the first batch.
         processSuccessfulLastOplogEntryFetcherResponse({makeOplogEntryObj(7)});
     }
-    log() << "Done playing all but last successful response";
+    LOGV2("Done playing all but last successful response");
 
     auto progress = initialSyncer->getInitialSyncProgress();
-    log() << "Progress after all but last successful response: " << progress;
+    LOGV2("Progress after all but last successful response: {}", "progress"_attr = progress);
     ASSERT_EQUALS(progress.nFields(), 8) << progress;
     ASSERT_EQUALS(progress.getIntField("failedInitialSyncAttempts"), 1) << progress;
     ASSERT_EQUALS(progress.getIntField("maxFailedInitialSyncAttempts"), 2) << progress;
@@ -4550,7 +4550,7 @@ TEST_F(InitialSyncerTest, GetInitialSyncProgressReturnsCorrectProgress) {
         net->runReadyNetworkOperations();
     }
 
-    log() << "waiting for initial sync to verify it completed OK";
+    LOGV2("waiting for initial sync to verify it completed OK");
     initialSyncer->join();
     ASSERT_OK(_lastApplied.getStatus());
     auto dummyEntry = makeOplogEntry(7);
@@ -4558,7 +4558,7 @@ TEST_F(InitialSyncerTest, GetInitialSyncProgressReturnsCorrectProgress) {
     ASSERT_EQUALS(dummyEntry.getWallClockTime(), _lastApplied.getValue().wallTime);
 
     progress = initialSyncer->getInitialSyncProgress();
-    log() << "Progress at end: " << progress;
+    LOGV2("Progress at end: {}", "progress"_attr = progress);
     ASSERT_EQUALS(progress.nFields(), 10) << progress;
     ASSERT_EQUALS(progress.getIntField("failedInitialSyncAttempts"), 1) << progress;
     ASSERT_EQUALS(progress.getIntField("maxFailedInitialSyncAttempts"), 2) << progress;
diff --git a/src/mongo/db/repl/insert_group.cpp b/src/mongo/db/repl/insert_group.cpp
index 24acf95b0d..7297fc6373 100644
--- a/src/mongo/db/repl/insert_group.cpp
+++ b/src/mongo/db/repl/insert_group.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/ops/write_ops.h"
 #include "mongo/db/repl/oplog_applier_impl.h"
 #include "mongo/db/repl/oplog_entry.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -139,7 +140,7 @@ StatusWith<InsertGroup::ConstIterator> InsertGroup::groupAndApplyInserts(ConstIt
 
         // It's not an error during initial sync to encounter DuplicateKey errors.
         if (Mode::kInitialSync == _mode && ErrorCodes::DuplicateKey == status) {
-            LOG(2) << status;
+            LOGV2_DEBUG(2, "{}", "status"_attr = status);
         } else {
             error() << status;
         }
diff --git a/src/mongo/db/repl/isself.cpp b/src/mongo/db/repl/isself.cpp
index b50a893efb..422f3bac51 100644
--- a/src/mongo/db/repl/isself.cpp
+++ b/src/mongo/db/repl/isself.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/auth/privilege.h"
 #include "mongo/db/commands.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/socket_utils.h"
 #include "mongo/util/scopeguard.h"
@@ -147,7 +148,7 @@ std::vector<std::string> getAddrsForHost(const std::string& iporhost,
         for (std::vector<std::string>::const_iterator o = out.begin(); o != out.end(); ++o) {
             builder << " [ " << *o << "]";
         }
-        LOG(2) << builder.str();
+        LOGV2_DEBUG(2, "{}", "builder_str"_attr = builder.str());
     }
 
     return out;
@@ -336,7 +337,7 @@ std::vector<std::string> getBoundAddrs(const bool ipv6enabled) {
         for (std::vector<std::string>::const_iterator o = out.begin(); o != out.end(); ++o) {
             builder << " [ " << *o << "]";
         }
-        LOG(2) << builder.str();
+        LOGV2_DEBUG(2, "{}", "builder_str"_attr = builder.str());
     }
     return out;
 }
diff --git a/src/mongo/db/repl/member_data.cpp b/src/mongo/db/repl/member_data.cpp
index 571e83d3a1..3a1338660c 100644
--- a/src/mongo/db/repl/member_data.cpp
+++ b/src/mongo/db/repl/member_data.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/repl/member_data.h"
 #include "mongo/db/repl/rslog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -69,8 +70,7 @@ bool MemberData::setUpValues(Date_t now, ReplSetHeartbeatResponse&& hbResponse)
     }
     // Log if the state changes
     if (_lastResponse.getState() != hbResponse.getState()) {
-        log() << "Member " << _hostAndPort.toString() << " is now in state "
-              << hbResponse.getState().toString() << rsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kRS}, "Member {} is now in state {}", "_hostAndPort_toString"_attr = _hostAndPort.toString(), "hbResponse_getState_toString"_attr = hbResponse.getState().toString());
     }
 
     bool opTimeAdvanced =
@@ -93,8 +93,7 @@ void MemberData::setDownValues(Date_t now, const std::string& heartbeatMessage)
     _lastHeartbeatMessage = heartbeatMessage;
 
     if (_lastResponse.getState() != MemberState::RS_DOWN) {
-        log() << "Member " << _hostAndPort.toString() << " is now in state RS_DOWN - "
-              << redact(heartbeatMessage) << rsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kRS}, "Member {} is now in state RS_DOWN - {}", "_hostAndPort_toString"_attr = _hostAndPort.toString(), "redact_heartbeatMessage"_attr = redact(heartbeatMessage));
     }
 
     _lastResponse = ReplSetHeartbeatResponse();
@@ -116,8 +115,7 @@ void MemberData::setAuthIssue(Date_t now) {
     _lastHeartbeatMessage.clear();
 
     if (_lastResponse.getState() != MemberState::RS_UNKNOWN) {
-        log() << "Member " << _hostAndPort.toString()
-              << " is now in state RS_UNKNOWN due to authentication issue." << rsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kRS}, "Member {} is now in state RS_UNKNOWN due to authentication issue.", "_hostAndPort_toString"_attr = _hostAndPort.toString());
     }
 
     _lastResponse = ReplSetHeartbeatResponse();
@@ -142,12 +140,8 @@ void MemberData::setLastDurableOpTimeAndWallTime(OpTimeAndWallTime opTime, Date_
     if (_lastAppliedOpTime < opTime.opTime) {
         // TODO(russotto): We think this should never happen, rollback or no rollback.  Make this an
         // invariant and see what happens.
-        log() << "Durable progress (" << opTime.opTime << ") is ahead of the applied progress ("
-              << _lastAppliedOpTime
-              << ". This is likely due to a "
-                 "rollback."
-              << " memberid: " << _memberId << _hostAndPort.toString()
-              << " previous durable progress: " << _lastDurableOpTime;
+        LOGV2("Durable progress ({}) is ahead of the applied progress ({}. This is likely due to a "
+                 "rollback. memberid: {}{} previous durable progress: {}", "opTime_opTime"_attr = opTime.opTime, "_lastAppliedOpTime"_attr = _lastAppliedOpTime, "_memberId"_attr = _memberId, "_hostAndPort_toString"_attr = _hostAndPort.toString(), "_lastDurableOpTime"_attr = _lastDurableOpTime);
     } else {
         _lastDurableOpTime = opTime.opTime;
         _lastDurableWallTime = opTime.wallTime;
diff --git a/src/mongo/db/repl/noop_writer.cpp b/src/mongo/db/repl/noop_writer.cpp
index 29ee8017bf..7a53281058 100644
--- a/src/mongo/db/repl/noop_writer.cpp
+++ b/src/mongo/db/repl/noop_writer.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/repl/noop_writer.h"
 #include "mongo/db/repl/oplog.h"
 #include "mongo/db/repl/repl_server_parameters_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/log.h"
 
@@ -150,14 +151,14 @@ void NoopWriter::_writeNoop(OperationContext* opCtx) {
     Lock::GlobalLock lock(
         opCtx, MODE_IX, Date_t::now() + Milliseconds(1), Lock::InterruptBehavior::kLeaveUnlocked);
     if (!lock.isLocked()) {
-        LOG(1) << "Global lock is not available skipping noopWrite";
+        LOGV2_DEBUG(1, "Global lock is not available skipping noopWrite");
         return;
     }
 
     auto replCoord = ReplicationCoordinator::get(opCtx);
     // Its a proxy for being a primary
     if (!replCoord->canAcceptWritesForDatabase(opCtx, "admin")) {
-        LOG(1) << "Not a primary, skipping the noop write";
+        LOGV2_DEBUG(1, "Not a primary, skipping the noop write");
         return;
     }
 
@@ -165,14 +166,11 @@ void NoopWriter::_writeNoop(OperationContext* opCtx) {
 
     // _lastKnownOpTime is not protected by lock as its used only by one thread.
     if (lastAppliedOpTime != _lastKnownOpTime) {
-        LOG(1) << "Not scheduling a noop write. Last known OpTime: " << _lastKnownOpTime
-               << " != last primary OpTime: " << lastAppliedOpTime;
+        LOGV2_DEBUG(1, "Not scheduling a noop write. Last known OpTime: {} != last primary OpTime: {}", "_lastKnownOpTime"_attr = _lastKnownOpTime, "lastAppliedOpTime"_attr = lastAppliedOpTime);
     } else {
         if (writePeriodicNoops.load()) {
             const auto logLevel = getTestCommandsEnabled() ? 0 : 1;
-            LOG(logLevel)
-                << "Writing noop to oplog as there has been no writes to this replica set in over "
-                << _writeInterval;
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(logLevel).toInt(), "Writing noop to oplog as there has been no writes to this replica set in over {}", "_writeInterval"_attr = _writeInterval);
             writeConflictRetry(
                 opCtx, "writeNoop", NamespaceString::kRsOplogNamespace.ns(), [&opCtx] {
                     WriteUnitOfWork uow(opCtx);
@@ -184,7 +182,7 @@ void NoopWriter::_writeNoop(OperationContext* opCtx) {
     }
 
     _lastKnownOpTime = replCoord->getMyLastAppliedOpTime();
-    LOG(1) << "Set last known op time to " << _lastKnownOpTime;
+    LOGV2_DEBUG(1, "Set last known op time to {}", "_lastKnownOpTime"_attr = _lastKnownOpTime);
 }
 
 }  // namespace repl
diff --git a/src/mongo/db/repl/oplog.cpp b/src/mongo/db/repl/oplog.cpp
index d37e669e53..0c046f0ab7 100644
--- a/src/mongo/db/repl/oplog.cpp
+++ b/src/mongo/db/repl/oplog.cpp
@@ -89,6 +89,7 @@
 #include "mongo/db/storage/storage_options.h"
 #include "mongo/db/transaction_participant.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/scripting/engine.h"
@@ -125,8 +126,7 @@ bool shouldBuildInForeground(OperationContext* opCtx,
                              const NamespaceString& indexNss,
                              repl::OplogApplication::Mode mode) {
     if (mode == OplogApplication::Mode::kRecovering) {
-        LOG(3) << "apply op: building background index " << index
-               << " in the foreground because the node is in recovery";
+        LOGV2_DEBUG(3, "apply op: building background index {} in the foreground because the node is in recovery", "index"_attr = index);
         return true;
     }
 
@@ -135,8 +135,7 @@ bool shouldBuildInForeground(OperationContext* opCtx,
     const bool isPrimary =
         repl::ReplicationCoordinator::get(opCtx)->canAcceptWritesFor(opCtx, indexNss);
     if (isPrimary) {
-        LOG(3) << "apply op: not building background index " << index
-               << " in a background thread because this is a primary";
+        LOGV2_DEBUG(3, "apply op: not building background index {} in a background thread because this is a primary", "index"_attr = index);
         return true;
     }
 
@@ -350,7 +349,7 @@ void _logOpsInner(OperationContext* opCtx,
 
             // Optionally hang before advancing lastApplied.
             if (MONGO_unlikely(hangBeforeLogOpAdvancesLastApplied.shouldFail())) {
-                log() << "hangBeforeLogOpAdvancesLastApplied fail point enabled.";
+                LOGV2("hangBeforeLogOpAdvancesLastApplied fail point enabled.");
                 hangBeforeLogOpAdvancesLastApplied.pauseWhileSet(opCtx);
             }
 
@@ -488,8 +487,7 @@ std::vector<OpTime> logInsertOps(OperationContext* opCtx,
 
     sleepBetweenInsertOpTimeGenerationAndLogOp.execute([&](const BSONObj& data) {
         auto numMillis = data["waitForMillis"].numberInt();
-        log() << "Sleeping for " << numMillis << "ms after receiving " << count << " optimes from "
-              << opTimes.front() << " to " << opTimes.back();
+        LOGV2("Sleeping for {}ms after receiving {} optimes from {} to {}", "numMillis"_attr = numMillis, "count"_attr = count, "opTimes_front"_attr = opTimes.front(), "opTimes_back"_attr = opTimes.back());
         sleepmillis(numMillis);
     });
 
@@ -598,7 +596,7 @@ void createOplog(OperationContext* opCtx,
                 stringstream ss;
                 ss << "cmdline oplogsize (" << n << ") different than existing (" << o
                    << ") see: http://dochub.mongodb.org/core/increase-oplog";
-                log() << ss.str() << endl;
+                LOGV2("{}", "ss_str"_attr = ss.str());
                 uasserted(13257, ss.str());
             }
         }
@@ -611,8 +609,8 @@ void createOplog(OperationContext* opCtx,
     /* create an oplog collection, if it doesn't yet exist. */
     const auto sz = getNewOplogSizeBytes(opCtx, replSettings);
 
-    log() << "******" << endl;
-    log() << "creating replication oplog of size: " << (int)(sz / (1024 * 1024)) << "MB..." << endl;
+    LOGV2("******");
+    LOGV2("creating replication oplog of size: {}MB...", "int_sz_1024_1024"_attr = (int)(sz / (1024 * 1024)));
 
     CollectionOptions options;
     options.capped = true;
@@ -633,7 +631,7 @@ void createOplog(OperationContext* opCtx,
     StorageEngine* storageEngine = service->getStorageEngine();
     storageEngine->flushAllFiles(opCtx, true);
 
-    log() << "******" << endl;
+    LOGV2("******");
 }
 
 void createOplog(OperationContext* opCtx) {
@@ -960,10 +958,7 @@ const StringMap<ApplyOpMetadata> kOpsMap = {
           const auto& cmd = entry.getObject();
           auto nss = extractNsFromUUIDorNs(opCtx, entry.getNss(), entry.getUuid(), cmd);
           if (nss.isDropPendingNamespace()) {
-              log()
-                  << "applyCommand: " << nss
-                  << " : collection is already in a drop-pending state: ignoring collection drop: "
-                  << redact(cmd);
+              LOGV2("applyCommand: {} : collection is already in a drop-pending state: ignoring collection drop: {}", "nss"_attr = nss, "redact_cmd"_attr = redact(cmd));
               return Status::OK();
           }
           // Parse optime from oplog entry unless we are applying this command in standalone or on a
@@ -1110,8 +1105,7 @@ Status applyOperation_inlock(OperationContext* opCtx,
                              IncrementOpsAppliedStatsFn incrementOpsAppliedStats) {
     // Get the single oplog entry to be applied or the first oplog entry of grouped inserts.
     auto op = opOrGroupedInserts.getOp();
-    LOG(3) << "applying op (or grouped inserts): " << redact(opOrGroupedInserts.toBSON())
-           << ", oplog application mode: " << OplogApplication::modeToString(mode);
+    LOGV2_DEBUG(3, "applying op (or grouped inserts): {}, oplog application mode: {}", "redact_opOrGroupedInserts_toBSON"_attr = redact(opOrGroupedInserts.toBSON()), "OplogApplication_modeToString_mode"_attr = OplogApplication::modeToString(mode));
 
     // Choose opCounters based on running on standalone/primary or secondary by checking
     // whether writes are replicated. Atomic applyOps command is an exception, which runs
@@ -1514,8 +1508,7 @@ Status applyOperation_inlock(OperationContext* opCtx,
 Status applyCommand_inlock(OperationContext* opCtx,
                            const OplogEntry& entry,
                            OplogApplication::Mode mode) {
-    LOG(3) << "applying command op: " << redact(entry.toBSON())
-           << ", oplog application mode: " << OplogApplication::modeToString(mode);
+    LOGV2_DEBUG(3, "applying command op: {}, oplog application mode: {}", "redact_entry_toBSON"_attr = redact(entry.toBSON()), "OplogApplication_modeToString_mode"_attr = OplogApplication::modeToString(mode));
 
     // Only commands are processed here.
     invariant(entry.getOpType() == OpTypeEnum::kCommand);
@@ -1643,9 +1636,8 @@ Status applyCommand_inlock(OperationContext* opCtx,
                 opCtx->recoveryUnit()->abandonSnapshot();
                 opCtx->checkForInterrupt();
 
-                LOG(1)
-                    << "Acceptable error during oplog application: background operation in progress for DB '{}' from oplog entry {}"_format(
-                           nss.db(), redact(entry.toBSON()));
+                LOGV2_DEBUG(1, "{}", "Acceptable_error_during_oplog_application_background_operation_in_progress_for_DB_from_oplog_entry__format_nss_db_redact_entry_toBSON"_attr = "Acceptable error during oplog application: background operation in progress for DB '{}' from oplog entry {}"_format(
+                           nss.db(), redact(entry.toBSON())));
                 break;
             }
             case ErrorCodes::BackgroundOperationInProgressForNamespace: {
@@ -1669,9 +1661,8 @@ Status applyCommand_inlock(OperationContext* opCtx,
                 opCtx->recoveryUnit()->abandonSnapshot();
                 opCtx->checkForInterrupt();
 
-                LOG(1)
-                    << "Acceptable error during oplog application: background operation in progress for ns '{}' from oplog entry {}"_format(
-                           ns, redact(entry.toBSON()));
+                LOGV2_DEBUG(1, "{}", "Acceptable_error_during_oplog_application_background_operation_in_progress_for_ns_from_oplog_entry__format_ns_redact_entry_toBSON"_attr = "Acceptable error during oplog application: background operation in progress for ns '{}' from oplog entry {}"_format(
+                           ns, redact(entry.toBSON())));
                 break;
             }
             default: {
@@ -1681,9 +1672,8 @@ Status applyCommand_inlock(OperationContext* opCtx,
                     return status;
                 }
 
-                LOG(1)
-                    << "Acceptable error during oplog application on db '{}' with status '{}' from oplog entry {}"_format(
-                           nss.db(), status.toString(), redact(entry.toBSON()));
+                LOGV2_DEBUG(1, "{}", "Acceptable_error_during_oplog_application_on_db_with_status_from_oplog_entry__format_nss_db_status_toString_redact_entry_toBSON"_attr = "Acceptable error during oplog application on db '{}' with status '{}' from oplog entry {}"_format(
+                           nss.db(), status.toString(), redact(entry.toBSON())));
             }
             // fallthrough
             case ErrorCodes::OK:
@@ -1707,7 +1697,7 @@ void initTimestampFromOplog(OperationContext* opCtx, const NamespaceString& oplo
         c.findOne(oplogNss.ns(), Query().sort(reverseNaturalObj), nullptr, QueryOption_SlaveOk);
 
     if (!lastOp.isEmpty()) {
-        LOG(1) << "replSet setting last Timestamp";
+        LOGV2_DEBUG(1, "replSet setting last Timestamp");
         const OpTime opTime = fassert(28696, OpTime::parseFromOplogEntry(lastOp));
         setNewTimestamp(opCtx->getServiceContext(), opTime.getTimestamp());
     }
diff --git a/src/mongo/db/repl/oplog_applier.cpp b/src/mongo/db/repl/oplog_applier.cpp
index f505933bbd..ba3056a581 100644
--- a/src/mongo/db/repl/oplog_applier.cpp
+++ b/src/mongo/db/repl/oplog_applier.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/namespace_string.h"
 #include "mongo/db/repl/repl_server_parameters_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/time_support.h"
 
@@ -63,9 +64,9 @@ Future<void> OplogApplier::startup() {
     auto callback =
         [ this, promise = std::move(pf.promise) ](const CallbackArgs& args) mutable noexcept {
         invariant(args.status);
-        log() << "Starting oplog application";
+        LOGV2("Starting oplog application");
         _run(_oplogBuffer);
-        log() << "Finished oplog application";
+        LOGV2("Finished oplog application");
         promise.setWith([] {});
     };
     invariant(_executor->scheduleWork(std::move(callback)).getStatus());
@@ -110,7 +111,7 @@ void OplogApplier::enqueue(OperationContext* opCtx,
                            OplogBuffer::Batch::const_iterator end) {
     static Occasionally sampler;
     if (sampler.tick()) {
-        LOG(2) << "oplog buffer has " << _oplogBuffer->getSize() << " bytes";
+        LOGV2_DEBUG(2, "oplog buffer has {} bytes", "_oplogBuffer_getSize"_attr = _oplogBuffer->getSize());
     }
     _oplogBuffer->push(opCtx, begin, end);
 }
diff --git a/src/mongo/db/repl/oplog_applier_impl.cpp b/src/mongo/db/repl/oplog_applier_impl.cpp
index ab42b32502..c8d383d201 100644
--- a/src/mongo/db/repl/oplog_applier_impl.cpp
+++ b/src/mongo/db/repl/oplog_applier_impl.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/repl/insert_group.h"
 #include "mongo/db/repl/transaction_oplog_application.h"
 #include "mongo/db/stats/timer_stats.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/basic.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -120,7 +121,7 @@ Status finishAndLogApply(ClockSource* clockSource,
             s << redact(entryOrGroupedInserts.toBSON());
             s << ", took " << diffMS << "ms";
 
-            log() << s.str();
+            LOGV2("{}", "s_str"_attr = s.str());
         }
     }
     return finalStatus;
@@ -396,8 +397,8 @@ void OplogApplierImpl::_run(OplogBuffer* oplogBuffer) {
 
         // For pausing replication in tests.
         if (MONGO_unlikely(rsSyncApplyStop.shouldFail())) {
-            log() << "Oplog Applier - rsSyncApplyStop fail point enabled. Blocking until fail "
-                     "point is disabled.";
+            LOGV2("Oplog Applier - rsSyncApplyStop fail point enabled. Blocking until fail "
+                     "point is disabled.");
             rsSyncApplyStop.pauseWhileSet(&opCtx);
         }
 
@@ -570,7 +571,7 @@ StatusWith<OpTime> OplogApplierImpl::_applyOplogBatch(OperationContext* opCtx,
                                                       std::vector<OplogEntry> ops) {
     invariant(!ops.empty());
 
-    LOG(2) << "replication batch size is " << ops.size();
+    LOGV2_DEBUG(2, "replication batch size is {}", "ops_size"_attr = ops.size());
 
     // Stop all readers until we're done. This also prevents doc-locking engines from deleting old
     // entries from the oplog until we finish writing.
@@ -620,8 +621,8 @@ StatusWith<OpTime> OplogApplierImpl::_applyOplogBatch(OperationContext* opCtx,
         // Use this fail point to hold the PBWM lock after we have written the oplog entries but
         // before we have applied them.
         if (MONGO_unlikely(pauseBatchApplicationAfterWritingOplogEntries.shouldFail())) {
-            log() << "pauseBatchApplicationAfterWritingOplogEntries fail point enabled. Blocking "
-                     "until fail point is disabled.";
+            LOGV2("pauseBatchApplicationAfterWritingOplogEntries fail point enabled. Blocking "
+                     "until fail point is disabled.");
             pauseBatchApplicationAfterWritingOplogEntries.pauseWhileSet(opCtx);
         }
 
@@ -688,8 +689,8 @@ StatusWith<OpTime> OplogApplierImpl::_applyOplogBatch(OperationContext* opCtx,
 
     // Use this fail point to hold the PBWM lock and prevent the batch from completing.
     if (MONGO_unlikely(pauseBatchApplicationBeforeCompletion.shouldFail())) {
-        log() << "pauseBatchApplicationBeforeCompletion fail point enabled. Blocking until fail "
-                 "point is disabled.";
+        LOGV2("pauseBatchApplicationBeforeCompletion fail point enabled. Blocking until fail "
+                 "point is disabled.");
         while (MONGO_unlikely(pauseBatchApplicationBeforeCompletion.shouldFail())) {
             if (inShutdown()) {
                 severe() << "Turn off pauseBatchApplicationBeforeCompletion before attempting "
@@ -872,10 +873,9 @@ Status applyOplogEntryOrGroupedInserts(OperationContext* opCtx,
     auto applyStartTime = clockSource->now();
 
     if (MONGO_unlikely(hangAfterRecordingOpApplicationStartTime.shouldFail())) {
-        log() << "applyOplogEntryOrGroupedInserts - fail point "
+        LOGV2("applyOplogEntryOrGroupedInserts - fail point "
                  "hangAfterRecordingOpApplicationStartTime "
-                 "enabled. "
-              << "Blocking until fail point is disabled. ";
+                 "enabled. Blocking until fail point is disabled. ");
         hangAfterRecordingOpApplicationStartTime.pauseWhileSet();
     }
 
diff --git a/src/mongo/db/repl/oplog_fetcher.cpp b/src/mongo/db/repl/oplog_fetcher.cpp
index 514de02e8c..0b263a0bd7 100644
--- a/src/mongo/db/repl/oplog_fetcher.cpp
+++ b/src/mongo/db/repl/oplog_fetcher.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/matcher/matcher.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/stats/timer_stats.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/oplog_query_metadata.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/fail_point.h"
@@ -395,7 +396,7 @@ StatusWith<BSONObj> OplogFetcher::_onSuccessfulBatch(const Fetcher::QueryRespons
             [&](auto&&) {
                 status = {ErrorCodes::FailPointEnabled,
                           "stopReplProducerOnDocument fail point is enabled."};
-                log() << status.reason();
+                LOGV2("{}", "status_reason"_attr = status.reason());
             },
             [&](const BSONObj& data) {
                 auto opCtx = cc().makeOperationContext();
@@ -413,11 +414,9 @@ StatusWith<BSONObj> OplogFetcher::_onSuccessfulBatch(const Fetcher::QueryRespons
     auto firstDocToApply = documents.cbegin();
 
     if (!documents.empty()) {
-        LOG(2) << "oplog fetcher read " << documents.size()
-               << " operations from remote oplog starting at " << documents.front()["ts"]
-               << " and ending at " << documents.back()["ts"];
+        LOGV2_DEBUG(2, "oplog fetcher read {} operations from remote oplog starting at {} and ending at {}", "documents_size"_attr = documents.size(), "documents_front_ts"_attr = documents.front()["ts"], "documents_back_ts"_attr = documents.back()["ts"]);
     } else {
-        LOG(2) << "oplog fetcher read 0 operations from remote oplog";
+        LOGV2_DEBUG(2, "oplog fetcher read 0 operations from remote oplog");
     }
 
     auto oqMetadataResult = parseOplogQueryMetadata(queryResponse);
@@ -447,7 +446,7 @@ StatusWith<BSONObj> OplogFetcher::_onSuccessfulBatch(const Fetcher::QueryRespons
             return status;
         }
 
-        LOG(1) << "oplog fetcher successfully fetched from " << _getSource();
+        LOGV2_DEBUG(1, "oplog fetcher successfully fetched from {}", "_getSource"_attr = _getSource());
 
         // We do not always enqueue the first document. We elect to skip it for the following
         // reasons:
diff --git a/src/mongo/db/repl/repl_client_info.cpp b/src/mongo/db/repl/repl_client_info.cpp
index dc4c04342c..2edf4747e4 100644
--- a/src/mongo/db/repl/repl_client_info.cpp
+++ b/src/mongo/db/repl/repl_client_info.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/client.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/repl/replication_coordinator.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/decorable.h"
 #include "mongo/util/log.h"
 
@@ -77,10 +78,8 @@ void ReplClientInfo::setLastOpToSystemLastOpTime(OperationContext* opCtx) {
         if (systemOpTime >= _lastOp) {
             _lastOp = systemOpTime;
         } else {
-            log() << "Not setting the last OpTime for this Client from " << _lastOp
-                  << " to the current system time of " << systemOpTime
-                  << " as that would be moving the OpTime backwards.  This should only happen if "
-                     "there was a rollback recently";
+            LOGV2("Not setting the last OpTime for this Client from {} to the current system time of {} as that would be moving the OpTime backwards.  This should only happen if "
+                     "there was a rollback recently", "_lastOp"_attr = _lastOp, "systemOpTime"_attr = systemOpTime);
         }
 
         lastOpInfo(opCtx).lastOpSetExplicitly = true;
diff --git a/src/mongo/db/repl/repl_set_commands.cpp b/src/mongo/db/repl/repl_set_commands.cpp
index a9c7bdc533..717b23e3ff 100644
--- a/src/mongo/db/repl/repl_set_commands.cpp
+++ b/src/mongo/db/repl/repl_set_commands.cpp
@@ -62,6 +62,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/storage_engine.h"
 #include "mongo/executor/network_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/session.h"
 #include "mongo/transport/transport_layer.h"
 #include "mongo/util/decimal_counter.h"
@@ -103,7 +104,7 @@ public:
                      const string&,
                      const BSONObj& cmdObj,
                      BSONObjBuilder& result) {
-        log() << "replSetTest command received: " << cmdObj.toString();
+        LOGV2("replSetTest command received: {}", "cmdObj_toString"_attr = cmdObj.toString());
 
         auto replCoord = ReplicationCoordinator::get(getGlobalServiceContext());
 
@@ -120,8 +121,7 @@ public:
             status = bsonExtractIntegerField(cmdObj, "timeoutMillis", &timeoutMillis);
             uassertStatusOK(status);
             Milliseconds timeout(timeoutMillis);
-            log() << "replSetTest: waiting " << timeout << " for member state to become "
-                  << expectedState;
+            LOGV2("replSetTest: waiting {} for member state to become {}", "timeout"_attr = timeout, "expectedState"_attr = expectedState);
 
             status = replCoord->waitForMemberState(expectedState, timeout);
 
@@ -132,7 +132,7 @@ public:
             auto status = bsonExtractIntegerField(cmdObj, "waitForDrainFinish", &timeoutMillis);
             uassertStatusOK(status);
             Milliseconds timeout(timeoutMillis);
-            log() << "replSetTest: waiting " << timeout << " for applier buffer to finish draining";
+            LOGV2("replSetTest: waiting {} for applier buffer to finish draining", "timeout"_attr = timeout);
 
             status = replCoord->waitForDrainFinish(timeout);
 
@@ -275,7 +275,7 @@ void parseReplSetSeedList(ReplicationCoordinatorExternalState* externalState,
         seedSet.insert(m);
         // uassert(13101, "can't use localhost in replset host list", !m.isLocalHost());
         if (externalState->isSelf(m, getGlobalServiceContext())) {
-            LOG(1) << "ignoring seed " << m.toString() << " (=self)";
+            LOGV2_DEBUG(1, "ignoring seed {} (=self)", "m_toString"_attr = m.toString());
         } else {
             seeds->push_back(m);
         }
@@ -315,7 +315,7 @@ public:
                 "no configuration specified. "
                 "Using a default configuration for the set";
             result.append("info2", noConfigMessage);
-            log() << "initiate : " << noConfigMessage;
+            LOGV2("initiate : {}", "noConfigMessage"_attr = noConfigMessage);
 
             ReplicationCoordinatorExternalStateImpl externalState(
                 opCtx->getServiceContext(),
@@ -346,7 +346,7 @@ public:
             }
             b.appendArray("members", members.obj());
             configObj = b.obj();
-            log() << "created this configuration for initiation : " << configObj.toString();
+            LOGV2("created this configuration for initiation : {}", "configObj_toString"_attr = configObj.toString());
         }
 
         if (configObj.getField("version").eoo()) {
@@ -522,12 +522,12 @@ public:
             uassertStatusOK(status);
         }
 
-        log() << "Attempting to step down in response to replSetStepDown command";
+        LOGV2("Attempting to step down in response to replSetStepDown command");
 
         ReplicationCoordinator::get(opCtx)->stepDown(
             opCtx, force, Seconds(secondaryCatchUpPeriodSecs), Seconds(stepDownForSecs));
 
-        log() << "replSetStepDown command completed";
+        LOGV2("replSetStepDown command completed");
 
         onExitGuard.dismiss();
         return true;
@@ -726,13 +726,13 @@ public:
         Status status = ReplicationCoordinator::get(opCtx)->checkReplEnabledForCommand(&result);
         uassertStatusOK(status);
 
-        log() << "Received replSetStepUp request";
+        LOGV2("Received replSetStepUp request");
 
         const bool skipDryRun = cmdObj["skipDryRun"].trueValue();
         status = ReplicationCoordinator::get(opCtx)->stepUpIfEligible(skipDryRun);
 
         if (!status.isOK()) {
-            log() << "replSetStepUp request failed" << causedBy(status);
+            LOGV2("replSetStepUp request failed{}", "causedBy_status"_attr = causedBy(status));
         }
 
         uassertStatusOK(status);
@@ -761,13 +761,13 @@ public:
                      BSONObjBuilder& result) override {
         Status status = ReplicationCoordinator::get(opCtx)->checkReplEnabledForCommand(&result);
         uassertStatusOK(status);
-        log() << "Received replSetAbortPrimaryCatchUp request";
+        LOGV2("Received replSetAbortPrimaryCatchUp request");
 
         status = ReplicationCoordinator::get(opCtx)->abortCatchupIfNeeded(
             ReplicationCoordinator::PrimaryCatchUpConclusionReason::
                 kFailedWithReplSetAbortPrimaryCatchUpCmd);
         if (!status.isOK()) {
-            log() << "replSetAbortPrimaryCatchUp request failed" << causedBy(status);
+            LOGV2("replSetAbortPrimaryCatchUp request failed{}", "causedBy_status"_attr = causedBy(status));
         }
         uassertStatusOK(status);
         return true;
diff --git a/src/mongo/db/repl/replication_consistency_markers_impl.cpp b/src/mongo/db/repl/replication_consistency_markers_impl.cpp
index d45aa9c492..3fa9b1c80f 100644
--- a/src/mongo/db/repl/replication_consistency_markers_impl.cpp
+++ b/src/mongo/db/repl/replication_consistency_markers_impl.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/repl/optime.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/repl/storage_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -93,7 +94,7 @@ void ReplicationConsistencyMarkersImpl::_updateMinValidDocument(
 }
 
 void ReplicationConsistencyMarkersImpl::initializeMinValidDocument(OperationContext* opCtx) {
-    LOG(3) << "Initializing minValid document";
+    LOGV2_DEBUG(3, "Initializing minValid document");
 
     // This initializes the values of the required fields if they are not already set.
     // If one of the fields is already set, the $max will prefer the existing value since it
@@ -114,22 +115,22 @@ void ReplicationConsistencyMarkersImpl::initializeMinValidDocument(OperationCont
 bool ReplicationConsistencyMarkersImpl::getInitialSyncFlag(OperationContext* opCtx) const {
     auto doc = _getMinValidDocument(opCtx);
     if (!doc) {
-        LOG(3) << "No min valid document found, returning initial sync flag value of false.";
+        LOGV2_DEBUG(3, "No min valid document found, returning initial sync flag value of false.");
         return false;
     }
 
     boost::optional<bool> flag = doc->getInitialSyncFlag();
     if (!flag) {
-        LOG(3) << "No initial sync flag set, returning initial sync flag value of false.";
+        LOGV2_DEBUG(3, "No initial sync flag set, returning initial sync flag value of false.");
         return false;
     }
 
-    LOG(3) << "returning initial sync flag value of " << flag.get();
+    LOGV2_DEBUG(3, "returning initial sync flag value of {}", "flag_get"_attr = flag.get());
     return flag.get();
 }
 
 void ReplicationConsistencyMarkersImpl::setInitialSyncFlag(OperationContext* opCtx) {
-    LOG(3) << "setting initial sync flag";
+    LOGV2_DEBUG(3, "setting initial sync flag");
     TimestampedBSONObj update;
     update.obj = BSON("$set" << kInitialSyncFlag);
 
@@ -143,7 +144,7 @@ void ReplicationConsistencyMarkersImpl::setInitialSyncFlag(OperationContext* opC
 }
 
 void ReplicationConsistencyMarkersImpl::clearInitialSyncFlag(OperationContext* opCtx) {
-    LOG(3) << "clearing initial sync flag";
+    LOGV2_DEBUG(3, "clearing initial sync flag");
 
     auto replCoord = repl::ReplicationCoordinator::get(opCtx);
     OpTimeAndWallTime opTimeAndWallTime = replCoord->getMyLastAppliedOpTimeAndWallTime();
@@ -181,15 +182,14 @@ OpTime ReplicationConsistencyMarkersImpl::getMinValid(OperationContext* opCtx) c
 
     auto minValid = OpTime(doc->getMinValidTimestamp(), doc->getMinValidTerm());
 
-    LOG(3) << "returning minvalid: " << minValid.toString() << "(" << minValid.toBSON() << ")";
+    LOGV2_DEBUG(3, "returning minvalid: {}({})", "minValid_toString"_attr = minValid.toString(), "minValid_toBSON"_attr = minValid.toBSON());
 
     return minValid;
 }
 
 void ReplicationConsistencyMarkersImpl::setMinValid(OperationContext* opCtx,
                                                     const OpTime& minValid) {
-    LOG(3) << "setting minvalid to exactly: " << minValid.toString() << "(" << minValid.toBSON()
-           << ")";
+    LOGV2_DEBUG(3, "setting minvalid to exactly: {}({})", "minValid_toString"_attr = minValid.toString(), "minValid_toBSON"_attr = minValid.toBSON());
     TimestampedBSONObj update;
     update.obj =
         BSON("$set" << BSON(MinValidDocument::kMinValidTimestampFieldName
@@ -206,8 +206,7 @@ void ReplicationConsistencyMarkersImpl::setMinValid(OperationContext* opCtx,
 
 void ReplicationConsistencyMarkersImpl::setMinValidToAtLeast(OperationContext* opCtx,
                                                              const OpTime& minValid) {
-    LOG(3) << "setting minvalid to at least: " << minValid.toString() << "(" << minValid.toBSON()
-           << ")";
+    LOGV2_DEBUG(3, "setting minvalid to at least: {}({})", "minValid_toString"_attr = minValid.toString(), "minValid_toBSON"_attr = minValid.toBSON());
 
     auto& termField = MinValidDocument::kMinValidTermFieldName;
     auto& tsField = MinValidDocument::kMinValidTimestampFieldName;
@@ -247,7 +246,7 @@ void ReplicationConsistencyMarkersImpl::setAppliedThrough(OperationContext* opCt
                                                           const OpTime& optime,
                                                           bool setTimestamp) {
     invariant(!optime.isNull());
-    LOG(3) << "setting appliedThrough to: " << optime.toString() << "(" << optime.toBSON() << ")";
+    LOGV2_DEBUG(3, "setting appliedThrough to: {}({})", "optime_toString"_attr = optime.toString(), "optime_toBSON"_attr = optime.toBSON());
 
     // We set the 'appliedThrough' to the provided timestamp. The 'appliedThrough' is only valid
     // in checkpoints that contain all writes through this timestamp since it indicates the top of
@@ -263,7 +262,7 @@ void ReplicationConsistencyMarkersImpl::setAppliedThrough(OperationContext* opCt
 
 void ReplicationConsistencyMarkersImpl::clearAppliedThrough(OperationContext* opCtx,
                                                             const Timestamp& writeTimestamp) {
-    LOG(3) << "clearing appliedThrough at: " << writeTimestamp.toString();
+    LOGV2_DEBUG(3, "clearing appliedThrough at: {}", "writeTimestamp_toString"_attr = writeTimestamp.toString());
 
     TimestampedBSONObj update;
     update.timestamp = writeTimestamp;
@@ -278,11 +277,10 @@ OpTime ReplicationConsistencyMarkersImpl::getAppliedThrough(OperationContext* op
 
     auto appliedThrough = doc->getAppliedThrough();
     if (!appliedThrough) {
-        LOG(3) << "No appliedThrough OpTime set, returning empty appliedThrough OpTime.";
+        LOGV2_DEBUG(3, "No appliedThrough OpTime set, returning empty appliedThrough OpTime.");
         return {};
     }
-    LOG(3) << "returning appliedThrough: " << appliedThrough->toString() << "("
-           << appliedThrough->toBSON() << ")";
+    LOGV2_DEBUG(3, "returning appliedThrough: {}({})", "appliedThrough_toString"_attr = appliedThrough->toString(), "appliedThrough_toBSON"_attr = appliedThrough->toBSON());
 
     return appliedThrough.get();
 }
@@ -310,8 +308,7 @@ ReplicationConsistencyMarkersImpl::_getOplogTruncateAfterPointDocument(
 
 void ReplicationConsistencyMarkersImpl::ensureFastCountOnOplogTruncateAfterPoint(
     OperationContext* opCtx) {
-    LOG(3) << "Updating cached fast-count on collection " << _oplogTruncateAfterPointNss
-           << " in case an unclean shutdown caused it to become incorrect.";
+    LOGV2_DEBUG(3, "Updating cached fast-count on collection {} in case an unclean shutdown caused it to become incorrect.", "_oplogTruncateAfterPointNss"_attr = _oplogTruncateAfterPointNss);
 
     auto result = _storageInterface->findSingleton(opCtx, _oplogTruncateAfterPointNss);
 
@@ -351,7 +348,7 @@ void ReplicationConsistencyMarkersImpl::_upsertOplogTruncateAfterPointDocument(
 
 void ReplicationConsistencyMarkersImpl::setOplogTruncateAfterPoint(OperationContext* opCtx,
                                                                    const Timestamp& timestamp) {
-    LOG(3) << "setting oplog truncate after point to: " << timestamp.toBSON();
+    LOGV2_DEBUG(3, "setting oplog truncate after point to: {}", "timestamp_toBSON"_attr = timestamp.toBSON());
     _upsertOplogTruncateAfterPointDocument(
         opCtx,
         BSON("$set" << BSON(OplogTruncateAfterPointDocument::kOplogTruncateAfterPointFieldName
@@ -362,13 +359,13 @@ Timestamp ReplicationConsistencyMarkersImpl::getOplogTruncateAfterPoint(
     OperationContext* opCtx) const {
     auto doc = _getOplogTruncateAfterPointDocument(opCtx);
     if (!doc) {
-        LOG(3) << "Returning empty oplog truncate after point since document did not exist";
+        LOGV2_DEBUG(3, "Returning empty oplog truncate after point since document did not exist");
         return {};
     }
 
     Timestamp out = doc->getOplogTruncateAfterPoint();
 
-    LOG(3) << "returning oplog truncate after point: " << out;
+    LOGV2_DEBUG(3, "returning oplog truncate after point: {}", "out"_attr = out);
     return out;
 }
 
diff --git a/src/mongo/db/repl/replication_coordinator_external_state_impl.cpp b/src/mongo/db/repl/replication_coordinator_external_state_impl.cpp
index fba3f695cb..3e8bc75274 100644
--- a/src/mongo/db/repl/replication_coordinator_external_state_impl.cpp
+++ b/src/mongo/db/repl/replication_coordinator_external_state_impl.cpp
@@ -93,6 +93,7 @@
 #include "mongo/executor/network_interface.h"
 #include "mongo/executor/network_interface_factory.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/egress_metadata_hook_list.h"
 #include "mongo/s/catalog/type_shard.h"
 #include "mongo/s/catalog_cache_loader.h"
@@ -238,13 +239,13 @@ void ReplicationCoordinatorExternalStateImpl::startSteadyStateReplication(
     _bgSync =
         std::make_unique<BackgroundSync>(replCoord, this, _replicationProcess, _oplogApplier.get());
 
-    log() << "Starting replication fetcher thread";
+    LOGV2("Starting replication fetcher thread");
     _bgSync->startup(opCtx);
 
-    log() << "Starting replication applier thread";
+    LOGV2("Starting replication applier thread");
     _oplogApplierShutdownFuture = _oplogApplier->startup();
 
-    log() << "Starting replication reporter thread";
+    LOGV2("Starting replication reporter thread");
     invariant(!_syncSourceFeedbackThread);
     // Get the pointer while holding the lock so that _stopDataReplication_inlock() won't
     // leave the unique pointer empty if the _syncSourceFeedbackThread's function starts
@@ -275,18 +276,18 @@ void ReplicationCoordinatorExternalStateImpl::_stopDataReplication_inlock(
     // _syncSourceFeedbackThread should be joined before _bgSync's shutdown because it has
     // a pointer of _bgSync.
     if (oldSSF) {
-        log() << "Stopping replication reporter thread";
+        LOGV2("Stopping replication reporter thread");
         _syncSourceFeedback.shutdown();
         oldSSF->join();
     }
 
     if (oldBgSync) {
-        log() << "Stopping replication fetcher thread";
+        LOGV2("Stopping replication fetcher thread");
         oldBgSync->shutdown(opCtx);
     }
 
     if (oldApplier) {
-        log() << "Stopping replication applier thread";
+        LOGV2("Stopping replication applier thread");
         oldApplier->shutdown();
     }
 
@@ -321,10 +322,10 @@ void ReplicationCoordinatorExternalStateImpl::startThreads(const ReplSettings& s
         return;
     }
     if (_inShutdown) {
-        log() << "Not starting replication storage threads because replication is shutting down.";
+        LOGV2("Not starting replication storage threads because replication is shutting down.");
     }
 
-    log() << "Starting replication storage threads";
+    LOGV2("Starting replication storage threads");
     _service->getStorageEngine()->setJournalListener(this);
 
     _oplogApplierTaskExecutor =
@@ -348,7 +349,7 @@ void ReplicationCoordinatorExternalStateImpl::shutdown(OperationContext* opCtx)
 
     _stopDataReplication_inlock(opCtx, lk);
 
-    log() << "Stopping replication storage threads";
+    LOGV2("Stopping replication storage threads");
     _taskExecutor->shutdown();
     _oplogApplierTaskExecutor->shutdown();
 
@@ -361,7 +362,7 @@ void ReplicationCoordinatorExternalStateImpl::shutdown(OperationContext* opCtx)
     // itself can block on the ReplicationCoordinator mutex. It is safe to access _noopWriter
     // outside of _threadMutex because _noopWriter is protected by its own mutex.
     invariant(_noopWriter);
-    LOG(1) << "Stopping noop writer";
+    LOGV2_DEBUG(1, "Stopping noop writer");
     _noopWriter->stopWritingPeriodicNoops();
 
     // We must wait for _taskExecutor outside of _threadMutex, since _taskExecutor is used to run
@@ -859,7 +860,7 @@ void ReplicationCoordinatorExternalStateImpl::_dropAllTempCollections(OperationC
         // replica set members.
         if (*it == "local")
             continue;
-        LOG(2) << "Removing temporary collections from " << *it;
+        LOGV2_DEBUG(2, "Removing temporary collections from {}", "it"_attr = *it);
         AutoGetDb autoDb(opCtx, *it, MODE_IX);
         invariant(autoDb.getDb(), str::stream() << "Unable to get reference to database " << *it);
         autoDb.getDb()->clearTmpCollections(opCtx);
@@ -904,10 +905,9 @@ void ReplicationCoordinatorExternalStateImpl::notifyOplogMetadataWaiters(
                 _taskExecutor.get(),
                 [committedOpTime, reaper](const executor::TaskExecutor::CallbackArgs& args) {
                     if (MONGO_unlikely(dropPendingCollectionReaperHang.shouldFail())) {
-                        log() << "fail point dropPendingCollectionReaperHang enabled. "
+                        LOGV2("fail point dropPendingCollectionReaperHang enabled. "
                                  "Blocking until fail point is disabled. "
-                                 "committedOpTime: "
-                              << committedOpTime;
+                                 "committedOpTime: {}", "committedOpTime"_attr = committedOpTime);
                         dropPendingCollectionReaperHang.pauseWhileSet();
                     }
                     auto opCtx = cc().makeOperationContext();
diff --git a/src/mongo/db/repl/replication_coordinator_impl.cpp b/src/mongo/db/repl/replication_coordinator_impl.cpp
index 1937c8b856..ba5e471de1 100644
--- a/src/mongo/db/repl/replication_coordinator_impl.cpp
+++ b/src/mongo/db/repl/replication_coordinator_impl.cpp
@@ -83,6 +83,7 @@
 #include "mongo/db/write_concern_options.h"
 #include "mongo/executor/connection_pool_stats.h"
 #include "mongo/executor/network_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/metadata/oplog_query_metadata.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
@@ -443,7 +444,7 @@ bool ReplicationCoordinatorImpl::_startLoadLocalConfig(OperationContext* opCtx)
     }
     if (lastVote.getValue().getTerm() == OpTime::kInitialTerm) {
         // This log line is checked in unit tests.
-        log() << "Did not find local initialized voted for document at startup.";
+        LOGV2("Did not find local initialized voted for document at startup.");
     }
     {
         stdx::lock_guard<Latch> lk(_mutex);
@@ -454,7 +455,7 @@ bool ReplicationCoordinatorImpl::_startLoadLocalConfig(OperationContext* opCtx)
     auto status = _replicationProcess->refreshRollbackID(opCtx);
     if (!status.isOK()) {
         if (status == ErrorCodes::NamespaceNotFound) {
-            log() << "Did not find local Rollback ID document at startup. Creating one.";
+            LOGV2("Did not find local Rollback ID document at startup. Creating one.");
             auto initializingStatus = _replicationProcess->initializeRollbackID(opCtx);
             fassert(40424, initializingStatus);
         } else {
@@ -530,7 +531,7 @@ void ReplicationCoordinatorImpl::_finishLoadLocalConfig(
     const StatusWith<OpTimeAndWallTime>& lastOpTimeAndWallTimeStatus,
     const StatusWith<LastVote>& lastVoteStatus) {
     if (!cbData.status.isOK()) {
-        LOG(1) << "Loading local replica set configuration failed due to " << cbData.status;
+        LOGV2_DEBUG(1, "Loading local replica set configuration failed due to {}", "cbData_status"_attr = cbData.status);
         return;
     }
 
@@ -561,15 +562,12 @@ void ReplicationCoordinatorImpl::_finishLoadLocalConfig(
 
     if (serverGlobalParams.enableMajorityReadConcern && localConfig.getNumMembers() == 3 &&
         localConfig.getNumDataBearingMembers() == 2) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: This replica set has a Primary-Secondary-Arbiter architecture, but "
-                 "readConcern:majority is enabled "
-              << startupWarningsLog;
-        log() << "**          for this node. This is not a recommended configuration. Please see "
-              << startupWarningsLog;
-        log() << "**          https://dochub.mongodb.org/core/psa-disable-rc-majority"
-              << startupWarningsLog;
-        log() << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: This replica set has a Primary-Secondary-Arbiter architecture, but "
+                 "readConcern:majority is enabled ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          for this node. This is not a recommended configuration. Please see ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          https://dochub.mongodb.org/core/psa-disable-rc-majority");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
     }
 
     // Do not check optime, if this node is an arbiter.
@@ -641,7 +639,7 @@ void ReplicationCoordinatorImpl::_finishLoadLocalConfig(
         // Step down is impossible, so we don't need to wait for the returned event.
         _updateTerm_inlock(term);
     }
-    LOG(1) << "Current term is now " << term;
+    LOGV2_DEBUG(1, "Current term is now {}", "term"_attr = term);
     _performPostMemberStateUpdateAction(action);
 
     if (!isArbiter) {
@@ -657,8 +655,7 @@ void ReplicationCoordinatorImpl::_stopDataReplication(OperationContext* opCtx) {
         _initialSyncer.swap(initialSyncerCopy);
     }
     if (initialSyncerCopy) {
-        LOG(1)
-            << "ReplicationCoordinatorImpl::_stopDataReplication calling InitialSyncer::shutdown.";
+        LOGV2_DEBUG(1, "ReplicationCoordinatorImpl::_stopDataReplication calling InitialSyncer::shutdown.");
         const auto status = initialSyncerCopy->shutdown();
         if (!status.isOK()) {
             warning() << "InitialSyncer shutdown failed: " << status;
@@ -666,8 +663,8 @@ void ReplicationCoordinatorImpl::_stopDataReplication(OperationContext* opCtx) {
         initialSyncerCopy.reset();
         // Do not return here, fall through.
     }
-    LOG(1) << "ReplicationCoordinatorImpl::_stopDataReplication calling "
-              "ReplCoordExtState::stopDataReplication.";
+    LOGV2_DEBUG(1, "ReplicationCoordinatorImpl::_stopDataReplication calling "
+              "ReplCoordExtState::stopDataReplication.");
     _externalState->stopDataReplication(opCtx);
 }
 
@@ -689,7 +686,7 @@ void ReplicationCoordinatorImpl::_startDataReplication(OperationContext* opCtx,
 
     // Do initial sync.
     if (!_externalState->getTaskExecutor()) {
-        log() << "not running initial sync during test.";
+        LOGV2("not running initial sync during test.");
         return;
     }
 
@@ -697,12 +694,11 @@ void ReplicationCoordinatorImpl::_startDataReplication(OperationContext* opCtx,
         {
             stdx::lock_guard<Latch> lock(_mutex);
             if (opTimeStatus == ErrorCodes::CallbackCanceled) {
-                log() << "Initial Sync has been cancelled: " << opTimeStatus.getStatus();
+                LOGV2("Initial Sync has been cancelled: {}", "opTimeStatus_getStatus"_attr = opTimeStatus.getStatus());
                 return;
             } else if (!opTimeStatus.isOK()) {
                 if (_inShutdown) {
-                    log() << "Initial Sync failed during shutdown due to "
-                          << opTimeStatus.getStatus();
+                    LOGV2("Initial Sync failed during shutdown due to {}", "opTimeStatus_getStatus"_attr = opTimeStatus.getStatus());
                     return;
                 } else {
                     error() << "Initial sync failed, shutting down now. Restart the server "
@@ -752,7 +748,7 @@ void ReplicationCoordinatorImpl::_startDataReplication(OperationContext* opCtx,
         uassertStatusOK(initialSyncerCopy->startup(opCtx, numInitialSyncAttempts.load()));
     } catch (const DBException& e) {
         auto status = e.toStatus();
-        log() << "Initial Sync failed to start: " << status;
+        LOGV2("Initial Sync failed to start: {}", "status"_attr = status);
         if (ErrorCodes::CallbackCanceled == status || ErrorCodes::isShutdownError(status.code())) {
             return;
         }
@@ -814,7 +810,7 @@ void ReplicationCoordinatorImpl::shutdown(OperationContext* opCtx) {
         return;
     }
 
-    log() << "shutting down replication subsystems";
+    LOGV2("shutting down replication subsystems");
 
     // Used to shut down outside of the lock.
     std::shared_ptr<InitialSyncer> initialSyncerCopy;
@@ -846,7 +842,7 @@ void ReplicationCoordinatorImpl::shutdown(OperationContext* opCtx) {
 
     // joining the replication executor is blocking so it must be run outside of the mutex
     if (initialSyncerCopy) {
-        LOG(1) << "ReplicationCoordinatorImpl::shutdown calling InitialSyncer::shutdown.";
+        LOGV2_DEBUG(1, "ReplicationCoordinatorImpl::shutdown calling InitialSyncer::shutdown.");
         const auto status = initialSyncerCopy->shutdown();
         if (!status.isOK()) {
             warning() << "InitialSyncer shutdown failed: " << status;
@@ -1026,7 +1022,7 @@ void ReplicationCoordinatorImpl::signalDrainComplete(OperationContext* opCtx,
 
         auto status = _topCoord->completeTransitionToPrimary(firstOpTime);
         if (status.code() == ErrorCodes::PrimarySteppedDown) {
-            log() << "Transition to primary failed" << causedBy(status);
+            LOGV2("Transition to primary failed{}", "causedBy_status"_attr = causedBy(status));
             return;
         }
         invariant(status);
@@ -1136,7 +1132,7 @@ void ReplicationCoordinatorImpl::resetMyLastOpTimes() {
 }
 
 void ReplicationCoordinatorImpl::_resetMyLastOpTimes(WithLock lk) {
-    LOG(1) << "resetting durable/applied optimes.";
+    LOGV2_DEBUG(1, "resetting durable/applied optimes.");
     // Reset to uninitialized OpTime
     bool isRollbackAllowed = true;
     _setMyLastAppliedOpTimeAndWallTime(
@@ -1369,8 +1365,7 @@ Status ReplicationCoordinatorImpl::_waitUntilOpTime(OperationContext* opCtx,
             // We just need to wait for the opTime to catch up to what we need (not majority RC).
             auto future = _opTimeWaiterList.add_inlock(targetOpTime);
 
-            LOG(3) << "waitUntilOpTime: OpID " << opCtx->getOpID() << " is waiting for OpTime "
-                   << targetOpTime << " until " << deadline.value_or(opCtx->getDeadline());
+            LOGV2_DEBUG(3, "waitUntilOpTime: OpID {} is waiting for OpTime {} until {}", "opCtx_getOpID"_attr = opCtx->getOpID(), "targetOpTime"_attr = targetOpTime, "deadline_value_or_opCtx_getDeadline"_attr = deadline.value_or(opCtx->getDeadline()));
 
             lock.unlock();
             auto waitStatus = futureGetNoThrowWithDeadline(
@@ -1413,12 +1408,9 @@ Status ReplicationCoordinatorImpl::_waitUntilMajorityOpTime(mongo::OperationCont
 
     stdx::unique_lock lock(_mutex);
 
-    LOG(1) << "waitUntilOpTime: waiting for optime:" << targetOpTime
-           << " to be in a snapshot -- current snapshot: "
-           << _getCurrentCommittedSnapshotOpTime_inlock();
+    LOGV2_DEBUG(1, "waitUntilOpTime: waiting for optime:{} to be in a snapshot -- current snapshot: {}", "targetOpTime"_attr = targetOpTime, "_getCurrentCommittedSnapshotOpTime_inlock"_attr = _getCurrentCommittedSnapshotOpTime_inlock());
 
-    LOG(3) << "waitUntilOpTime: waiting for a new snapshot until "
-           << deadline.value_or(opCtx->getDeadline());
+    LOGV2_DEBUG(3, "waitUntilOpTime: waiting for a new snapshot until {}", "deadline_value_or_opCtx_getDeadline"_attr = deadline.value_or(opCtx->getDeadline()));
 
     try {
         auto ok = opCtx->waitForConditionOrInterruptUntil(
@@ -1442,7 +1434,7 @@ Status ReplicationCoordinatorImpl::_waitUntilMajorityOpTime(mongo::OperationCont
         // _currentCommittedSnapshot, _getCurrentCommittedSnapshotOpTime_inlock() also returns
         // default OpTime{}. Hence this branch only runs if _currentCommittedSnapshot actually
         // exists.
-        LOG(3) << "Got notified of new snapshot: " << _currentCommittedSnapshot->toString();
+        LOGV2_DEBUG(3, "Got notified of new snapshot: {}", "_currentCommittedSnapshot_toString"_attr = _currentCommittedSnapshot->toString());
     }
     return Status::OK();
 }
@@ -1596,8 +1588,7 @@ bool ReplicationCoordinatorImpl::_doneWaitingForReplication_inlock(
             // Wait for the "current" snapshot to advance to/past the opTime.
             const auto haveSnapshot = _currentCommittedSnapshot->opTime >= opTime;
             if (!haveSnapshot) {
-                LOG(1) << "Required snapshot optime: " << opTime << " is not yet part of the "
-                       << "current 'committed' snapshot: " << _currentCommittedSnapshot->opTime;
+                LOGV2_DEBUG(1, "Required snapshot optime: {} is not yet part of the current 'committed' snapshot: {}", "opTime"_attr = opTime, "_currentCommittedSnapshot_opTime"_attr = _currentCommittedSnapshot->opTime);
                 return false;
             }
 
@@ -1608,14 +1599,9 @@ bool ReplicationCoordinatorImpl::_doneWaitingForReplication_inlock(
         // removed from storage.
         if (auto dropOpTime = _externalState->getEarliestDropPendingOpTime()) {
             if (*dropOpTime <= opTime) {
-                LOG(1) << "Unable to satisfy the requested majority write concern at "
-                          "'committed' optime "
-                       << opTime
-                       << ". There are still drop pending collections (earliest drop optime: "
-                       << *dropOpTime
-                       << ") that have to be removed from storage before we can "
-                          "satisfy the write concern "
-                       << writeConcern.toBSON();
+                LOGV2_DEBUG(1, "Unable to satisfy the requested majority write concern at "
+                          "'committed' optime {}. There are still drop pending collections (earliest drop optime: {}) that have to be removed from storage before we can "
+                          "satisfy the write concern {}", "opTime"_attr = opTime, "dropOpTime"_attr = *dropOpTime, "writeConcern_toBSON"_attr = writeConcern.toBSON());
                 return false;
             }
         }
@@ -1675,9 +1661,7 @@ ReplicationCoordinator::StatusAndDuration ReplicationCoordinatorImpl::awaitRepli
 
     if (getTestCommandsEnabled() && !status.isOK()) {
         stdx::lock_guard lock(_mutex);
-        log() << "Replication failed for write concern: " << writeConcern.toBSON()
-              << ", waiting for optime: " << opTime << ", opID: " << opCtx->getOpID()
-              << ", progress: " << _getReplicationProgress(lock);
+        LOGV2("Replication failed for write concern: {}, waiting for optime: {}, opID: {}, progress: {}", "writeConcern_toBSON"_attr = writeConcern.toBSON(), "opTime"_attr = opTime, "opCtx_getOpID"_attr = opCtx->getOpID(), "_getReplicationProgress_lock"_attr = _getReplicationProgress(lock));
     }
     return {std::move(status), duration_cast<Milliseconds>(timer.elapsed())};
 }
@@ -1820,7 +1804,7 @@ void ReplicationCoordinatorImpl::updateAndLogStateTransitionMetrics(
     bob.appendNumber("userOpsKilled", userOpsKilled.get());
     bob.appendNumber("userOpsRunning", userOpsRunning.get());
 
-    log() << "State transition ops metrics: " << bob.obj();
+    LOGV2("State transition ops metrics: {}", "bob_obj"_attr = bob.obj());
 }
 
 std::shared_ptr<IsMasterResponse> ReplicationCoordinatorImpl::_makeIsMasterResponse(
@@ -1910,8 +1894,7 @@ std::shared_ptr<const IsMasterResponse> ReplicationCoordinatorImpl::awaitIsMaste
     lk.unlock();
 
     // Wait for a topology change with timeout set to deadline.
-    LOG(1) << "Waiting for an isMaster response from a topology change or until deadline: "
-           << deadline.get() << ". Current TopologyVersion counter is " << topologyVersionCounter;
+    LOGV2_DEBUG(1, "Waiting for an isMaster response from a topology change or until deadline: {}. Current TopologyVersion counter is {}", "deadline_get"_attr = deadline.get(), "topologyVersionCounter"_attr = topologyVersionCounter);
     auto statusWithIsMaster =
         futureGetNoThrowWithDeadline(opCtx, future, deadline.get(), opCtx->getTimeoutError());
     auto status = statusWithIsMaster.getStatus();
@@ -1988,7 +1971,7 @@ void ReplicationCoordinatorImpl::AutoGetRstlForStepUpStepDown::_killOpThreadFn()
 
     invariant(!cc().isFromUserConnection());
 
-    log() << "Starting to kill user operations";
+    LOGV2("Starting to kill user operations");
     auto uniqueOpCtx = cc().makeOperationContext();
     OperationContext* opCtx = uniqueOpCtx.get();
 
@@ -2016,7 +1999,7 @@ void ReplicationCoordinatorImpl::AutoGetRstlForStepUpStepDown::_killOpThreadFn()
             stdx::unique_lock<Latch> lock(_mutex);
             if (_stopKillingOps.wait_for(
                     lock, Milliseconds(10).toSystemDuration(), [this] { return _killSignaled; })) {
-                log() << "Stopped killing user operations";
+                LOGV2("Stopped killing user operations");
                 _replCord->updateAndLogStateTransitionMetrics(
                     _stateTransition, getUserOpsKilled(), getUserOpsRunning());
                 _killSignaled = false;
@@ -2127,9 +2110,9 @@ void ReplicationCoordinatorImpl::stepDown(OperationContext* opCtx,
         lk.unlock();
 
         if (MONGO_unlikely(stepdownHangBeforePerformingPostMemberStateUpdateActions.shouldFail())) {
-            log() << "stepping down from primary - "
+            LOGV2("stepping down from primary - "
                      "stepdownHangBeforePerformingPostMemberStateUpdateActions fail point enabled. "
-                     "Blocking until fail point is disabled.";
+                     "Blocking until fail point is disabled.");
             while (MONGO_unlikely(
                 stepdownHangBeforePerformingPostMemberStateUpdateActions.shouldFail())) {
                 mongo::sleepsecs(1);
@@ -2243,24 +2226,23 @@ void ReplicationCoordinatorImpl::_performElectionHandoff() {
     auto candidateIndex = _topCoord->chooseElectionHandoffCandidate();
 
     if (candidateIndex < 0) {
-        log() << "Could not find node to hand off election to.";
+        LOGV2("Could not find node to hand off election to.");
         return;
     }
 
     auto target = _rsConfig.getMemberAt(candidateIndex).getHostAndPort();
     executor::RemoteCommandRequest request(
         target, "admin", BSON("replSetStepUp" << 1 << "skipDryRun" << true), nullptr);
-    log() << "Handing off election to " << target;
+    LOGV2("Handing off election to {}", "target"_attr = target);
 
     auto callbackHandleSW = _replExecutor->scheduleRemoteCommand(
         request, [target](const executor::TaskExecutor::RemoteCommandCallbackArgs& callbackData) {
             auto status = callbackData.response.status;
 
             if (status.isOK()) {
-                LOG(1) << "replSetStepUp request to " << target << " succeeded with response -- "
-                       << callbackData.response.data;
+                LOGV2_DEBUG(1, "replSetStepUp request to {} succeeded with response -- {}", "target"_attr = target, "callbackData_response_data"_attr = callbackData.response.data);
             } else {
-                log() << "replSetStepUp request to " << target << " failed due to " << status;
+                LOGV2("replSetStepUp request to {} failed due to {}", "target"_attr = target, "status"_attr = status);
             }
         });
 
@@ -2569,16 +2551,14 @@ Status ReplicationCoordinatorImpl::setMaintenanceMode(bool activate) {
 
     int curMaintenanceCalls = _topCoord->getMaintenanceCount();
     if (activate) {
-        log() << "going into maintenance mode with " << curMaintenanceCalls
-              << " other maintenance mode tasks in progress" << rsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kRS}, "going into maintenance mode with {} other maintenance mode tasks in progress", "curMaintenanceCalls"_attr = curMaintenanceCalls);
         _topCoord->adjustMaintenanceCountBy(1);
     } else if (curMaintenanceCalls > 0) {
         invariant(_topCoord->getRole() == TopologyCoordinator::Role::kFollower);
 
         _topCoord->adjustMaintenanceCountBy(-1);
 
-        log() << "leaving maintenance mode (" << curMaintenanceCalls - 1
-              << " other maintenance mode tasks ongoing)" << rsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kRS}, "leaving maintenance mode ({} other maintenance mode tasks ongoing)", "curMaintenanceCalls_1"_attr = curMaintenanceCalls - 1);
     } else {
         warning() << "Attempted to leave maintenance mode but it is not currently active";
         return Status(ErrorCodes::OperationFailed, "already out of maintenance mode");
@@ -2709,8 +2689,7 @@ Status ReplicationCoordinatorImpl::processReplSetReconfig(OperationContext* opCt
                       myIndex.getStatus().reason());
     }
 
-    log() << "replSetReconfig config object with " << newConfig.getNumMembers()
-          << " members parses ok";
+    LOGV2("replSetReconfig config object with {} members parses ok", "newConfig_getNumMembers"_attr = newConfig.getNumMembers());
 
     if (!args.force) {
         status = checkQuorumForReconfig(
@@ -2747,8 +2726,7 @@ void ReplicationCoordinatorImpl::_finishReplSetReconfig(OperationContext* opCtx,
     // we have already set our ReplicationCoordinatorImpl::_rsConfigState state to
     // "kConfigReconfiguring" which prevents new elections from happening.
     if (electionFinishedEvent) {
-        LOG(2) << "Waiting for election to complete before finishing reconfig to version "
-               << newConfig.getConfigVersion();
+        LOGV2_DEBUG(2, "Waiting for election to complete before finishing reconfig to version {}", "newConfig_getConfigVersion"_attr = newConfig.getConfigVersion());
         // Wait for the election to complete and the node's Role to be set to follower.
         _replExecutor->waitForEvent(electionFinishedEvent);
     }
@@ -2766,7 +2744,7 @@ void ReplicationCoordinatorImpl::_finishReplSetReconfig(OperationContext* opCtx,
         lk.lock();
         if (_topCoord->isSteppingDownUnconditionally()) {
             invariant(opCtx->lockState()->isRSTLExclusive());
-            log() << "stepping down from primary, because we received a new config";
+            LOGV2("stepping down from primary, because we received a new config");
             // We need to release the mutex before yielding locks for prepared transactions, which
             // might check out sessions, to avoid deadlocks with checked-out sessions accessing
             // this mutex.
@@ -2808,7 +2786,7 @@ void ReplicationCoordinatorImpl::_finishReplSetReconfig(OperationContext* opCtx,
 Status ReplicationCoordinatorImpl::processReplSetInitiate(OperationContext* opCtx,
                                                           const BSONObj& configObj,
                                                           BSONObjBuilder* resultObj) {
-    log() << "replSetInitiate admin command received from client";
+    LOGV2("replSetInitiate admin command received from client");
 
     const auto replEnabled = _settings.usingReplSets();
     stdx::unique_lock<Latch> lk(_mutex);
@@ -2852,8 +2830,7 @@ Status ReplicationCoordinatorImpl::processReplSetInitiate(OperationContext* opCt
         return Status(ErrorCodes::InvalidReplicaSetConfig, myIndex.getStatus().reason());
     }
 
-    log() << "replSetInitiate config object with " << newConfig.getNumMembers()
-          << " members parses ok";
+    LOGV2("replSetInitiate config object with {} members parses ok", "newConfig_getNumMembers"_attr = newConfig.getNumMembers());
 
     // In pv1, the TopologyCoordinator has not set the term yet. It will be set to kInitialTerm if
     // the initiate succeeds so we pass that here.
@@ -3058,7 +3035,7 @@ ReplicationCoordinatorImpl::_updateMemberStateFromTopologyCoordinator(WithLock l
         _cancelPriorityTakeover_inlock();
     }
 
-    log() << "transition to " << newState << " from " << _memberState << rsLog;
+    LOGV2_OPTIONS({logv2::LogTag::kRS}, "transition to {} from {}", "newState"_attr = newState, "_memberState"_attr = _memberState);
     // Initializes the featureCompatibilityVersion to the latest value, because arbiters do not
     // receive the replicated version. This is to avoid bugs like SERVER-32639.
     if (newState.arbiter()) {
@@ -3130,7 +3107,7 @@ void ReplicationCoordinatorImpl::_onFollowerModeStateChange() {
 }
 
 void ReplicationCoordinatorImpl::CatchupState::start_inlock() {
-    log() << "Entering primary catch-up mode.";
+    LOGV2("Entering primary catch-up mode.");
 
     // Reset the number of catchup operations performed before starting catchup.
     _numCatchUpOps = 0;
@@ -3145,7 +3122,7 @@ void ReplicationCoordinatorImpl::CatchupState::start_inlock() {
 
     // When catchUpTimeoutMillis is 0, we skip doing catchup entirely.
     if (catchupTimeout == ReplSetConfig::kCatchUpDisabled) {
-        log() << "Skipping primary catchup since the catchup timeout is 0.";
+        LOGV2("Skipping primary catchup since the catchup timeout is 0.");
         abort_inlock(PrimaryCatchUpConclusionReason::kSkipped);
         return;
     }
@@ -3160,7 +3137,7 @@ void ReplicationCoordinatorImpl::CatchupState::start_inlock() {
         if (cbData.myHandle.isCanceled()) {
             return;
         }
-        log() << "Catchup timed out after becoming primary.";
+        LOGV2("Catchup timed out after becoming primary.");
         abort_inlock(PrimaryCatchUpConclusionReason::kTimedOut);
     };
 
@@ -3173,7 +3150,7 @@ void ReplicationCoordinatorImpl::CatchupState::start_inlock() {
     auto timeoutDate = _repl->_replExecutor->now() + catchupTimeout;
     auto status = _repl->_replExecutor->scheduleWorkAt(timeoutDate, std::move(timeoutCB));
     if (!status.isOK()) {
-        log() << "Failed to schedule catchup timeout work.";
+        LOGV2("Failed to schedule catchup timeout work.");
         abort_inlock(PrimaryCatchUpConclusionReason::kFailedWithError);
         return;
     }
@@ -3186,7 +3163,7 @@ void ReplicationCoordinatorImpl::CatchupState::abort_inlock(PrimaryCatchUpConclu
     ReplicationMetrics::get(getGlobalServiceContext())
         .incrementNumCatchUpsConcludedForReason(reason);
 
-    log() << "Exited primary catch-up mode.";
+    LOGV2("Exited primary catch-up mode.");
     // Clean up its own members.
     if (_timeoutCbh) {
         _repl->_replExecutor->cancel(_timeoutCbh);
@@ -3212,8 +3189,7 @@ void ReplicationCoordinatorImpl::CatchupState::signalHeartbeatUpdate_inlock() {
     // We've caught up.
     const auto myLastApplied = _repl->_getMyLastAppliedOpTime_inlock();
     if (*targetOpTime <= myLastApplied) {
-        log() << "Caught up to the latest optime known via heartbeats after becoming primary. "
-              << "Target optime: " << *targetOpTime << ". My Last Applied: " << myLastApplied;
+        LOGV2("Caught up to the latest optime known via heartbeats after becoming primary. Target optime: {}. My Last Applied: {}", "targetOpTime"_attr = *targetOpTime, "myLastApplied"_attr = myLastApplied);
         // Report the number of ops applied during catchup in replSetGetStatus once the primary is
         // caught up.
         ReplicationMetrics::get(getGlobalServiceContext()).setNumCatchUpOps(_numCatchUpOps);
@@ -3229,12 +3205,11 @@ void ReplicationCoordinatorImpl::CatchupState::signalHeartbeatUpdate_inlock() {
 
     ReplicationMetrics::get(getGlobalServiceContext()).setTargetCatchupOpTime(_targetOpTime);
 
-    log() << "Heartbeats updated catchup target optime to " << _targetOpTime;
-    log() << "Latest known optime per replica set member:";
+    LOGV2("Heartbeats updated catchup target optime to {}", "_targetOpTime"_attr = _targetOpTime);
+    LOGV2("Latest known optime per replica set member:");
     auto opTimesPerMember = _repl->_topCoord->latestKnownOpTimeSinceHeartbeatRestartPerMember();
     for (auto&& pair : opTimesPerMember) {
-        log() << "Member ID: " << pair.first
-              << ", latest known optime: " << (pair.second ? (*pair.second).toString() : "unknown");
+        LOGV2("Member ID: {}, latest known optime: {}", "pair_first"_attr = pair.first, "pair_second_pair_second_toString_unknown"_attr = (pair.second ? (*pair.second).toString() : "unknown"));
     }
 
     if (_waiter) {
@@ -3251,8 +3226,7 @@ void ReplicationCoordinatorImpl::CatchupState::signalHeartbeatUpdate_inlock() {
         // Double check the target time since stepdown may signal us too.
         const auto myLastApplied = _repl->_getMyLastAppliedOpTime_inlock();
         if (_targetOpTime <= myLastApplied) {
-            log() << "Caught up to the latest known optime successfully after becoming primary. "
-                  << "Target optime: " << _targetOpTime << ". My Last Applied: " << myLastApplied;
+            LOGV2("Caught up to the latest known optime successfully after becoming primary. Target optime: {}. My Last Applied: {}", "_targetOpTime"_attr = _targetOpTime, "myLastApplied"_attr = myLastApplied);
             // Report the number of ops applied during catchup in replSetGetStatus once the primary
             // is caught up.
             ReplicationMetrics::get(getGlobalServiceContext()).setNumCatchUpOps(_numCatchUpOps);
@@ -3323,21 +3297,15 @@ ReplicationCoordinatorImpl::_setCurrentRSConfig(WithLock lk,
     if (storageEngine && !storageEngine->isDurable() &&
         (newConfig.getWriteConcernMajorityShouldJournal() &&
          (!oldConfig.isInitialized() || !oldConfig.getWriteConcernMajorityShouldJournal()))) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: This replica set node is running without journaling enabled but the "
-              << startupWarningsLog;
-        log() << "**          writeConcernMajorityJournalDefault option to the replica set config "
-              << startupWarningsLog;
-        log() << "**          is set to true. The writeConcernMajorityJournalDefault "
-              << startupWarningsLog;
-        log() << "**          option to the replica set config must be set to false "
-              << startupWarningsLog;
-        log() << "**          or w:majority write concerns will never complete."
-              << startupWarningsLog;
-        log() << "**          In addition, this node's memory consumption may increase until all"
-              << startupWarningsLog;
-        log() << "**          available free RAM is exhausted." << startupWarningsLog;
-        log() << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: This replica set node is running without journaling enabled but the ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          writeConcernMajorityJournalDefault option to the replica set config ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          is set to true. The writeConcernMajorityJournalDefault ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          option to the replica set config must be set to false ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          or w:majority write concerns will never complete.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          In addition, this node's memory consumption may increase until all");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          available free RAM is exhausted.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
     }
 
     // Warn if using the in-memory (ephemeral) storage engine with
@@ -3345,30 +3313,24 @@ ReplicationCoordinatorImpl::_setCurrentRSConfig(WithLock lk,
     if (storageEngine && storageEngine->isEphemeral() &&
         (newConfig.getWriteConcernMajorityShouldJournal() &&
          (!oldConfig.isInitialized() || !oldConfig.getWriteConcernMajorityShouldJournal()))) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: This replica set node is using in-memory (ephemeral) storage with the"
-              << startupWarningsLog;
-        log() << "**          writeConcernMajorityJournalDefault option to the replica set config "
-              << startupWarningsLog;
-        log() << "**          set to true. The writeConcernMajorityJournalDefault option to the "
-              << startupWarningsLog;
-        log() << "**          replica set config must be set to false " << startupWarningsLog;
-        log() << "**          or w:majority write concerns will never complete."
-              << startupWarningsLog;
-        log() << "**          In addition, this node's memory consumption may increase until all"
-              << startupWarningsLog;
-        log() << "**          available free RAM is exhausted." << startupWarningsLog;
-        log() << startupWarningsLog;
-    }
-
-
-    log() << "New replica set config in use: " << _rsConfig.toBSON() << rsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: This replica set node is using in-memory (ephemeral) storage with the");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          writeConcernMajorityJournalDefault option to the replica set config ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          set to true. The writeConcernMajorityJournalDefault option to the ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          replica set config must be set to false ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          or w:majority write concerns will never complete.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          In addition, this node's memory consumption may increase until all");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          available free RAM is exhausted.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+    }
+
+
+    LOGV2_OPTIONS({logv2::LogTag::kRS}, "New replica set config in use: {}", "_rsConfig_toBSON"_attr = _rsConfig.toBSON());
     _selfIndex = myIndex;
     if (_selfIndex >= 0) {
-        log() << "This node is " << _rsConfig.getMemberAt(_selfIndex).getHostAndPort()
-              << " in the config";
+        LOGV2("This node is {} in the config", "_rsConfig_getMemberAt__selfIndex_getHostAndPort"_attr = _rsConfig.getMemberAt(_selfIndex).getHostAndPort());
     } else {
-        log() << "This node is not a member of the config";
+        LOGV2("This node is not a member of the config");
     }
 
     // Wake up writeConcern waiters that are no longer satisfiable due to the rsConfig change.
@@ -3764,7 +3726,7 @@ void ReplicationCoordinatorImpl::_setStableTimestampForStorage(WithLock lk) {
     // If there is a valid stable optime, set it for the storage engine, and then remove any
     // old, unneeded stable optime candidates.
     if (stableOpTime) {
-        LOG(2) << "Setting replication's stable optime to " << stableOpTime.value();
+        LOGV2_DEBUG(2, "Setting replication's stable optime to {}", "stableOpTime_value"_attr = stableOpTime.value());
 
         if (!gTestingSnapshotBehaviorInIsolation) {
             // Update committed snapshot and wake up any threads waiting on read concern or
@@ -3818,15 +3780,14 @@ void ReplicationCoordinatorImpl::finishRecoveryIfEligible(OperationContext* opCt
     // We can only transition to SECONDARY from RECOVERING state.
     MemberState state(getMemberState());
     if (!state.recovering()) {
-        LOG(2) << "We cannot transition to SECONDARY state since we are not currently in "
-                  "RECOVERING state. Current state: "
-               << state.toString();
+        LOGV2_DEBUG(2, "We cannot transition to SECONDARY state since we are not currently in "
+                  "RECOVERING state. Current state: {}", "state_toString"_attr = state.toString());
         return;
     }
 
     // Maintenance mode will force us to remain in RECOVERING state, no matter what.
     if (getMaintenanceMode()) {
-        LOG(1) << "We cannot transition to SECONDARY state while in maintenance mode.";
+        LOGV2_DEBUG(1, "We cannot transition to SECONDARY state while in maintenance mode.");
         return;
     }
 
@@ -3836,9 +3797,8 @@ void ReplicationCoordinatorImpl::finishRecoveryIfEligible(OperationContext* opCt
     auto lastApplied = getMyLastAppliedOpTime();
     auto minValid = _replicationProcess->getConsistencyMarkers()->getMinValid(opCtx);
     if (lastApplied < minValid) {
-        LOG(2) << "We cannot transition to SECONDARY state because our 'lastApplied' optime"
-                  " is less than the 'minValid' optime. minValid optime: "
-               << minValid << ", lastApplied optime: " << lastApplied;
+        LOGV2_DEBUG(2, "We cannot transition to SECONDARY state because our 'lastApplied' optime"
+                  " is less than the 'minValid' optime. minValid optime: {}, lastApplied optime: {}", "minValid"_attr = minValid, "lastApplied"_attr = lastApplied);
         return;
     }
 
@@ -4105,12 +4065,12 @@ EventHandle ReplicationCoordinatorImpl::_updateTerm_inlock(
             _pendingTermUpdateDuringStepDown = term;
         }
         if (_topCoord->prepareForUnconditionalStepDown()) {
-            log() << "stepping down from primary, because a new term has begun: " << term;
+            LOGV2("stepping down from primary, because a new term has begun: {}", "term"_attr = term);
             ReplicationMetrics::get(getServiceContext()).incrementNumStepDownsCausedByHigherTerm();
             return _stepDownStart();
         } else {
-            LOG(2) << "Updated term but not triggering stepdown because we are already in the "
-                      "process of stepping down";
+            LOGV2_DEBUG(2, "Updated term but not triggering stepdown because we are already in the "
+                      "process of stepping down");
         }
     }
     return EventHandle();
@@ -4168,7 +4128,7 @@ bool ReplicationCoordinatorImpl::_updateCommittedSnapshot(
     // If we are in ROLLBACK state, do not set any new _currentCommittedSnapshot, as it will be
     // cleared at the end of rollback anyway.
     if (_memberState.rollback()) {
-        log() << "Not updating committed snapshot because we are in rollback";
+        LOGV2("Not updating committed snapshot because we are in rollback");
         return false;
     }
     invariant(!newCommittedSnapshot.opTime.isNull());
diff --git a/src/mongo/db/repl/replication_coordinator_impl_elect_v1.cpp b/src/mongo/db/repl/replication_coordinator_impl_elect_v1.cpp
index 6d44c96bc0..b374e6ff32 100644
--- a/src/mongo/db/repl/replication_coordinator_impl_elect_v1.cpp
+++ b/src/mongo/db/repl/replication_coordinator_impl_elect_v1.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/repl/replication_metrics.h"
 #include "mongo/db/repl/topology_coordinator.h"
 #include "mongo/db/repl/vote_requester.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -55,7 +56,7 @@ public:
         if (_dismissed) {
             return;
         }
-        log() << "Lost " << (_isDryRun ? "dry run " : "") << "election due to internal error";
+        LOGV2("Lost {}election due to internal error", "_isDryRun_dry_run"_attr = (_isDryRun ? "dry run " : ""));
         _replCoord->_topCoord->processLoseElection();
         _replCoord->_voteRequester.reset(nullptr);
         if (_isDryRun && _replCoord->_electionDryRunFinishedEvent.isValid()) {
@@ -134,8 +135,8 @@ void ReplicationCoordinatorImpl::_startElectSelfV1_inlock(StartElectionReasonEnu
     const auto lastOpTime = _getMyLastAppliedOpTime_inlock();
 
     if (lastOpTime == OpTime()) {
-        log() << "not trying to elect self, "
-                 "do not yet have a complete set of data from any point in time";
+        LOGV2("not trying to elect self, "
+                 "do not yet have a complete set of data from any point in time");
         return;
     }
 
@@ -144,13 +145,13 @@ void ReplicationCoordinatorImpl::_startElectSelfV1_inlock(StartElectionReasonEnu
 
     if (reason == StartElectionReasonEnum::kStepUpRequestSkipDryRun) {
         long long newTerm = term + 1;
-        log() << "skipping dry run and running for election in term " << newTerm;
+        LOGV2("skipping dry run and running for election in term {}", "newTerm"_attr = newTerm);
         _startRealElection_inlock(newTerm, reason);
         lossGuard.dismiss();
         return;
     }
 
-    log() << "conducting a dry run election to see if we could be elected. current term: " << term;
+    LOGV2("conducting a dry run election to see if we could be elected. current term: {}", "term"_attr = term);
     _voteRequester.reset(new VoteRequester);
 
     // Only set primaryIndex if the primary's vote is required during the dry run.
@@ -186,29 +187,28 @@ void ReplicationCoordinatorImpl::_processDryRunResult(long long originalTerm,
     invariant(_voteRequester);
 
     if (_topCoord->getTerm() != originalTerm) {
-        log() << "not running for primary, we have been superseded already during dry run. "
-              << "original term: " << originalTerm << ", current term: " << _topCoord->getTerm();
+        LOGV2("not running for primary, we have been superseded already during dry run. original term: {}, current term: {}", "originalTerm"_attr = originalTerm, "_topCoord_getTerm"_attr = _topCoord->getTerm());
         return;
     }
 
     const VoteRequester::Result endResult = _voteRequester->getResult();
 
     if (endResult == VoteRequester::Result::kInsufficientVotes) {
-        log() << "not running for primary, we received insufficient votes";
+        LOGV2("not running for primary, we received insufficient votes");
         return;
     } else if (endResult == VoteRequester::Result::kStaleTerm) {
-        log() << "not running for primary, we have been superseded already";
+        LOGV2("not running for primary, we have been superseded already");
         return;
     } else if (endResult == VoteRequester::Result::kPrimaryRespondedNo) {
-        log() << "not running for primary, the current primary responded no in the dry run";
+        LOGV2("not running for primary, the current primary responded no in the dry run");
         return;
     } else if (endResult != VoteRequester::Result::kSuccessfullyElected) {
-        log() << "not running for primary, we received an unexpected problem";
+        LOGV2("not running for primary, we received an unexpected problem");
         return;
     }
 
     long long newTerm = originalTerm + 1;
-    log() << "dry election run succeeded, running for election in term " << newTerm;
+    LOGV2("dry election run succeeded, running for election in term {}", "newTerm"_attr = newTerm);
 
     _startRealElection_inlock(newTerm, reason);
     lossGuard.dismiss();
@@ -291,14 +291,13 @@ void ReplicationCoordinatorImpl::_writeLastVoteForMyElection(
     }
 
     if (!status.isOK()) {
-        log() << "failed to store LastVote document when voting for myself: " << status;
+        LOGV2("failed to store LastVote document when voting for myself: {}", "status"_attr = status);
         return;
     }
 
     if (_topCoord->getTerm() != lastVote.getTerm()) {
-        log() << "not running for primary, we have been superseded already while writing our last "
-                 "vote. election term: "
-              << lastVote.getTerm() << ", current term: " << _topCoord->getTerm();
+        LOGV2("not running for primary, we have been superseded already while writing our last "
+                 "vote. election term: {}, current term: {}", "lastVote_getTerm"_attr = lastVote.getTerm(), "_topCoord_getTerm"_attr = _topCoord->getTerm());
         return;
     }
     _startVoteRequester_inlock(lastVote.getTerm(), reason);
@@ -336,8 +335,7 @@ void ReplicationCoordinatorImpl::_onVoteRequestComplete(long long newTerm,
     invariant(_voteRequester);
 
     if (_topCoord->getTerm() != newTerm) {
-        log() << "not becoming primary, we have been superseded already during election. "
-              << "election term: " << newTerm << ", current term: " << _topCoord->getTerm();
+        LOGV2("not becoming primary, we have been superseded already during election. election term: {}, current term: {}", "newTerm"_attr = newTerm, "_topCoord_getTerm"_attr = _topCoord->getTerm());
         return;
     }
 
@@ -346,13 +344,13 @@ void ReplicationCoordinatorImpl::_onVoteRequestComplete(long long newTerm,
 
     switch (endResult) {
         case VoteRequester::Result::kInsufficientVotes:
-            log() << "not becoming primary, we received insufficient votes";
+            LOGV2("not becoming primary, we received insufficient votes");
             return;
         case VoteRequester::Result::kStaleTerm:
-            log() << "not becoming primary, we have been superseded already";
+            LOGV2("not becoming primary, we have been superseded already");
             return;
         case VoteRequester::Result::kSuccessfullyElected:
-            log() << "election succeeded, assuming primary role in term " << _topCoord->getTerm();
+            LOGV2("election succeeded, assuming primary role in term {}", "_topCoord_getTerm"_attr = _topCoord->getTerm());
             ReplicationMetrics::get(getServiceContext())
                 .incrementNumElectionsSuccessfulForReason(reason);
             break;
@@ -372,9 +370,8 @@ void ReplicationCoordinatorImpl::_onVoteRequestComplete(long long newTerm,
 
     electionHangsBeforeUpdateMemberState.execute([&](const BSONObj& customWait) {
         auto waitForMillis = Milliseconds(customWait["waitForMillis"].numberInt());
-        log() << "election succeeded - electionHangsBeforeUpdateMemberState fail point "
-                 "enabled, sleeping "
-              << waitForMillis;
+        LOGV2("election succeeded - electionHangsBeforeUpdateMemberState fail point "
+                 "enabled, sleeping {}", "waitForMillis"_attr = waitForMillis);
         sleepFor(waitForMillis);
     });
 
diff --git a/src/mongo/db/repl/replication_coordinator_impl_elect_v1_test.cpp b/src/mongo/db/repl/replication_coordinator_impl_elect_v1_test.cpp
index 06c6cd8b6c..f1f109069a 100644
--- a/src/mongo/db/repl/replication_coordinator_impl_elect_v1_test.cpp
+++ b/src/mongo/db/repl/replication_coordinator_impl_elect_v1_test.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/repl/replication_metrics.h"
 #include "mongo/db/repl/topology_coordinator.h"
 #include "mongo/executor/network_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -129,7 +130,7 @@ TEST_F(ReplCoordTest, ElectionSucceedsWhenNodeIsTheOnlyElectableNode) {
 
     auto electionTimeoutWhen = getReplCoord()->getElectionTimeout_forTest();
     ASSERT_NOT_EQUALS(Date_t(), electionTimeoutWhen);
-    log() << "Election timeout scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election timeout scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
 
     NetworkInterfaceMock* net = getNet();
     net->enterNetwork();
@@ -354,7 +355,7 @@ TEST_F(ReplCoordTest, ElectionFailsWhenInsufficientVotesAreReceivedDuringDryRun)
 
     auto electionTimeoutWhen = getReplCoord()->getElectionTimeout_forTest();
     ASSERT_NOT_EQUALS(Date_t(), electionTimeoutWhen);
-    log() << "Election timeout scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election timeout scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
 
     int voteRequests = 0;
     NetworkInterfaceMock* net = getNet();
@@ -366,7 +367,7 @@ TEST_F(ReplCoordTest, ElectionFailsWhenInsufficientVotesAreReceivedDuringDryRun)
         ASSERT_TRUE(net->hasReadyRequests());
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         if (consumeHeartbeatV1(noi)) {
             // The heartbeat has been consumed.
         } else if (request.cmdObj.firstElement().fieldNameStringData() == "replSetRequestVotes") {
@@ -422,7 +423,7 @@ TEST_F(ReplCoordTest, ElectionFailsWhenDryRunResponseContainsANewerTerm) {
 
     auto electionTimeoutWhen = getReplCoord()->getElectionTimeout_forTest();
     ASSERT_NOT_EQUALS(Date_t(), electionTimeoutWhen);
-    log() << "Election timeout scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election timeout scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
 
     int voteRequests = 0;
     NetworkInterfaceMock* net = getNet();
@@ -434,7 +435,7 @@ TEST_F(ReplCoordTest, ElectionFailsWhenDryRunResponseContainsANewerTerm) {
         ASSERT_TRUE(net->hasReadyRequests());
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         if (consumeHeartbeatV1(noi)) {
             // The heartbeat has been consumed.
         } else if (request.cmdObj.firstElement().fieldNameStringData() == "replSetRequestVotes") {
@@ -527,7 +528,7 @@ TEST_F(ReplCoordTest, NodeWillNotStandForElectionDuringHeartbeatReconfig) {
     for (int i = 0; i < 2; ++i) {
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         ReplSetHeartbeatArgsV1 hbArgs;
         if (hbArgs.initialize(request.cmdObj).isOK()) {
             ReplSetHeartbeatResponse hbResp;
@@ -552,7 +553,7 @@ TEST_F(ReplCoordTest, NodeWillNotStandForElectionDuringHeartbeatReconfig) {
     // Advance the simulator clock sufficiently to trigger an election.
     auto electionTimeoutWhen = getReplCoord()->getElectionTimeout_forTest();
     ASSERT_NOT_EQUALS(Date_t(), electionTimeoutWhen);
-    log() << "Election timeout scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election timeout scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
 
     net->enterNetwork();
     while (net->now() < electionTimeoutWhen) {
@@ -605,7 +606,7 @@ TEST_F(ReplCoordTest, ElectionFailsWhenInsufficientVotesAreReceivedDuringRequest
     while (net->hasReadyRequests()) {
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         if (request.cmdObj.firstElement().fieldNameStringData() != "replSetRequestVotes") {
             net->blackHole(noi);
         } else {
@@ -697,7 +698,7 @@ TEST_F(ReplCoordTest, ElectionFailsWhenVoteRequestResponseContainsANewerTerm) {
     while (net->hasReadyRequests()) {
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         if (request.cmdObj.firstElement().fieldNameStringData() != "replSetRequestVotes") {
             net->blackHole(noi);
         } else {
@@ -792,7 +793,7 @@ TEST_F(ReplCoordTest, ElectionFailsWhenTermChangesDuringActualElection) {
     while (net->hasReadyRequests()) {
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         if (request.cmdObj.firstElement().fieldNameStringData() != "replSetRequestVotes") {
             net->blackHole(noi);
         } else {
@@ -935,7 +936,7 @@ private:
             noi = net->getNextReadyRequest();
             auto&& request = noi->getRequest();
 
-            log() << request.target << " processing " << request.cmdObj << " at " << net->now();
+            LOGV2("{} processing {} at {}", "request_target"_attr = request.target, "request_cmdObj"_attr = request.cmdObj, "net_now"_attr = net->now());
 
             // Make sure the heartbeat request is valid.
             ReplSetHeartbeatArgsV1 hbArgs;
@@ -1538,10 +1539,10 @@ TEST_F(TakeoverTest, CatchupTakeoverDryRunFailsPrimarySaysNo) {
     NetworkInterfaceMock::NetworkOperationIterator noi_primary;
     Date_t until = net->now() + Seconds(1);
     while (voteRequests < votesExpected) {
-        unittest::log() << "request: " << voteRequests << " expected: " << votesExpected;
+        unittest::LOGV2("request: {} expected: {}", "voteRequests"_attr = voteRequests, "votesExpected"_attr = votesExpected);
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         if (request.cmdObj.firstElement().fieldNameStringData() != "replSetRequestVotes") {
             net->blackHole(noi);
         } else {
@@ -2110,13 +2111,13 @@ protected:
 
         auto electionTimeoutWhen = replCoord->getElectionTimeout_forTest();
         ASSERT_NOT_EQUALS(Date_t(), electionTimeoutWhen);
-        log() << "Election timeout scheduled at " << electionTimeoutWhen << " (simulator time)";
+        LOGV2("Election timeout scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
 
         ASSERT(replCoord->getMemberState().secondary()) << replCoord->getMemberState().toString();
         // Process requests until we're primary but leave the heartbeats for the notification
         // of election win. Exit immediately on unexpected requests.
         while (!replCoord->getMemberState().primary()) {
-            log() << "Waiting on network in state " << replCoord->getMemberState();
+            LOGV2("Waiting on network in state {}", "replCoord_getMemberState"_attr = replCoord->getMemberState());
             net->enterNetwork();
             if (net->now() < electionTimeoutWhen) {
                 net->runUntil(electionTimeoutWhen);
@@ -2124,7 +2125,7 @@ protected:
             // Peek the next request, don't consume it yet.
             const NetworkOpIter noi = net->getFrontOfUnscheduledQueue();
             const RemoteCommandRequest& request = noi->getRequest();
-            log() << request.target.toString() << " processing " << request.cmdObj;
+            LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
             if (ReplSetHeartbeatArgsV1().initialize(request.cmdObj).isOK()) {
                 OpTime opTime(Timestamp(), getReplCoord()->getTerm());
                 net->scheduleResponse(
@@ -2189,13 +2190,11 @@ protected:
         while (net->hasReadyRequests()) {
             const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
             const RemoteCommandRequest& request = noi->getRequest();
-            log() << request.target.toString() << " processing heartbeat " << request.cmdObj
-                  << " at " << net->now();
+            LOGV2("{} processing heartbeat {} at {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj, "net_now"_attr = net->now());
             if (ReplSetHeartbeatArgsV1().initialize(request.cmdObj).isOK()) {
                 onHeartbeatRequest(noi);
             } else {
-                log() << "Black holing unexpected request to " << request.target << ": "
-                      << request.cmdObj;
+                LOGV2("Black holing unexpected request to {}: {}", "request_target"_attr = request.target, "request_cmdObj"_attr = request.cmdObj);
                 net->blackHole(noi);
             }
             net->runReadyNetworkOperations();
@@ -2212,7 +2211,7 @@ protected:
                 // Peek the next request
                 auto noi = net->getFrontOfUnscheduledQueue();
                 auto& request = noi->getRequest();
-                log() << request.target << " at " << net->now() << " processing " << request.cmdObj;
+                LOGV2("{} at {} processing {}", "request_target"_attr = request.target, "net_now"_attr = net->now(), "request_cmdObj"_attr = request.cmdObj);
                 if (ReplSetHeartbeatArgsV1().initialize(request.cmdObj).isOK()) {
                     // Consume the next request
                     onHeartbeatRequest(net->getNextReadyRequest());
@@ -2414,7 +2413,7 @@ TEST_F(PrimaryCatchUpTest, HeartbeatTimeout) {
     replyHeartbeatsAndRunUntil(catchupTimeoutTime, [this, time1](const NetworkOpIter noi) {
         const RemoteCommandRequest& request = noi->getRequest();
         if (request.target.host() == "node2") {
-            log() << "Black holing heartbeat from " << request.target.host();
+            LOGV2("Black holing heartbeat from {}", "request_target_host"_attr = request.target.host());
             getNet()->blackHole(noi);
         } else {
             getNet()->scheduleResponse(noi, getNet()->now(), makeHeartbeatResponse(time1));
diff --git a/src/mongo/db/repl/replication_coordinator_impl_heartbeat.cpp b/src/mongo/db/repl/replication_coordinator_impl_heartbeat.cpp
index bc733ba345..c8b3530dd7 100644
--- a/src/mongo/db/repl/replication_coordinator_impl_heartbeat.cpp
+++ b/src/mongo/db/repl/replication_coordinator_impl_heartbeat.cpp
@@ -54,6 +54,7 @@
 #include "mongo/db/repl/topology_coordinator.h"
 #include "mongo/db/repl/vote_requester.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
@@ -271,11 +272,11 @@ stdx::unique_lock<Latch> ReplicationCoordinatorImpl::_handleHeartbeatResponseAct
         case HeartbeatResponseAction::StepDownSelf:
             invariant(action.getPrimaryConfigIndex() == _selfIndex);
             if (_topCoord->prepareForUnconditionalStepDown()) {
-                log() << "Stepping down from primary in response to heartbeat";
+                LOGV2("Stepping down from primary in response to heartbeat");
                 _stepDownStart();
             } else {
-                LOG(2) << "Heartbeat would have triggered a stepdown, but we're already in the "
-                          "process of stepping down";
+                LOGV2_DEBUG(2, "Heartbeat would have triggered a stepdown, but we're already in the "
+                          "process of stepping down");
             }
             break;
         case HeartbeatResponseAction::PriorityTakeover: {
@@ -322,8 +323,7 @@ void remoteStepdownCallback(const executor::TaskExecutor::RemoteCommandCallbackA
     }
 
     if (status.isOK()) {
-        LOG(1) << "stepdown of primary(" << cbData.request.target << ") succeeded with response -- "
-               << cbData.response.data;
+        LOGV2_DEBUG(1, "stepdown of primary({}) succeeded with response -- {}", "cbData_request_target"_attr = cbData.request.target, "cbData_response_data"_attr = cbData.response.data);
     } else {
         warning() << "stepdown of primary(" << cbData.request.target << ") failed due to "
                   << cbData.response.status;
@@ -341,7 +341,7 @@ void ReplicationCoordinatorImpl::_requestRemotePrimaryStepdown(const HostAndPort
                                            20LL)),
         nullptr);
 
-    log() << "Requesting " << target << " step down from primary";
+    LOGV2("Requesting {} step down from primary", "target"_attr = target);
     auto cbh = _replExecutor->scheduleRemoteCommand(request, remoteStepdownCallback);
     if (cbh.getStatus() != ErrorCodes::ShutdownInProgress) {
         fassert(18808, cbh.getStatus());
@@ -372,8 +372,8 @@ void ReplicationCoordinatorImpl::_stepDownFinish(
 
     if (MONGO_unlikely(blockHeartbeatStepdown.shouldFail())) {
         // This log output is used in js tests so please leave it.
-        log() << "stepDown - blockHeartbeatStepdown fail point enabled. "
-                 "Blocking until fail point is disabled.";
+        LOGV2("stepDown - blockHeartbeatStepdown fail point enabled. "
+                 "Blocking until fail point is disabled.");
 
         auto inShutdown = [&] {
             stdx::lock_guard<Latch> lk(_mutex);
@@ -487,8 +487,7 @@ void ReplicationCoordinatorImpl::_heartbeatReconfigStore(
     const executor::TaskExecutor::CallbackArgs& cbd, const ReplSetConfig& newConfig) {
 
     if (cbd.status.code() == ErrorCodes::CallbackCanceled) {
-        log() << "The callback to persist the replica set configuration was canceled - "
-              << "the configuration was not persisted but was used: " << newConfig.toBSON();
+        LOGV2("The callback to persist the replica set configuration was canceled - the configuration was not persisted but was used: {}", "newConfig_toBSON"_attr = newConfig.toBSON());
         return;
     }
 
@@ -625,7 +624,7 @@ void ReplicationCoordinatorImpl::_heartbeatReconfigFinish(
         lk.lock();
         if (_topCoord->isSteppingDownUnconditionally()) {
             invariant(opCtx->lockState()->isRSTLExclusive());
-            log() << "stepping down from primary, because we received a new config via heartbeat";
+            LOGV2("stepping down from primary, because we received a new config via heartbeat");
             // We need to release the mutex before yielding locks for prepared transactions, which
             // might check out sessions, to avoid deadlocks with checked-out sessions accessing
             // this mutex.
@@ -776,7 +775,7 @@ void ReplicationCoordinatorImpl::_scheduleNextLivenessUpdate_inlock() {
     }
 
     auto nextTimeout = earliestDate + _rsConfig.getElectionTimeoutPeriod();
-    LOG(3) << "scheduling next check at " << nextTimeout;
+    LOGV2_DEBUG(3, "scheduling next check at {}", "nextTimeout"_attr = nextTimeout);
 
     // It is possible we will schedule the next timeout in the past.
     // ThreadPoolTaskExecutor::_scheduleWorkAt() schedules its work immediately if it's given a
@@ -808,7 +807,7 @@ void ReplicationCoordinatorImpl::_cancelAndRescheduleLivenessUpdate_inlock(int u
 
 void ReplicationCoordinatorImpl::_cancelPriorityTakeover_inlock() {
     if (_priorityTakeoverCbh.isValid()) {
-        log() << "Canceling priority takeover callback";
+        LOGV2("Canceling priority takeover callback");
         _replExecutor->cancel(_priorityTakeoverCbh);
         _priorityTakeoverCbh = CallbackHandle();
         _priorityTakeoverWhen = Date_t();
@@ -817,7 +816,7 @@ void ReplicationCoordinatorImpl::_cancelPriorityTakeover_inlock() {
 
 void ReplicationCoordinatorImpl::_cancelCatchupTakeover_inlock() {
     if (_catchupTakeoverCbh.isValid()) {
-        log() << "Canceling catchup takeover callback";
+        LOGV2("Canceling catchup takeover callback");
         _replExecutor->cancel(_catchupTakeoverCbh);
         _catchupTakeoverCbh = CallbackHandle();
         _catchupTakeoverWhen = Date_t();
diff --git a/src/mongo/db/repl/replication_coordinator_impl_heartbeat_v1_test.cpp b/src/mongo/db/repl/replication_coordinator_impl_heartbeat_v1_test.cpp
index c26b8d114d..07a5a2f1e2 100644
--- a/src/mongo/db/repl/replication_coordinator_impl_heartbeat_v1_test.cpp
+++ b/src/mongo/db/repl/replication_coordinator_impl_heartbeat_v1_test.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/repl/replication_coordinator_test_fixture.h"
 #include "mongo/db/repl/topology_coordinator.h"
 #include "mongo/executor/network_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
@@ -416,7 +417,7 @@ TEST_F(ReplCoordHBV1Test,
     enterNetwork();
     const NetworkInterfaceMock::NetworkOperationIterator noi = getNet()->getNextReadyRequest();
     const RemoteCommandRequest& request = noi->getRequest();
-    log() << request.target.toString() << " processing " << request.cmdObj;
+    LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
     getNet()->scheduleResponse(
         noi,
         getNet()->now(),
@@ -490,11 +491,10 @@ TEST_F(ReplCoordHBV1Test, IgnoreTheContentsOfMetadataWhenItsReplicaSetIdDoesNotM
         const RemoteCommandRequest& request = noi->getRequest();
         if (request.target == host2 &&
             request.cmdObj.firstElement().fieldNameStringData() == "replSetHeartbeat") {
-            log() << request.target.toString() << " processing " << request.cmdObj;
+            LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
             net->scheduleResponse(noi, net->now(), heartbeatResponse);
         } else {
-            log() << "blackholing request to " << request.target.toString() << ": "
-                  << request.cmdObj;
+            LOGV2("blackholing request to {}: {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
             net->blackHole(noi);
         }
         net->runReadyNetworkOperations();
@@ -508,7 +508,7 @@ TEST_F(ReplCoordHBV1Test, IgnoreTheContentsOfMetadataWhenItsReplicaSetIdDoesNotM
     ASSERT_OK(getReplCoord()->processReplSetGetStatus(
         &statusBuilder, ReplicationCoordinator::ReplSetGetStatusResponseStyle::kBasic));
     auto statusObj = statusBuilder.obj();
-    unittest::log() << "replica set status = " << statusObj;
+    unittest::LOGV2("replica set status = {}", "statusObj"_attr = statusObj);
 
     ASSERT_EQ(mongo::Array, statusObj["members"].type());
     auto members = statusObj["members"].Array();
diff --git a/src/mongo/db/repl/replication_coordinator_impl_test.cpp b/src/mongo/db/repl/replication_coordinator_impl_test.cpp
index b0776c42eb..6b5f8151c1 100644
--- a/src/mongo/db/repl/replication_coordinator_impl_test.cpp
+++ b/src/mongo/db/repl/replication_coordinator_impl_test.cpp
@@ -63,6 +63,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/write_concern_options.h"
 #include "mongo/executor/network_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/oplog_query_metadata.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/stdx/future.h"
@@ -1320,7 +1321,7 @@ protected:
         getNet()->runUntil(getNet()->now() + heartbeatInterval);
         NetworkInterfaceMock::NetworkOperationIterator noi = getNet()->getNextReadyRequest();
         RemoteCommandRequest request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         ReplSetHeartbeatArgsV1 hbArgs;
         if (hbArgs.initialize(request.cmdObj).isOK()) {
             ReplSetHeartbeatResponse hbResp;
@@ -1336,7 +1337,7 @@ protected:
         }
         while (getNet()->hasReadyRequests()) {
             auto noi = getNet()->getNextReadyRequest();
-            log() << "Blackholing network request " << noi->getRequest().cmdObj;
+            LOGV2("Blackholing network request {}", "noi_getRequest_cmdObj"_attr = noi->getRequest().cmdObj);
             getNet()->blackHole(noi);
         }
 
@@ -1973,7 +1974,7 @@ protected:
             ReplSetHeartbeatArgsV1 hbArgs;
             ASSERT_OK(hbArgs.initialize(request.cmdObj));
 
-            log() << request.target.toString() << " processing " << request.cmdObj;
+            LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
 
             // Catch up 'numNodesCaughtUp' nodes out of 5.
             OpTime optimeResponse = (hbNum <= numNodesCaughtUp) ? optimePrimary : optimeLagged;
@@ -2369,7 +2370,7 @@ TEST_F(StepDownTest,
     getNet()->runUntil(getNet()->now() + Milliseconds(2000));
     NetworkInterfaceMock::NetworkOperationIterator noi = getNet()->getNextReadyRequest();
     RemoteCommandRequest request = noi->getRequest();
-    log() << "HB1: " << request.target.toString() << " processing " << request.cmdObj;
+    LOGV2("HB1: {} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
     ReplSetHeartbeatArgsV1 hbArgs;
     if (hbArgs.initialize(request.cmdObj).isOK()) {
         ReplSetHeartbeatResponse hbResp;
@@ -2655,7 +2656,7 @@ TEST_F(ReplCoordTest, NodeIncludesOtherMembersProgressInUpdatePositionCommand) {
         long long memberId = entry[UpdatePositionArgs::kMemberIdFieldName].Number();
         memberIds.insert(memberId);
         if (memberId == 0) {
-            log() << 0;
+            LOGV2("{}", "0"_attr = 0);
             ASSERT_OK(bsonExtractOpTimeField(
                 entry, UpdatePositionArgs::kAppliedOpTimeFieldName, &appliedOpTime));
             ASSERT_OK(bsonExtractOpTimeField(
@@ -2663,7 +2664,7 @@ TEST_F(ReplCoordTest, NodeIncludesOtherMembersProgressInUpdatePositionCommand) {
             ASSERT_EQUALS(optime1, appliedOpTime);
             ASSERT_EQUALS(optime1, durableOpTime);
         } else if (memberId == 1) {
-            log() << 1;
+            LOGV2("{}", "1"_attr = 1);
             ASSERT_OK(bsonExtractOpTimeField(
                 entry, UpdatePositionArgs::kAppliedOpTimeFieldName, &appliedOpTime));
             ASSERT_OK(bsonExtractOpTimeField(
@@ -2671,7 +2672,7 @@ TEST_F(ReplCoordTest, NodeIncludesOtherMembersProgressInUpdatePositionCommand) {
             ASSERT_EQUALS(optime2, appliedOpTime);
             ASSERT_EQUALS(OpTime(), durableOpTime);
         } else if (memberId == 2) {
-            log() << 2;
+            LOGV2("{}", "2"_attr = 2);
             ASSERT_OK(bsonExtractOpTimeField(
                 entry, UpdatePositionArgs::kAppliedOpTimeFieldName, &appliedOpTime));
             ASSERT_OK(bsonExtractOpTimeField(
@@ -2679,7 +2680,7 @@ TEST_F(ReplCoordTest, NodeIncludesOtherMembersProgressInUpdatePositionCommand) {
             ASSERT_EQUALS(optime3, appliedOpTime);
             ASSERT_EQUALS(optime3, durableOpTime);
         } else {
-            log() << 3;
+            LOGV2("{}", "3"_attr = 3);
             ASSERT_EQUALS(3, memberId);
             ASSERT_OK(bsonExtractOpTimeField(
                 entry, UpdatePositionArgs::kAppliedOpTimeFieldName, &appliedOpTime));
@@ -5107,7 +5108,7 @@ TEST_F(ReplCoordTest, PrepareOplogQueryMetadata) {
         &metadataBob);
 
     BSONObj metadata = metadataBob.done();
-    log() << metadata;
+    LOGV2("{}", "metadata"_attr = metadata);
 
     auto oqMetadata = rpc::OplogQueryMetadata::readFromMetadata(metadata);
     ASSERT_OK(oqMetadata.getStatus());
@@ -5213,12 +5214,12 @@ TEST_F(ReplCoordTest,
     const auto& request = noi->getRequest();
     ASSERT_EQUALS(HostAndPort("node2", 12345), request.target);
     ASSERT_EQUALS("replSetHeartbeat", request.cmdObj.firstElement().fieldNameStringData());
-    log() << "black holing " << noi->getRequest().cmdObj;
+    LOGV2("black holing {}", "noi_getRequest_cmdObj"_attr = noi->getRequest().cmdObj);
     net->blackHole(noi);
 
     // Advance simulator clock to some time before the first scheduled election.
     auto electionTimeoutWhen = replCoord->getElectionTimeout_forTest();
-    log() << "Election initially scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election initially scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
     ASSERT_GREATER_THAN(electionTimeoutWhen, net->now());
     auto until = net->now() + (electionTimeoutWhen - net->now()) / 2;
     net->runUntil(until);
@@ -5302,7 +5303,7 @@ TEST_F(ReplCoordTest,
     ASSERT_TRUE(net->hasReadyRequests());
     auto noi = net->getNextReadyRequest();
     auto&& request = noi->getRequest();
-    log() << "processing " << request.cmdObj;
+    LOGV2("processing {}", "request_cmdObj"_attr = request.cmdObj);
     ASSERT_EQUALS(HostAndPort("node2", 12345), request.target);
     ASSERT_EQUALS("replSetHeartbeat", request.cmdObj.firstElement().fieldNameStringData());
 
@@ -5359,7 +5360,7 @@ TEST_F(ReplCoordTest,
     ASSERT_TRUE(net->hasReadyRequests());
     auto noi = net->getNextReadyRequest();
     auto&& request = noi->getRequest();
-    log() << "processing " << request.cmdObj;
+    LOGV2("processing {}", "request_cmdObj"_attr = request.cmdObj);
     ASSERT_EQUALS(HostAndPort("node2", 12345), request.target);
 
     ASSERT_EQUALS("replSetHeartbeat", request.cmdObj.firstElement().fieldNameStringData());
@@ -5412,7 +5413,7 @@ TEST_F(ReplCoordTest,
     ASSERT_TRUE(net->hasReadyRequests());
     auto noi = net->getNextReadyRequest();
     auto&& request = noi->getRequest();
-    log() << "processing " << request.cmdObj;
+    LOGV2("processing {}", "request_cmdObj"_attr = request.cmdObj);
     ASSERT_EQUALS(HostAndPort("node2", 12345), request.target);
 
     ASSERT_EQUALS("replSetHeartbeat", request.cmdObj.firstElement().fieldNameStringData());
@@ -5460,7 +5461,7 @@ TEST_F(ReplCoordTest,
     ASSERT_TRUE(net->hasReadyRequests());
     auto noi = net->getNextReadyRequest();
     auto&& request = noi->getRequest();
-    log() << "processing " << request.cmdObj;
+    LOGV2("processing {}", "request_cmdObj"_attr = request.cmdObj);
     ASSERT_EQUALS(HostAndPort("node2", 12345), request.target);
 
     ASSERT_EQUALS("replSetHeartbeat", request.cmdObj.firstElement().fieldNameStringData());
@@ -5522,12 +5523,12 @@ TEST_F(ReplCoordTest, CancelAndRescheduleElectionTimeoutLogging) {
     const auto& request = noi->getRequest();
     ASSERT_EQUALS(HostAndPort("node2", 12345), request.target);
     ASSERT_EQUALS("replSetHeartbeat", request.cmdObj.firstElement().fieldNameStringData());
-    log() << "black holing " << noi->getRequest().cmdObj;
+    LOGV2("black holing {}", "noi_getRequest_cmdObj"_attr = noi->getRequest().cmdObj);
     net->blackHole(noi);
 
     // Advance simulator clock to some time after the first scheduled election.
     auto electionTimeoutWhen = replCoord->getElectionTimeout_forTest();
-    log() << "Election initially scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election initially scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
     ASSERT_GREATER_THAN(electionTimeoutWhen, net->now());
     auto until = electionTimeoutWhen + Milliseconds(1);
     net->runUntil(until);
diff --git a/src/mongo/db/repl/replication_coordinator_test_fixture.cpp b/src/mongo/db/repl/replication_coordinator_test_fixture.cpp
index e989785c50..f66a688501 100644
--- a/src/mongo/db/repl/replication_coordinator_test_fixture.cpp
+++ b/src/mongo/db/repl/replication_coordinator_test_fixture.cpp
@@ -52,6 +52,7 @@
 #include "mongo/executor/network_interface_mock.h"
 #include "mongo/executor/thread_pool_mock.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -217,7 +218,7 @@ void ReplCoordTest::assertStartSuccess(const BSONObj& configDoc, const HostAndPo
 
 executor::RemoteCommandResponse ReplCoordTest::makeResponseStatus(const BSONObj& doc,
                                                                   Milliseconds millis) {
-    log() << "Responding with " << doc << " (elapsed: " << millis << ")";
+    LOGV2("Responding with {} (elapsed: {})", "doc"_attr = doc, "millis"_attr = millis);
     return RemoteCommandResponse(doc, millis);
 }
 
@@ -229,7 +230,7 @@ void ReplCoordTest::simulateEnoughHeartbeatsForAllNodesUp() {
     for (int i = 0; i < rsConfig.getNumMembers() - 1; ++i) {
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         ReplSetHeartbeatArgsV1 hbArgs;
         if (hbArgs.initialize(request.cmdObj).isOK()) {
             ReplSetHeartbeatResponse hbResp;
@@ -260,12 +261,11 @@ void ReplCoordTest::simulateSuccessfulDryRun(
 
     auto electionTimeoutWhen = replCoord->getElectionTimeout_forTest();
     ASSERT_NOT_EQUALS(Date_t(), electionTimeoutWhen);
-    log() << "Election timeout scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election timeout scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
 
     int voteRequests = 0;
     int votesExpected = rsConfig.getNumMembers() / 2;
-    log() << "Simulating dry run responses - expecting " << votesExpected
-          << " replSetRequestVotes requests";
+    LOGV2("Simulating dry run responses - expecting {} replSetRequestVotes requests", "votesExpected"_attr = votesExpected);
     net->enterNetwork();
     while (voteRequests < votesExpected) {
         if (net->now() < electionTimeoutWhen) {
@@ -273,7 +273,7 @@ void ReplCoordTest::simulateSuccessfulDryRun(
         }
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         if (request.cmdObj.firstElement().fieldNameStringData() == "replSetRequestVotes") {
             ASSERT_TRUE(request.cmdObj.getBoolField("dryRun"));
             onDryRunRequest(request);
@@ -295,10 +295,9 @@ void ReplCoordTest::simulateSuccessfulDryRun(
         net->runReadyNetworkOperations();
     }
     net->exitNetwork();
-    log() << "Simulating dry run responses - scheduled " << voteRequests
-          << " replSetRequestVotes responses";
+    LOGV2("Simulating dry run responses - scheduled {} replSetRequestVotes responses", "voteRequests"_attr = voteRequests);
     getReplCoord()->waitForElectionDryRunFinish_forTest();
-    log() << "Simulating dry run responses - dry run completed";
+    LOGV2("Simulating dry run responses - dry run completed");
 }
 
 void ReplCoordTest::simulateSuccessfulDryRun() {
@@ -309,7 +308,7 @@ void ReplCoordTest::simulateSuccessfulDryRun() {
 void ReplCoordTest::simulateSuccessfulV1Election() {
     auto electionTimeoutWhen = getReplCoord()->getElectionTimeout_forTest();
     ASSERT_NOT_EQUALS(Date_t(), electionTimeoutWhen);
-    log() << "Election timeout scheduled at " << electionTimeoutWhen << " (simulator time)";
+    LOGV2("Election timeout scheduled at {} (simulator time)", "electionTimeoutWhen"_attr = electionTimeoutWhen);
 
     simulateSuccessfulV1ElectionAt(electionTimeoutWhen);
 }
@@ -324,14 +323,14 @@ void ReplCoordTest::simulateSuccessfulV1ElectionWithoutExitingDrainMode(Date_t e
     // Process requests until we're primary and consume the heartbeats for the notification
     // of election win.
     while (!replCoord->getMemberState().primary() || hasReadyRequests) {
-        log() << "Waiting on network in state " << replCoord->getMemberState();
+        LOGV2("Waiting on network in state {}", "replCoord_getMemberState"_attr = replCoord->getMemberState());
         getNet()->enterNetwork();
         if (net->now() < electionTime) {
             net->runUntil(electionTime);
         }
         const NetworkInterfaceMock::NetworkOperationIterator noi = net->getNextReadyRequest();
         const RemoteCommandRequest& request = noi->getRequest();
-        log() << request.target.toString() << " processing " << request.cmdObj;
+        LOGV2("{} processing {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         ReplSetHeartbeatArgsV1 hbArgs;
         Status status = hbArgs.initialize(request.cmdObj);
         if (status.isOK()) {
@@ -464,7 +463,7 @@ void ReplCoordTest::simulateCatchUpAbort() {
         auto noi = net->getNextReadyRequest();
         auto request = noi->getRequest();
         // Black hole heartbeat requests caused by time advance.
-        log() << "Black holing request to " << request.target.toString() << " : " << request.cmdObj;
+        LOGV2("Black holing request to {} : {}", "request_target_toString"_attr = request.target.toString(), "request_cmdObj"_attr = request.cmdObj);
         net->blackHole(noi);
         if (net->now() < heartbeatTimeoutWhen) {
             net->runUntil(heartbeatTimeoutWhen);
diff --git a/src/mongo/db/repl/replication_process.cpp b/src/mongo/db/repl/replication_process.cpp
index 117972289a..c01f748cc3 100644
--- a/src/mongo/db/repl/replication_process.cpp
+++ b/src/mongo/db/repl/replication_process.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/repl/rollback_gen.h"
 #include "mongo/db/repl/storage_interface.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -92,9 +93,9 @@ Status ReplicationProcess::refreshRollbackID(OperationContext* opCtx) {
     }
 
     if (kUninitializedRollbackId == _rbid) {
-        log() << "Rollback ID is " << rbidResult.getValue();
+        LOGV2("Rollback ID is {}", "rbidResult_getValue"_attr = rbidResult.getValue());
     } else {
-        log() << "Rollback ID is " << rbidResult.getValue() << " (previously " << _rbid << ")";
+        LOGV2("Rollback ID is {} (previously {})", "rbidResult_getValue"_attr = rbidResult.getValue(), "_rbid"_attr = _rbid);
     }
     _rbid = rbidResult.getValue();
 
@@ -122,7 +123,7 @@ Status ReplicationProcess::initializeRollbackID(OperationContext* opCtx) {
 
     auto initRbidSW = _storageInterface->initializeRollbackID(opCtx);
     if (initRbidSW.isOK()) {
-        log() << "Initialized the rollback ID to " << initRbidSW.getValue();
+        LOGV2("Initialized the rollback ID to {}", "initRbidSW_getValue"_attr = initRbidSW.getValue());
         _rbid = initRbidSW.getValue();
         invariant(kUninitializedRollbackId != _rbid);
     } else {
@@ -139,7 +140,7 @@ Status ReplicationProcess::incrementRollbackID(OperationContext* opCtx) {
     // If the rollback ID was incremented successfully, cache the new value in _rbid to be returned
     // the next time getRollbackID() is called.
     if (status.isOK()) {
-        log() << "Incremented the rollback ID to " << status.getValue();
+        LOGV2("Incremented the rollback ID to {}", "status_getValue"_attr = status.getValue());
         _rbid = status.getValue();
         invariant(kUninitializedRollbackId != _rbid);
     } else {
diff --git a/src/mongo/db/repl/replication_recovery.cpp b/src/mongo/db/repl/replication_recovery.cpp
index 2a4ae7d1c1..009efa9e06 100644
--- a/src/mongo/db/repl/replication_recovery.cpp
+++ b/src/mongo/db/repl/replication_recovery.cpp
@@ -50,6 +50,7 @@
 #include "mongo/db/storage/storage_parameters_gen.h"
 #include "mongo/db/transaction_history_iterator.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/timer.h"
 
@@ -90,8 +91,7 @@ public:
     void onBatchEnd(const StatusWith<OpTime>&, const std::vector<OplogEntry>&) final {}
 
     void complete(const OpTime& applyThroughOpTime) const {
-        log() << "Applied " << _numOpsApplied << " operations in " << _numBatches
-              << " batches. Last operation applied with optime: " << applyThroughOpTime;
+        LOGV2("Applied {} operations in {} batches. Last operation applied with optime: {}", "_numOpsApplied"_attr = _numOpsApplied, "_numBatches"_attr = _numBatches, "applyThroughOpTime"_attr = applyThroughOpTime);
     }
 
 private:
@@ -269,11 +269,9 @@ void ReplicationRecoveryImpl::recoverFromOplogAsStandalone(OperationContext* opC
         if (gTakeUnstableCheckpointOnShutdown) {
             // Ensure 'recoverFromOplogAsStandalone' with 'takeUnstableCheckpointOnShutdown'
             // is safely idempotent when it succeeds.
-            log() << "Recovering from unstable checkpoint with 'takeUnstableCheckpointOnShutdown'."
-                  << " Confirming that no oplog recovery is needed.";
+            LOGV2("Recovering from unstable checkpoint with 'takeUnstableCheckpointOnShutdown'. Confirming that no oplog recovery is needed.");
             _assertNoRecoveryNeededOnUnstableCheckpoint(opCtx);
-            log() << "Not doing any oplog recovery since there is an unstable checkpoint that is "
-                  << "up to date.";
+            LOGV2("Not doing any oplog recovery since there is an unstable checkpoint that is up to date.");
         } else {
             severe() << "Cannot use 'recoverFromOplogAsStandalone' without a stable checkpoint.";
             fassertFailedNoTrace(31229);
@@ -290,7 +288,7 @@ void ReplicationRecoveryImpl::recoverFromOplogAsStandalone(OperationContext* opC
 void ReplicationRecoveryImpl::recoverFromOplog(OperationContext* opCtx,
                                                boost::optional<Timestamp> stableTimestamp) try {
     if (_consistencyMarkers->getInitialSyncFlag(opCtx)) {
-        log() << "No recovery needed. Initial sync flag set.";
+        LOGV2("No recovery needed. Initial sync flag set.");
         return;  // Initial Sync will take over so no cleanup is needed.
     }
 
@@ -330,7 +328,7 @@ void ReplicationRecoveryImpl::recoverFromOplog(OperationContext* opCtx,
         topOfOplogSW.getStatus() == ErrorCodes::NamespaceNotFound) {
         // Oplog is empty. There are no oplog entries to apply, so we exit recovery and go into
         // initial sync.
-        log() << "No oplog entries to apply for recovery. Oplog is empty.";
+        LOGV2("No oplog entries to apply for recovery. Oplog is empty.");
         return;
     }
     fassert(40290, topOfOplogSW);
@@ -354,11 +352,9 @@ void ReplicationRecoveryImpl::_recoverFromStableTimestamp(OperationContext* opCt
     invariant(!stableTimestamp.isNull());
     invariant(!topOfOplog.isNull());
     const auto truncateAfterPoint = _consistencyMarkers->getOplogTruncateAfterPoint(opCtx);
-    log() << "Recovering from stable timestamp: " << stableTimestamp
-          << " (top of oplog: " << topOfOplog << ", appliedThrough: " << appliedThrough
-          << ", TruncateAfter: " << truncateAfterPoint << ")";
+    LOGV2("Recovering from stable timestamp: {} (top of oplog: {}, appliedThrough: {}, TruncateAfter: {})", "stableTimestamp"_attr = stableTimestamp, "topOfOplog"_attr = topOfOplog, "appliedThrough"_attr = appliedThrough, "truncateAfterPoint"_attr = truncateAfterPoint);
 
-    log() << "Starting recovery oplog application at the stable timestamp: " << stableTimestamp;
+    LOGV2("Starting recovery oplog application at the stable timestamp: {}", "stableTimestamp"_attr = stableTimestamp);
     _applyToEndOfOplog(opCtx, stableTimestamp, topOfOplog.getTimestamp());
 }
 
@@ -366,18 +362,16 @@ void ReplicationRecoveryImpl::_recoverFromUnstableCheckpoint(OperationContext* o
                                                              OpTime appliedThrough,
                                                              OpTime topOfOplog) {
     invariant(!topOfOplog.isNull());
-    log() << "Recovering from an unstable checkpoint (top of oplog: " << topOfOplog
-          << ", appliedThrough: " << appliedThrough << ")";
+    LOGV2("Recovering from an unstable checkpoint (top of oplog: {}, appliedThrough: {})", "topOfOplog"_attr = topOfOplog, "appliedThrough"_attr = appliedThrough);
 
     if (appliedThrough.isNull()) {
         // The appliedThrough would be null if we shut down cleanly or crashed as a primary. Either
         // way we are consistent at the top of the oplog.
-        log() << "No oplog entries to apply for recovery. appliedThrough is null.";
+        LOGV2("No oplog entries to apply for recovery. appliedThrough is null.");
     } else {
         // If the appliedThrough is not null, then we shut down uncleanly during secondary oplog
         // application and must apply from the appliedThrough to the top of the oplog.
-        log() << "Starting recovery oplog application at the appliedThrough: " << appliedThrough
-              << ", through the top of the oplog: " << topOfOplog;
+        LOGV2("Starting recovery oplog application at the appliedThrough: {}, through the top of the oplog: {}", "appliedThrough"_attr = appliedThrough, "topOfOplog"_attr = topOfOplog);
 
         // When `recoverFromOplog` truncates the oplog, that also happens to set the "oldest
         // timestamp" to the truncation point[1]. `_applyToEndOfOplog` will then perform writes
@@ -427,7 +421,7 @@ void ReplicationRecoveryImpl::_applyToEndOfOplog(OperationContext* opCtx,
     // Check if we have any unapplied ops in our oplog. It is important that this is done after
     // deleting the ragged end of the oplog.
     if (oplogApplicationStartPoint == topOfOplog) {
-        log() << "No oplog entries to apply for recovery. Start point is at the top of the oplog.";
+        LOGV2("No oplog entries to apply for recovery. Start point is at the top of the oplog.");
         return;  // We've applied all the valid oplog we have.
     } else if (oplogApplicationStartPoint > topOfOplog) {
         severe() << "Applied op " << oplogApplicationStartPoint.toBSON()
@@ -435,8 +429,7 @@ void ReplicationRecoveryImpl::_applyToEndOfOplog(OperationContext* opCtx,
         fassertFailedNoTrace(40313);
     }
 
-    log() << "Replaying stored operations from " << oplogApplicationStartPoint.toBSON()
-          << " (exclusive) to " << topOfOplog.toBSON() << " (inclusive).";
+    LOGV2("Replaying stored operations from {} (exclusive) to {} (inclusive).", "oplogApplicationStartPoint_toBSON"_attr = oplogApplicationStartPoint.toBSON(), "topOfOplog_toBSON"_attr = topOfOplog.toBSON());
 
     OplogBufferLocalOplog oplogBuffer(oplogApplicationStartPoint);
     oplogBuffer.startup(opCtx);
@@ -532,9 +525,9 @@ void ReplicationRecoveryImpl::_truncateOplogTo(OperationContext* opCtx,
         const auto tsElem = entry["ts"];
         if (count == 1) {
             if (tsElem.eoo())
-                LOG(2) << "Oplog tail entry: " << redact(entry);
+                LOGV2_DEBUG(2, "Oplog tail entry: {}", "redact_entry"_attr = redact(entry));
             else
-                LOG(2) << "Oplog tail entry ts field: " << tsElem;
+                LOGV2_DEBUG(2, "Oplog tail entry ts field: {}", "tsElem"_attr = tsElem);
         }
 
         if (tsElem.timestamp() < truncateTimestamp) {
@@ -544,8 +537,7 @@ void ReplicationRecoveryImpl::_truncateOplogTo(OperationContext* opCtx,
                 invariant(!oldestIDToDelete.isNull());
                 oplogCollection->cappedTruncateAfter(opCtx, oldestIDToDelete, inclusive);
             }
-            log() << "Replication recovery oplog truncation finished in: " << timer.millis()
-                  << "ms";
+            LOGV2("Replication recovery oplog truncation finished in: {}ms", "timer_millis"_attr = timer.millis());
             return;
         }
 
@@ -574,16 +566,13 @@ void ReplicationRecoveryImpl::_truncateOplogIfNeededAndThenClearOplogTruncateAft
         AutoGetCollectionForRead oplog(opCtx, NamespaceString::kRsOplogNamespace);
         invariant(oplog.getCollection());
 
-        log() << "The oplog truncation point (" << truncatePoint
-              << ") is equal to or earlier than the stable timestamp (" << stableTimestamp.get()
-              << "), so truncating after the stable timestamp instead";
+        LOGV2("The oplog truncation point ({}) is equal to or earlier than the stable timestamp ({}), so truncating after the stable timestamp instead", "truncatePoint"_attr = truncatePoint, "stableTimestamp_get"_attr = stableTimestamp.get());
 
         inclusive = false;
         truncatePoint = stableTimestamp.get();
     }
 
-    log() << "Removing unapplied oplog entries starting at: " << truncatePoint.toBSON() << ", "
-          << (inclusive ? "inclusive" : "not inclusive");
+    LOGV2("Removing unapplied oplog entries starting at: {}, {}", "truncatePoint_toBSON"_attr = truncatePoint.toBSON(), "inclusive_inclusive_not_inclusive"_attr = (inclusive ? "inclusive" : "not inclusive"));
     _truncateOplogTo(opCtx, truncatePoint, inclusive);
 
     // Clear the oplogTruncateAfterPoint now that we have removed any holes that might exist in the
diff --git a/src/mongo/db/repl/reporter.cpp b/src/mongo/db/repl/reporter.cpp
index f66eb93089..3db5df10cd 100644
--- a/src/mongo/db/repl/reporter.cpp
+++ b/src/mongo/db/repl/reporter.cpp
@@ -37,6 +37,7 @@
 #include "mongo/bson/util/bson_extract.h"
 #include "mongo/db/commands/server_status_metric.h"
 #include "mongo/db/repl/update_position_args.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/destructor_guard.h"
@@ -190,8 +191,7 @@ Status Reporter::trigger() {
 
     _status = scheduleResult.getStatus();
     if (!_status.isOK()) {
-        LOG(2) << "Reporter failed to schedule callback to prepare and send update command: "
-               << _status;
+        LOGV2_DEBUG(2, "Reporter failed to schedule callback to prepare and send update command: {}", "_status"_attr = _status);
         return _status;
     }
 
@@ -212,8 +212,7 @@ StatusWith<BSONObj> Reporter::_prepareCommand() {
 
     // If there was an error in preparing the command, abort and return that error.
     if (!prepareResult.isOK()) {
-        LOG(2) << "Reporter failed to prepare update command with status: "
-               << prepareResult.getStatus();
+        LOGV2_DEBUG(2, "Reporter failed to prepare update command with status: {}", "prepareResult_getStatus"_attr = prepareResult.getStatus());
         _status = prepareResult.getStatus();
         return _status;
     }
@@ -222,8 +221,7 @@ StatusWith<BSONObj> Reporter::_prepareCommand() {
 }
 
 void Reporter::_sendCommand_inlock(BSONObj commandRequest, Milliseconds netTimeout) {
-    LOG(2) << "Reporter sending slave oplog progress to upstream updater " << _target << ": "
-           << commandRequest;
+    LOGV2_DEBUG(2, "Reporter sending slave oplog progress to upstream updater {}: {}", "_target"_attr = _target, "commandRequest"_attr = commandRequest);
 
     auto scheduleResult = _executor->scheduleRemoteCommand(
         executor::RemoteCommandRequest(_target, "admin", commandRequest, nullptr, netTimeout),
@@ -233,7 +231,7 @@ void Reporter::_sendCommand_inlock(BSONObj commandRequest, Milliseconds netTimeo
 
     _status = scheduleResult.getStatus();
     if (!_status.isOK()) {
-        LOG(2) << "Reporter failed to schedule with status: " << _status;
+        LOGV2_DEBUG(2, "Reporter failed to schedule with status: {}", "_status"_attr = _status);
         if (_status != ErrorCodes::ShutdownInProgress) {
             fassert(34434, _status);
         }
@@ -272,8 +270,7 @@ void Reporter::_processResponseCallback(
         // sync target.
         if (_status == ErrorCodes::InvalidReplicaSetConfig &&
             _isTargetConfigNewerThanRequest(commandResult, rcbd.request.cmdObj)) {
-            LOG(1) << "Reporter found newer configuration on sync source: " << _target
-                   << ". Retrying.";
+            LOGV2_DEBUG(1, "Reporter found newer configuration on sync source: {}. Retrying.", "_target"_attr = _target);
             _status = Status::OK();
             // Do not resend update command immediately.
             _isWaitingToSendReporter = false;
diff --git a/src/mongo/db/repl/roll_back_local_operations.cpp b/src/mongo/db/repl/roll_back_local_operations.cpp
index 1e5b102a59..31ccfec31d 100644
--- a/src/mongo/db/repl/roll_back_local_operations.cpp
+++ b/src/mongo/db/repl/roll_back_local_operations.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/db/repl/roll_back_local_operations.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -114,7 +115,7 @@ StatusWith<RollBackLocalOperations::RollbackCommonPoint> RollBackLocalOperations
 
     while (getTimestamp(_localOplogValue) > getTimestamp(operation)) {
         _scanned++;
-        LOG(2) << "Local oplog entry to roll back: " << redact(_localOplogValue.first);
+        LOGV2_DEBUG(2, "Local oplog entry to roll back: {}", "redact__localOplogValue_first"_attr = redact(_localOplogValue.first));
         auto status = _rollbackOperation(_localOplogValue.first);
         if (!status.isOK()) {
             invariant(ErrorCodes::NoSuchKey != status.code());
diff --git a/src/mongo/db/repl/roll_back_local_operations_test.cpp b/src/mongo/db/repl/roll_back_local_operations_test.cpp
index 6d4261938e..09581e0c0e 100644
--- a/src/mongo/db/repl/roll_back_local_operations_test.cpp
+++ b/src/mongo/db/repl/roll_back_local_operations_test.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/repl/oplog_interface_mock.h"
 #include "mongo/db/repl/oplog_interface_remote.h"
 #include "mongo/db/repl/roll_back_local_operations.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 
 namespace {
@@ -326,14 +327,12 @@ public:
                                           int batchSize) override {
         if (_initFailuresLeft > 0) {
             _initFailuresLeft--;
-            unittest::log()
-                << "Throwing DBException on DBClientCursorForTest::query(). Failures left: "
-                << _initFailuresLeft;
+            unittest::LOGV2("Throwing DBException on DBClientCursorForTest::query(). Failures left: {}", "_initFailuresLeft"_attr = _initFailuresLeft);
             uasserted(50852, "Simulated network error");
             MONGO_UNREACHABLE;
         }
 
-        unittest::log() << "Returning success on DBClientCursorForTest::query()";
+        unittest::LOGV2("Returning success on DBClientCursorForTest::query()");
 
         BSONArrayBuilder builder;
         builder.append(makeOp(1));
diff --git a/src/mongo/db/repl/rollback_impl.cpp b/src/mongo/db/repl/rollback_impl.cpp
index b94f350d50..8b72427f98 100644
--- a/src/mongo/db/repl/rollback_impl.cpp
+++ b/src/mongo/db/repl/rollback_impl.cpp
@@ -62,6 +62,7 @@
 #include "mongo/db/session_txn_record_gen.h"
 #include "mongo/db/storage/remove_saver.h"
 #include "mongo/db/transaction_history_iterator.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_config_version.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -121,8 +122,7 @@ boost::optional<long long> _parseDroppedCollectionCount(const OplogEntry& oplogE
         return boost::none;
     }
 
-    LOG(2) << "Parsed collection count of " << count << " from " << desc
-           << ". oplog op: " << redact(oplogEntry.toBSON());
+    LOGV2_DEBUG(2, "Parsed collection count of {} from {}. oplog op: {}", "count"_attr = count, "desc"_attr = desc, "redact_oplogEntry_toBSON"_attr = redact(oplogEntry.toBSON()));
     return count;
 }
 
@@ -182,8 +182,8 @@ Status RollbackImpl::runRollback(OperationContext* opCtx) {
     _listener->onTransitionToRollback();
 
     if (MONGO_unlikely(rollbackHangAfterTransitionToRollback.shouldFail())) {
-        log() << "rollbackHangAfterTransitionToRollback fail point enabled. Blocking until fail "
-                 "point is disabled (rollback_impl).";
+        LOGV2("rollbackHangAfterTransitionToRollback fail point enabled. Blocking until fail "
+                 "point is disabled (rollback_impl).");
         rollbackHangAfterTransitionToRollback.pauseWhileSet(opCtx);
     }
 
@@ -251,7 +251,7 @@ Status RollbackImpl::runRollback(OperationContext* opCtx) {
     }
     _listener->onRollbackOpObserver(_observerInfo);
 
-    log() << "Rollback complete";
+    LOGV2("Rollback complete");
 
     return Status::OK();
 }
@@ -308,7 +308,7 @@ Status RollbackImpl::_transitionToRollback(OperationContext* opCtx) {
         return Status(ErrorCodes::ShutdownInProgress, "rollback shutting down");
     }
 
-    log() << "transition to ROLLBACK";
+    LOGV2("transition to ROLLBACK");
     {
         ReplicationStateTransitionLockGuard rstlLock(
             opCtx, MODE_X, ReplicationStateTransitionLockGuard::EnqueueOnly());
@@ -327,7 +327,7 @@ Status RollbackImpl::_transitionToRollback(OperationContext* opCtx) {
                               << "Cannot transition from "
                               << _replicationCoordinator->getMemberState().toString() << " to "
                               << MemberState(MemberState::RS_ROLLBACK).toString());
-            log() << status;
+            LOGV2("{}", "status"_attr = status);
             return status;
         }
     }
@@ -350,14 +350,12 @@ Status RollbackImpl::_awaitBgIndexCompletion(OperationContext* opCtx) {
 
     // Wait for all background operations to complete by waiting on each database.
     std::vector<StringData> dbNames(dbs.begin(), dbs.end());
-    log() << "Waiting for all background operations to complete before starting rollback";
+    LOGV2("Waiting for all background operations to complete before starting rollback");
     for (auto db : dbNames) {
         auto numInProg = BackgroundOperation::numInProgForDb(db);
         auto numInProgInCoordinator = IndexBuildsCoordinator::get(opCtx)->numInProgForDb(db);
         if (numInProg > 0 || numInProgInCoordinator > 0) {
-            LOG(1) << "Waiting for "
-                   << (numInProg > numInProgInCoordinator ? numInProg : numInProgInCoordinator)
-                   << " background operations to complete on database '" << db << "'";
+            LOGV2_DEBUG(1, "Waiting for {} background operations to complete on database '{}'", "numInProg_numInProgInCoordinator_numInProg_numInProgInCoordinator"_attr = (numInProg > numInProgInCoordinator ? numInProg : numInProgInCoordinator), "db"_attr = db);
             BackgroundOperation::awaitNoBgOpInProgForDb(db);
             IndexBuildsCoordinator::get(opCtx)->awaitNoBgOpInProgForDb(db);
         }
@@ -368,7 +366,7 @@ Status RollbackImpl::_awaitBgIndexCompletion(OperationContext* opCtx) {
         }
     }
 
-    log() << "Finished waiting for background operations to complete before rollback";
+    LOGV2("Finished waiting for background operations to complete before rollback");
     return Status::OK();
 }
 
@@ -478,7 +476,7 @@ void RollbackImpl::_runPhaseFromAbortToReconstructPreparedTxns(
         status = _writeRollbackFiles(opCtx);
         fassert(31228, status);
     } else {
-        log() << "Not writing rollback files. 'createRollbackDataFiles' set to false.";
+        LOGV2("Not writing rollback files. 'createRollbackDataFiles' set to false.");
     }
 
     // If there were rolled back operations on any session, invalidate all sessions.
@@ -497,10 +495,7 @@ void RollbackImpl::_runPhaseFromAbortToReconstructPreparedTxns(
 
     // Log the total number of insert and update operations that have been rolled back as a
     // result of recovering to the stable timestamp.
-    log() << "Rollback reverted " << _observerInfo.rollbackCommandCounts[kInsertCmdName]
-          << " insert operations, " << _observerInfo.rollbackCommandCounts[kUpdateCmdName]
-          << " update operations and " << _observerInfo.rollbackCommandCounts[kDeleteCmdName]
-          << " delete operations.";
+    LOGV2("Rollback reverted {} insert operations, {} update operations and {} delete operations.", "_observerInfo_rollbackCommandCounts_kInsertCmdName"_attr = _observerInfo.rollbackCommandCounts[kInsertCmdName], "_observerInfo_rollbackCommandCounts_kUpdateCmdName"_attr = _observerInfo.rollbackCommandCounts[kUpdateCmdName], "_observerInfo_rollbackCommandCounts_kDeleteCmdName"_attr = _observerInfo.rollbackCommandCounts[kDeleteCmdName]);
 
     // During replication recovery, we truncate all oplog entries with timestamps greater than
     // or equal to the oplog truncate after point. As a result, we must find the oplog entry
@@ -568,9 +563,7 @@ void RollbackImpl::_correctRecordStoreCounts(OperationContext* opCtx) {
         // if we just set the collection count here.
         if (sizeRecoveryState(opCtx->getServiceContext())
                 .collectionAlwaysNeedsSizeAdjustment(ident)) {
-            LOG(2) << "Not setting collection count to " << newCount << " for " << nss.ns() << " ("
-                   << uuid.toString() << ") [" << ident
-                   << "] because it is marked for size adjustment.";
+            LOGV2_DEBUG(2, "Not setting collection count to {} for {} ({}) [{}] because it is marked for size adjustment.", "newCount"_attr = newCount, "nss_ns"_attr = nss.ns(), "uuid_toString"_attr = uuid.toString(), "ident"_attr = ident);
             continue;
         }
 
@@ -578,8 +571,7 @@ void RollbackImpl::_correctRecordStoreCounts(OperationContext* opCtx) {
         // (most likely due to a 4.0 drop oplog entry without the count information), we will
         // determine the correct count here post-recovery using a collection scan.
         if (kCollectionScanRequired == newCount) {
-            log() << "Scanning collection " << nss.ns() << " (" << uuid.toString()
-                  << ") to fix collection count.";
+            LOGV2("Scanning collection {} ({}) to fix collection count.", "nss_ns"_attr = nss.ns(), "uuid_toString"_attr = uuid.toString());
             AutoGetCollectionForRead autoCollToScan(opCtx, nss);
             auto collToScan = autoCollToScan.getCollection();
             invariant(coll == collToScan,
@@ -612,8 +604,7 @@ void RollbackImpl::_correctRecordStoreCounts(OperationContext* opCtx) {
             warning() << "Failed to set count of " << nss.ns() << " (" << uuid.toString() << ") ["
                       << ident << "] to " << newCount << ". Received: " << status;
         } else {
-            LOG(2) << "Set collection count of " << nss.ns() << " (" << uuid.toString() << ") ["
-                   << ident << "] to " << newCount << ".";
+            LOGV2_DEBUG(2, "Set collection count of {} ({}) [{}] to {}.", "nss_ns"_attr = nss.ns(), "uuid_toString"_attr = uuid.toString(), "ident"_attr = ident, "newCount"_attr = newCount);
         }
     }
 }
@@ -622,7 +613,7 @@ Status RollbackImpl::_findRecordStoreCounts(OperationContext* opCtx) {
     const auto& catalog = CollectionCatalog::get(opCtx);
     auto storageEngine = opCtx->getServiceContext()->getStorageEngine();
 
-    log() << "finding record store counts";
+    LOGV2("finding record store counts");
     for (const auto& uiCount : _countDiffs) {
         auto uuid = uiCount.first;
         auto countDiff = uiCount.second;
@@ -681,9 +672,7 @@ Status RollbackImpl::_findRecordStoreCounts(OperationContext* opCtx) {
                       << oldCount << ". Count change: " << countDiff;
             newCount = 0;
         }
-        LOG(2) << "Record count of " << nss->ns() << " (" << uuid.toString()
-               << ") before rollback is " << oldCount << ". Setting it to " << newCount
-               << ", due to change of " << countDiff;
+        LOGV2_DEBUG(2, "Record count of {} ({}) before rollback is {}. Setting it to {}, due to change of {}", "nss_ns"_attr = nss->ns(), "uuid_toString"_attr = uuid.toString(), "oldCount"_attr = oldCount, "newCount"_attr = newCount, "countDiff"_attr = countDiff);
         _newCounts[uuid] = newCount;
     }
 
@@ -902,7 +891,7 @@ StatusWith<RollBackLocalOperations::RollbackCommonPoint> RollbackImpl::_findComm
         return Status(ErrorCodes::ShutdownInProgress, "rollback shutting down");
     }
 
-    log() << "finding common point";
+    LOGV2("finding common point");
 
     // We save some aggregate information about all operations that are rolled back, so that we can
     // pass this information to the rollback op observer. In most cases, other subsystems do not
@@ -934,7 +923,7 @@ StatusWith<RollBackLocalOperations::RollbackCommonPoint> RollbackImpl::_findComm
     auto stableTimestamp =
         _storageInterface->getLastStableRecoveryTimestamp(opCtx->getServiceContext());
 
-    log() << "Rollback common point is " << commonPointOpTime;
+    LOGV2("Rollback common point is {}", "commonPointOpTime"_attr = commonPointOpTime);
 
     // Rollback common point should be >= the replication commit point.
     invariant(commonPointOpTime.getTimestamp() >= lastCommittedOpTime.getTimestamp());
@@ -1029,8 +1018,7 @@ Timestamp RollbackImpl::_findTruncateTimestamp(
     auto truncatePointTime = OpTime::parseFromOplogEntry(truncatePointRecord->data.releaseToBson());
     invariant(truncatePointTime.getStatus());
 
-    log() << "Marking to truncate all oplog entries with timestamps greater than or equal to "
-          << truncatePointTime.getValue();
+    LOGV2("Marking to truncate all oplog entries with timestamps greater than or equal to {}", "truncatePointTime_getValue"_attr = truncatePointTime.getValue());
     return truncatePointTime.getValue().getTimestamp();
 }
 
@@ -1062,10 +1050,8 @@ Status RollbackImpl::_writeRollbackFiles(OperationContext* opCtx) {
         // Drop-pending collections are not visible to rollback via the catalog when they are
         // managed by the storage engine. See StorageEngine::supportsPendingDrops().
         if (!nss && storageEngine->supportsPendingDrops()) {
-            log() << "The collection with UUID " << uuid
-                  << " is missing in the CollectionCatalog. This could be due to a dropped "
-                     " collection. Not writing rollback file for uuid "
-                  << uuid;
+            LOGV2("The collection with UUID {} is missing in the CollectionCatalog. This could be due to a dropped "
+                     " collection. Not writing rollback file for uuid {}", "uuid"_attr = uuid, "uuid"_attr = uuid);
             continue;
         }
 
@@ -1084,8 +1070,7 @@ void RollbackImpl::_writeRollbackFileForNamespace(OperationContext* opCtx,
                                                   NamespaceString nss,
                                                   const SimpleBSONObjUnorderedSet& idSet) {
     RemoveSaver removeSaver(kRollbackRemoveSaverType, uuid.toString(), kRollbackRemoveSaverWhy);
-    log() << "Preparing to write deleted documents to a rollback file for collection " << nss.ns()
-          << " with uuid " << uuid.toString() << " to " << removeSaver.file().generic_string();
+    LOGV2("Preparing to write deleted documents to a rollback file for collection {} with uuid {} to {}", "nss_ns"_attr = nss.ns(), "uuid_toString"_attr = uuid.toString(), "removeSaver_file_generic_string"_attr = removeSaver.file().generic_string());
 
     // The RemoveSaver will save the data files in a directory structure similar to the following:
     //
@@ -1134,7 +1119,7 @@ Status RollbackImpl::_triggerOpObserver(OperationContext* opCtx) {
     if (_isInShutdown()) {
         return Status(ErrorCodes::ShutdownInProgress, "rollback shutting down");
     }
-    log() << "Triggering the rollback op observer";
+    LOGV2("Triggering the rollback op observer");
     opCtx->getServiceContext()->getOpObserver()->onReplicationRollback(opCtx, _observerInfo);
     return Status::OK();
 }
@@ -1143,7 +1128,7 @@ void RollbackImpl::_transitionFromRollbackToSecondary(OperationContext* opCtx) {
     invariant(opCtx);
     invariant(_replicationCoordinator->getMemberState() == MemberState(MemberState::RS_ROLLBACK));
 
-    log() << "transition to SECONDARY";
+    LOGV2("transition to SECONDARY");
 
     ReplicationStateTransitionLockGuard transitionGuard(opCtx, MODE_X);
 
@@ -1178,21 +1163,20 @@ void RollbackImpl::_resetDropPendingState(OperationContext* opCtx) {
 }
 
 void RollbackImpl::_summarizeRollback(OperationContext* opCtx) const {
-    log() << "Rollback summary:";
-    log() << "\tstart time: " << _rollbackStats.startTime;
-    log() << "\tend time: " << opCtx->getServiceContext()->getFastClockSource()->now();
-    log() << "\tsync source: " << _remoteOplog->hostAndPort().toString();
+    LOGV2("Rollback summary:");
+    LOGV2("\tstart time: {}", "_rollbackStats_startTime"_attr = _rollbackStats.startTime);
+    LOGV2("\tend time: {}", "opCtx_getServiceContext_getFastClockSource_now"_attr = opCtx->getServiceContext()->getFastClockSource()->now());
+    LOGV2("\tsync source: {}", "_remoteOplog_hostAndPort_toString"_attr = _remoteOplog->hostAndPort().toString());
     log() << "\trollback data file directory: "
           << _rollbackStats.rollbackDataFileDirectory.value_or("none; no files written");
     if (_rollbackStats.rollbackId) {
-        log() << "\trollback id: " << *_rollbackStats.rollbackId;
+        LOGV2("\trollback id: {}", "_rollbackStats_rollbackId"_attr = *_rollbackStats.rollbackId);
     }
     if (_rollbackStats.lastLocalOptime) {
-        log() << "\tlast optime on branch of history rolled back: "
-              << *_rollbackStats.lastLocalOptime;
+        LOGV2("\tlast optime on branch of history rolled back: {}", "_rollbackStats_lastLocalOptime"_attr = *_rollbackStats.lastLocalOptime);
     }
     if (_rollbackStats.commonPoint) {
-        log() << "\tcommon point optime: " << *_rollbackStats.commonPoint;
+        LOGV2("\tcommon point optime: {}", "_rollbackStats_commonPoint"_attr = *_rollbackStats.commonPoint);
     }
     if (_rollbackStats.lastLocalWallClockTime &&
         _rollbackStats.firstOpWallClockTimeAfterCommonPoint) {
@@ -1203,36 +1187,31 @@ void RollbackImpl::_summarizeRollback(OperationContext* opCtx) const {
         unsigned long long diff =
             durationCount<Seconds>(Milliseconds(lastWall - firstOpWallClockTimeAfterCommonPoint));
 
-        log() << "\tlast wall clock time on the branch of history rolled back: " << lastWall;
-        log() << "\twall clock time of the first operation after the common point: "
-              << firstOpWallClockTimeAfterCommonPoint;
-        log() << "\tdifference in wall clock times: " << diff << " second(s)";
+        LOGV2("\tlast wall clock time on the branch of history rolled back: {}", "lastWall"_attr = lastWall);
+        LOGV2("\twall clock time of the first operation after the common point: {}", "firstOpWallClockTimeAfterCommonPoint"_attr = firstOpWallClockTimeAfterCommonPoint);
+        LOGV2("\tdifference in wall clock times: {} second(s)", "diff"_attr = diff);
     }
     if (_rollbackStats.truncateTimestamp) {
-        log() << "\ttruncate timestamp: " << *_rollbackStats.truncateTimestamp;
+        LOGV2("\ttruncate timestamp: {}", "_rollbackStats_truncateTimestamp"_attr = *_rollbackStats.truncateTimestamp);
     }
     if (_rollbackStats.stableTimestamp) {
-        log() << "\tstable timestamp: " << *_rollbackStats.stableTimestamp;
+        LOGV2("\tstable timestamp: {}", "_rollbackStats_stableTimestamp"_attr = *_rollbackStats.stableTimestamp);
     }
-    log() << "\tshard identity document rolled back: " << std::boolalpha
-          << _observerInfo.shardIdentityRolledBack;
-    log() << "\tconfig server config version document rolled back: " << std::boolalpha
-          << _observerInfo.configServerConfigVersionRolledBack;
-    log() << "\taffected sessions: " << (_observerInfo.rollbackSessionIds.empty() ? "none" : "");
+    LOGV2("\tshard identity document rolled back: {}", "_observerInfo_shardIdentityRolledBack"_attr = _observerInfo.shardIdentityRolledBack);
+    LOGV2("\tconfig server config version document rolled back: {}", "_observerInfo_configServerConfigVersionRolledBack"_attr = _observerInfo.configServerConfigVersionRolledBack);
+    LOGV2("\taffected sessions: {}", "_observerInfo_rollbackSessionIds_empty_none"_attr = (_observerInfo.rollbackSessionIds.empty() ? "none" : ""));
     for (const auto& sessionId : _observerInfo.rollbackSessionIds) {
-        log() << "\t\t" << sessionId;
+        LOGV2("\t\t{}", "sessionId"_attr = sessionId);
     }
-    log() << "\taffected namespaces: " << (_observerInfo.rollbackNamespaces.empty() ? "none" : "");
+    LOGV2("\taffected namespaces: {}", "_observerInfo_rollbackNamespaces_empty_none"_attr = (_observerInfo.rollbackNamespaces.empty() ? "none" : ""));
     for (const auto& nss : _observerInfo.rollbackNamespaces) {
-        log() << "\t\t" << nss.ns();
+        LOGV2("\t\t{}", "nss_ns"_attr = nss.ns());
     }
-    log() << "\tcounts of interesting commands rolled back: "
-          << (_observerInfo.rollbackCommandCounts.empty() ? "none" : "");
+    LOGV2("\tcounts of interesting commands rolled back: {}", "_observerInfo_rollbackCommandCounts_empty_none"_attr = (_observerInfo.rollbackCommandCounts.empty() ? "none" : ""));
     for (const auto& entry : _observerInfo.rollbackCommandCounts) {
-        log() << "\t\t" << entry.first << ": " << entry.second;
+        LOGV2("\t\t{}: {}", "entry_first"_attr = entry.first, "entry_second"_attr = entry.second);
     }
-    log() << "\ttotal number of entries rolled back (including no-ops): "
-          << _observerInfo.numberOfEntriesObserved;
+    LOGV2("\ttotal number of entries rolled back (including no-ops): {}", "_observerInfo_numberOfEntriesObserved"_attr = _observerInfo.numberOfEntriesObserved);
 }
 
 }  // namespace repl
diff --git a/src/mongo/db/repl/rollback_impl_test.cpp b/src/mongo/db/repl/rollback_impl_test.cpp
index 3907363362..dfe7f2e5f0 100644
--- a/src/mongo/db/repl/rollback_impl_test.cpp
+++ b/src/mongo/db/repl/rollback_impl_test.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/s/shard_identity_rollback_notifier.h"
 #include "mongo/db/s/type_shard_identity.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_config_version.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/transport/session.h"
@@ -113,10 +114,9 @@ protected:
                                         UUID uuid,
                                         NamespaceString nss,
                                         const SimpleBSONObjUnorderedSet& idSet) final {
-        log() << "Simulating writing a rollback file for namespace " << nss.ns() << " with uuid "
-              << uuid;
+        LOGV2("Simulating writing a rollback file for namespace {} with uuid {}", "nss_ns"_attr = nss.ns(), "uuid"_attr = uuid);
         for (auto&& id : idSet) {
-            log() << "Looking up " << id.jsonString(JsonStringFormat::LegacyStrict);
+            LOGV2("Looking up {}", "id_jsonString_JsonStringFormat_LegacyStrict"_attr = id.jsonString(JsonStringFormat::LegacyStrict));
             auto document = _findDocumentById(opCtx, uuid, nss, id.firstElement());
             if (document) {
                 _uuidToObjsMap[uuid].push_back(*document);
@@ -531,12 +531,12 @@ TEST_F(RollbackImplTest, RollbackKillsNecessaryOperations) {
     }
 
     // We assume that an interrupted opCtx would release its locks.
-    unittest::log() << "Both opCtx's marked for kill";
+    unittest::LOGV2("Both opCtx's marked for kill");
     ASSERT_EQ(ErrorCodes::InterruptedDueToReplStateChange, writeOpCtx->checkForInterruptNoAssert());
     globalWrite = boost::none;
     ASSERT_EQ(ErrorCodes::InterruptedDueToReplStateChange, readOpCtx->checkForInterruptNoAssert());
     globalRead = boost::none;
-    unittest::log() << "Both opCtx's were interrupted";
+    unittest::LOGV2("Both opCtx's were interrupted");
 
     rollbackThread.join();
     ASSERT_OK(status);
@@ -879,7 +879,7 @@ DEATH_TEST_F(RollbackImplTest,
     _storageInterface->setStableTimestamp(nullptr, Timestamp(1, 1));
 
     auto status = _rollback->runRollback(_opCtx.get());
-    unittest::log() << "Mongod did not crash. Status: " << status;
+    unittest::LOGV2("Mongod did not crash. Status: {}", "status"_attr = status);
     MONGO_UNREACHABLE;
 }
 
@@ -1753,7 +1753,7 @@ DEATH_TEST_F(RollbackImplObserverInfoTest,
         Timestamp(2, 2), boost::none, "admin.$cmd", BSON("applyOps" << subops.arr()), 2);
 
     auto status = _rollback->_namespacesForOp_forTest(OplogEntry(applyOpsCmdOp.first));
-    unittest::log() << "Mongod did not crash. Status: " << status.getStatus();
+    unittest::LOGV2("Mongod did not crash. Status: {}", "status_getStatus"_attr = status.getStatus());
     MONGO_UNREACHABLE;
 }
 
@@ -1855,7 +1855,7 @@ DEATH_TEST_F(RollbackImplObserverInfoTest,
     ASSERT_OK(_insertOplogEntry(unknownCmdOp.first));
 
     auto status = _rollback->runRollback(_opCtx.get());
-    unittest::log() << "Mongod did not crash. Status: " << status;
+    unittest::LOGV2("Mongod did not crash. Status: {}", "status"_attr = status);
     MONGO_UNREACHABLE;
 }
 
diff --git a/src/mongo/db/repl/rs_rollback.cpp b/src/mongo/db/repl/rs_rollback.cpp
index 5e3b43c70e..148a3028e9 100644
--- a/src/mongo/db/repl/rs_rollback.cpp
+++ b/src/mongo/db/repl/rs_rollback.cpp
@@ -75,6 +75,7 @@
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/storage/remove_saver.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/exit.h"
@@ -132,9 +133,8 @@ void FixUpInfo::removeRedundantOperations() {
 }
 
 bool FixUpInfo::removeRedundantIndexCommands(UUID uuid, std::string indexName) {
-    LOG(2) << "Attempting to remove redundant index operations from the set of indexes to create "
-              "for collection "
-           << uuid << ", for index '" << indexName << "'";
+    LOGV2_DEBUG(2, "Attempting to remove redundant index operations from the set of indexes to create "
+              "for collection {}, for index '{}'", "uuid"_attr = uuid, "indexName"_attr = indexName);
 
     // See if there are any indexes to create for this collection.
     auto indexes = indexesToCreate.find(uuid);
@@ -142,10 +142,7 @@ bool FixUpInfo::removeRedundantIndexCommands(UUID uuid, std::string indexName) {
     // There are no indexes to create for this collection UUID, so there are no index creation
     // operations to remove.
     if (indexes == indexesToCreate.end()) {
-        LOG(2)
-            << "Collection " << uuid
-            << " has no indexes to create. Not removing any index creation operations for index '"
-            << indexName << "'.";
+        LOGV2_DEBUG(2, "Collection {} has no indexes to create. Not removing any index creation operations for index '{}'.", "uuid"_attr = uuid, "indexName"_attr = indexName);
         return false;
     }
 
@@ -156,15 +153,13 @@ bool FixUpInfo::removeRedundantIndexCommands(UUID uuid, std::string indexName) {
     // If this index was not previously added to the set of indexes that need to be created for this
     // collection, then we do nothing.
     if (indexesToCreateForColl->find(indexName) == indexesToCreateForColl->end()) {
-        LOG(2) << "Index '" << indexName << "' was not previously set to be created for collection "
-               << uuid << ". Not removing any index creation operations.";
+        LOGV2_DEBUG(2, "Index '{}' was not previously set to be created for collection {}. Not removing any index creation operations.", "indexName"_attr = indexName, "uuid"_attr = uuid);
         return false;
     }
 
     // This index was previously added to the set of indexes to create for this collection, so we
     // remove it from that set.
-    LOG(2) << "Index '" << indexName << "' was previously set to be created for collection " << uuid
-           << ". Removing this redundant index creation operation.";
+    LOGV2_DEBUG(2, "Index '{}' was previously set to be created for collection {}. Removing this redundant index creation operation.", "indexName"_attr = indexName, "uuid"_attr = uuid);
     indexesToCreateForColl->erase(indexName);
     // If there are now no remaining indexes to create for this collection, remove it from
     // the set of collections that we need to create indexes for.
@@ -323,8 +318,7 @@ Status rollback_internal::updateFixUpInfoFromLocalOplogEntry(OperationContext* o
     const OplogEntry oplogEntry(fixedObj);
 
     if (isNestedApplyOpsCommand) {
-        LOG(2) << "Updating rollback FixUpInfo for nested applyOps oplog entry: "
-               << redact(oplogEntry.toBSON());
+        LOGV2_DEBUG(2, "Updating rollback FixUpInfo for nested applyOps oplog entry: {}", "redact_oplogEntry_toBSON"_attr = redact(oplogEntry.toBSON()));
     }
 
     // Extract the op's collection namespace and UUID.
@@ -525,9 +519,8 @@ Status rollback_internal::updateFixUpInfoFromLocalOplogEntry(OperationContext* o
                 auto buildUUID = indexBuildOplogObject.buildUUID;
                 auto existingIt = buildsToRestart.find(buildUUID);
                 if (existingIt != buildsToRestart.end()) {
-                    LOG(2) << "Index build that was previously marked to be restarted will now be "
-                              "dropped due to a rolled-back 'startIndexBuild' oplog entry: "
-                           << buildUUID;
+                    LOGV2_DEBUG(2, "Index build that was previously marked to be restarted will now be "
+                              "dropped due to a rolled-back 'startIndexBuild' oplog entry: {}", "buildUUID"_attr = buildUUID);
                     buildsToRestart.erase(existingIt);
 
                     // If the index build was committed or aborted, we must mark the index as
@@ -566,8 +559,7 @@ Status rollback_internal::updateFixUpInfoFromLocalOplogEntry(OperationContext* o
                                  "UUID is already marked to be restarted: "
                               << buildUUID);
 
-                LOG(2) << "Index build will be restarted after a rolled-back 'abortIndexBuild': "
-                       << buildUUID;
+                LOGV2_DEBUG(2, "Index build will be restarted after a rolled-back 'abortIndexBuild': {}", "buildUUID"_attr = buildUUID);
                 IndexBuildDetails details{*uuid};
                 for (auto& spec : indexBuildOplogObject.indexSpecs) {
                     invariant(spec.isOwned());
@@ -608,8 +600,7 @@ Status rollback_internal::updateFixUpInfoFromLocalOplogEntry(OperationContext* o
                                  "UUID is already marked to be restarted: "
                               << buildUUID);
 
-                LOG(2) << "Index build will be restarted after a rolled-back 'commitIndexBuild': "
-                       << buildUUID;
+                LOGV2_DEBUG(2, "Index build will be restarted after a rolled-back 'commitIndexBuild': {}", "buildUUID"_attr = buildUUID);
 
                 IndexBuildDetails details{*uuid};
                 for (auto& spec : indexBuildOplogObject.indexSpecs) {
@@ -637,7 +628,7 @@ Status rollback_internal::updateFixUpInfoFromLocalOplogEntry(OperationContext* o
                 if (ns.empty()) {
                     std::string message = str::stream()
                         << "Collection name missing from oplog entry: " << redact(obj);
-                    log() << message;
+                    LOGV2("{}", "message"_attr = message);
                     return Status(ErrorCodes::UnrecoverableRollbackError, message);
                 }
 
@@ -845,7 +836,7 @@ void checkRbidAndUpdateMinValid(OperationContext* opCtx,
     // RECOVERING state to SECONDARY state until we have reached the minValid oplog entry.
 
     OpTime minValid = fassert(40492, OpTime::parseFromOplogEntry(newMinValidDoc));
-    log() << "Setting minvalid to " << minValid;
+    LOGV2("Setting minvalid to {}", "minValid"_attr = minValid);
 
     // This method is only used with storage engines that do not support recover to stable
     // timestamp. As a result, the timestamp on the 'appliedThrough' update does not matter.
@@ -856,8 +847,8 @@ void checkRbidAndUpdateMinValid(OperationContext* opCtx,
     if (MONGO_unlikely(rollbackHangThenFailAfterWritingMinValid.shouldFail())) {
 
         // This log output is used in jstests so please leave it.
-        log() << "rollback - rollbackHangThenFailAfterWritingMinValid fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("rollback - rollbackHangThenFailAfterWritingMinValid fail point "
+                 "enabled. Blocking until fail point is disabled.");
         while (MONGO_unlikely(rollbackHangThenFailAfterWritingMinValid.shouldFail())) {
             invariant(!globalInShutdownDeprecated());  // It is an error to shutdown while enabled.
             mongo::sleepsecs(1);
@@ -915,29 +906,25 @@ void rollbackCreateIndexes(OperationContext* opCtx, UUID uuid, std::set<std::str
 
     // If we cannot find the collection, we skip over dropping the index.
     if (!collection) {
-        LOG(2) << "Cannot find the collection with uuid: " << uuid.toString()
-               << " in CollectionCatalog during roll back of a createIndexes command.";
+        LOGV2_DEBUG(2, "Cannot find the collection with uuid: {} in CollectionCatalog during roll back of a createIndexes command.", "uuid_toString"_attr = uuid.toString());
         return;
     }
 
     // If we cannot find the index catalog, we skip over dropping the index.
     auto indexCatalog = collection->getIndexCatalog();
     if (!indexCatalog) {
-        LOG(2) << "Cannot find the index catalog in collection with uuid: " << uuid.toString()
-               << " during roll back of a createIndexes command.";
+        LOGV2_DEBUG(2, "Cannot find the index catalog in collection with uuid: {} during roll back of a createIndexes command.", "uuid_toString"_attr = uuid.toString());
         return;
     }
 
     for (auto itIndex = indexNames.begin(); itIndex != indexNames.end(); itIndex++) {
         const string& indexName = *itIndex;
 
-        log() << "Dropping index in rollback for collection: " << *nss << ", UUID: " << uuid
-              << ", index: " << indexName;
+        LOGV2("Dropping index in rollback for collection: {}, UUID: {}, index: {}", "nss"_attr = *nss, "uuid"_attr = uuid, "indexName"_attr = indexName);
 
         dropIndex(opCtx, indexCatalog, indexName, *nss);
 
-        LOG(1) << "Dropped index in rollback for collection: " << *nss << ", UUID: " << uuid
-               << ", index: " << indexName;
+        LOGV2_DEBUG(1, "Dropped index in rollback for collection: {}, UUID: {}, index: {}", "nss"_attr = *nss, "uuid"_attr = uuid, "indexName"_attr = indexName);
     }
 }
 
@@ -957,8 +944,7 @@ void rollbackDropIndexes(OperationContext* opCtx,
 
     // If we cannot find the collection, we skip over dropping the index.
     if (!collection) {
-        LOG(2) << "Cannot find the collection with uuid: " << uuid.toString()
-               << "in CollectionCatalog during roll back of a dropIndexes command.";
+        LOGV2_DEBUG(2, "Cannot find the collection with uuid: {}in CollectionCatalog during roll back of a dropIndexes command.", "uuid_toString"_attr = uuid.toString());
         return;
     }
 
@@ -966,13 +952,11 @@ void rollbackDropIndexes(OperationContext* opCtx,
         const string indexName = itIndex->first;
         BSONObj indexSpec = itIndex->second;
 
-        log() << "Creating index in rollback for collection: " << *nss << ", UUID: " << uuid
-              << ", index: " << indexName;
+        LOGV2("Creating index in rollback for collection: {}, UUID: {}, index: {}", "nss"_attr = *nss, "uuid"_attr = uuid, "indexName"_attr = indexName);
 
         createIndexForApplyOps(opCtx, indexSpec, *nss, OplogApplication::Mode::kRecovering);
 
-        LOG(1) << "Created index in rollback for collection: " << *nss << ", UUID: " << uuid
-               << ", index: " << indexName;
+        LOGV2_DEBUG(1, "Created index in rollback for collection: {}, UUID: {}, index: {}", "nss"_attr = *nss, "uuid"_attr = uuid, "indexName"_attr = indexName);
     }
 }
 
@@ -985,10 +969,7 @@ void dropCollection(OperationContext* opCtx,
                     Database* db) {
     if (RollbackImpl::shouldCreateDataFiles()) {
         RemoveSaver removeSaver("rollback", "", collection->uuid().toString());
-        log() << "Rolling back createCollection on " << nss
-              << ": Preparing to write documents to a rollback file for a collection " << nss
-              << " with uuid " << collection->uuid() << " to "
-              << removeSaver.file().generic_string();
+        LOGV2("Rolling back createCollection on {}: Preparing to write documents to a rollback file for a collection {} with uuid {} to {}", "nss"_attr = nss, "nss"_attr = nss, "collection_uuid"_attr = collection->uuid(), "removeSaver_file_generic_string"_attr = removeSaver.file().generic_string());
 
         // Performs a collection scan and writes all documents in the collection to disk
         // in order to keep an archive of items that were rolled back.
@@ -1065,10 +1046,7 @@ void renameOutOfTheWay(OperationContext* opCtx, RenameCollectionInfo info, Datab
     }
     const auto& tempNss = tmpNameResult.getValue();
 
-    LOG(2) << "Attempted to rename collection from " << info.renameFrom << " to " << info.renameTo
-           << " but " << info.renameTo << " exists already. Temporarily renaming collection "
-           << info.renameTo << " with UUID " << collection->uuid() << " out of the way to "
-           << tempNss;
+    LOGV2_DEBUG(2, "Attempted to rename collection from {} to {} but {} exists already. Temporarily renaming collection {} with UUID {} out of the way to {}", "info_renameFrom"_attr = info.renameFrom, "info_renameTo"_attr = info.renameTo, "info_renameTo"_attr = info.renameTo, "info_renameTo"_attr = info.renameTo, "collection_uuid"_attr = collection->uuid(), "tempNss"_attr = tempNss);
 
     // Renaming the collection that was clashing with the attempted rename
     // operation to a different collection name.
@@ -1089,8 +1067,7 @@ void rollbackRenameCollection(OperationContext* opCtx, UUID uuid, RenameCollecti
 
     auto dbName = info.renameFrom.db();
 
-    log() << "Attempting to rename collection with UUID: " << uuid << ", from: " << info.renameFrom
-          << ", to: " << info.renameTo;
+    LOGV2("Attempting to rename collection with UUID: {}, from: {}, to: {}", "uuid"_attr = uuid, "info_renameFrom"_attr = info.renameFrom, "info_renameTo"_attr = info.renameTo);
     Lock::DBLock dbLock(opCtx, dbName, MODE_X);
     auto databaseHolder = DatabaseHolder::get(opCtx);
     auto db = databaseHolder->openDb(opCtx, dbName);
@@ -1122,8 +1099,7 @@ void rollbackRenameCollection(OperationContext* opCtx, UUID uuid, RenameCollecti
         throw RSFatalException("Unable to rollback renameCollection command");
     }
 
-    LOG(1) << "Renamed collection with UUID: " << uuid << ", from: " << info.renameFrom
-           << ", to: " << info.renameTo;
+    LOGV2_DEBUG(1, "Renamed collection with UUID: {}, from: {}, to: {}", "uuid"_attr = uuid, "info_renameFrom"_attr = info.renameFrom, "info_renameTo"_attr = info.renameTo);
 }
 
 Status _syncRollback(OperationContext* opCtx,
@@ -1137,7 +1113,7 @@ Status _syncRollback(OperationContext* opCtx,
 
     FixUpInfo how;
     how.localTopOfOplog = replCoord->getMyLastAppliedOpTime();
-    log() << "Starting rollback. Sync source: " << rollbackSource.getSource() << rsLog;
+    LOGV2_OPTIONS({logv2::LogTag::kRS}, "Starting rollback. Sync source: {}", "rollbackSource_getSource"_attr = rollbackSource.getSource());
     how.rbid = rollbackSource.getRollbackId();
     uassert(
         40506, "Upstream node rolled back. Need to retry our rollback.", how.rbid == requiredRBID);
@@ -1151,7 +1127,7 @@ Status _syncRollback(OperationContext* opCtx,
     // they may be made redundant by a rolled-back startIndexBuild oplog entry.
     how.indexBuildsToRestart.insert(abortedIndexBuilds.begin(), abortedIndexBuilds.end());
 
-    log() << "Finding the Common Point";
+    LOGV2("Finding the Common Point");
     try {
 
         auto processOperationForFixUp = [&how, &opCtx, &localOplog](const BSONObj& operation) {
@@ -1188,7 +1164,7 @@ Status _syncRollback(OperationContext* opCtx,
     OpTime lastCommittedOpTime = replCoord->getLastCommittedOpTime();
     OpTime committedSnapshot = replCoord->getCurrentCommittedSnapshotOpTime();
 
-    log() << "Rollback common point is " << commonPoint;
+    LOGV2("Rollback common point is {}", "commonPoint"_attr = commonPoint);
 
     // Rollback common point should be >= the replication commit point.
     invariant(commonPoint.getTimestamp() >= lastCommittedOpTime.getTimestamp());
@@ -1206,8 +1182,8 @@ Status _syncRollback(OperationContext* opCtx,
         syncFixUp(opCtx, how, rollbackSource, replCoord, replicationProcess);
 
         if (MONGO_unlikely(rollbackExitEarlyAfterCollectionDrop.shouldFail())) {
-            log() << "rollbackExitEarlyAfterCollectionDrop fail point enabled. Returning early "
-                     "until fail point is disabled.";
+            LOGV2("rollbackExitEarlyAfterCollectionDrop fail point enabled. Returning early "
+                     "until fail point is disabled.");
             return Status(ErrorCodes::NamespaceNotFound,
                           str::stream() << "Failing rollback because "
                                            "rollbackExitEarlyAfterCollectionDrop fail point "
@@ -1219,8 +1195,8 @@ Status _syncRollback(OperationContext* opCtx,
 
     if (MONGO_unlikely(rollbackHangBeforeFinish.shouldFail())) {
         // This log output is used in js tests so please leave it.
-        log() << "rollback - rollbackHangBeforeFinish fail point "
-                 "enabled. Blocking until fail point is disabled.";
+        LOGV2("rollback - rollbackHangBeforeFinish fail point "
+                 "enabled. Blocking until fail point is disabled.");
         while (MONGO_unlikely(rollbackHangBeforeFinish.shouldFail())) {
             invariant(!globalInShutdownDeprecated());  // It is an error to shutdown while enabled.
             mongo::sleepsecs(1);
@@ -1246,7 +1222,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
     // Fetches all the goodVersions of each document from the current sync source.
     unsigned long long numFetched = 0;
 
-    log() << "Starting refetching documents";
+    LOGV2("Starting refetching documents");
 
     for (auto&& doc : fixUpInfo.docsToRefetch) {
         invariant(!doc._id.eoo());  // This is checked when we insert to the set.
@@ -1256,10 +1232,9 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
 
         try {
             if (nss) {
-                LOG(2) << "Refetching document, collection: " << *nss << ", UUID: " << uuid << ", "
-                       << redact(doc._id);
+                LOGV2_DEBUG(2, "Refetching document, collection: {}, UUID: {}, {}", "nss"_attr = *nss, "uuid"_attr = uuid, "redact_doc__id"_attr = redact(doc._id));
             } else {
-                LOG(2) << "Refetching document, UUID: " << uuid << ", " << redact(doc._id);
+                LOGV2_DEBUG(2, "Refetching document, UUID: {}, {}", "uuid"_attr = uuid, "redact_doc__id"_attr = redact(doc._id));
             }
             // TODO : Slow. Lots of round trips.
             numFetched++;
@@ -1308,27 +1283,24 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
                 ex.code() == ErrorCodes::NamespaceNotFound)
                 continue;
 
-            log() << "Rollback couldn't re-fetch from uuid: " << uuid << " _id: " << redact(doc._id)
-                  << ' ' << numFetched << '/' << fixUpInfo.docsToRefetch.size() << ": "
-                  << redact(ex);
+            LOGV2("Rollback couldn't re-fetch from uuid: {} _id: {} {}/{}: {}", "uuid"_attr = uuid, "redact_doc__id"_attr = redact(doc._id), "numFetched"_attr = numFetched, "fixUpInfo_docsToRefetch_size"_attr = fixUpInfo.docsToRefetch.size(), "redact_ex"_attr = redact(ex));
             throw;
         }
     }
 
-    log() << "Finished refetching documents. Total size of documents refetched: "
-          << goodVersions.size();
+    LOGV2("Finished refetching documents. Total size of documents refetched: {}", "goodVersions_size"_attr = goodVersions.size());
 
     // We must start taking unstable checkpoints before rolling back oplog entries. Otherwise, a
     // stable checkpoint could include the fixup write (since it is untimestamped) but not the write
     // being rolled back (if it is after the stable timestamp), leading to inconsistent state. An
     // unstable checkpoint will include both writes.
     if (!serverGlobalParams.enableMajorityReadConcern) {
-        log() << "Setting initialDataTimestamp to 0 so that we start taking unstable checkpoints.";
+        LOGV2("Setting initialDataTimestamp to 0 so that we start taking unstable checkpoints.");
         opCtx->getServiceContext()->getStorageEngine()->setInitialDataTimestamp(
             Timestamp::kAllowUnstableCheckpointsSentinel);
     }
 
-    log() << "Checking the RollbackID and updating the MinValid if necessary";
+    LOGV2("Checking the RollbackID and updating the MinValid if necessary");
 
     checkRbidAndUpdateMinValid(opCtx, fixUpInfo.rbid, rollbackSource, replicationProcess);
 
@@ -1343,7 +1315,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
     // indexes.
     // We drop indexes before renaming collections so that if a collection name gets longer,
     // any indexes with names that are now too long will already be dropped.
-    log() << "Rolling back createIndexes and startIndexBuild operations";
+    LOGV2("Rolling back createIndexes and startIndexBuild operations");
     for (auto it = fixUpInfo.indexesToDrop.begin(); it != fixUpInfo.indexesToDrop.end(); it++) {
 
         UUID uuid = it->first;
@@ -1356,7 +1328,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
     // rolled-back, but the unfinished index still exists in the catalog. Drop these before any
     // collection drops, because one of the preconditions of dropping a collection is that there are
     // no unfinished indxes.
-    log() << "Rolling back unfinished startIndexBuild operations";
+    LOGV2("Rolling back unfinished startIndexBuild operations");
     for (auto index : fixUpInfo.unfinishedIndexesToDrop) {
         UUID uuid = index.first;
         std::set<std::string> indexNames = index.second;
@@ -1364,7 +1336,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
         rollbackCreateIndexes(opCtx, uuid, indexNames);
     }
 
-    log() << "Dropping collections to roll back create operations";
+    LOGV2("Dropping collections to roll back create operations");
 
     // Drops collections before updating individual documents. We drop these collections before
     // rolling back any other commands to prevent namespace collisions that may occur
@@ -1387,9 +1359,9 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
         // Do not attempt to acquire the database lock with an empty namespace. We should survive
         // an attempt to drop a non-existent collection.
         if (!nss) {
-            log() << "This collection does not exist, UUID: " << uuid;
+            LOGV2("This collection does not exist, UUID: {}", "uuid"_attr = uuid);
         } else {
-            log() << "Dropping collection: " << *nss << ", UUID: " << uuid;
+            LOGV2("Dropping collection: {}, UUID: {}", "nss"_attr = *nss, "uuid"_attr = uuid);
             AutoGetDb dbLock(opCtx, nss->db(), MODE_X);
 
             Database* db = dbLock.getDb();
@@ -1397,7 +1369,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
                 Collection* collection =
                     CollectionCatalog::get(opCtx).lookupCollectionByUUID(opCtx, uuid);
                 dropCollection(opCtx, *nss, collection, db);
-                LOG(1) << "Dropped collection: " << *nss << ", UUID: " << uuid;
+                LOGV2_DEBUG(1, "Dropped collection: {}, UUID: {}", "nss"_attr = *nss, "uuid"_attr = uuid);
             }
         }
     }
@@ -1407,7 +1379,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
     }
 
     // Rolling back renameCollection commands.
-    log() << "Rolling back renameCollection commands and collection drop commands.";
+    LOGV2("Rolling back renameCollection commands and collection drop commands.");
 
     for (auto it = fixUpInfo.collectionsToRename.begin(); it != fixUpInfo.collectionsToRename.end();
          it++) {
@@ -1418,16 +1390,15 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
         rollbackRenameCollection(opCtx, uuid, info);
     }
 
-    log() << "Rolling back collections pending being dropped: Removing them from the list of "
-             "drop-pending collections in the DropPendingCollectionReaper.";
+    LOGV2("Rolling back collections pending being dropped: Removing them from the list of "
+             "drop-pending collections in the DropPendingCollectionReaper.");
 
     // Roll back any drop-pending collections. This must be done first so that the collection
     // exists when we attempt to resync its metadata or insert documents into it.
     for (const auto& collPair : fixUpInfo.collectionsToRemoveFromDropPendingCollections) {
         const auto& optime = collPair.second.first;
         const auto& collectionNamespace = collPair.second.second;
-        LOG(1) << "Rolling back collection pending being dropped for OpTime: " << optime
-               << ", collection: " << collectionNamespace;
+        LOGV2_DEBUG(1, "Rolling back collection pending being dropped for OpTime: {}, collection: {}", "optime"_attr = optime, "collectionNamespace"_attr = collectionNamespace);
         DropPendingCollectionReaper::get(opCtx)->rollBackDropPendingCollection(
             opCtx, optime, collectionNamespace);
     }
@@ -1446,7 +1417,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
                 CollectionCatalog::get(opCtx).lookupNSSByUUID(opCtx, uuid);
             invariant(nss);
 
-            log() << "Resyncing collection metadata for collection: " << *nss << ", UUID: " << uuid;
+            LOGV2("Resyncing collection metadata for collection: {}, UUID: {}", "nss"_attr = *nss, "uuid"_attr = uuid);
 
             Lock::DBLock dbLock(opCtx, nss->db(), MODE_X);
 
@@ -1466,9 +1437,8 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
                 // is rolled back upstream and we restart, we expect to still have the
                 // collection.
 
-                log() << nss->ns()
-                      << " not found on remote host, so we do not roll back collmod "
-                         "operation. Instead, we will drop the collection soon.";
+                LOGV2("{} not found on remote host, so we do not roll back collmod "
+                         "operation. Instead, we will drop the collection soon.", "nss_ns"_attr = nss->ns());
                 continue;
             }
 
@@ -1515,22 +1485,20 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
 
             wuow.commit();
 
-            LOG(1) << "Resynced collection metadata for collection: " << *nss << ", UUID: " << uuid
-                   << ", with: " << redact(info) << ", to: "
-                   << redact(DurableCatalog::get(opCtx)
+            LOGV2_DEBUG(1, "Resynced collection metadata for collection: {}, UUID: {}, with: {}, to: {}", "nss"_attr = *nss, "uuid"_attr = uuid, "redact_info"_attr = redact(info), "redact_DurableCatalog_get_opCtx_getCollectionOptions_opCtx_collection_getCatalogId_toBSON"_attr = redact(DurableCatalog::get(opCtx)
                                  ->getCollectionOptions(opCtx, collection->getCatalogId())
-                                 .toBSON());
+                                 .toBSON()));
         }
 
         // Since we read from the sync source to retrieve the metadata of the
         // collection, we must check if the sync source rolled back as well as update
         // minValid if necessary.
-        log() << "Rechecking the Rollback ID and minValid";
+        LOGV2("Rechecking the Rollback ID and minValid");
         checkRbidAndUpdateMinValid(opCtx, fixUpInfo.rbid, rollbackSource, replicationProcess);
     }
 
     // Rolls back dropIndexes commands by re-creating the indexes that were dropped.
-    log() << "Rolling back dropIndexes commands.";
+    LOGV2("Rolling back dropIndexes commands.");
     for (auto it = fixUpInfo.indexesToCreate.begin(); it != fixUpInfo.indexesToCreate.end(); it++) {
 
         UUID uuid = it->first;
@@ -1539,12 +1507,12 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
         rollbackDropIndexes(opCtx, uuid, indexNames);
     }
 
-    log() << "Restarting rolled-back committed or aborted index builds.";
+    LOGV2("Restarting rolled-back committed or aborted index builds.");
     IndexBuildsCoordinator::get(opCtx)->restartIndexBuildsForRecovery(
         opCtx, fixUpInfo.indexBuildsToRestart);
 
-    log() << "Deleting and updating documents to roll back insert, update and remove "
-             "operations";
+    LOGV2("Deleting and updating documents to roll back insert, update and remove "
+             "operations");
     unsigned deletes = 0, updates = 0;
     time_t lastProgressUpdate = time(nullptr);
     time_t progressUpdateGap = 10;
@@ -1565,18 +1533,14 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
 
         if (RollbackImpl::shouldCreateDataFiles()) {
             removeSaver = std::make_unique<RemoveSaver>("rollback", "", uuid.toString());
-            log() << "Preparing to write deleted documents to a rollback file for collection "
-                  << *nss << " with uuid " << uuid.toString() << " to "
-                  << removeSaver->file().generic_string();
+            LOGV2("Preparing to write deleted documents to a rollback file for collection {} with uuid {} to {}", "nss"_attr = *nss, "uuid_toString"_attr = uuid.toString(), "removeSaver_file_generic_string"_attr = removeSaver->file().generic_string());
         }
 
         const auto& goodVersionsByDocID = nsAndGoodVersionsByDocID.second;
         for (const auto& idAndDoc : goodVersionsByDocID) {
             time_t now = time(nullptr);
             if (now - lastProgressUpdate > progressUpdateGap) {
-                log() << deletes << " delete and " << updates
-                      << " update operations processed out of " << goodVersions.size()
-                      << " total operations.";
+                LOGV2("{} delete and {} update operations processed out of {} total operations.", "deletes"_attr = deletes, "updates"_attr = updates, "goodVersions_size"_attr = goodVersions.size());
                 lastProgressUpdate = now;
             }
             const DocID& doc = idAndDoc.first;
@@ -1614,8 +1578,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
                 }
 
                 if (idAndDoc.second.isEmpty()) {
-                    LOG(2) << "Deleting document with: " << redact(doc._id)
-                           << ", from collection: " << doc.ns << ", with UUID: " << uuid;
+                    LOGV2_DEBUG(2, "Deleting document with: {}, from collection: {}, with UUID: {}", "redact_doc__id"_attr = redact(doc._id), "doc_ns"_attr = doc.ns, "uuid"_attr = uuid);
                     // If the document could not be found on the primary, deletes the document.
                     // TODO 1.6 : can't delete from a capped collection. Need to handle that
                     // here.
@@ -1685,9 +1648,7 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
                         }
                     }
                 } else {
-                    LOG(2) << "Updating document with: " << redact(doc._id)
-                           << ", from collection: " << doc.ns << ", UUID: " << uuid
-                           << ", to: " << redact(idAndDoc.second);
+                    LOGV2_DEBUG(2, "Updating document with: {}, from collection: {}, UUID: {}, to: {}", "redact_doc__id"_attr = redact(doc._id), "doc_ns"_attr = doc.ns, "uuid"_attr = uuid, "redact_idAndDoc_second"_attr = redact(idAndDoc.second));
                     // TODO faster...
                     updates++;
 
@@ -1701,23 +1662,20 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
                     update(opCtx, ctx.db(), request);
                 }
             } catch (const DBException& e) {
-                log() << "Exception in rollback ns:" << nss->ns() << ' ' << pattern.toString()
-                      << ' ' << redact(e) << " ndeletes:" << deletes;
+                LOGV2("Exception in rollback ns:{} {} {} ndeletes:{}", "nss_ns"_attr = nss->ns(), "pattern_toString"_attr = pattern.toString(), "redact_e"_attr = redact(e), "deletes"_attr = deletes);
                 throw;
             }
         }
     }
 
-    log() << "Rollback deleted " << deletes << " documents and updated " << updates
-          << " documents.";
+    LOGV2("Rollback deleted {} documents and updated {} documents.", "deletes"_attr = deletes, "updates"_attr = updates);
 
     if (!serverGlobalParams.enableMajorityReadConcern) {
         // When majority read concern is disabled, the stable timestamp may be ahead of the common
         // point. Force the stable timestamp back to the common point, to allow writes after the
         // common point.
         const bool force = true;
-        log() << "Forcing the stable timestamp to the common point: "
-              << fixUpInfo.commonPoint.getTimestamp();
+        LOGV2("Forcing the stable timestamp to the common point: {}", "fixUpInfo_commonPoint_getTimestamp"_attr = fixUpInfo.commonPoint.getTimestamp());
         opCtx->getServiceContext()->getStorageEngine()->setStableTimestamp(
             fixUpInfo.commonPoint.getTimestamp(), force);
 
@@ -1731,22 +1689,19 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
         auto syncSourceTopOfOplog = OpTime::parseFromOplogEntry(rollbackSource.getLastOperation())
                                         .getValue()
                                         .getTimestamp();
-        log() << "Setting initialDataTimestamp to the max of local top of oplog and sync source "
-                 "top of oplog. Local top of oplog: "
-              << fixUpInfo.localTopOfOplog.getTimestamp()
-              << ", sync source top of oplog: " << syncSourceTopOfOplog;
+        LOGV2("Setting initialDataTimestamp to the max of local top of oplog and sync source "
+                 "top of oplog. Local top of oplog: {}, sync source top of oplog: {}", "fixUpInfo_localTopOfOplog_getTimestamp"_attr = fixUpInfo.localTopOfOplog.getTimestamp(), "syncSourceTopOfOplog"_attr = syncSourceTopOfOplog);
         opCtx->getServiceContext()->getStorageEngine()->setInitialDataTimestamp(
             std::max(fixUpInfo.localTopOfOplog.getTimestamp(), syncSourceTopOfOplog));
 
         // Take an unstable checkpoint to ensure that all of the writes performed during rollback
         // are persisted to disk before truncating oplog.
-        log() << "Waiting for an unstable checkpoint";
+        LOGV2("Waiting for an unstable checkpoint");
         const bool stableCheckpoint = false;
         opCtx->recoveryUnit()->waitUntilUnjournaledWritesDurable(opCtx, stableCheckpoint);
     }
 
-    log() << "Truncating the oplog at " << fixUpInfo.commonPoint.toString() << " ("
-          << fixUpInfo.commonPointOurDiskloc << "), non-inclusive";
+    LOGV2("Truncating the oplog at {} ({}), non-inclusive", "fixUpInfo_commonPoint_toString"_attr = fixUpInfo.commonPoint.toString(), "fixUpInfo_commonPointOurDiskloc"_attr = fixUpInfo.commonPointOurDiskloc);
 
     // Cleans up the oplog.
     {
@@ -1773,18 +1728,18 @@ void rollback_internal::syncFixUp(OperationContext* opCtx,
         // This is done using an untimestamped write, since timestamping the write with the common
         // point TS would be incorrect (since this is equal to the stable timestamp), and this write
         // will be included in the unstable checkpoint regardless of its timestamp.
-        log() << "Setting appliedThrough to the common point: " << fixUpInfo.commonPoint;
+        LOGV2("Setting appliedThrough to the common point: {}", "fixUpInfo_commonPoint"_attr = fixUpInfo.commonPoint);
         const bool setTimestamp = false;
         replicationProcess->getConsistencyMarkers()->setAppliedThrough(
             opCtx, fixUpInfo.commonPoint, setTimestamp);
 
         // Take an unstable checkpoint to ensure the appliedThrough write is persisted to disk.
-        log() << "Waiting for an unstable checkpoint";
+        LOGV2("Waiting for an unstable checkpoint");
         const bool stableCheckpoint = false;
         opCtx->recoveryUnit()->waitUntilUnjournaledWritesDurable(opCtx, stableCheckpoint);
 
         // Ensure that appliedThrough is unset in the next stable checkpoint.
-        log() << "Clearing appliedThrough";
+        LOGV2("Clearing appliedThrough");
         replicationProcess->getConsistencyMarkers()->clearAppliedThrough(opCtx, Timestamp());
     }
 
@@ -1841,8 +1796,7 @@ Status syncRollback(OperationContext* opCtx,
                                   replCoord,
                                   replicationProcess);
 
-    log() << "Rollback finished. The final minValid is: "
-          << replicationProcess->getConsistencyMarkers()->getMinValid(opCtx) << rsLog;
+    LOGV2_OPTIONS({logv2::LogTag::kRS}, "Rollback finished. The final minValid is: {}", "replicationProcess_getConsistencyMarkers_getMinValid_opCtx"_attr = replicationProcess->getConsistencyMarkers()->getMinValid(opCtx));
 
     return status;
 }
@@ -1872,15 +1826,14 @@ void rollback(OperationContext* opCtx,
 
         auto status = replCoord->setFollowerModeStrict(opCtx, MemberState::RS_ROLLBACK);
         if (!status.isOK()) {
-            log() << "Cannot transition from " << replCoord->getMemberState().toString() << " to "
-                  << MemberState(MemberState::RS_ROLLBACK).toString() << causedBy(status);
+            LOGV2("Cannot transition from {} to {}{}", "replCoord_getMemberState_toString"_attr = replCoord->getMemberState().toString(), "MemberState_MemberState_RS_ROLLBACK_toString"_attr = MemberState(MemberState::RS_ROLLBACK).toString(), "causedBy_status"_attr = causedBy(status));
             return;
         }
     }
 
     if (MONGO_unlikely(rollbackHangAfterTransitionToRollback.shouldFail())) {
-        log() << "rollbackHangAfterTransitionToRollback fail point enabled. Blocking until fail "
-                 "point is disabled (rs_rollback).";
+        LOGV2("rollbackHangAfterTransitionToRollback fail point enabled. Blocking until fail "
+                 "point is disabled (rs_rollback).");
         rollbackHangAfterTransitionToRollback.pauseWhileSet(opCtx);
     }
 
diff --git a/src/mongo/db/repl/scatter_gather_runner.cpp b/src/mongo/db/repl/scatter_gather_runner.cpp
index 18e3bc761b..00fd6aa93d 100644
--- a/src/mongo/db/repl/scatter_gather_runner.cpp
+++ b/src/mongo/db/repl/scatter_gather_runner.cpp
@@ -38,6 +38,7 @@
 
 #include "mongo/base/status_with.h"
 #include "mongo/db/repl/scatter_gather_algorithm.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -105,8 +106,7 @@ StatusWith<EventHandle> ScatterGatherRunner::RunnerImpl::start(
 
     std::vector<RemoteCommandRequest> requests = _algorithm->getRequests();
     for (size_t i = 0; i < requests.size(); ++i) {
-        log() << "Scheduling remote command request for " << _logMessage << ": "
-              << requests[i].toString();
+        LOGV2("Scheduling remote command request for {}: {}", "_logMessage"_attr = _logMessage, "requests_i_toString"_attr = requests[i].toString());
         const StatusWith<CallbackHandle> cbh =
             _executor->scheduleRemoteCommand(requests[i], processResponseCB);
         if (cbh.getStatus() == ErrorCodes::ShutdownInProgress) {
diff --git a/src/mongo/db/repl/storage_interface_impl.cpp b/src/mongo/db/repl/storage_interface_impl.cpp
index 17af180cd4..1ebe44c4e1 100644
--- a/src/mongo/db/repl/storage_interface_impl.cpp
+++ b/src/mongo/db/repl/storage_interface_impl.cpp
@@ -76,6 +76,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/storage/oplog_cap_maintainer_thread.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/background.h"
 #include "mongo/util/log.h"
@@ -190,7 +191,7 @@ StorageInterfaceImpl::createCollectionForBulkLoading(
     const BSONObj idIndexSpec,
     const std::vector<BSONObj>& secondaryIndexSpecs) {
 
-    LOG(2) << "StorageInterfaceImpl::createCollectionForBulkLoading called for ns: " << nss.ns();
+    LOGV2_DEBUG(2, "StorageInterfaceImpl::createCollectionForBulkLoading called for ns: {}", "nss_ns"_attr = nss.ns());
 
     class StashClient {
     public:
@@ -384,7 +385,7 @@ Status StorageInterfaceImpl::dropReplicatedDatabases(OperationContext* opCtx) {
     std::vector<std::string> dbNames =
         opCtx->getServiceContext()->getStorageEngine()->listDatabases();
     invariant(!dbNames.empty());
-    log() << "dropReplicatedDatabases - dropping " << dbNames.size() << " databases";
+    LOGV2("dropReplicatedDatabases - dropping {} databases", "dbNames_size"_attr = dbNames.size());
 
     ReplicationCoordinator::get(opCtx)->dropAllSnapshots();
 
@@ -401,14 +402,13 @@ Status StorageInterfaceImpl::dropReplicatedDatabases(OperationContext* opCtx) {
             } else {
                 // This is needed since dropDatabase can't be rolled back.
                 // This is safe be replaced by "invariant(db);dropDatabase(opCtx, db);" once fixed.
-                log() << "dropReplicatedDatabases - database disappeared after retrieving list of "
-                         "database names but before drop: "
-                      << dbName;
+                LOGV2("dropReplicatedDatabases - database disappeared after retrieving list of "
+                         "database names but before drop: {}", "dbName"_attr = dbName);
             }
         });
     }
     invariant(hasLocalDatabase, "local database missing");
-    log() << "dropReplicatedDatabases - dropped " << dbNames.size() << " databases";
+    LOGV2("dropReplicatedDatabases - dropped {} databases", "dbNames_size"_attr = dbNames.size());
 
     return Status::OK();
 }
diff --git a/src/mongo/db/repl/storage_interface_mock.cpp b/src/mongo/db/repl/storage_interface_mock.cpp
index e9fa17504b..fbfa167985 100644
--- a/src/mongo/db/repl/storage_interface_mock.cpp
+++ b/src/mongo/db/repl/storage_interface_mock.cpp
@@ -34,6 +34,7 @@
 
 #include "mongo/db/repl/storage_interface_mock.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 
@@ -103,14 +104,14 @@ bool StorageInterfaceMock::supportsDocLocking(ServiceContext* serviceCtx) const
 }
 
 Status CollectionBulkLoaderMock::init(const std::vector<BSONObj>& secondaryIndexSpecs) {
-    LOG(1) << "CollectionBulkLoaderMock::init called";
+    LOGV2_DEBUG(1, "CollectionBulkLoaderMock::init called");
     stats->initCalled = true;
     return Status::OK();
 };
 
 Status CollectionBulkLoaderMock::insertDocuments(const std::vector<BSONObj>::const_iterator begin,
                                                  const std::vector<BSONObj>::const_iterator end) {
-    LOG(1) << "CollectionBulkLoaderMock::insertDocuments called";
+    LOGV2_DEBUG(1, "CollectionBulkLoaderMock::insertDocuments called");
     const auto status = insertDocsFn(begin, end);
 
     // Only count if it succeeds.
@@ -121,7 +122,7 @@ Status CollectionBulkLoaderMock::insertDocuments(const std::vector<BSONObj>::con
 };
 
 Status CollectionBulkLoaderMock::commit() {
-    LOG(1) << "CollectionBulkLoaderMock::commit called";
+    LOGV2_DEBUG(1, "CollectionBulkLoaderMock::commit called");
     stats->commitCalled = true;
     return commitFn();
 };
diff --git a/src/mongo/db/repl/sync_source_feedback.cpp b/src/mongo/db/repl/sync_source_feedback.cpp
index 03b5af9837..47c2ff31e0 100644
--- a/src/mongo/db/repl/sync_source_feedback.cpp
+++ b/src/mongo/db/repl/sync_source_feedback.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/repl/reporter.h"
 #include "mongo/executor/task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/hostandport.h"
@@ -124,7 +125,7 @@ Status SyncSourceFeedback::_updateUpstream(Reporter* reporter) {
     auto status = reporter->join();
 
     if (!status.isOK()) {
-        log() << "SyncSourceFeedback error sending update to " << syncTarget << ": " << status;
+        LOGV2("SyncSourceFeedback error sending update to {}: {}", "syncTarget"_attr = syncTarget, "status"_attr = status);
     }
 
     // Sync source blacklisting will be done in BackgroundSync and SyncSourceResolver.
@@ -202,15 +203,14 @@ void SyncSourceFeedback::run(executor::TaskExecutor* executor,
         }
 
         if (syncTarget != target) {
-            LOG(1) << "setting syncSourceFeedback to " << target;
+            LOGV2_DEBUG(1, "setting syncSourceFeedback to {}", "target"_attr = target);
             syncTarget = target;
 
             // Update keepalive value from config.
             auto oldKeepAliveInterval = keepAliveInterval;
             keepAliveInterval = calculateKeepAliveInterval(replCoord->getConfig());
             if (oldKeepAliveInterval != keepAliveInterval) {
-                LOG(1) << "new syncSourceFeedback keep alive duration = " << keepAliveInterval
-                       << " (previously " << oldKeepAliveInterval << ")";
+                LOGV2_DEBUG(1, "new syncSourceFeedback keep alive duration = {} (previously {})", "keepAliveInterval"_attr = keepAliveInterval, "oldKeepAliveInterval"_attr = oldKeepAliveInterval);
             }
         }
 
@@ -233,9 +233,8 @@ void SyncSourceFeedback::run(executor::TaskExecutor* executor,
 
         auto status = _updateUpstream(&reporter);
         if (!status.isOK()) {
-            LOG(1) << "The replication progress command (replSetUpdatePosition) failed and will be "
-                      "retried: "
-                   << status;
+            LOGV2_DEBUG(1, "The replication progress command (replSetUpdatePosition) failed and will be "
+                      "retried: {}", "status"_attr = status);
         }
     }
 }
diff --git a/src/mongo/db/repl/sync_source_resolver.cpp b/src/mongo/db/repl/sync_source_resolver.cpp
index 0b371f9359..6979632885 100644
--- a/src/mongo/db/repl/sync_source_resolver.cpp
+++ b/src/mongo/db/repl/sync_source_resolver.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/repl/oplog_entry.h"
 #include "mongo/db/repl/replication_process.h"
 #include "mongo/db/repl/sync_source_selector.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/destructor_guard.h"
@@ -229,8 +230,7 @@ OpTime SyncSourceResolver::_parseRemoteEarliestOpTime(const HostAndPort& candida
     if (queryResponse.documents.empty()) {
         // Remote oplog is empty.
         const auto until = _taskExecutor->now() + kOplogEmptyBlacklistDuration;
-        log() << "Blacklisting " << candidate << " due to empty oplog for "
-              << kOplogEmptyBlacklistDuration << " until: " << until;
+        LOGV2("Blacklisting {} due to empty oplog for {} until: {}", "candidate"_attr = candidate, "kOplogEmptyBlacklistDuration"_attr = kOplogEmptyBlacklistDuration, "until"_attr = until);
         _syncSourceSelector->blacklistSyncSource(candidate, until);
         return OpTime();
     }
@@ -239,8 +239,7 @@ OpTime SyncSourceResolver::_parseRemoteEarliestOpTime(const HostAndPort& candida
     if (firstObjFound.isEmpty()) {
         // First document in remote oplog is empty.
         const auto until = _taskExecutor->now() + kFirstOplogEntryEmptyBlacklistDuration;
-        log() << "Blacklisting " << candidate << " due to empty first document for "
-              << kFirstOplogEntryEmptyBlacklistDuration << " until: " << until;
+        LOGV2("Blacklisting {} due to empty first document for {} until: {}", "candidate"_attr = candidate, "kFirstOplogEntryEmptyBlacklistDuration"_attr = kFirstOplogEntryEmptyBlacklistDuration, "until"_attr = until);
         _syncSourceSelector->blacklistSyncSource(candidate, until);
         return OpTime();
     }
@@ -248,10 +247,7 @@ OpTime SyncSourceResolver::_parseRemoteEarliestOpTime(const HostAndPort& candida
     const auto remoteEarliestOpTime = OpTime::parseFromOplogEntry(firstObjFound);
     if (!remoteEarliestOpTime.isOK()) {
         const auto until = _taskExecutor->now() + kFirstOplogEntryNullTimestampBlacklistDuration;
-        log() << "Blacklisting " << candidate << " due to error parsing OpTime from the oldest"
-              << " oplog entry for " << kFirstOplogEntryNullTimestampBlacklistDuration
-              << " until: " << until << ". Error: " << remoteEarliestOpTime.getStatus()
-              << ", Entry: " << redact(firstObjFound);
+        LOGV2("Blacklisting {} due to error parsing OpTime from the oldest oplog entry for {} until: {}. Error: {}, Entry: {}", "candidate"_attr = candidate, "kFirstOplogEntryNullTimestampBlacklistDuration"_attr = kFirstOplogEntryNullTimestampBlacklistDuration, "until"_attr = until, "remoteEarliestOpTime_getStatus"_attr = remoteEarliestOpTime.getStatus(), "redact_firstObjFound"_attr = redact(firstObjFound));
         _syncSourceSelector->blacklistSyncSource(candidate, until);
         return OpTime();
     }
@@ -259,8 +255,7 @@ OpTime SyncSourceResolver::_parseRemoteEarliestOpTime(const HostAndPort& candida
     if (remoteEarliestOpTime.getValue().isNull()) {
         // First document in remote oplog is empty.
         const auto until = _taskExecutor->now() + kFirstOplogEntryNullTimestampBlacklistDuration;
-        log() << "Blacklisting " << candidate << " due to null timestamp in first document for "
-              << kFirstOplogEntryNullTimestampBlacklistDuration << " until: " << until;
+        LOGV2("Blacklisting {} due to null timestamp in first document for {} until: {}", "candidate"_attr = candidate, "kFirstOplogEntryNullTimestampBlacklistDuration"_attr = kFirstOplogEntryNullTimestampBlacklistDuration, "until"_attr = until);
         _syncSourceSelector->blacklistSyncSource(candidate, until);
         return OpTime();
     }
@@ -289,8 +284,7 @@ void SyncSourceResolver::_firstOplogEntryFetcherCallback(
     if (!queryResult.isOK()) {
         // We got an error.
         const auto until = _taskExecutor->now() + kFetcherErrorBlacklistDuration;
-        log() << "Blacklisting " << candidate << " due to error: '" << queryResult.getStatus()
-              << "' for " << kFetcherErrorBlacklistDuration << " until: " << until;
+        LOGV2("Blacklisting {} due to error: '{}' for {} until: {}", "candidate"_attr = candidate, "queryResult_getStatus"_attr = queryResult.getStatus(), "kFetcherErrorBlacklistDuration"_attr = kFetcherErrorBlacklistDuration, "until"_attr = until);
         _syncSourceSelector->blacklistSyncSource(candidate, until);
 
         _chooseAndProbeNextSyncSource(earliestOpTimeSeen).transitional_ignore();
@@ -310,11 +304,7 @@ void SyncSourceResolver::_firstOplogEntryFetcherCallback(
         const auto blacklistDuration = kTooStaleBlacklistDuration;
         const auto until = _taskExecutor->now() + Minutes(1);
 
-        log() << "We are too stale to use " << candidate << " as a sync source. "
-              << "Blacklisting this sync source"
-              << " because our last fetched timestamp: " << _lastOpTimeFetched.getTimestamp()
-              << " is before their earliest timestamp: " << remoteEarliestOpTime.getTimestamp()
-              << " for " << blacklistDuration << " until: " << until;
+        LOGV2("We are too stale to use {} as a sync source. Blacklisting this sync source because our last fetched timestamp: {} is before their earliest timestamp: {} for {} until: {}", "candidate"_attr = candidate, "_lastOpTimeFetched_getTimestamp"_attr = _lastOpTimeFetched.getTimestamp(), "remoteEarliestOpTime_getTimestamp"_attr = remoteEarliestOpTime.getTimestamp(), "blacklistDuration"_attr = blacklistDuration, "until"_attr = until);
 
         _syncSourceSelector->blacklistSyncSource(candidate, until);
 
@@ -380,8 +370,7 @@ void SyncSourceResolver::_rbidRequestCallback(
         rbid = rbidReply.response.data["rbid"].Int();
     } catch (const DBException& ex) {
         const auto until = _taskExecutor->now() + kFetcherErrorBlacklistDuration;
-        log() << "Blacklisting " << candidate << " due to error: '" << ex << "' for "
-              << kFetcherErrorBlacklistDuration << " until: " << until;
+        LOGV2("Blacklisting {} due to error: '{}' for {} until: {}", "candidate"_attr = candidate, "ex"_attr = ex, "kFetcherErrorBlacklistDuration"_attr = kFetcherErrorBlacklistDuration, "until"_attr = until);
         _syncSourceSelector->blacklistSyncSource(candidate, until);
         _chooseAndProbeNextSyncSource(earliestOpTimeSeen).transitional_ignore();
         return;
@@ -450,9 +439,7 @@ void SyncSourceResolver::_requiredOpTimeFetcherCallback(
     if (!queryResult.isOK()) {
         // We got an error.
         const auto until = _taskExecutor->now() + kFetcherErrorBlacklistDuration;
-        log() << "Blacklisting " << candidate << " due to required optime fetcher error: '"
-              << queryResult.getStatus() << "' for " << kFetcherErrorBlacklistDuration
-              << " until: " << until << ". required optime: " << _requiredOpTime;
+        LOGV2("Blacklisting {} due to required optime fetcher error: '{}' for {} until: {}. required optime: {}", "candidate"_attr = candidate, "queryResult_getStatus"_attr = queryResult.getStatus(), "kFetcherErrorBlacklistDuration"_attr = kFetcherErrorBlacklistDuration, "until"_attr = until, "_requiredOpTime"_attr = _requiredOpTime);
         _syncSourceSelector->blacklistSyncSource(candidate, until);
 
         _chooseAndProbeNextSyncSource(earliestOpTimeSeen).transitional_ignore();
diff --git a/src/mongo/db/repl/task_runner.cpp b/src/mongo/db/repl/task_runner.cpp
index 86edc6da9c..199cda21e6 100644
--- a/src/mongo/db/repl/task_runner.cpp
+++ b/src/mongo/db/repl/task_runner.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/client.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/concurrency/thread_name.h"
 #include "mongo/util/destructor_guard.h"
@@ -65,7 +66,7 @@ TaskRunner::NextAction runSingleTask(const TaskRunner::Task& task,
     try {
         return task(opCtx, status);
     } catch (...) {
-        log() << "Unhandled exception in task runner: " << redact(exceptionToStatus());
+        LOGV2("Unhandled exception in task runner: {}", "redact_exceptionToStatus"_attr = redact(exceptionToStatus()));
     }
     return TaskRunner::NextAction::kCancel;
 }
diff --git a/src/mongo/db/repl/topology_coordinator.cpp b/src/mongo/db/repl/topology_coordinator.cpp
index a43ca66599..7175e61463 100644
--- a/src/mongo/db/repl/topology_coordinator.cpp
+++ b/src/mongo/db/repl/topology_coordinator.cpp
@@ -51,6 +51,7 @@
 #include "mongo/db/repl/isself.h"
 #include "mongo/db/repl/member_data.h"
 #include "mongo/db/repl/rslog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/oplog_query_metadata.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/util/assert_util.h"
@@ -207,7 +208,7 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
                                                      ChainingPreference chainingPreference) {
     // If we are not a member of the current replica set configuration, no sync source is valid.
     if (_selfIndex == -1) {
-        LOG(1) << "Cannot sync from any members because we are not in the replica set config";
+        LOGV2_DEBUG(1, "Cannot sync from any members because we are not in the replica set config");
         return HostAndPort();
     }
 
@@ -223,23 +224,20 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
         const auto hostAndPort = HostAndPort(hostAndPortElem.checkAndGetStringData());
         const int syncSourceIndex = _rsConfig.findMemberIndexByHostAndPort(hostAndPort);
         if (syncSourceIndex < 0) {
-            log() << "'forceSyncSourceCandidate' failed due to host and port not in "
-                     "replica set config: "
-                  << hostAndPort.toString();
+            LOGV2("'forceSyncSourceCandidate' failed due to host and port not in "
+                     "replica set config: {}", "hostAndPort_toString"_attr = hostAndPort.toString());
             fassertFailed(50836);
         }
 
 
         if (_memberIsBlacklisted(_rsConfig.getMemberAt(syncSourceIndex), now)) {
-            log() << "Cannot select a sync source because forced candidate is blacklisted: "
-                  << hostAndPort.toString();
+            LOGV2("Cannot select a sync source because forced candidate is blacklisted: {}", "hostAndPort_toString"_attr = hostAndPort.toString());
             _syncSource = HostAndPort();
             return _syncSource;
         }
 
         _syncSource = _rsConfig.getMemberAt(syncSourceIndex).getHostAndPort();
-        log() << "choosing sync source candidate due to 'forceSyncSourceCandidate' parameter: "
-              << _syncSource;
+        LOGV2("choosing sync source candidate due to 'forceSyncSourceCandidate' parameter: {}", "_syncSource"_attr = _syncSource);
         std::string msg(str::stream() << "syncing from: " << _syncSource.toString()
                                       << " by 'forceSyncSourceCandidate' parameter");
         setMyHeartbeatMessage(now, msg);
@@ -251,7 +249,7 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
         invariant(_forceSyncSourceIndex < _rsConfig.getNumMembers());
         _syncSource = _rsConfig.getMemberAt(_forceSyncSourceIndex).getHostAndPort();
         _forceSyncSourceIndex = -1;
-        log() << "choosing sync source candidate by request: " << _syncSource;
+        LOGV2("choosing sync source candidate by request: {}", "_syncSource"_attr = _syncSource);
         std::string msg(str::stream()
                         << "syncing from: " << _syncSource.toString() << " by request");
         setMyHeartbeatMessage(now, msg);
@@ -264,7 +262,7 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
     if (needMorePings > 0) {
         static Occasionally sampler;
         if (sampler.tick()) {
-            log() << "waiting for " << needMorePings << " pings from other members before syncing";
+            LOGV2("waiting for {} pings from other members before syncing", "needMorePings"_attr = needMorePings);
         }
         _syncSource = HostAndPort();
         return _syncSource;
@@ -274,25 +272,22 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
     if (chainingPreference == ChainingPreference::kUseConfiguration &&
         !_rsConfig.isChainingAllowed()) {
         if (_currentPrimaryIndex == -1) {
-            LOG(1) << "Cannot select a sync source because chaining is"
-                      " not allowed and primary is unknown/down";
+            LOGV2_DEBUG(1, "Cannot select a sync source because chaining is"
+                      " not allowed and primary is unknown/down");
             _syncSource = HostAndPort();
             return _syncSource;
         } else if (_memberIsBlacklisted(*_currentPrimaryMember(), now)) {
-            LOG(1) << "Cannot select a sync source because chaining is not allowed and primary "
-                      "member is blacklisted: "
-                   << _currentPrimaryMember()->getHostAndPort();
+            LOGV2_DEBUG(1, "Cannot select a sync source because chaining is not allowed and primary "
+                      "member is blacklisted: {}", "_currentPrimaryMember_getHostAndPort"_attr = _currentPrimaryMember()->getHostAndPort());
             _syncSource = HostAndPort();
             return _syncSource;
         } else if (_currentPrimaryIndex == _selfIndex) {
-            LOG(1)
-                << "Cannot select a sync source because chaining is not allowed and we are primary";
+            LOGV2_DEBUG(1, "Cannot select a sync source because chaining is not allowed and we are primary");
             _syncSource = HostAndPort();
             return _syncSource;
         } else {
             _syncSource = _currentPrimaryMember()->getHostAndPort();
-            log() << "chaining not allowed, choosing primary as sync source candidate: "
-                  << _syncSource;
+            LOGV2("chaining not allowed, choosing primary as sync source candidate: {}", "_syncSource"_attr = _syncSource);
             std::string msg(str::stream() << "syncing from primary: " << _syncSource.toString());
             setMyHeartbeatMessage(now, msg);
             return _syncSource;
@@ -343,14 +338,12 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
 
             // Candidate must be up to be considered.
             if (!it->up()) {
-                LOG(2) << "Cannot select sync source because it is not up: "
-                       << itMemberConfig.getHostAndPort();
+                LOGV2_DEBUG(2, "Cannot select sync source because it is not up: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
                 continue;
             }
             // Candidate must be PRIMARY or SECONDARY state to be considered.
             if (!it->getState().readable()) {
-                LOG(2) << "Cannot select sync source because it is not readable: "
-                       << itMemberConfig.getHostAndPort();
+                LOGV2_DEBUG(2, "Cannot select sync source because it is not readable: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
                 continue;
             }
 
@@ -358,61 +351,48 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
             if (attempts == 0) {
                 // Candidate must be a voter if we are a voter.
                 if (_selfConfig().isVoter() && !itMemberConfig.isVoter()) {
-                    LOG(2) << "Cannot select sync source because we are a voter and it is not: "
-                           << itMemberConfig.getHostAndPort();
+                    LOGV2_DEBUG(2, "Cannot select sync source because we are a voter and it is not: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
                     continue;
                 }
                 // Candidates must not be hidden.
                 if (itMemberConfig.isHidden()) {
-                    LOG(2) << "Cannot select sync source because it is hidden: "
-                           << itMemberConfig.getHostAndPort();
+                    LOGV2_DEBUG(2, "Cannot select sync source because it is hidden: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
                     continue;
                 }
                 // Candidates cannot be excessively behind.
                 if (it->getHeartbeatAppliedOpTime() < oldestSyncOpTime) {
-                    LOG(2) << "Cannot select sync source because it is too far behind."
-                           << "Latest optime of sync candidate " << itMemberConfig.getHostAndPort()
-                           << ": " << it->getHeartbeatAppliedOpTime()
-                           << ", oldest acceptable optime: " << oldestSyncOpTime;
+                    LOGV2_DEBUG(2, "Cannot select sync source because it is too far behind.Latest optime of sync candidate {}: {}, oldest acceptable optime: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort(), "it_getHeartbeatAppliedOpTime"_attr = it->getHeartbeatAppliedOpTime(), "oldestSyncOpTime"_attr = oldestSyncOpTime);
                     continue;
                 }
                 // Candidate must not have a configured delay larger than ours.
                 if (_selfConfig().getSlaveDelay() < itMemberConfig.getSlaveDelay()) {
-                    LOG(2) << "Cannot select sync source with larger slaveDelay than ours: "
-                           << itMemberConfig.getHostAndPort();
+                    LOGV2_DEBUG(2, "Cannot select sync source with larger slaveDelay than ours: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
                     continue;
                 }
             }
             // Candidate must build indexes if we build indexes, to be considered.
             if (_selfConfig().shouldBuildIndexes()) {
                 if (!itMemberConfig.shouldBuildIndexes()) {
-                    LOG(2) << "Cannot select sync source with shouldBuildIndex differences: "
-                           << itMemberConfig.getHostAndPort();
+                    LOGV2_DEBUG(2, "Cannot select sync source with shouldBuildIndex differences: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
                     continue;
                 }
             }
             // Only select a candidate that is ahead of me.
             if (it->getHeartbeatAppliedOpTime() <= lastOpTimeFetched) {
-                LOG(1) << "Cannot select this sync source. Sync source must be ahead of me. "
-                       << "Sync candidate: " << itMemberConfig.getHostAndPort()
-                       << ", my last fetched oplog optime: " << lastOpTimeFetched.toBSON()
-                       << ", latest oplog optime of sync candidate: "
-                       << it->getHeartbeatAppliedOpTime().toBSON();
+                LOGV2_DEBUG(1, "Cannot select this sync source. Sync source must be ahead of me. Sync candidate: {}, my last fetched oplog optime: {}, latest oplog optime of sync candidate: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort(), "lastOpTimeFetched_toBSON"_attr = lastOpTimeFetched.toBSON(), "it_getHeartbeatAppliedOpTime_toBSON"_attr = it->getHeartbeatAppliedOpTime().toBSON());
                 continue;
             }
             // Candidate cannot be more latent than anything we've already considered.
             if ((closestIndex != -1) &&
                 (_getPing(itMemberConfig.getHostAndPort()) >
                  _getPing(_rsConfig.getMemberAt(closestIndex).getHostAndPort()))) {
-                LOG(2) << "Cannot select sync source with higher latency than the best candidate: "
-                       << itMemberConfig.getHostAndPort();
+                LOGV2_DEBUG(2, "Cannot select sync source with higher latency than the best candidate: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
 
                 continue;
             }
             // Candidate cannot be blacklisted.
             if (_memberIsBlacklisted(itMemberConfig, now)) {
-                LOG(1) << "Cannot select sync source which is blacklisted: "
-                       << itMemberConfig.getHostAndPort();
+                LOGV2_DEBUG(1, "Cannot select sync source which is blacklisted: {}", "itMemberConfig_getHostAndPort"_attr = itMemberConfig.getHostAndPort());
 
                 continue;
             }
@@ -428,7 +408,7 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
         std::string msg("could not find member to sync from");
         // Only log when we had a valid sync source before
         if (!_syncSource.empty()) {
-            log() << msg << rsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kRS}, "{}", "msg"_attr = msg);
         }
         setMyHeartbeatMessage(now, msg);
 
@@ -436,7 +416,7 @@ HostAndPort TopologyCoordinator::chooseNewSyncSource(Date_t now,
         return _syncSource;
     }
     _syncSource = _rsConfig.getMemberAt(closestIndex).getHostAndPort();
-    log() << "sync source candidate: " << _syncSource;
+    LOGV2("sync source candidate: {}", "_syncSource"_attr = _syncSource);
     std::string msg(str::stream() << "syncing from: " << _syncSource.toString(), 0);
     setMyHeartbeatMessage(now, msg);
     return _syncSource;
@@ -454,14 +434,14 @@ bool TopologyCoordinator::_memberIsBlacklisted(const MemberConfig& memberConfig,
 }
 
 void TopologyCoordinator::blacklistSyncSource(const HostAndPort& host, Date_t until) {
-    LOG(2) << "blacklisting " << host << " until " << until.toString();
+    LOGV2_DEBUG(2, "blacklisting {} until {}", "host"_attr = host, "until_toString"_attr = until.toString());
     _syncSourceBlacklist[host] = until;
 }
 
 void TopologyCoordinator::unblacklistSyncSource(const HostAndPort& host, Date_t now) {
     std::map<HostAndPort, Date_t>::iterator hostItr = _syncSourceBlacklist.find(host);
     if (hostItr != _syncSourceBlacklist.end() && now >= hostItr->second) {
-        LOG(2) << "unblacklisting " << host;
+        LOGV2_DEBUG(2, "unblacklisting {}", "host"_attr = host);
         _syncSourceBlacklist.erase(hostItr);
     }
 }
@@ -752,9 +732,9 @@ HeartbeatResponseAction TopologyCoordinator::processHeartbeatResponse(
             // Could be we got the newer version before we got the response, or the
             // target erroneously sent us one, even through it isn't newer.
             if (newConfig.getConfigVersion() < currentConfigVersion) {
-                LOG(1) << "Config version from heartbeat was older than ours.";
+                LOGV2_DEBUG(1, "Config version from heartbeat was older than ours.");
             } else {
-                LOG(2) << "Config from heartbeat response was same as ours.";
+                LOGV2_DEBUG(2, "Config from heartbeat response was same as ours.");
             }
             if (shouldLog(MongoLogDefaultComponent_component,
                           ::mongo::LogstreamBuilder::severityCast(2))) {
@@ -776,18 +756,15 @@ HeartbeatResponseAction TopologyCoordinator::processHeartbeatResponse(
     }
     // If we're not in the config, we don't need to respond to heartbeats.
     if (_selfIndex == -1) {
-        LOG(1) << "Could not find ourself in current config so ignoring heartbeat from " << target
-               << " -- current config: " << _rsConfig.toBSON();
+        LOGV2_DEBUG(1, "Could not find ourself in current config so ignoring heartbeat from {} -- current config: {}", "target"_attr = target, "_rsConfig_toBSON"_attr = _rsConfig.toBSON());
         HeartbeatResponseAction nextAction = HeartbeatResponseAction::makeNoAction();
         nextAction.setNextHeartbeatStartDate(nextHeartbeatStartDate);
         return nextAction;
     }
     const int memberIndex = _rsConfig.findMemberIndexByHostAndPort(target);
     if (memberIndex == -1) {
-        LOG(1) << "Could not find " << target
-               << " in current config so ignoring --"
-                  " current config: "
-               << _rsConfig.toBSON();
+        LOGV2_DEBUG(1, "Could not find {} in current config so ignoring --"
+                  " current config: {}", "target"_attr = target, "_rsConfig_toBSON"_attr = _rsConfig.toBSON());
         HeartbeatResponseAction nextAction = HeartbeatResponseAction::makeNoAction();
         nextAction.setNextHeartbeatStartDate(nextHeartbeatStartDate);
         return nextAction;
@@ -813,7 +790,7 @@ HeartbeatResponseAction TopologyCoordinator::processHeartbeatResponse(
         }
     } else {
         ReplSetHeartbeatResponse hbr = std::move(hbResponse.getValue());
-        LOG(3) << "setUpValues: heartbeat response good for member _id:" << member.getId();
+        LOGV2_DEBUG(3, "setUpValues: heartbeat response good for member _id:{}", "member_getId"_attr = member.getId());
         advancedOpTime = hbData.setUpValues(now, std::move(hbr));
     }
 
@@ -923,7 +900,7 @@ HeartbeatResponseAction TopologyCoordinator::checkMemberTimeouts(Date_t now) {
         }
     }
     if (stepdown) {
-        log() << "can't see a majority of the set, relinquishing primary";
+        LOGV2("can't see a majority of the set, relinquishing primary");
         return HeartbeatResponseAction::makeStepDownSelfAction(_selfIndex);
     }
     return HeartbeatResponseAction::makeNoAction();
@@ -972,13 +949,13 @@ std::pair<MemberId, Date_t> TopologyCoordinator::getStalestLiveMember() const {
             // Already stale.
             continue;
         }
-        LOG(3) << "memberData lastupdate is: " << memberData.getLastUpdate();
+        LOGV2_DEBUG(3, "memberData lastupdate is: {}", "memberData_getLastUpdate"_attr = memberData.getLastUpdate());
         if (earliestDate > memberData.getLastUpdate()) {
             earliestDate = memberData.getLastUpdate();
             earliestMemberId = memberData.getMemberId();
         }
     }
-    LOG(3) << "stalest member " << earliestMemberId << " date: " << earliestDate;
+    LOGV2_DEBUG(3, "stalest member {} date: {}", "earliestMemberId"_attr = earliestMemberId, "earliestDate"_attr = earliestDate);
     return std::make_pair(earliestMemberId, earliestDate);
 }
 
@@ -1062,17 +1039,14 @@ StatusWith<bool> TopologyCoordinator::setLastOptime(const UpdatePositionArgs::Up
         return false;
     }
 
-    LOG(2) << "received notification that node with memberID " << memberId
-           << " in config with version " << args.cfgver
-           << " has reached optime: " << args.appliedOpTime
-           << " and is durable through: " << args.durableOpTime;
+    LOGV2_DEBUG(2, "received notification that node with memberID {} in config with version {} has reached optime: {} and is durable through: {}", "memberId"_attr = memberId, "args_cfgver"_attr = args.cfgver, "args_appliedOpTime"_attr = args.appliedOpTime, "args_durableOpTime"_attr = args.durableOpTime);
 
     if (args.cfgver != _rsConfig.getConfigVersion()) {
         std::string errmsg = str::stream()
             << "Received replSetUpdatePosition for node with memberId " << memberId
             << " whose config version of " << args.cfgver << " doesn't match our config version of "
             << _rsConfig.getConfigVersion();
-        LOG(1) << errmsg;
+        LOGV2_DEBUG(1, "{}", "errmsg"_attr = errmsg);
         *configVersion = _rsConfig.getConfigVersion();
         return Status(ErrorCodes::InvalidReplicaSetConfig, errmsg);
     }
@@ -1084,7 +1058,7 @@ StatusWith<bool> TopologyCoordinator::setLastOptime(const UpdatePositionArgs::Up
         std::string errmsg = str::stream()
             << "Received replSetUpdatePosition for node with memberId " << memberId
             << " which doesn't exist in our config";
-        LOG(1) << errmsg;
+        LOGV2_DEBUG(1, "{}", "errmsg"_attr = errmsg);
         return Status(ErrorCodes::NodeNotFound, errmsg);
     }
 
@@ -1386,7 +1360,7 @@ void TopologyCoordinator::changeMemberState_forTest(const MemberState& newMember
                  << getMemberState();
         MONGO_UNREACHABLE;
     }
-    log() << newMemberState;
+    LOGV2("{}", "newMemberState"_attr = newMemberState);
 }
 
 void TopologyCoordinator::setCurrentPrimary_forTest(int primaryIndex,
@@ -1801,13 +1775,13 @@ TopologyCoordinator::prepareFreezeResponse(Date_t now, int secs, BSONObjBuilder*
         std::string msg = str::stream()
             << "cannot freeze node when primary or running for election. state: "
             << (_role == TopologyCoordinator::Role::kLeader ? "Primary" : "Running-Election");
-        log() << msg;
+        LOGV2("{}", "msg"_attr = msg);
         return Status(ErrorCodes::NotSecondary, msg);
     }
 
     if (secs == 0) {
         _stepDownUntil = now;
-        log() << "'unfreezing'";
+        LOGV2("'unfreezing'");
         response->append("info", "unfreezing");
         return PrepareFreezeResponseResult::kSingleNodeSelfElect;
     } else {
@@ -1815,7 +1789,7 @@ TopologyCoordinator::prepareFreezeResponse(Date_t now, int secs, BSONObjBuilder*
             response->append("warning", "you really want to freeze for only 1 second?");
 
         _stepDownUntil = std::max(_stepDownUntil, now + Seconds(secs));
-        log() << "'freezing' for " << secs << " seconds";
+        LOGV2("'freezing' for {} seconds", "secs"_attr = secs);
     }
 
     return PrepareFreezeResponseResult::kNoAction;
@@ -1892,7 +1866,7 @@ void TopologyCoordinator::updateConfig(const ReplSetConfig& newConfig, int selfI
     // Reset term on startup.
     if (!_rsConfig.isInitialized()) {
         _term = OpTime::kInitialTerm;
-        LOG(1) << "Updated term in topology coordinator to " << _term << " due to new config";
+        LOGV2_DEBUG(1, "Updated term in topology coordinator to {} due to new config", "_term"_attr = _term);
     }
 
     _updateHeartbeatDataForReconfig(newConfig, selfIndex, now);
@@ -1902,9 +1876,9 @@ void TopologyCoordinator::updateConfig(const ReplSetConfig& newConfig, int selfI
 
     if (_role == Role::kLeader) {
         if (_selfIndex == -1) {
-            log() << "Could not remain primary because no longer a member of the replica set";
+            LOGV2("Could not remain primary because no longer a member of the replica set");
         } else if (!_selfConfig().isElectable()) {
-            log() << " Could not remain primary because no longer electable";
+            LOGV2(" Could not remain primary because no longer electable");
         } else {
             // Don't stepdown if you don't have to.
             _currentPrimaryIndex = _selfIndex;
@@ -2466,8 +2440,7 @@ bool TopologyCoordinator::advanceLastCommittedOpTimeAndWallTime(OpTimeAndWallTim
 
     // This check is performed to ensure primaries do not commit an OpTime from a previous term.
     if (_iAmPrimary() && committedOpTime.opTime < _firstOpTimeOfMyTerm) {
-        LOG(1) << "Ignoring older committed snapshot from before I became primary, optime: "
-               << committedOpTime.opTime << ", firstOpTimeOfMyTerm: " << _firstOpTimeOfMyTerm;
+        LOGV2_DEBUG(1, "Ignoring older committed snapshot from before I became primary, optime: {}, firstOpTimeOfMyTerm: {}", "committedOpTime_opTime"_attr = committedOpTime.opTime, "_firstOpTimeOfMyTerm"_attr = _firstOpTimeOfMyTerm);
         return false;
     }
 
@@ -2477,11 +2450,9 @@ bool TopologyCoordinator::advanceLastCommittedOpTimeAndWallTime(OpTimeAndWallTim
         if (fromSyncSource) {
             committedOpTime = std::min(committedOpTime, getMyLastAppliedOpTimeAndWallTime());
         } else {
-            LOG(1) << "Ignoring commit point with different term than my lastApplied, since it "
+            LOGV2_DEBUG(1, "Ignoring commit point with different term than my lastApplied, since it "
                       "may "
-                      "not be on the same oplog branch as mine. optime: "
-                   << committedOpTime
-                   << ", my last applied: " << getMyLastAppliedOpTimeAndWallTime();
+                      "not be on the same oplog branch as mine. optime: {}, my last applied: {}", "committedOpTime"_attr = committedOpTime, "getMyLastAppliedOpTimeAndWallTime"_attr = getMyLastAppliedOpTimeAndWallTime());
             return false;
         }
     }
@@ -2491,12 +2462,11 @@ bool TopologyCoordinator::advanceLastCommittedOpTimeAndWallTime(OpTimeAndWallTim
     }
 
     if (committedOpTime.opTime < _lastCommittedOpTimeAndWallTime.opTime) {
-        LOG(1) << "Ignoring older committed snapshot optime: " << committedOpTime
-               << ", currentCommittedOpTime: " << _lastCommittedOpTimeAndWallTime;
+        LOGV2_DEBUG(1, "Ignoring older committed snapshot optime: {}, currentCommittedOpTime: {}", "committedOpTime"_attr = committedOpTime, "_lastCommittedOpTimeAndWallTime"_attr = _lastCommittedOpTimeAndWallTime);
         return false;
     }
 
-    LOG(2) << "Updating _lastCommittedOpTimeAndWallTime to " << committedOpTime;
+    LOGV2_DEBUG(2, "Updating _lastCommittedOpTimeAndWallTime to {}", "committedOpTime"_attr = committedOpTime);
     _lastCommittedOpTimeAndWallTime = committedOpTime;
     return true;
 }
@@ -2558,7 +2528,7 @@ TopologyCoordinator::UpdateTermResult TopologyCoordinator::updateTerm(long long
     if (_iAmPrimary()) {
         return TopologyCoordinator::UpdateTermResult::kTriggerStepDown;
     }
-    LOG(1) << "Updating term from " << _term << " to " << term;
+    LOGV2_DEBUG(1, "Updating term from {} to {}", "_term"_attr = _term, "term"_attr = term);
     _term = term;
     return TopologyCoordinator::UpdateTermResult::kUpdatedTerm;
 }
@@ -2583,29 +2553,24 @@ bool TopologyCoordinator::shouldChangeSyncSource(
     // progress, return true.
 
     if (_selfIndex == -1) {
-        log() << "Not choosing new sync source because we are not in the config.";
+        LOGV2("Not choosing new sync source because we are not in the config.");
         return false;
     }
 
     // If the user requested a sync source change, return true.
     if (_forceSyncSourceIndex != -1) {
-        log() << "Choosing new sync source because the user has requested to use "
-              << _rsConfig.getMemberAt(_forceSyncSourceIndex).getHostAndPort()
-              << " as a sync source";
+        LOGV2("Choosing new sync source because the user has requested to use {} as a sync source", "_rsConfig_getMemberAt__forceSyncSourceIndex_getHostAndPort"_attr = _rsConfig.getMemberAt(_forceSyncSourceIndex).getHostAndPort());
         return true;
     }
 
     if (replMetadata.getConfigVersion() != _rsConfig.getConfigVersion()) {
-        log() << "Choosing new sync source because the config version supplied by " << currentSource
-              << ", " << replMetadata.getConfigVersion() << ", does not match ours, "
-              << _rsConfig.getConfigVersion();
+        LOGV2("Choosing new sync source because the config version supplied by {}, {}, does not match ours, {}", "currentSource"_attr = currentSource, "replMetadata_getConfigVersion"_attr = replMetadata.getConfigVersion(), "_rsConfig_getConfigVersion"_attr = _rsConfig.getConfigVersion());
         return true;
     }
 
     const int currentSourceIndex = _rsConfig.findMemberIndexByHostAndPort(currentSource);
     if (currentSourceIndex == -1) {
-        log() << "Choosing new sync source because " << currentSource.toString()
-              << " is not in our config";
+        LOGV2("Choosing new sync source because {} is not in our config", "currentSource_toString"_attr = currentSource.toString());
         return true;
     }
 
@@ -2654,15 +2619,13 @@ bool TopologyCoordinator::shouldChangeSyncSource(
         } else {
             logMessage << " (sync source does not know the primary)";
         }
-        log() << logMessage.str();
+        LOGV2("{}", "logMessage_str"_attr = logMessage.str());
         return true;
     }
 
     if (MONGO_unlikely(disableMaxSyncSourceLagSecs.shouldFail())) {
-        log() << "disableMaxSyncSourceLagSecs fail point enabled - not checking the most recent "
-                 "OpTime, "
-              << currentSourceOpTime.toString() << ", of our current sync source, " << currentSource
-              << ", against the OpTimes of the other nodes in this replica set.";
+        LOGV2("disableMaxSyncSourceLagSecs fail point enabled - not checking the most recent "
+                 "OpTime, {}, of our current sync source, {}, against the OpTimes of the other nodes in this replica set.", "currentSourceOpTime_toString"_attr = currentSourceOpTime.toString(), "currentSource"_attr = currentSource);
     } else {
         unsigned int currentSecs = currentSourceOpTime.getSecs();
         unsigned int goalSecs = currentSecs + durationCount<Seconds>(_options.maxSyncSourceLagSecs);
@@ -2676,13 +2639,8 @@ bool TopologyCoordinator::shouldChangeSyncSource(
                 (candidateConfig.shouldBuildIndexes() || !_selfConfig().shouldBuildIndexes()) &&
                 it->getState().readable() && !_memberIsBlacklisted(candidateConfig, now) &&
                 goalSecs < it->getHeartbeatAppliedOpTime().getSecs()) {
-                log() << "Choosing new sync source because the most recent OpTime of our sync "
-                         "source, "
-                      << currentSource << ", is " << currentSourceOpTime.toString()
-                      << " which is more than " << _options.maxSyncSourceLagSecs
-                      << " behind member " << candidateConfig.getHostAndPort().toString()
-                      << " whose most recent OpTime is "
-                      << it->getHeartbeatAppliedOpTime().toString();
+                LOGV2("Choosing new sync source because the most recent OpTime of our sync "
+                         "source, {}, is {} which is more than {} behind member {} whose most recent OpTime is {}", "currentSource"_attr = currentSource, "currentSourceOpTime_toString"_attr = currentSourceOpTime.toString(), "_options_maxSyncSourceLagSecs"_attr = _options.maxSyncSourceLagSecs, "candidateConfig_getHostAndPort_toString"_attr = candidateConfig.getHostAndPort().toString(), "it_getHeartbeatAppliedOpTime_toString"_attr = it->getHeartbeatAppliedOpTime().toString());
                 invariant(itIndex != _selfIndex);
                 return true;
             }
@@ -2716,7 +2674,7 @@ void TopologyCoordinator::processReplSetRequestVotes(const ReplSetRequestVotesAr
     response->setTerm(_term);
 
     if (MONGO_unlikely(voteNoInElection.shouldFail())) {
-        log() << "failpoint voteNoInElection enabled";
+        LOGV2("failpoint voteNoInElection enabled");
         response->setVoteGranted(false);
         response->setReason(str::stream() << "forced to vote no during dry run election due to "
                                              "failpoint voteNoInElection set");
@@ -2724,7 +2682,7 @@ void TopologyCoordinator::processReplSetRequestVotes(const ReplSetRequestVotesAr
     }
 
     if (MONGO_unlikely(voteYesInDryRunButNoInRealElection.shouldFail())) {
-        log() << "failpoint voteYesInDryRunButNoInRealElection enabled";
+        LOGV2("failpoint voteYesInDryRunButNoInRealElection enabled");
         if (args.isADryRun()) {
             response->setVoteGranted(true);
             response->setReason(str::stream() << "forced to vote yes in dry run due to failpoint "
diff --git a/src/mongo/db/repl/topology_coordinator_v1_test.cpp b/src/mongo/db/repl/topology_coordinator_v1_test.cpp
index 2ea7224b00..9cbad2036b 100644
--- a/src/mongo/db/repl/topology_coordinator_v1_test.cpp
+++ b/src/mongo/db/repl/topology_coordinator_v1_test.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/executor/task_executor.h"
 #include "mongo/logger/logger.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/oplog_query_metadata.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/unittest/unittest.h"
@@ -1609,7 +1610,7 @@ TEST_F(TopoCoordTest, ReplSetGetStatus) {
         &resultStatus);
     ASSERT_OK(resultStatus);
     BSONObj rsStatus = statusBuilder.obj();
-    unittest::log() << rsStatus;
+    unittest::LOGV2("{}", "rsStatus"_attr = rsStatus);
 
     // Test results for all non-self members
     ASSERT_EQUALS(setName, rsStatus["set"].String());
@@ -1725,7 +1726,7 @@ TEST_F(TopoCoordTest, ReplSetGetStatus) {
         &resultStatus);
     ASSERT_OK(resultStatus);
     rsStatus = statusBuilder2.obj();
-    unittest::log() << rsStatus;
+    unittest::LOGV2("{}", "rsStatus"_attr = rsStatus);
     ASSERT_EQUALS(setName, rsStatus["set"].String());
     ASSERT_FALSE(rsStatus.hasField("lastStableRecoveryTimestamp"));
     ASSERT_FALSE(rsStatus.hasField("electionCandidateMetrics"));
@@ -1795,7 +1796,7 @@ TEST_F(TopoCoordTest, ReplSetGetStatusIPs) {
         getTopoCoord().prepareStatusResponse({}, &statusBuilder, &resultStatus);
         ASSERT_OK(resultStatus);
         BSONObj rsStatus = statusBuilder.obj();
-        unittest::log() << rsStatus;
+        unittest::LOGV2("{}", "rsStatus"_attr = rsStatus);
         auto elem = rsStatus["members"].Array()[0]["ip"];
         return elem.isNull() ? "null" : elem.String();
     };
diff --git a/src/mongo/db/repl/transaction_oplog_application.cpp b/src/mongo/db/repl/transaction_oplog_application.cpp
index 986c566472..60b1ca44fc 100644
--- a/src/mongo/db/repl/transaction_oplog_application.cpp
+++ b/src/mongo/db/repl/transaction_oplog_application.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/session_catalog_mongod.h"
 #include "mongo/db/transaction_history_iterator.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -369,7 +370,7 @@ Status _applyPrepareTransaction(OperationContext* opCtx,
     fassert(31137, status);
 
     if (MONGO_unlikely(applyOpsHangBeforePreparingTransaction.shouldFail())) {
-        LOG(0) << "Hit applyOpsHangBeforePreparingTransaction failpoint";
+        LOGV2("Hit applyOpsHangBeforePreparingTransaction failpoint");
         applyOpsHangBeforePreparingTransaction.pauseWhileSet(opCtx);
     }
 
@@ -448,7 +449,7 @@ Status applyPrepareTransaction(OperationContext* opCtx,
 
 void reconstructPreparedTransactions(OperationContext* opCtx, repl::OplogApplication::Mode mode) {
     if (MONGO_unlikely(skipReconstructPreparedTransactions.shouldFail())) {
-        log() << "Hit skipReconstructPreparedTransactions failpoint";
+        LOGV2("Hit skipReconstructPreparedTransactions failpoint");
         return;
     }
     // Read the transactions table and the oplog collection without a timestamp.
diff --git a/src/mongo/db/s/balancer/balancer.cpp b/src/mongo/db/s/balancer/balancer.cpp
index a81122592d..d5152e2ef9 100644
--- a/src/mongo/db/s/balancer/balancer.cpp
+++ b/src/mongo/db/s/balancer/balancer.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/s/balancer/balancer_chunk_selection_policy_impl.h"
 #include "mongo/db/s/balancer/cluster_statistics_impl.h"
 #include "mongo/db/s/sharding_logging.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/catalog_cache.h"
@@ -240,7 +241,7 @@ void Balancer::waitForBalancerToStop() {
     _state = kStopped;
     _thread = {};
 
-    LOG(1) << "Balancer thread terminated";
+    LOGV2_DEBUG(1, "Balancer thread terminated");
 }
 
 void Balancer::joinCurrentRound(OperationContext* opCtx) {
@@ -259,7 +260,7 @@ Status Balancer::rebalanceSingleChunk(OperationContext* opCtx, const ChunkType&
 
     auto migrateInfo = std::move(migrateStatus.getValue());
     if (!migrateInfo) {
-        LOG(1) << "Unable to find more appropriate location for chunk " << redact(chunk.toString());
+        LOGV2_DEBUG(1, "Unable to find more appropriate location for chunk {}", "redact_chunk_toString"_attr = redact(chunk.toString()));
         return Status::OK();
     }
 
@@ -317,7 +318,7 @@ void Balancer::_mainThread() {
     auto opCtx = cc().makeOperationContext();
     auto shardingContext = Grid::get(opCtx.get());
 
-    log() << "CSRS balancer is starting";
+    LOGV2("CSRS balancer is starting");
 
     {
         stdx::lock_guard<Latch> scopedLock(_mutex);
@@ -341,13 +342,13 @@ void Balancer::_mainThread() {
         break;
     }
 
-    log() << "CSRS balancer thread is recovering";
+    LOGV2("CSRS balancer thread is recovering");
 
     _migrationManager.finishRecovery(opCtx.get(),
                                      balancerConfig->getMaxChunkSizeBytes(),
                                      balancerConfig->getSecondaryThrottle());
 
-    log() << "CSRS balancer thread is recovered";
+    LOGV2("CSRS balancer thread is recovered");
 
     // Main balancer loop
     while (!_stopRequested()) {
@@ -368,16 +369,13 @@ void Balancer::_mainThread() {
             }
 
             if (!balancerConfig->shouldBalance()) {
-                LOG(1) << "Skipping balancing round because balancing is disabled";
+                LOGV2_DEBUG(1, "Skipping balancing round because balancing is disabled");
                 _endRound(opCtx.get(), kBalanceRoundDefaultInterval);
                 continue;
             }
 
             {
-                LOG(1) << "*** start balancing round. "
-                       << "waitForDelete: " << balancerConfig->waitForDelete()
-                       << ", secondaryThrottle: "
-                       << balancerConfig->getSecondaryThrottle().toBSON();
+                LOGV2_DEBUG(1, "*** start balancing round. waitForDelete: {}, secondaryThrottle: {}", "balancerConfig_waitForDelete"_attr = balancerConfig->waitForDelete(), "balancerConfig_getSecondaryThrottle_toBSON"_attr = balancerConfig->getSecondaryThrottle().toBSON());
 
                 static Occasionally sampler;
                 if (sampler.tick()) {
@@ -388,14 +386,14 @@ void Balancer::_mainThread() {
                 if (!status.isOK()) {
                     warning() << "Failed to enforce tag ranges" << causedBy(status);
                 } else {
-                    LOG(1) << "Done enforcing tag range boundaries.";
+                    LOGV2_DEBUG(1, "Done enforcing tag range boundaries.");
                 }
 
                 const auto candidateChunks =
                     uassertStatusOK(_chunkSelectionPolicy->selectChunksToMove(opCtx.get()));
 
                 if (candidateChunks.empty()) {
-                    LOG(1) << "no need to move any chunk";
+                    LOGV2_DEBUG(1, "no need to move any chunk");
                     _balancedLastTime = 0;
                 } else {
                     _balancedLastTime = _moveChunks(opCtx.get(), candidateChunks);
@@ -408,7 +406,7 @@ void Balancer::_mainThread() {
                         .ignore();
                 }
 
-                LOG(1) << "*** End of balancing round";
+                LOGV2_DEBUG(1, "*** End of balancing round");
             }
 
             Milliseconds balancerInterval =
@@ -416,16 +414,15 @@ void Balancer::_mainThread() {
 
             overrideBalanceRoundInterval.execute([&](const BSONObj& data) {
                 balancerInterval = Milliseconds(data["intervalMs"].numberInt());
-                log() << "overrideBalanceRoundInterval: using shorter balancing interval: "
-                      << balancerInterval;
+                LOGV2("overrideBalanceRoundInterval: using shorter balancing interval: {}", "balancerInterval"_attr = balancerInterval);
             });
 
             _endRound(opCtx.get(), balancerInterval);
         } catch (const DBException& e) {
-            log() << "caught exception while doing balance: " << e.what();
+            LOGV2("caught exception while doing balance: {}", "e_what"_attr = e.what());
 
             // Just to match the opening statement if in log level 1
-            LOG(1) << "*** End of balancing round";
+            LOGV2_DEBUG(1, "*** End of balancing round");
 
             // This round failed, tell the world!
             roundDetails.setFailed(e.what());
@@ -454,7 +451,7 @@ void Balancer::_mainThread() {
         _threadOperationContext = nullptr;
     }
 
-    log() << "CSRS balancer is now stopped";
+    LOGV2("CSRS balancer is now stopped");
 }
 
 bool Balancer::_stopRequested() {
@@ -519,8 +516,7 @@ bool Balancer::_checkOIDs(OperationContext* opCtx) {
             if (oids.count(x) == 0) {
                 oids[x] = shardId;
             } else {
-                log() << "error: 2 machines have " << x << " as oid machine piece: " << shardId
-                      << " and " << oids[x];
+                LOGV2("error: 2 machines have {} as oid machine piece: {} and {}", "x"_attr = x, "shardId"_attr = shardId, "oids_x"_attr = oids[x]);
 
                 result = uassertStatusOK(s->runCommandWithFixedRetryAttempts(
                     opCtx,
@@ -545,7 +541,7 @@ bool Balancer::_checkOIDs(OperationContext* opCtx) {
                 return false;
             }
         } else {
-            log() << "warning: oidMachine not set on: " << s->toString();
+            LOGV2("warning: oidMachine not set on: {}", "s_toString"_attr = s->toString());
         }
     }
 
@@ -591,7 +587,7 @@ int Balancer::_moveChunks(OperationContext* opCtx,
 
     // If the balancer was disabled since we started this round, don't start new chunk moves
     if (_stopRequested() || !balancerConfig->shouldBalance()) {
-        LOG(1) << "Skipping balancing round because balancer was stopped";
+        LOGV2_DEBUG(1, "Skipping balancing round because balancer was stopped");
         return 0;
     }
 
@@ -629,15 +625,13 @@ int Balancer::_moveChunks(OperationContext* opCtx,
         if (status == ErrorCodes::ChunkTooBig || status == ErrorCodes::ExceededMemoryLimit) {
             numChunksProcessed++;
 
-            log() << "Performing a split because migration " << redact(requestIt->toString())
-                  << " failed for size reasons" << causedBy(redact(status));
+            LOGV2("Performing a split because migration {} failed for size reasons{}", "redact_requestIt_toString"_attr = redact(requestIt->toString()), "causedBy_redact_status"_attr = causedBy(redact(status)));
 
             _splitOrMarkJumbo(opCtx, requestIt->nss, requestIt->minKey);
             continue;
         }
 
-        log() << "Balancer move " << redact(requestIt->toString()) << " failed"
-              << causedBy(redact(status));
+        LOGV2("Balancer move {} failed{}", "redact_requestIt_toString"_attr = redact(requestIt->toString()), "causedBy_redact_status"_attr = causedBy(redact(status)));
     }
 
     return numChunksProcessed;
@@ -663,7 +657,7 @@ void Balancer::_splitOrMarkJumbo(OperationContext* opCtx,
             boost::none));
 
         if (splitPoints.empty()) {
-            log() << "Marking chunk " << redact(chunk.toString()) << " as jumbo.";
+            LOGV2("Marking chunk {} as jumbo.", "redact_chunk_toString"_attr = redact(chunk.toString()));
             chunk.markAsJumbo();
 
             auto status = Grid::get(opCtx)->catalogClient()->updateConfigDocument(
@@ -674,9 +668,7 @@ void Balancer::_splitOrMarkJumbo(OperationContext* opCtx,
                 false,
                 ShardingCatalogClient::kMajorityWriteConcern);
             if (!status.isOK()) {
-                log() << "Couldn't set jumbo for chunk with namespace " << redact(nss.ns())
-                      << " and min key " << redact(chunk.getMin())
-                      << causedBy(redact(status.getStatus()));
+                LOGV2("Couldn't set jumbo for chunk with namespace {} and min key {}{}", "redact_nss_ns"_attr = redact(nss.ns()), "redact_chunk_getMin"_attr = redact(chunk.getMin()), "causedBy_redact_status_getStatus"_attr = causedBy(redact(status.getStatus())));
             }
 
             return;
diff --git a/src/mongo/db/s/balancer/balancer_chunk_selection_policy_impl.cpp b/src/mongo/db/s/balancer/balancer_chunk_selection_policy_impl.cpp
index f387556b02..1cb4b0eadf 100644
--- a/src/mongo/db/s/balancer/balancer_chunk_selection_policy_impl.cpp
+++ b/src/mongo/db/s/balancer/balancer_chunk_selection_policy_impl.cpp
@@ -39,6 +39,7 @@
 
 #include "mongo/base/status_with.h"
 #include "mongo/bson/bsonobj_comparator_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/catalog/type_collection.h"
diff --git a/src/mongo/db/s/balancer/balancer_policy.cpp b/src/mongo/db/s/balancer/balancer_policy.cpp
index 022379992f..d7adc7d1d7 100644
--- a/src/mongo/db/s/balancer/balancer_policy.cpp
+++ b/src/mongo/db/s/balancer/balancer_policy.cpp
@@ -36,6 +36,7 @@
 #include <random>
 
 #include "mongo/db/s/balancer/type_migration.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_shard.h"
 #include "mongo/s/catalog/type_tags.h"
 #include "mongo/util/fail_point.h"
@@ -342,8 +343,7 @@ MigrateInfo chooseRandomMigration(const ShardStatisticsVector& shardStats,
     const int destIndex = indices[choice];
     const auto& destShardId = shardStats[destIndex].shardId;
 
-    LOG(1) << "balancerShouldReturnRandomMigrations: source: " << sourceShardId
-           << " dest: " << destShardId;
+    LOGV2_DEBUG(1, "balancerShouldReturnRandomMigrations: source: {} dest: {}", "sourceShardId"_attr = sourceShardId, "destShardId"_attr = destShardId);
 
     const auto& chunks = distribution.getChunks(sourceShardId);
 
@@ -361,7 +361,7 @@ vector<MigrateInfo> BalancerPolicy::balance(const ShardStatisticsVector& shardSt
 
     if (MONGO_unlikely(balancerShouldReturnRandomMigrations.shouldFail()) &&
         !distribution.nss().isConfigDB()) {
-        LOG(1) << "balancerShouldReturnRandomMigrations failpoint is set";
+        LOGV2_DEBUG(1, "balancerShouldReturnRandomMigrations failpoint is set");
 
         if (shardStats.size() < 2)
             return migrations;
@@ -552,7 +552,7 @@ bool BalancerPolicy::_singleZoneBalance(const ShardStatisticsVector& shardStats,
     const ShardId to = _getLeastLoadedReceiverShard(shardStats, distribution, tag, *usedShards);
     if (!to.isValid()) {
         if (migrations->empty()) {
-            log() << "No available shards to take chunks for zone [" << tag << "]";
+            LOGV2("No available shards to take chunks for zone [{}]", "tag"_attr = tag);
         }
         return false;
     }
@@ -565,12 +565,12 @@ bool BalancerPolicy::_singleZoneBalance(const ShardStatisticsVector& shardStats,
 
     const size_t imbalance = max - idealNumberOfChunksPerShardForTag;
 
-    LOG(1) << "collection : " << distribution.nss().ns();
-    LOG(1) << "zone       : " << tag;
-    LOG(1) << "donor      : " << from << " chunks on " << max;
-    LOG(1) << "receiver   : " << to << " chunks on " << min;
-    LOG(1) << "ideal      : " << idealNumberOfChunksPerShardForTag;
-    LOG(1) << "threshold  : " << kDefaultImbalanceThreshold;
+    LOGV2_DEBUG(1, "collection : {}", "distribution_nss_ns"_attr = distribution.nss().ns());
+    LOGV2_DEBUG(1, "zone       : {}", "tag"_attr = tag);
+    LOGV2_DEBUG(1, "donor      : {} chunks on {}", "from"_attr = from, "max"_attr = max);
+    LOGV2_DEBUG(1, "receiver   : {} chunks on {}", "to"_attr = to, "min"_attr = min);
+    LOGV2_DEBUG(1, "ideal      : {}", "idealNumberOfChunksPerShardForTag"_attr = idealNumberOfChunksPerShardForTag);
+    LOGV2_DEBUG(1, "threshold  : {}", "kDefaultImbalanceThreshold"_attr = kDefaultImbalanceThreshold);
 
     // Check whether it is necessary to balance within this zone
     if (imbalance < kDefaultImbalanceThreshold)
diff --git a/src/mongo/db/s/balancer/cluster_statistics_impl.cpp b/src/mongo/db/s/balancer/cluster_statistics_impl.cpp
index 9fd3ebf675..33c34d98dc 100644
--- a/src/mongo/db/s/balancer/cluster_statistics_impl.cpp
+++ b/src/mongo/db/s/balancer/cluster_statistics_impl.cpp
@@ -38,6 +38,7 @@
 #include "mongo/base/status_with.h"
 #include "mongo/bson/util/bson_extract.h"
 #include "mongo/client/read_preference.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_shard.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
@@ -141,8 +142,7 @@ StatusWith<std::vector<ShardStatistics>> ClusterStatisticsImpl::getStats(Operati
         } else {
             // Since the mongod version is only used for reporting, there is no need to fail the
             // entire round if it cannot be retrieved, so just leave it empty
-            log() << "Unable to obtain shard version for " << shard.getName()
-                  << causedBy(mongoDVersionStatus.getStatus());
+            LOGV2("Unable to obtain shard version for {}{}", "shard_getName"_attr = shard.getName(), "causedBy_mongoDVersionStatus_getStatus"_attr = causedBy(mongoDVersionStatus.getStatus()));
         }
 
         std::set<std::string> shardTags;
diff --git a/src/mongo/db/s/balancer/migration_manager.cpp b/src/mongo/db/s/balancer/migration_manager.cpp
index ae0997fa9d..990ada515e 100644
--- a/src/mongo/db/s/balancer/migration_manager.cpp
+++ b/src/mongo/db/s/balancer/migration_manager.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/s/balancer/scoped_migration_request.h"
 #include "mongo/db/s/balancer/type_migration.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_registry.h"
@@ -234,9 +235,7 @@ void MigrationManager::startRecoveryAndAcquireDistLocks(OperationContext* opCtx)
             boost::none);
 
     if (!statusWithMigrationsQueryResponse.isOK()) {
-        log() << "Unable to read config.migrations collection documents for balancer migration"
-              << " recovery. Abandoning balancer recovery."
-              << causedBy(redact(statusWithMigrationsQueryResponse.getStatus()));
+        LOGV2("Unable to read config.migrations collection documents for balancer migration recovery. Abandoning balancer recovery.{}", "causedBy_redact_statusWithMigrationsQueryResponse_getStatus"_attr = causedBy(redact(statusWithMigrationsQueryResponse.getStatus())));
         return;
     }
 
@@ -246,9 +245,7 @@ void MigrationManager::startRecoveryAndAcquireDistLocks(OperationContext* opCtx)
             // The format of this migration document is incorrect. The balancer holds a distlock for
             // this migration, but without parsing the migration document we cannot identify which
             // distlock must be released. So we must release all distlocks.
-            log() << "Unable to parse config.migrations document '" << redact(migration.toString())
-                  << "' for balancer migration recovery. Abandoning balancer recovery."
-                  << causedBy(redact(statusWithMigrationType.getStatus()));
+            LOGV2("Unable to parse config.migrations document '{}' for balancer migration recovery. Abandoning balancer recovery.{}", "redact_migration_toString"_attr = redact(migration.toString()), "causedBy_redact_statusWithMigrationType_getStatus"_attr = causedBy(redact(statusWithMigrationType.getStatus())));
             return;
         }
         MigrationType migrateType = std::move(statusWithMigrationType.getValue());
@@ -265,11 +262,7 @@ void MigrationManager::startRecoveryAndAcquireDistLocks(OperationContext* opCtx)
             auto statusWithDistLockHandle = distLockManager->tryLockWithLocalWriteConcern(
                 opCtx, migrateType.getNss().ns(), whyMessage, _lockSessionID);
             if (!statusWithDistLockHandle.isOK()) {
-                log() << "Failed to acquire distributed lock for collection '"
-                      << migrateType.getNss().ns()
-                      << "' during balancer recovery of an active migration. Abandoning"
-                      << " balancer recovery."
-                      << causedBy(redact(statusWithDistLockHandle.getStatus()));
+                LOGV2("Failed to acquire distributed lock for collection '{}' during balancer recovery of an active migration. Abandoning balancer recovery.{}", "migrateType_getNss_ns"_attr = migrateType.getNss().ns(), "causedBy_redact_statusWithDistLockHandle_getStatus"_attr = causedBy(redact(statusWithDistLockHandle.getStatus())));
                 return;
             }
         }
@@ -320,9 +313,7 @@ void MigrationManager::finishRecovery(OperationContext* opCtx,
             // This shouldn't happen because the collection was intact and sharded when the previous
             // config primary was active and the dist locks have been held by the balancer
             // throughout. Abort migration recovery.
-            log() << "Unable to reload chunk metadata for collection '" << nss
-                  << "' during balancer recovery. Abandoning recovery."
-                  << causedBy(redact(routingInfoStatus.getStatus()));
+            LOGV2("Unable to reload chunk metadata for collection '{}' during balancer recovery. Abandoning recovery.{}", "nss"_attr = nss, "causedBy_redact_routingInfoStatus_getStatus"_attr = causedBy(redact(routingInfoStatus.getStatus())));
             return;
         }
 
diff --git a/src/mongo/db/s/balancer/scoped_migration_request.cpp b/src/mongo/db/s/balancer/scoped_migration_request.cpp
index 3333b5f3ab..abaffbc668 100644
--- a/src/mongo/db/s/balancer/scoped_migration_request.cpp
+++ b/src/mongo/db/s/balancer/scoped_migration_request.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/s/balancer/type_migration.h"
 #include "mongo/db/write_concern_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
@@ -68,8 +69,7 @@ ScopedMigrationRequest::~ScopedMigrationRequest() {
         _opCtx, MigrationType::ConfigNS, migrationDocumentIdentifier, kMajorityWriteConcern);
 
     if (!result.isOK()) {
-        LOG(0) << "Failed to remove config.migrations document for migration '"
-               << migrationDocumentIdentifier.toString() << "'" << causedBy(redact(result));
+        LOGV2("Failed to remove config.migrations document for migration '{}'{}", "migrationDocumentIdentifier_toString"_attr = migrationDocumentIdentifier.toString(), "causedBy_redact_result"_attr = causedBy(redact(result)));
     }
 }
 
@@ -141,10 +141,7 @@ StatusWith<ScopedMigrationRequest> ScopedMigrationRequest::writeMigration(
             MigrateInfo activeMigrateInfo = statusWithActiveMigration.getValue().toMigrateInfo();
             if (activeMigrateInfo.to != migrateInfo.to ||
                 activeMigrateInfo.from != migrateInfo.from) {
-                log() << "Failed to write document '" << redact(migrateInfo.toString())
-                      << "' to config.migrations because there is already an active migration for"
-                      << " that chunk: '" << redact(activeMigrateInfo.toString()) << "'."
-                      << causedBy(redact(result));
+                LOGV2("Failed to write document '{}' to config.migrations because there is already an active migration for that chunk: '{}'.{}", "redact_migrateInfo_toString"_attr = redact(migrateInfo.toString()), "redact_activeMigrateInfo_toString"_attr = redact(activeMigrateInfo.toString()), "causedBy_redact_result"_attr = causedBy(redact(result)));
                 return result;
             }
 
@@ -195,8 +192,7 @@ Status ScopedMigrationRequest::tryToRemoveMigration() {
 void ScopedMigrationRequest::keepDocumentOnDestruct() {
     invariant(_opCtx);
     _opCtx = nullptr;
-    LOG(1) << "Keeping config.migrations document with namespace '" << _nss << "' and minKey '"
-           << _minKey << "' for balancer recovery";
+    LOGV2_DEBUG(1, "Keeping config.migrations document with namespace '{}' and minKey '{}' for balancer recovery", "_nss"_attr = _nss, "_minKey"_attr = _minKey);
 }
 
 }  // namespace mongo
diff --git a/src/mongo/db/s/chunk_splitter.cpp b/src/mongo/db/s/chunk_splitter.cpp
index c7dd1e2225..a1ae93e9d5 100644
--- a/src/mongo/db/s/chunk_splitter.cpp
+++ b/src/mongo/db/s/chunk_splitter.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/s/split_chunk.h"
 #include "mongo/db/s/split_vector.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/catalog_cache.h"
@@ -204,8 +205,7 @@ bool isAutoBalanceEnabled(OperationContext* opCtx,
 
     auto collStatus = Grid::get(opCtx)->catalogClient()->getCollection(opCtx, nss);
     if (!collStatus.isOK()) {
-        log() << "Auto-split for " << nss << " failed to load collection metadata"
-              << causedBy(redact(collStatus.getStatus()));
+        LOGV2("Auto-split for {} failed to load collection metadata{}", "nss"_attr = nss, "causedBy_redact_collStatus_getStatus"_attr = causedBy(redact(collStatus.getStatus())));
         return false;
     }
 
@@ -245,7 +245,7 @@ void ChunkSplitter::onStepUp() {
     }
     _isPrimary = true;
 
-    log() << "The ChunkSplitter has started and will accept autosplit tasks.";
+    LOGV2("The ChunkSplitter has started and will accept autosplit tasks.");
 }
 
 void ChunkSplitter::onStepDown() {
@@ -255,8 +255,7 @@ void ChunkSplitter::onStepDown() {
     }
     _isPrimary = false;
 
-    log() << "The ChunkSplitter has stopped and will no longer run new autosplit tasks. Any "
-          << "autosplit tasks that have already started will be allowed to finish.";
+    LOGV2("The ChunkSplitter has stopped and will no longer run new autosplit tasks. Any autosplit tasks that have already started will be allowed to finish.");
 }
 
 void ChunkSplitter::waitForIdle() {
@@ -312,9 +311,7 @@ void ChunkSplitter::_runAutosplit(std::shared_ptr<ChunkSplitStateDriver> chunkSp
 
         const uint64_t maxChunkSizeBytes = balancerConfig->getMaxChunkSizeBytes();
 
-        LOG(1) << "about to initiate autosplit: " << redact(chunk.toString())
-               << " dataWritten since last check: " << dataWritten
-               << " maxChunkSizeBytes: " << maxChunkSizeBytes;
+        LOGV2_DEBUG(1, "about to initiate autosplit: {} dataWritten since last check: {} maxChunkSizeBytes: {}", "redact_chunk_toString"_attr = redact(chunk.toString()), "dataWritten"_attr = dataWritten, "maxChunkSizeBytes"_attr = maxChunkSizeBytes);
 
         chunkSplitStateDriver->prepareSplit();
         auto splitPoints = uassertStatusOK(splitVector(opCtx.get(),
@@ -329,9 +326,7 @@ void ChunkSplitter::_runAutosplit(std::shared_ptr<ChunkSplitStateDriver> chunkSp
                                                        maxChunkSizeBytes));
 
         if (splitPoints.size() <= 1) {
-            LOG(1)
-                << "ChunkSplitter attempted split but not enough split points were found for chunk "
-                << redact(chunk.toString());
+            LOGV2_DEBUG(1, "ChunkSplitter attempted split but not enough split points were found for chunk {}", "redact_chunk_toString"_attr = redact(chunk.toString()));
             // Reset our size estimate that we had prior to splitVector to 0, while still counting
             // the bytes that have been written in parallel to this split task
             chunkSplitStateDriver->abandonPrepare();
@@ -380,12 +375,9 @@ void ChunkSplitter::_runAutosplit(std::shared_ptr<ChunkSplitStateDriver> chunkSp
 
         const bool shouldBalance = isAutoBalanceEnabled(opCtx.get(), nss, balancerConfig);
 
-        log() << "autosplitted " << nss << " chunk: " << redact(chunk.toString()) << " into "
-              << (splitPoints.size() + 1) << " parts (maxChunkSizeBytes " << maxChunkSizeBytes
-              << ")"
-              << (topChunkMinKey.isEmpty() ? ""
+        LOGV2("autosplitted {} chunk: {} into {} parts (maxChunkSizeBytes {}){}", "nss"_attr = nss, "redact_chunk_toString"_attr = redact(chunk.toString()), "splitPoints_size_1"_attr = (splitPoints.size() + 1), "maxChunkSizeBytes"_attr = maxChunkSizeBytes, "topChunkMinKey_isEmpty_top_chunk_migration_suggested_std_string_shouldBalance_but_no_migrations_allowed"_attr = (topChunkMinKey.isEmpty() ? ""
                                            : " (top chunk migration suggested" +
-                          (std::string)(shouldBalance ? ")" : ", but no migrations allowed)"));
+                          (std::string)(shouldBalance ? ")" : ", but no migrations allowed)")));
 
         // Because the ShardServerOpObserver uses the metadata from the CSS for tracking incoming
         // writes, if we split a chunk but do not force a CSS refresh, subsequent inserts will see
@@ -406,13 +398,10 @@ void ChunkSplitter::_runAutosplit(std::shared_ptr<ChunkSplitStateDriver> chunkSp
             // assumption that succeeding inserts will fall on the top chunk.
             moveChunk(opCtx.get(), nss, topChunkMinKey);
         } catch (const DBException& ex) {
-            log() << "Top-chunk optimization failed to move chunk "
-                  << redact(ChunkRange(min, max).toString()) << " in collection " << nss
-                  << " after a successful split" << causedBy(redact(ex.toStatus()));
+            LOGV2("Top-chunk optimization failed to move chunk {} in collection {} after a successful split{}", "redact_ChunkRange_min_max_toString"_attr = redact(ChunkRange(min, max).toString()), "nss"_attr = nss, "causedBy_redact_ex_toStatus"_attr = causedBy(redact(ex.toStatus())));
         }
     } catch (const DBException& ex) {
-        log() << "Unable to auto-split chunk " << redact(ChunkRange(min, max).toString())
-              << " in namespace " << nss << causedBy(redact(ex.toStatus()));
+        LOGV2("Unable to auto-split chunk {} in namespace {}{}", "redact_ChunkRange_min_max_toString"_attr = redact(ChunkRange(min, max).toString()), "nss"_attr = nss, "causedBy_redact_ex_toStatus"_attr = causedBy(redact(ex.toStatus())));
     }
 }
 
diff --git a/src/mongo/db/s/cleanup_orphaned_cmd.cpp b/src/mongo/db/s/cleanup_orphaned_cmd.cpp
index 146198e741..237ed8b5c0 100644
--- a/src/mongo/db/s/cleanup_orphaned_cmd.cpp
+++ b/src/mongo/db/s/cleanup_orphaned_cmd.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/s/shard_filtering_metadata_refresh.h"
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/request_types/migration_secondary_throttle_options.h"
 #include "mongo/util/log.h"
 
@@ -80,8 +81,7 @@ CleanupResult cleanupOrphanedData(OperationContext* opCtx,
         auto* const css = CollectionShardingRuntime::get(opCtx, ns);
         const auto metadata = css->getCurrentMetadata();
         if (!metadata->isSharded()) {
-            LOG(0) << "skipping orphaned data cleanup for " << ns.ns()
-                   << ", collection is not sharded";
+            LOGV2("skipping orphaned data cleanup for {}, collection is not sharded", "ns_ns"_attr = ns.ns());
             return CleanupResult::kDone;
         }
 
@@ -92,7 +92,7 @@ CleanupResult cleanupOrphanedData(OperationContext* opCtx,
                     << "could not cleanup orphaned data, start key " << startingFromKey
                     << " does not match shard key pattern " << keyPattern;
 
-                log() << *errMsg;
+                LOGV2("{}", "errMsg"_attr = *errMsg);
                 return CleanupResult::kError;
             }
         } else {
@@ -101,8 +101,7 @@ CleanupResult cleanupOrphanedData(OperationContext* opCtx,
 
         targetRange = css->getNextOrphanRange(startingFromKey);
         if (!targetRange) {
-            LOG(1) << "cleanupOrphaned requested for " << ns.toString() << " starting from "
-                   << redact(startingFromKey) << ", no orphan ranges remain";
+            LOGV2_DEBUG(1, "cleanupOrphaned requested for {} starting from {}, no orphan ranges remain", "ns_toString"_attr = ns.toString(), "redact_startingFromKey"_attr = redact(startingFromKey));
 
             return CleanupResult::kDone;
         }
@@ -121,10 +120,10 @@ CleanupResult cleanupOrphanedData(OperationContext* opCtx,
 
     Status result = notifn.waitStatus(opCtx);
 
-    LOG(1) << "Finished waiting for last " << ns.toString() << " orphan range cleanup";
+    LOGV2_DEBUG(1, "Finished waiting for last {} orphan range cleanup", "ns_toString"_attr = ns.toString());
 
     if (!result.isOK()) {
-        log() << redact(result.reason());
+        LOGV2("{}", "redact_result_reason"_attr = redact(result.reason()));
         *errMsg = result.reason();
         return CleanupResult::kError;
     }
diff --git a/src/mongo/db/s/collection_range_deleter.cpp b/src/mongo/db/s/collection_range_deleter.cpp
index bc8f2b2008..65845cbcc9 100644
--- a/src/mongo/db/s/collection_range_deleter.cpp
+++ b/src/mongo/db/s/collection_range_deleter.cpp
@@ -61,6 +61,7 @@
 #include "mongo/db/storage/remove_saver.h"
 #include "mongo/db/write_concern.h"
 #include "mongo/executor/task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 #include "mongo/util/str.h"
@@ -115,7 +116,7 @@ StatusWith<int> doDeletion(OperationContext* opCtx,
     if (!idx) {
         std::string msg = str::stream()
             << "Unable to find shard key index for " << keyPattern.toString() << " in " << nss.ns();
-        LOG(0) << msg;
+        LOGV2("{}", "msg"_attr = msg);
         return {ErrorCodes::InternalError, msg};
     }
 
@@ -128,7 +129,7 @@ StatusWith<int> doDeletion(OperationContext* opCtx,
     const auto min = extend(range.getMin());
     const auto max = extend(range.getMax());
 
-    LOG(1) << "begin removal of " << min << " to " << max << " in " << nss.ns();
+    LOGV2_DEBUG(1, "begin removal of {} to {} in {}", "min"_attr = min, "max"_attr = max, "nss_ns"_attr = nss.ns());
 
     const auto indexName = idx->indexName();
     const IndexDescriptor* descriptor =
@@ -136,7 +137,7 @@ StatusWith<int> doDeletion(OperationContext* opCtx,
     if (!descriptor) {
         std::string msg = str::stream()
             << "shard key index with name " << indexName << " on '" << nss.ns() << "' was dropped";
-        LOG(0) << msg;
+        LOGV2("{}", "msg"_attr = msg);
         return {ErrorCodes::InternalError, msg};
     }
 
@@ -161,7 +162,7 @@ StatusWith<int> doDeletion(OperationContext* opCtx,
                                                      InternalPlanner::FORWARD);
 
     if (MONGO_unlikely(hangBeforeDoingDeletion.shouldFail())) {
-        LOG(0) << "Hit hangBeforeDoingDeletion failpoint";
+        LOGV2("Hit hangBeforeDoingDeletion failpoint");
         hangBeforeDoingDeletion.pauseWhileSet(opCtx);
     }
 
@@ -243,7 +244,7 @@ boost::optional<Date_t> CollectionRangeDeleter::cleanUpNextRange(
         {
             stdx::lock_guard<Latch> scopedLock(csr->_metadataManager->_managerLock);
             if (self->isEmpty()) {
-                LOG(1) << "No further range deletions scheduled on " << nss.ns();
+                LOGV2_DEBUG(1, "No further range deletions scheduled on {}", "nss_ns"_attr = nss.ns());
                 return boost::none;
             }
 
@@ -252,15 +253,13 @@ boost::optional<Date_t> CollectionRangeDeleter::cleanUpNextRange(
                 // We have delayed deletions; see if any are ready.
                 auto& df = self->_delayedOrphans.front();
                 if (df.whenToDelete > Date_t::now()) {
-                    LOG(0) << "Deferring deletion of " << nss.ns() << " range "
-                           << redact(df.range.toString()) << " until " << df.whenToDelete;
+                    LOGV2("Deferring deletion of {} range {} until {}", "nss_ns"_attr = nss.ns(), "redact_df_range_toString"_attr = redact(df.range.toString()), "df_whenToDelete"_attr = df.whenToDelete);
                     return df.whenToDelete;
                 }
 
                 // Move a single range from _delayedOrphans to _orphans
                 orphans.splice(orphans.end(), self->_delayedOrphans, self->_delayedOrphans.begin());
-                LOG(1) << "Proceeding with deferred deletion of " << nss.ns() << " range "
-                       << redact(orphans.front().range.toString());
+                LOGV2_DEBUG(1, "Proceeding with deferred deletion of {} range {}", "nss_ns"_attr = nss.ns(), "redact_orphans_front_range_toString"_attr = redact(orphans.front().range.toString()));
 
                 writeOpLog = true;
             }
@@ -311,7 +310,7 @@ boost::optional<Date_t> CollectionRangeDeleter::cleanUpNextRange(
                                       // taking the MetadataManager lock is not required.
                                       self->_throwWriteConflictForTest);
             if (swNumDeleted.isOK()) {
-                LOG(0) << "Deleted " << swNumDeleted.getValue() << " documents in pass.";
+                LOGV2("Deleted {} documents in pass.", "swNumDeleted_getValue"_attr = swNumDeleted.getValue());
             }
         } catch (const DBException& e) {
             swNumDeleted = e.toStatus();
@@ -330,16 +329,14 @@ boost::optional<Date_t> CollectionRangeDeleter::cleanUpNextRange(
     // This branch means that we will NOT continue deleting documents from this range.
     if (!continueDeleting) {
         if (swNumDeleted.isOK()) {
-            LOG(0) << "No documents remain to delete in " << nss << " range "
-                   << redact(range->toString());
+            LOGV2("No documents remain to delete in {} range {}", "nss"_attr = nss, "redact_range_toString"_attr = redact(range->toString()));
         }
 
         // Wait for majority replication even when swNumDeleted isn't OK or == 0, because it might
         // have been OK and/or > 0 previously, and the deletions must be persistent before notifying
         // clients in _pop().
 
-        LOG(0) << "Waiting for majority replication of local deletions in " << nss.ns() << " range "
-               << redact(range->toString());
+        LOGV2("Waiting for majority replication of local deletions in {} range {}", "nss_ns"_attr = nss.ns(), "redact_range_toString"_attr = redact(range->toString()));
 
         repl::ReplClientInfo::forClient(opCtx->getClient()).setLastOpToSystemLastOpTime(opCtx);
         const auto clientOpTime = repl::ReplClientInfo::forClient(opCtx->getClient()).getLastOp();
@@ -375,8 +372,7 @@ boost::optional<Date_t> CollectionRangeDeleter::cleanUpNextRange(
             stdx::lock_guard<Latch> scopedLock(csr->_metadataManager->_managerLock);
 
             if (!replicationStatus.isOK()) {
-                LOG(0) << "Error when waiting for write concern after removing " << nss << " range "
-                       << redact(range->toString()) << " : " << redact(replicationStatus.reason());
+                LOGV2("Error when waiting for write concern after removing {} range {} : {}", "nss"_attr = nss, "redact_range_toString"_attr = redact(range->toString()), "redact_replicationStatus_reason"_attr = redact(replicationStatus.reason()));
 
                 // If range were already popped (e.g. by dropping nss during the waitForWriteConcern
                 // above) its notification would have been triggered, so this check suffices to
@@ -384,22 +380,18 @@ boost::optional<Date_t> CollectionRangeDeleter::cleanUpNextRange(
                 if (!notification.ready()) {
                     invariant(!self->isEmpty() &&
                               self->_orphans.front().notification == notification);
-                    LOG(0) << "Abandoning deletion of latest range in " << nss.ns()
-                           << " after local "
-                           << "deletions because of replication failure";
+                    LOGV2("Abandoning deletion of latest range in {} after local deletions because of replication failure", "nss_ns"_attr = nss.ns());
                     self->_pop(replicationStatus);
                 }
             } else {
-                LOG(0) << "Finished deleting documents in " << nss.ns() << " range "
-                       << redact(range->toString());
+                LOGV2("Finished deleting documents in {} range {}", "nss_ns"_attr = nss.ns(), "redact_range_toString"_attr = redact(range->toString()));
 
                 finishedDeleting = true;
                 self->_pop(swNumDeleted.getStatus());
             }
 
             if (!self->_orphans.empty()) {
-                LOG(1) << "Deleting " << nss.ns() << " range "
-                       << redact(self->_orphans.front().range.toString()) << " next.";
+                LOGV2_DEBUG(1, "Deleting {} range {} next.", "nss_ns"_attr = nss.ns(), "redact_self__orphans_front_range_toString"_attr = redact(self->_orphans.front().range.toString()));
             }
         }
 
@@ -412,8 +404,7 @@ boost::optional<Date_t> CollectionRangeDeleter::cleanUpNextRange(
                                    << collectionUuid << RangeDeletionTask::kRangeFieldName
                                    << range->toBSON()));
             } catch (const DBException& e) {
-                LOG(0) << "Failed to delete range deletion task for range " << range.get()
-                       << " in collection " << nss << causedBy(e.what());
+                LOGV2("Failed to delete range deletion task for range {} in collection {}{}", "range_get"_attr = range.get(), "nss"_attr = nss, "causedBy_e_what"_attr = causedBy(e.what()));
             }
         }
 
@@ -438,8 +429,7 @@ bool CollectionRangeDeleter::_checkCollectionMetadataStillValid(
         metadataManager->getActiveMetadata(metadataManager, boost::none);
 
     if (!scopedCollectionMetadata) {
-        LOG(0) << "Abandoning any range deletions because the metadata for " << nss.ns()
-               << " was reset";
+        LOGV2("Abandoning any range deletions because the metadata for {} was reset", "nss_ns"_attr = nss.ns());
         stdx::lock_guard<Latch> lk(metadataManager->_managerLock);
         metadataManager->_clearAllCleanups(lk);
         return false;
@@ -449,10 +439,9 @@ bool CollectionRangeDeleter::_checkCollectionMetadataStillValid(
 
     if (!forTestOnly && (!collection || !metadata->isSharded())) {
         if (!collection) {
-            LOG(0) << "Abandoning any range deletions left over from dropped " << nss.ns();
+            LOGV2("Abandoning any range deletions left over from dropped {}", "nss_ns"_attr = nss.ns());
         } else {
-            LOG(0) << "Abandoning any range deletions left over from previously sharded"
-                   << nss.ns();
+            LOGV2("Abandoning any range deletions left over from previously sharded{}", "nss_ns"_attr = nss.ns());
         }
 
         stdx::lock_guard<Latch> lk(metadataManager->_managerLock);
@@ -461,9 +450,7 @@ bool CollectionRangeDeleter::_checkCollectionMetadataStillValid(
     }
 
     if (!forTestOnly && collection->uuid() != collectionUuid) {
-        LOG(1) << "Abandoning range deletion task for " << nss.ns() << " with UUID "
-               << collectionUuid << " because UUID of " << nss.ns() << "has changed (current is "
-               << collection->uuid() << ")";
+        LOGV2_DEBUG(1, "Abandoning range deletion task for {} with UUID {} because UUID of {}has changed (current is {})", "nss_ns"_attr = nss.ns(), "collectionUuid"_attr = collectionUuid, "nss_ns"_attr = nss.ns(), "collection_uuid"_attr = collection->uuid());
         return false;
     }
 
diff --git a/src/mongo/db/s/collection_sharding_runtime.cpp b/src/mongo/db/s/collection_sharding_runtime.cpp
index b0903581df..f1f35ebfa4 100644
--- a/src/mongo/db/s/collection_sharding_runtime.cpp
+++ b/src/mongo/db/s/collection_sharding_runtime.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/s/operation_sharding_state.h"
 #include "mongo/db/s/sharded_connection_info.h"
 #include "mongo/db/s/sharding_runtime_d_params_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/duration.h"
 #include "mongo/util/log.h"
 
@@ -256,13 +257,12 @@ Status CollectionShardingRuntime::waitForClean(OperationContext* opCtx,
 
             stillScheduled = self->trackOrphanedDataCleanup(orphanRange);
             if (!stillScheduled) {
-                log() << "Finished deleting " << nss.ns() << " range "
-                      << redact(orphanRange.toString());
+                LOGV2("Finished deleting {} range {}", "nss_ns"_attr = nss.ns(), "redact_orphanRange_toString"_attr = redact(orphanRange.toString()));
                 return Status::OK();
             }
         }
 
-        log() << "Waiting for deletion of " << nss.ns() << " range " << orphanRange;
+        LOGV2("Waiting for deletion of {} range {}", "nss_ns"_attr = nss.ns(), "orphanRange"_attr = orphanRange);
 
         Status result = stillScheduled->waitStatus(opCtx);
         if (!result.isOK()) {
@@ -307,16 +307,15 @@ boost::optional<ScopedCollectionMetadata> CollectionShardingRuntime::_getMetadat
     auto wantedShardVersion = ChunkVersion::UNSHARDED();
 
     if (MONGO_unlikely(useFCV44CheckShardVersionProtocol.shouldFail())) {
-        LOG(0) << "Received shardVersion: " << receivedShardVersion << " for " << _nss.ns();
+        LOGV2("Received shardVersion: {} for {}", "receivedShardVersion"_attr = receivedShardVersion, "_nss_ns"_attr = _nss.ns());
         if (isCollection) {
-            LOG(0) << "Namespace " << _nss.ns() << " is collection, "
-                   << (metadata ? "have shardVersion cached" : "don't know shardVersion");
+            LOGV2("Namespace {} is collection, {}", "_nss_ns"_attr = _nss.ns(), "metadata_have_shardVersion_cached_don_t_know_shardVersion"_attr = (metadata ? "have shardVersion cached" : "don't know shardVersion"));
             uassert(StaleConfigInfo(_nss, receivedShardVersion, wantedShardVersion),
                     "don't know shardVersion",
                     metadata);
             wantedShardVersion = (*metadata)->getShardVersion();
         }
-        LOG(0) << "Wanted shardVersion: " << wantedShardVersion << " for " << _nss.ns();
+        LOGV2("Wanted shardVersion: {} for {}", "wantedShardVersion"_attr = wantedShardVersion, "_nss_ns"_attr = _nss.ns());
     } else {
         if (metadata && (*metadata)->isSharded()) {
             wantedShardVersion = (*metadata)->getShardVersion();
diff --git a/src/mongo/db/s/collection_sharding_state.cpp b/src/mongo/db/s/collection_sharding_state.cpp
index c911634e89..9df46f7d9f 100644
--- a/src/mongo/db/s/collection_sharding_state.cpp
+++ b/src/mongo/db/s/collection_sharding_state.cpp
@@ -34,6 +34,7 @@
 #include "mongo/db/s/collection_sharding_state.h"
 
 #include "mongo/db/repl/read_concern_args.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/stale_exception.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
diff --git a/src/mongo/db/s/config/configsvr_add_shard_command.cpp b/src/mongo/db/s/config/configsvr_add_shard_command.cpp
index fcbb900622..80d298980f 100644
--- a/src/mongo/db/s/config/configsvr_add_shard_command.cpp
+++ b/src/mongo/db/s/config/configsvr_add_shard_command.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/repl/repl_set_config.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/s/config/sharding_catalog_manager.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_shard.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/request_types/add_shard_request_type.h"
@@ -129,8 +130,7 @@ public:
             parsedRequest.hasMaxSize() ? parsedRequest.getMaxSize() : kMaxSizeMBDefault);
 
         if (!addShardResult.isOK()) {
-            log() << "addShard request '" << parsedRequest << "'"
-                  << "failed" << causedBy(addShardResult.getStatus());
+            LOGV2("addShard request '{}'failed{}", "parsedRequest"_attr = parsedRequest, "causedBy_addShardResult_getStatus"_attr = causedBy(addShardResult.getStatus()));
             uassertStatusOK(addShardResult.getStatus());
         }
 
diff --git a/src/mongo/db/s/config/configsvr_move_primary_command.cpp b/src/mongo/db/s/config/configsvr_move_primary_command.cpp
index fe5c843303..1d249b0069 100644
--- a/src/mongo/db/s/config/configsvr_move_primary_command.cpp
+++ b/src/mongo/db/s/config/configsvr_move_primary_command.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/repl/repl_client_info.h"
 #include "mongo/db/s/config/sharding_catalog_manager.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_database.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_registry.h"
@@ -158,8 +159,7 @@ public:
         const auto toShard = [&]() {
             auto toShardStatus = shardRegistry->getShard(opCtx, to);
             if (!toShardStatus.isOK()) {
-                log() << "Could not move database '" << dbname << "' to shard '" << to
-                      << causedBy(toShardStatus.getStatus());
+                LOGV2("Could not move database '{}' to shard '{}{}", "dbname"_attr = dbname, "to"_attr = to, "causedBy_toShardStatus_getStatus"_attr = causedBy(toShardStatus.getStatus()));
                 uassertStatusOKWithContext(toShardStatus.getStatus(),
                                            str::stream() << "Could not move database '" << dbname
                                                          << "' to shard '" << to << "'");
diff --git a/src/mongo/db/s/config/configsvr_refine_collection_shard_key_command.cpp b/src/mongo/db/s/config/configsvr_refine_collection_shard_key_command.cpp
index 3b6a933701..2fd90dd524 100644
--- a/src/mongo/db/s/config/configsvr_refine_collection_shard_key_command.cpp
+++ b/src/mongo/db/s/config/configsvr_refine_collection_shard_key_command.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/s/config/sharding_catalog_manager.h"
 #include "mongo/db/s/shard_key_util.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/dist_lock_manager.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/request_types/refine_collection_shard_key_gen.h"
@@ -148,7 +149,7 @@ public:
                                                                  collType.getUnique(),
                                                                  false);  // createIndexIfPossible
 
-            LOG(0) << "CMD: refineCollectionShardKey: " << request().toBSON({});
+            LOGV2("CMD: refineCollectionShardKey: {}", "request_toBSON"_attr = request().toBSON({}));
 
             audit::logRefineCollectionShardKey(opCtx->getClient(), nss.ns(), proposedKey);
 
diff --git a/src/mongo/db/s/config/configsvr_remove_shard_command.cpp b/src/mongo/db/s/config/configsvr_remove_shard_command.cpp
index 9fd0d19059..78b36bf426 100644
--- a/src/mongo/db/s/config/configsvr_remove_shard_command.cpp
+++ b/src/mongo/db/s/config/configsvr_remove_shard_command.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/repl/read_concern_args.h"
 #include "mongo/db/s/config/sharding_catalog_manager.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_database.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_registry.h"
@@ -118,7 +119,7 @@ public:
             try {
                 return shardingCatalogManager->removeShard(opCtx, shard->getId());
             } catch (const DBException& ex) {
-                LOG(0) << "Failed to remove shard due to " << redact(ex);
+                LOGV2("Failed to remove shard due to {}", "redact_ex"_attr = redact(ex));
                 throw;
             }
         }();
diff --git a/src/mongo/db/s/config/sharding_catalog_manager_collection_operations.cpp b/src/mongo/db/s/config/sharding_catalog_manager_collection_operations.cpp
index 4979e519ed..95284181a6 100644
--- a/src/mongo/db/s/config/sharding_catalog_manager_collection_operations.cpp
+++ b/src/mongo/db/s/config/sharding_catalog_manager_collection_operations.cpp
@@ -56,6 +56,7 @@
 #include "mongo/db/s/sharding_logging.h"
 #include "mongo/executor/network_interface.h"
 #include "mongo/executor/task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog/sharding_catalog_client_impl.h"
@@ -430,15 +431,15 @@ void ShardingCatalogManager::dropCollection(OperationContext* opCtx, const Names
         BSONObj(),
         ShardingCatalogClient::kMajorityWriteConcern));
 
-    LOG(1) << "dropCollection " << nss.ns() << " started";
+    LOGV2_DEBUG(1, "dropCollection {} started", "nss_ns"_attr = nss.ns());
 
     sendDropCollectionToAllShards(opCtx, nss);
 
-    LOG(1) << "dropCollection " << nss.ns() << " shard data deleted";
+    LOGV2_DEBUG(1, "dropCollection {} shard data deleted", "nss_ns"_attr = nss.ns());
 
     removeChunksAndTagsForDroppedCollection(opCtx, nss);
 
-    LOG(1) << "dropCollection " << nss.ns() << " chunk and tag data deleted";
+    LOGV2_DEBUG(1, "dropCollection {} chunk and tag data deleted", "nss_ns"_attr = nss.ns());
 
     // Mark the collection as dropped
     CollectionType coll;
@@ -451,11 +452,11 @@ void ShardingCatalogManager::dropCollection(OperationContext* opCtx, const Names
     uassertStatusOK(ShardingCatalogClientImpl::updateShardingCatalogEntryForCollection(
         opCtx, nss, coll, upsert));
 
-    LOG(1) << "dropCollection " << nss.ns() << " collection marked as dropped";
+    LOGV2_DEBUG(1, "dropCollection {} collection marked as dropped", "nss_ns"_attr = nss.ns());
 
     sendSSVToAllShards(opCtx, nss);
 
-    LOG(1) << "dropCollection " << nss.ns() << " completed";
+    LOGV2_DEBUG(1, "dropCollection {} completed", "nss_ns"_attr = nss.ns());
 
     ShardingLogging::get(opCtx)->logChange(
         opCtx, "dropCollection", nss.ns(), BSONObj(), ShardingCatalogClient::kMajorityWriteConcern);
@@ -464,8 +465,7 @@ void ShardingCatalogManager::dropCollection(OperationContext* opCtx, const Names
 void ShardingCatalogManager::ensureDropCollectionCompleted(OperationContext* opCtx,
                                                            const NamespaceString& nss) {
 
-    LOG(1) << "Ensuring config entries for " << nss.ns()
-           << " from previous dropCollection are cleared";
+    LOGV2_DEBUG(1, "Ensuring config entries for {} from previous dropCollection are cleared", "nss_ns"_attr = nss.ns());
     sendDropCollectionToAllShards(opCtx, nss);
     removeChunksAndTagsForDroppedCollection(opCtx, nss);
     sendSSVToAllShards(opCtx, nss);
@@ -518,7 +518,7 @@ void ShardingCatalogManager::renameCollection(OperationContext* opCtx,
         Shard::RetryPolicy::kIdempotent));
 
     if (MONGO_unlikely(hangRenameCollectionAfterSendingRenameToPrimaryShard.shouldFail())) {
-        log() << "Hit hangRenameCollectionAfterSendingRenameToPrimaryShard";
+        LOGV2("Hit hangRenameCollectionAfterSendingRenameToPrimaryShard");
         hangRenameCollectionAfterSendingRenameToPrimaryShard.pauseWhileSet(opCtx);
     }
 
@@ -596,7 +596,7 @@ void ShardingCatalogManager::generateUUIDsForExistingShardedCollections(Operatio
             .docs;
 
     if (shardedColls.empty()) {
-        LOG(0) << "all sharded collections already have UUIDs";
+        LOGV2("all sharded collections already have UUIDs");
 
         // We did a local read of the collections collection above and found that all sharded
         // collections already have UUIDs. However, the data may not be majority committed (a
@@ -608,8 +608,7 @@ void ShardingCatalogManager::generateUUIDsForExistingShardedCollections(Operatio
     }
 
     // Generate and persist a new UUID for each collection that did not have a UUID.
-    LOG(0) << "generating UUIDs for " << shardedColls.size()
-           << " sharded collections that do not yet have a UUID";
+    LOGV2("generating UUIDs for {} sharded collections that do not yet have a UUID", "shardedColls_size"_attr = shardedColls.size());
     for (auto& coll : shardedColls) {
         auto collType = uassertStatusOK(CollectionType::fromBSON(coll));
         invariant(!collType.getUUID());
@@ -619,8 +618,7 @@ void ShardingCatalogManager::generateUUIDsForExistingShardedCollections(Operatio
 
         uassertStatusOK(ShardingCatalogClientImpl::updateShardingCatalogEntryForCollection(
             opCtx, collType.getNs(), collType, false /* upsert */));
-        LOG(2) << "updated entry in config.collections for sharded collection " << collType.getNs()
-               << " with generated UUID " << uuid;
+        LOGV2_DEBUG(2, "updated entry in config.collections for sharded collection {} with generated UUID {}", "collType_getNs"_attr = collType.getNs(), "uuid"_attr = uuid);
     }
 }
 
@@ -628,7 +626,7 @@ void ShardingCatalogManager::createCollection(OperationContext* opCtx,
                                               const NamespaceString& ns,
                                               const CollectionOptions& collOptions) {
     if (MONGO_unlikely(hangCreateCollectionAfterAcquiringDistlocks.shouldFail())) {
-        log() << "Hit hangCreateCollectionAfterAcquiringDistlocks";
+        LOGV2("Hit hangCreateCollectionAfterAcquiringDistlocks");
         hangCreateCollectionAfterAcquiringDistlocks.pauseWhileSet(opCtx);
     }
 
@@ -657,7 +655,7 @@ void ShardingCatalogManager::createCollection(OperationContext* opCtx,
         Shard::RetryPolicy::kIdempotent);
 
     if (MONGO_unlikely(hangCreateCollectionAfterSendingCreateToPrimaryShard.shouldFail())) {
-        log() << "Hit hangCreateCollectionAfterSendingCreateToPrimaryShard";
+        LOGV2("Hit hangCreateCollectionAfterSendingCreateToPrimaryShard");
         hangCreateCollectionAfterSendingCreateToPrimaryShard.pauseWhileSet(opCtx);
     }
 
@@ -669,7 +667,7 @@ void ShardingCatalogManager::createCollection(OperationContext* opCtx,
     const auto uuid = checkCollectionOptions(opCtx, primaryShard.get(), ns, collOptions);
 
     if (MONGO_unlikely(hangCreateCollectionAfterGettingUUIDFromPrimaryShard.shouldFail())) {
-        log() << "Hit hangCreateCollectionAfterGettingUUIDFromPrimaryShard";
+        LOGV2("Hit hangCreateCollectionAfterGettingUUIDFromPrimaryShard");
         hangCreateCollectionAfterGettingUUIDFromPrimaryShard.pauseWhileSet(opCtx);
     }
 
@@ -689,8 +687,7 @@ void ShardingCatalogManager::createCollection(OperationContext* opCtx,
         catalogClient->getCollection(opCtx, ns, repl::ReadConcernLevel::kLocalReadConcern);
     if (swExistingCollType != ErrorCodes::NamespaceNotFound) {
         const auto existingCollType = uassertStatusOK(swExistingCollType).value;
-        LOG(0) << "Collection " << ns.ns() << " already exists in sharding catalog as "
-               << existingCollType.toBSON() << ", createCollection not writing new entry";
+        LOGV2("Collection {} already exists in sharding catalog as {}, createCollection not writing new entry", "ns_ns"_attr = ns.ns(), "existingCollType_toBSON"_attr = existingCollType.toBSON());
         return;
     }
 
@@ -728,8 +725,7 @@ void ShardingCatalogManager::createCollection(OperationContext* opCtx,
     try {
         checkForExistingChunks(opCtx, ns);
     } catch (const ExceptionFor<ErrorCodes::ManualInterventionRequired>&) {
-        LOG(0) << "Found orphaned chunk metadata for " << ns.ns()
-               << ", going to remove it before writing new chunk metadata for createCollection";
+        LOGV2("Found orphaned chunk metadata for {}, going to remove it before writing new chunk metadata for createCollection", "ns_ns"_attr = ns.ns());
         uassertStatusOK(
             catalogClient->removeConfigDocuments(opCtx,
                                                  ChunkType::ConfigNS,
@@ -738,22 +734,20 @@ void ShardingCatalogManager::createCollection(OperationContext* opCtx,
     }
 
     if (MONGO_unlikely(writeUnshardedCollectionsToShardingCatalog.shouldFail())) {
-        LOG(0) << "Going to write initial chunk for new unsharded collection " << ns.ns() << ": "
-               << chunk.toString();
+        LOGV2("Going to write initial chunk for new unsharded collection {}: {}", "ns_ns"_attr = ns.ns(), "chunk_toString"_attr = chunk.toString());
         writeFirstChunksForCollection(opCtx, initialChunks);
 
         if (MONGO_unlikely(hangCreateCollectionAfterWritingEntryToConfigChunks.shouldFail())) {
-            log() << "Hit hangCreateCollectionAfterWritingEntryToConfigChunks";
+            LOGV2("Hit hangCreateCollectionAfterWritingEntryToConfigChunks");
             hangCreateCollectionAfterWritingEntryToConfigChunks.pauseWhileSet(opCtx);
         }
 
-        LOG(0) << "Going to write collection entry for new unsharded collection " << ns.ns() << ": "
-               << targetCollType.toBSON();
+        LOGV2("Going to write collection entry for new unsharded collection {}: {}", "ns_ns"_attr = ns.ns(), "targetCollType_toBSON"_attr = targetCollType.toBSON());
         uassertStatusOK(ShardingCatalogClientImpl::updateShardingCatalogEntryForCollection(
             opCtx, ns, targetCollType, true /*upsert*/));
 
         if (MONGO_unlikely(hangCreateCollectionAfterWritingEntryToConfigCollections.shouldFail())) {
-            log() << "Hit hangCreateCollectionAfterWritingEntryToConfigCollections";
+            LOGV2("Hit hangCreateCollectionAfterWritingEntryToConfigCollections");
             hangCreateCollectionAfterWritingEntryToConfigCollections.pauseWhileSet(opCtx);
         }
     }
@@ -834,9 +828,7 @@ void ShardingCatalogManager::refineCollectionShardKey(OperationContext* opCtx,
                                                                      true /* startTransaction */,
                                                                      txnNumber));
 
-        log() << "refineCollectionShardKey: updated collection entry for '" << nss.ns()
-              << "': took " << executionTimer.millis()
-              << " ms. Total time taken: " << totalTimer.millis() << " ms.";
+        LOGV2("refineCollectionShardKey: updated collection entry for '{}': took {} ms. Total time taken: {} ms.", "nss_ns"_attr = nss.ns(), "executionTimer_millis"_attr = executionTimer.millis(), "totalTimer_millis"_attr = totalTimer.millis());
         executionTimer.reset();
 
         // Update all config.chunks entries for the given namespace by setting (i) their epoch to
@@ -844,7 +836,7 @@ void ShardingCatalogManager::refineCollectionShardKey(OperationContext* opCtx,
         // MinKey (except for the global max chunk where the max bounds are set to MaxKey), and
         // unsetting (iii) their jumbo field.
         if (MONGO_unlikely(hangRefineCollectionShardKeyBeforeUpdatingChunks.shouldFail())) {
-            log() << "Hit hangRefineCollectionShardKeyBeforeUpdatingChunks failpoint";
+            LOGV2("Hit hangRefineCollectionShardKeyBeforeUpdatingChunks failpoint");
             hangRefineCollectionShardKeyBeforeUpdatingChunks.pauseWhileSet(opCtx);
         }
 
@@ -870,9 +862,7 @@ void ShardingCatalogManager::refineCollectionShardKey(OperationContext* opCtx,
             false,  // startTransaction
             txnNumber));
 
-        log() << "refineCollectionShardKey: updated chunk entries for '" << nss.ns() << "': took "
-              << executionTimer.millis() << " ms. Total time taken: " << totalTimer.millis()
-              << " ms.";
+        LOGV2("refineCollectionShardKey: updated chunk entries for '{}': took {} ms. Total time taken: {} ms.", "nss_ns"_attr = nss.ns(), "executionTimer_millis"_attr = executionTimer.millis(), "totalTimer_millis"_attr = totalTimer.millis());
         executionTimer.reset();
 
         // Update all config.tags entries for the given namespace by setting their bounds for each
@@ -897,12 +887,10 @@ void ShardingCatalogManager::refineCollectionShardKey(OperationContext* opCtx,
                                                   false,  // startTransaction
                                                   txnNumber));
 
-        log() << "refineCollectionShardKey: updated zone entries for '" << nss.ns() << "': took "
-              << executionTimer.millis() << " ms. Total time taken: " << totalTimer.millis()
-              << " ms.";
+        LOGV2("refineCollectionShardKey: updated zone entries for '{}': took {} ms. Total time taken: {} ms.", "nss_ns"_attr = nss.ns(), "executionTimer_millis"_attr = executionTimer.millis(), "totalTimer_millis"_attr = totalTimer.millis());
 
         if (MONGO_unlikely(hangRefineCollectionShardKeyBeforeCommit.shouldFail())) {
-            log() << "Hit hangRefineCollectionShardKeyBeforeCommit failpoint";
+            LOGV2("Hit hangRefineCollectionShardKeyBeforeCommit failpoint");
             hangRefineCollectionShardKeyBeforeCommit.pauseWhileSet(opCtx);
         }
 
diff --git a/src/mongo/db/s/config/sharding_catalog_manager_database_operations.cpp b/src/mongo/db/s/config/sharding_catalog_manager_database_operations.cpp
index 019e6a6659..6087990431 100644
--- a/src/mongo/db/s/config/sharding_catalog_manager_database_operations.cpp
+++ b/src/mongo/db/s/config/sharding_catalog_manager_database_operations.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/repl/repl_client_info.h"
 #include "mongo/db/server_options.h"
 #include "mongo/db/write_concern.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_database.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard.h"
@@ -128,7 +129,7 @@ DatabaseType ShardingCatalogManager::createDatabase(OperationContext* opCtx,
     DatabaseType db(
         dbName.toString(), std::move(primaryShardId), false, databaseVersion::makeNew());
 
-    log() << "Registering new database " << db << " in sharding catalog";
+    LOGV2("Registering new database {} in sharding catalog", "db"_attr = db);
 
     // Do this write with majority writeConcern to guarantee that the shard sees the write when it
     // receives the _flushDatabaseCacheUpdates.
@@ -200,7 +201,7 @@ void ShardingCatalogManager::enableSharding(OperationContext* opCtx,
                                                 Milliseconds{30000}),
                             &unusedResult));
 
-    log() << "Enabling sharding for database [" << dbName << "] in config db";
+    LOGV2("Enabling sharding for database [{}] in config db", "dbName"_attr = dbName);
     uassertStatusOK(Grid::get(opCtx)->catalogClient()->updateConfigDocument(
         opCtx,
         DatabaseType::ConfigNS,
@@ -288,8 +289,7 @@ Status ShardingCatalogManager::commitMovePrimary(OperationContext* opCtx,
         ShardingCatalogClient::kLocalWriteConcern);
 
     if (!updateStatus.isOK()) {
-        log() << "error committing movePrimary: " << dbname
-              << causedBy(redact(updateStatus.getStatus()));
+        LOGV2("error committing movePrimary: {}{}", "dbname"_attr = dbname, "causedBy_redact_updateStatus_getStatus"_attr = causedBy(redact(updateStatus.getStatus())));
         return updateStatus.getStatus();
     }
 
diff --git a/src/mongo/db/s/config/sharding_catalog_manager_shard_operations.cpp b/src/mongo/db/s/config/sharding_catalog_manager_shard_operations.cpp
index 5095691591..dd4565968f 100644
--- a/src/mongo/db/s/config/sharding_catalog_manager_shard_operations.cpp
+++ b/src/mongo/db/s/config/sharding_catalog_manager_shard_operations.cpp
@@ -60,6 +60,7 @@
 #include "mongo/db/s/type_shard_identity.h"
 #include "mongo/db/wire_version.h"
 #include "mongo/executor/task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog/config_server_version.h"
 #include "mongo/s/catalog/sharding_catalog_client.h"
@@ -163,7 +164,7 @@ StatusWith<Shard::CommandResponse> ShardingCatalogManager::_runCommandForAddShar
     _executorForAddShard->wait(swCallbackHandle.getValue());
 
     if (response.status == ErrorCodes::ExceededTimeLimit) {
-        LOG(0) << "Operation timed out with status " << redact(response.status);
+        LOGV2("Operation timed out with status {}", "redact_response_status"_attr = redact(response.status));
     }
 
     if (!response.isOK()) {
@@ -689,7 +690,7 @@ StatusWith<std::string> ShardingCatalogManager::addShard(
             return versionResponse.getValue().commandStatus;
         }
 
-        log() << "going to insert new entry for shard into config.shards: " << shardType.toString();
+        LOGV2("going to insert new entry for shard into config.shards: {}", "shardType_toString"_attr = shardType.toString());
 
         Status result = Grid::get(opCtx)->catalogClient()->insertConfigDocument(
             opCtx,
@@ -697,7 +698,7 @@ StatusWith<std::string> ShardingCatalogManager::addShard(
             shardType.toBSON(),
             ShardingCatalogClient::kLocalWriteConcern);
         if (!result.isOK()) {
-            log() << "error adding shard: " << shardType.toBSON() << " err: " << result.reason();
+            LOGV2("error adding shard: {} err: {}", "shardType_toBSON"_attr = shardType.toBSON(), "result_reason"_attr = result.reason());
             return result;
         }
     }
@@ -715,8 +716,7 @@ StatusWith<std::string> ShardingCatalogManager::addShard(
                 true,
                 ShardingCatalogClient::kLocalWriteConcern);
             if (!status.isOK()) {
-                log() << "adding shard " << shardConnectionString.toString()
-                      << " even though could not add database " << dbName;
+                LOGV2("adding shard {} even though could not add database {}", "shardConnectionString_toString"_attr = shardConnectionString.toString(), "dbName"_attr = dbName);
             }
         }
     }
@@ -791,7 +791,7 @@ RemoveShardProgress ShardingCatalogManager::removeShard(OperationContext* opCtx,
     auto* const catalogClient = Grid::get(opCtx)->catalogClient();
 
     if (!isShardCurrentlyDraining) {
-        log() << "going to start draining shard: " << name;
+        LOGV2("going to start draining shard: {}", "name"_attr = name);
 
         // Record start in changelog
         uassertStatusOK(ShardingLogging::get(opCtx)->logChangeChecked(
@@ -831,9 +831,9 @@ RemoveShardProgress ShardingCatalogManager::removeShard(OperationContext* opCtx,
 
     if (chunkCount > 0 || databaseCount > 0) {
         // Still more draining to do
-        LOG(0) << "chunkCount: " << chunkCount;
-        LOG(0) << "databaseCount: " << databaseCount;
-        LOG(0) << "jumboCount: " << jumboCount;
+        LOGV2("chunkCount: {}", "chunkCount"_attr = chunkCount);
+        LOGV2("databaseCount: {}", "databaseCount"_attr = databaseCount);
+        LOGV2("jumboCount: {}", "jumboCount"_attr = jumboCount);
 
         return {RemoveShardProgress::ONGOING,
                 boost::optional<RemoveShardProgress::DrainingShardUsage>(
@@ -841,7 +841,7 @@ RemoveShardProgress ShardingCatalogManager::removeShard(OperationContext* opCtx,
     }
 
     // Draining is done, now finish removing the shard.
-    log() << "going to remove shard: " << name;
+    LOGV2("going to remove shard: {}", "name"_attr = name);
     audit::logRemoveShard(opCtx->getClient(), name);
 
     uassertStatusOKWithContext(
diff --git a/src/mongo/db/s/database_sharding_state.cpp b/src/mongo/db/s/database_sharding_state.cpp
index 9580cf6026..a301f89f43 100644
--- a/src/mongo/db/s/database_sharding_state.cpp
+++ b/src/mongo/db/s/database_sharding_state.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/operation_context.h"
 #include "mongo/db/s/operation_sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/database_version_helpers.h"
 #include "mongo/s/stale_exception.h"
 #include "mongo/util/fail_point.h"
@@ -120,8 +121,7 @@ void DatabaseShardingState::setDbVersion(OperationContext* opCtx,
                                          boost::optional<DatabaseVersion> newDbVersion,
                                          DSSLock&) {
     invariant(opCtx->lockState()->isDbLockedForMode(_dbName, MODE_X));
-    log() << "setting this node's cached database version for " << _dbName << " to "
-          << (newDbVersion ? newDbVersion->toBSON() : BSONObj());
+    LOGV2("setting this node's cached database version for {} to {}", "_dbName"_attr = _dbName, "newDbVersion_newDbVersion_toBSON_BSONObj"_attr = (newDbVersion ? newDbVersion->toBSON() : BSONObj()));
     _dbVersion = newDbVersion;
 }
 
diff --git a/src/mongo/db/s/flush_database_cache_updates_command.cpp b/src/mongo/db/s/flush_database_cache_updates_command.cpp
index 5e4fadfaae..3979e42df0 100644
--- a/src/mongo/db/s/flush_database_cache_updates_command.cpp
+++ b/src/mongo/db/s/flush_database_cache_updates_command.cpp
@@ -50,6 +50,7 @@
 #include "mongo/s/request_types/flush_database_cache_updates_gen.h"
 
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -133,7 +134,7 @@ public:
             oss.waitForMigrationCriticalSectionSignal(opCtx);
 
             if (request().getSyncFromConfig()) {
-                LOG(1) << "Forcing remote routing table refresh for " << _dbName();
+                LOGV2_DEBUG(1, "Forcing remote routing table refresh for {}", "_dbName"_attr = _dbName());
                 forceDatabaseRefresh(opCtx, _dbName());
             }
 
diff --git a/src/mongo/db/s/flush_routing_table_cache_updates_command.cpp b/src/mongo/db/s/flush_routing_table_cache_updates_command.cpp
index f2791bf1fb..a47ff1321e 100644
--- a/src/mongo/db/s/flush_routing_table_cache_updates_command.cpp
+++ b/src/mongo/db/s/flush_routing_table_cache_updates_command.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/s/operation_sharding_state.h"
 #include "mongo/db/s/shard_filtering_metadata_refresh.h"
 #include "mongo/db/s/sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog_cache_loader.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/request_types/flush_routing_table_cache_updates_gen.h"
@@ -132,7 +133,7 @@ public:
             oss.waitForMigrationCriticalSectionSignal(opCtx);
 
             if (request().getSyncFromConfig()) {
-                LOG(1) << "Forcing remote routing table refresh for " << ns();
+                LOGV2_DEBUG(1, "Forcing remote routing table refresh for {}", "ns"_attr = ns());
                 forceShardFilteringMetadataRefresh(opCtx, ns());
             }
 
diff --git a/src/mongo/db/s/merge_chunks_command.cpp b/src/mongo/db/s/merge_chunks_command.cpp
index d6db92888e..bee70718dc 100644
--- a/src/mongo/db/s/merge_chunks_command.cpp
+++ b/src/mongo/db/s/merge_chunks_command.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/s/collection_sharding_state.h"
 #include "mongo/db/s/shard_filtering_metadata_refresh.h"
 #include "mongo/db/s/sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
@@ -227,8 +228,7 @@ void mergeChunks(OperationContext* opCtx,
 
     if ((!commandStatus.isOK() || !writeConcernStatus.isOK()) &&
         checkMetadataForSuccess(opCtx, nss, epoch, ChunkRange(minKey, maxKey))) {
-        LOG(1) << "mergeChunk [" << redact(minKey) << "," << redact(maxKey)
-               << ") has already been committed.";
+        LOGV2_DEBUG(1, "mergeChunk [{},{}) has already been committed.", "redact_minKey"_attr = redact(minKey), "redact_maxKey"_attr = redact(maxKey));
         return;
     }
 
diff --git a/src/mongo/db/s/metadata_manager.cpp b/src/mongo/db/s/metadata_manager.cpp
index fd7289649c..7550a4ba52 100644
--- a/src/mongo/db/s/metadata_manager.cpp
+++ b/src/mongo/db/s/metadata_manager.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/query/internal_plans.h"
 #include "mongo/db/range_arithmetic.h"
 #include "mongo/db/s/collection_sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/fail_point.h"
@@ -128,7 +129,7 @@ void scheduleCleanup(executor::TaskExecutor* executor,
                      NamespaceString nss,
                      UUID collectionUuid,
                      Date_t when) {
-    LOG(1) << "Scheduling cleanup on " << nss.ns() << " at " << when;
+    LOGV2_DEBUG(1, "Scheduling cleanup on {} at {}", "nss_ns"_attr = nss.ns(), "when"_attr = when);
     auto swCallbackHandle = executor->scheduleWorkAt(
         when, [executor, nss = std::move(nss), uuid = collectionUuid](auto& args) {
             auto& status = args.status;
@@ -154,8 +155,7 @@ void scheduleCleanup(executor::TaskExecutor* executor,
         });
 
     if (!swCallbackHandle.isOK()) {
-        log() << "Failed to schedule the orphan data cleanup task"
-              << causedBy(redact(swCallbackHandle.getStatus()));
+        LOGV2("Failed to schedule the orphan data cleanup task{}", "causedBy_redact_swCallbackHandle_getStatus"_attr = causedBy(redact(swCallbackHandle.getStatus())));
     }
 }
 
@@ -293,7 +293,7 @@ void MetadataManager::setFilteringMetadata(CollectionMetadata remoteMetadata) {
 
     // Collection is becoming sharded
     if (_metadata.empty()) {
-        LOG(0) << "Marking collection " << _nss.ns() << " as " << remoteMetadata.toStringBasic();
+        LOGV2("Marking collection {} as {}", "_nss_ns"_attr = _nss.ns(), "remoteMetadata_toStringBasic"_attr = remoteMetadata.toStringBasic());
 
         invariant(_receivingChunks.empty());
         invariant(_rangesToClean.isEmpty());
@@ -311,9 +311,7 @@ void MetadataManager::setFilteringMetadata(CollectionMetadata remoteMetadata) {
         (activeMetadata->isSharded() &&
          *activeMetadata->getChunkManager()->getUUID() !=
              remoteMetadata.getChunkManager()->getUUID())) {
-        LOG(0) << "Updating metadata for collection " << _nss.ns() << " from "
-               << activeMetadata->toStringBasic() << " to " << remoteMetadata.toStringBasic()
-               << " due to UUID change";
+        LOGV2("Updating metadata for collection {} from {} to {} due to UUID change", "_nss_ns"_attr = _nss.ns(), "activeMetadata_toStringBasic"_attr = activeMetadata->toStringBasic(), "remoteMetadata_toStringBasic"_attr = remoteMetadata.toStringBasic());
 
         _receivingChunks.clear();
         _clearAllCleanups(lg);
@@ -326,14 +324,11 @@ void MetadataManager::setFilteringMetadata(CollectionMetadata remoteMetadata) {
     // We already have the same or newer version
     if (activeMetadata->getCollVersion().epoch() == remoteMetadata.getCollVersion().epoch() &&
         activeMetadata->getCollVersion() >= remoteMetadata.getCollVersion()) {
-        LOG(1) << "Ignoring update of active metadata " << activeMetadata->toStringBasic()
-               << " with an older " << remoteMetadata.toStringBasic();
+        LOGV2_DEBUG(1, "Ignoring update of active metadata {} with an older {}", "activeMetadata_toStringBasic"_attr = activeMetadata->toStringBasic(), "remoteMetadata_toStringBasic"_attr = remoteMetadata.toStringBasic());
         return;
     }
 
-    LOG(0) << "Updating metadata for collection " << _nss.ns() << " from "
-           << activeMetadata->toStringBasic() << " to " << remoteMetadata.toStringBasic()
-           << " due to version change";
+    LOGV2("Updating metadata for collection {} from {} to {} due to version change", "_nss_ns"_attr = _nss.ns(), "activeMetadata_toStringBasic"_attr = activeMetadata->toStringBasic(), "remoteMetadata_toStringBasic"_attr = remoteMetadata.toStringBasic());
 
     // Resolve any receiving chunks, which might have completed by now
     for (auto it = _receivingChunks.begin(); it != _receivingChunks.end();) {
@@ -346,8 +341,7 @@ void MetadataManager::setFilteringMetadata(CollectionMetadata remoteMetadata) {
 
         // The remote metadata contains a chunk we were earlier in the process of receiving, so we
         // deem it successfully received
-        LOG(2) << "Verified chunk " << redact(receivingRange.toString()) << " for collection "
-               << _nss.ns() << " has been migrated to this shard earlier";
+        LOGV2_DEBUG(2, "Verified chunk {} for collection {} has been migrated to this shard earlier", "redact_receivingRange_toString"_attr = redact(receivingRange.toString()), "_nss_ns"_attr = _nss.ns());
 
         _receivingChunks.erase(it);
         it = _receivingChunks.begin();
@@ -466,8 +460,7 @@ auto MetadataManager::beginReceive(ChunkRange const& range) -> CleanupNotificati
 
     _receivingChunks.emplace(range.getMin().getOwned(), range.getMax().getOwned());
 
-    log() << "Scheduling deletion of any documents in " << _nss.ns() << " range "
-          << redact(range.toString()) << " before migrating in a chunk covering the range";
+    LOGV2("Scheduling deletion of any documents in {} range {} before migrating in a chunk covering the range", "_nss_ns"_attr = _nss.ns(), "redact_range_toString"_attr = redact(range.toString()));
 
     return _pushRangeToClean(lg, range, Date_t{});
 }
@@ -512,13 +505,11 @@ auto MetadataManager::cleanUpRange(ChunkRange const& range, Date_t whenToDelete)
     if (!overlapMetadata) {
         // No running queries can depend on it, so queue it for deletion immediately.
         const auto whenStr = (whenToDelete == Date_t{}) ? "immediate"_sd : "deferred"_sd;
-        log() << "Scheduling " << whenStr << " deletion of " << _nss.ns() << " range "
-              << redact(range.toString());
+        LOGV2("Scheduling {} deletion of {} range {}", "whenStr"_attr = whenStr, "_nss_ns"_attr = _nss.ns(), "redact_range_toString"_attr = redact(range.toString()));
         return _pushRangeToClean(lg, range, whenToDelete);
     }
 
-    log() << "Deletion of " << _nss.ns() << " range " << redact(range.toString())
-          << " will be scheduled after all possibly dependent queries finish";
+    LOGV2("Deletion of {} range {} will be scheduled after all possibly dependent queries finish", "_nss_ns"_attr = _nss.ns(), "redact_range_toString"_attr = redact(range.toString()));
 
     // Put it on the oldest metadata permissible; the current one might live a long time.
     auto& orphans = overlapMetadata->orphans;
diff --git a/src/mongo/db/s/migration_chunk_cloner_source_legacy.cpp b/src/mongo/db/s/migration_chunk_cloner_source_legacy.cpp
index f8920c6680..d765dc6afa 100644
--- a/src/mongo/db/s/migration_chunk_cloner_source_legacy.cpp
+++ b/src/mongo/db/s/migration_chunk_cloner_source_legacy.cpp
@@ -51,6 +51,7 @@
 #include "mongo/executor/remote_command_response.h"
 #include "mongo/executor/task_executor.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
@@ -374,7 +375,7 @@ void MigrationChunkClonerSourceLegacy::cancelClone(OperationContext* opCtx) {
                                                    kRecvChunkAbort, _args.getNss(), _sessionId))
                                     .getStatus();
             if (!status.isOK()) {
-                LOG(0) << "Failed to cancel migration " << causedBy(redact(status));
+                LOGV2("Failed to cancel migration {}", "causedBy_redact_status"_attr = causedBy(redact(status)));
             }
         }
         // Intentional fall through
@@ -972,13 +973,9 @@ Status MigrationChunkClonerSourceLegacy::_checkRecipientCloningStatus(OperationC
         const std::size_t cloneLocsRemaining = _cloneLocs.size();
 
         if (_forceJumbo && _jumboChunkCloneState) {
-            log() << "moveChunk data transfer progress: " << redact(res)
-                  << " mem used: " << _memoryUsed
-                  << " documents cloned so far: " << _jumboChunkCloneState->docsCloned;
+            LOGV2("moveChunk data transfer progress: {} mem used: {} documents cloned so far: {}", "redact_res"_attr = redact(res), "_memoryUsed"_attr = _memoryUsed, "_jumboChunkCloneState_docsCloned"_attr = _jumboChunkCloneState->docsCloned);
         } else {
-            log() << "moveChunk data transfer progress: " << redact(res)
-                  << " mem used: " << _memoryUsed
-                  << " documents remaining to clone: " << cloneLocsRemaining;
+            LOGV2("moveChunk data transfer progress: {} mem used: {} documents remaining to clone: {}", "redact_res"_attr = redact(res), "_memoryUsed"_attr = _memoryUsed, "cloneLocsRemaining"_attr = cloneLocsRemaining);
         }
 
         if (res["state"].String() == "steady") {
diff --git a/src/mongo/db/s/migration_destination_manager.cpp b/src/mongo/db/s/migration_destination_manager.cpp
index 1e2ab4fc61..7cf2e8a662 100644
--- a/src/mongo/db/s/migration_destination_manager.cpp
+++ b/src/mongo/db/s/migration_destination_manager.cpp
@@ -60,6 +60,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/remove_saver.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
@@ -238,7 +239,7 @@ void MigrationDestinationManager::setState(State newState) {
 }
 
 void MigrationDestinationManager::_setStateFail(StringData msg) {
-    log() << msg;
+    LOGV2("{}", "msg"_attr = msg);
     {
         stdx::lock_guard<Latch> sl(_mutex);
         _errmsg = msg.toString();
@@ -411,7 +412,7 @@ repl::OpTime MigrationDestinationManager::cloneDocumentsFromDonor(
         } catch (...) {
             stdx::lock_guard<Client> lk(*opCtx->getClient());
             opCtx->getServiceContext()->killOperation(lk, opCtx, ErrorCodes::Error(51008));
-            log() << "Batch insertion failed " << causedBy(redact(exceptionToStatus()));
+            LOGV2("Batch insertion failed {}", "causedBy_redact_exceptionToStatus"_attr = causedBy(redact(exceptionToStatus())));
         }
     }};
     auto inserterThreadJoinGuard = makeGuard([&] {
@@ -710,9 +711,7 @@ void MigrationDestinationManager::_migrateDriver(OperationContext* opCtx) {
     invariant(!_min.isEmpty());
     invariant(!_max.isEmpty());
 
-    log() << "Starting receiving end of migration of chunk " << redact(_min) << " -> "
-          << redact(_max) << " for collection " << _nss.ns() << " from " << _fromShard
-          << " at epoch " << _epoch.toString() << " with session id " << *_sessionId;
+    LOGV2("Starting receiving end of migration of chunk {} -> {} for collection {} from {} at epoch {} with session id {}", "redact__min"_attr = redact(_min), "redact__max"_attr = redact(_max), "_nss_ns"_attr = _nss.ns(), "_fromShard"_attr = _fromShard, "_epoch_toString"_attr = _epoch.toString(), "_sessionId"_attr = *_sessionId);
 
     MoveTimingHelper timing(
         opCtx, "to", _nss.ns(), _min, _max, 6 /* steps */, &_errmsg, ShardId(), ShardId());
@@ -745,9 +744,8 @@ void MigrationDestinationManager::_migrateDriver(OperationContext* opCtx) {
         const ChunkRange range(_min, _max);
 
         while (migrationutil::checkForConflictingDeletions(opCtx, range, collectionUuid)) {
-            LOG(0) << "Migration paused because range overlaps with a "
-                      "range that is scheduled for deletion: collection: "
-                   << _nss.ns() << " range: " << redact(range.toString());
+            LOGV2("Migration paused because range overlaps with a "
+                      "range that is scheduled for deletion: collection: {} range: {}", "_nss_ns"_attr = _nss.ns(), "redact_range_toString"_attr = redact(range.toString()));
 
             auto status = CollectionShardingRuntime::waitForClean(opCtx, _nss, _epoch, range);
 
@@ -921,7 +919,7 @@ void MigrationDestinationManager::_migrateDriver(OperationContext* opCtx) {
                 opCtx->checkForInterrupt();
 
                 if (getState() == ABORT) {
-                    log() << "Migration aborted while waiting for replication at catch up stage";
+                    LOGV2("Migration aborted while waiting for replication at catch up stage");
                     return;
                 }
 
@@ -929,7 +927,7 @@ void MigrationDestinationManager::_migrateDriver(OperationContext* opCtx) {
                     break;
 
                 if (i > 100) {
-                    log() << "secondaries having hard time keeping up with migrate";
+                    LOGV2("secondaries having hard time keeping up with migrate");
                 }
 
                 sleepmillis(20);
@@ -949,14 +947,14 @@ void MigrationDestinationManager::_migrateDriver(OperationContext* opCtx) {
         // Pause to wait for replication. This will prevent us from going into critical section
         // until we're ready.
 
-        log() << "Waiting for replication to catch up before entering critical section";
+        LOGV2("Waiting for replication to catch up before entering critical section");
 
         auto awaitReplicationResult = repl::ReplicationCoordinator::get(opCtx)->awaitReplication(
             opCtx, lastOpApplied, _writeConcern);
         uassertStatusOKWithContext(awaitReplicationResult.status,
                                    awaitReplicationResult.status.codeString());
 
-        log() << "Chunk data replicated successfully.";
+        LOGV2("Chunk data replicated successfully.");
     }
 
     {
@@ -993,7 +991,7 @@ void MigrationDestinationManager::_migrateDriver(OperationContext* opCtx) {
             }
 
             if (getState() == ABORT) {
-                log() << "Migration aborted while transferring mods";
+                LOGV2("Migration aborted while transferring mods");
                 return;
             }
 
@@ -1139,14 +1137,12 @@ bool MigrationDestinationManager::_flushPendingWrites(OperationContext* opCtx,
         repl::OpTime op(lastOpApplied);
         static Occasionally sampler;
         if (sampler.tick()) {
-            log() << "migrate commit waiting for a majority of slaves for '" << _nss.ns() << "' "
-                  << redact(_min) << " -> " << redact(_max) << " waiting for: " << op;
+            LOGV2("migrate commit waiting for a majority of slaves for '{}' {} -> {} waiting for: {}", "_nss_ns"_attr = _nss.ns(), "redact__min"_attr = redact(_min), "redact__max"_attr = redact(_max), "op"_attr = op);
         }
         return false;
     }
 
-    log() << "migrate commit succeeded flushing to secondaries for '" << _nss.ns() << "' "
-          << redact(_min) << " -> " << redact(_max);
+    LOGV2("migrate commit succeeded flushing to secondaries for '{}' {} -> {}", "_nss_ns"_attr = _nss.ns(), "redact__min"_attr = redact(_min), "redact__max"_attr = redact(_max));
 
     return true;
 }
@@ -1192,8 +1188,7 @@ void MigrationDestinationManager::_forgetPending(OperationContext* opCtx, ChunkR
     // checking this here is that in the future we shouldn't have this problem.
     if (!optMetadata || !(*optMetadata)->isSharded() ||
         (*optMetadata)->getCollVersion().epoch() != _epoch) {
-        LOG(0) << "No need to forget pending chunk " << redact(range.toString())
-               << " because the epoch for " << _nss.ns() << " changed";
+        LOGV2("No need to forget pending chunk {} because the epoch for {} changed", "redact_range_toString"_attr = redact(range.toString()), "_nss_ns"_attr = _nss.ns());
         return;
     }
 
diff --git a/src/mongo/db/s/migration_destination_manager_legacy_commands.cpp b/src/mongo/db/s/migration_destination_manager_legacy_commands.cpp
index 2cd586063a..08ecef160e 100644
--- a/src/mongo/db/s/migration_destination_manager_legacy_commands.cpp
+++ b/src/mongo/db/s/migration_destination_manager_legacy_commands.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/s/shard_filtering_metadata_refresh.h"
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/s/start_chunk_clone_request.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/chunk_version.h"
 #include "mongo/s/request_types/migration_secondary_throttle_options.h"
 #include "mongo/util/assert_util.h"
@@ -200,7 +201,7 @@ public:
         Status const status = mdm->startCommit(sessionId);
         mdm->report(result, opCtx, false);
         if (!status.isOK()) {
-            log() << status.reason();
+            LOGV2("{}", "status_reason"_attr = status.reason());
             uassertStatusOK(status);
         }
         return true;
@@ -248,7 +249,7 @@ public:
             Status const status = mdm->abort(migrationSessionIdStatus.getValue());
             mdm->report(result, opCtx, false);
             if (!status.isOK()) {
-                log() << status.reason();
+                LOGV2("{}", "status_reason"_attr = status.reason());
                 uassertStatusOK(status);
             }
         } else if (migrationSessionIdStatus == ErrorCodes::NoSuchKey) {
diff --git a/src/mongo/db/s/migration_source_manager.cpp b/src/mongo/db/s/migration_source_manager.cpp
index 1dbde53dab..713720d335 100644
--- a/src/mongo/db/s/migration_source_manager.cpp
+++ b/src/mongo/db/s/migration_source_manager.cpp
@@ -53,6 +53,7 @@
 #include "mongo/db/s/sharding_statistics.h"
 #include "mongo/executor/task_executor.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/catalog/type_shard_collection.h"
 #include "mongo/s/catalog_cache_loader.h"
@@ -147,8 +148,7 @@ MigrationSourceManager::MigrationSourceManager(OperationContext* opCtx,
             "Destination shard cannot be the same as source",
             _args.getFromShardId() != _args.getToShardId());
 
-    log() << "Starting chunk migration " << redact(_args.toString())
-          << " with expected collection version epoch " << _args.getVersionEpoch();
+    LOGV2("Starting chunk migration {} with expected collection version epoch {}", "redact__args_toString"_attr = redact(_args.toString()), "_args_getVersionEpoch"_attr = _args.getVersionEpoch());
 
     // Force refresh of the metadata to ensure we have the latest
     forceShardFilteringMetadataRefresh(_opCtx, getNss());
@@ -355,7 +355,7 @@ Status MigrationSourceManager::enterCriticalSection() {
                           << signalStatus.toString()};
     }
 
-    log() << "Migration successfully entered critical section";
+    LOGV2("Migration successfully entered critical section");
 
     scopedGuard.dismiss();
     return Status::OK();
@@ -446,10 +446,8 @@ Status MigrationSourceManager::commitChunkMetadataOnConfig() {
                 // Need to get the latest optime in case the refresh request goes to a secondary --
                 // otherwise the read won't wait for the write that _configsvrCommitChunkMigration
                 // may have done
-                log()
-                    << "Error occurred while committing the migration. Performing a majority write "
-                       "against the config server to obtain its latest optime"
-                    << causedBy(redact(migrationCommitStatus));
+                LOGV2("Error occurred while committing the migration. Performing a majority write "
+                       "against the config server to obtain its latest optime{}", "causedBy_redact_migrationCommitStatus"_attr = causedBy(redact(migrationCommitStatus)));
 
                 Status status = ShardingLogging::get(_opCtx)->logChangeChecked(
                     _opCtx,
@@ -541,9 +539,7 @@ Status MigrationSourceManager::commitChunkMetadataOnConfig() {
                         shutdown(waitForShutdown());
                     }
 
-                    LOG(0) << "_configsvrEnsureChunkVersionIsGreaterThan failed after " << attempts
-                           << " attempts " << causedBy(ensureChunkVersionIsGreaterThanStatus)
-                           << " . Will try again.";
+                    LOGV2("_configsvrEnsureChunkVersionIsGreaterThan failed after {} attempts {} . Will try again.", "attempts"_attr = attempts, "causedBy_ensureChunkVersionIsGreaterThanStatus"_attr = causedBy(ensureChunkVersionIsGreaterThanStatus));
                 }
             } break;
             default:
@@ -568,9 +564,7 @@ Status MigrationSourceManager::commitChunkMetadataOnConfig() {
                 shutdown(waitForShutdown());
             }
 
-            log() << "Failed to refresh metadata after " << attempts << " attempts, after a "
-                  << (migrationCommitStatus.isOK() ? "failed commit attempt" : "successful commit")
-                  << causedBy(redact(refreshStatus)) << ". Will try to refresh again.";
+            LOGV2("Failed to refresh metadata after {} attempts, after a {}{}. Will try to refresh again.", "attempts"_attr = attempts, "migrationCommitStatus_isOK_failed_commit_attempt_successful_commit"_attr = (migrationCommitStatus.isOK() ? "failed commit attempt" : "successful commit"), "causedBy_redact_refreshStatus"_attr = causedBy(redact(refreshStatus)));
         }
     }
 
@@ -590,8 +584,7 @@ Status MigrationSourceManager::commitChunkMetadataOnConfig() {
     }
 
     // Migration succeeded
-    LOG(0) << "Migration succeeded and updated collection version to "
-           << refreshedMetadata->getCollVersion();
+    LOGV2("Migration succeeded and updated collection version to {}", "refreshedMetadata_getCollVersion"_attr = refreshedMetadata->getCollVersion());
 
     hangBeforeLeavingCriticalSection.pauseWhileSet();
 
@@ -636,8 +629,7 @@ Status MigrationSourceManager::commitChunkMetadataOnConfig() {
         << redact(range.toString()) << " due to: ";
 
     if (_args.getWaitForDelete()) {
-        log() << "Waiting for cleanup of " << getNss().ns() << " range "
-              << redact(range.toString());
+        LOGV2("Waiting for cleanup of {} range {}", "getNss_ns"_attr = getNss().ns(), "redact_range_toString"_attr = redact(range.toString()));
         auto deleteStatus = notification.waitStatus(_opCtx);
         if (!deleteStatus.isOK()) {
             return {ErrorCodes::OrphanedRangeCleanUpFailed,
@@ -650,8 +642,7 @@ Status MigrationSourceManager::commitChunkMetadataOnConfig() {
         return {ErrorCodes::OrphanedRangeCleanUpFailed,
                 orphanedRangeCleanUpErrMsg + redact(notification.waitStatus(_opCtx))};
     } else {
-        log() << "Leaving cleanup of " << getNss().ns() << " range " << redact(range.toString())
-              << " to complete in background";
+        LOGV2("Leaving cleanup of {} range {} to complete in background", "getNss_ns"_attr = getNss().ns(), "redact_range_toString"_attr = redact(range.toString()));
         notification.abandon();
     }
 
diff --git a/src/mongo/db/s/migration_util.cpp b/src/mongo/db/s/migration_util.cpp
index 9a02d422ee..64d20d2bc0 100644
--- a/src/mongo/db/s/migration_util.cpp
+++ b/src/mongo/db/s/migration_util.cpp
@@ -49,6 +49,7 @@
 #include "mongo/db/write_concern.h"
 #include "mongo/executor/task_executor_pool.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/client/shard.h"
@@ -74,7 +75,7 @@ void sendToRecipient(OperationContext* opCtx, const ShardId& recipientId, const
     auto recipientShard =
         uassertStatusOK(Grid::get(opCtx)->shardRegistry()->getShard(opCtx, recipientId));
 
-    LOG(1) << "Sending request " << cmd.toBSON({}) << " to recipient.";
+    LOGV2_DEBUG(1, "Sending request {} to recipient.", "cmd_toBSON"_attr = cmd.toBSON({}));
 
     auto response = recipientShard->runCommandWithFixedRetryAttempts(
         opCtx,
@@ -125,34 +126,31 @@ bool submitRangeDeletionTask(OperationContext* opCtx, const RangeDeletionTask& d
     AutoGetCollection autoColl(opCtx, deletionTask.getNss(), MODE_IS);
 
     if (!autoColl.getCollection()) {
-        LOG(0) << "Namespace not found: " << deletionTask.getNss();
+        LOGV2("Namespace not found: {}", "deletionTask_getNss"_attr = deletionTask.getNss());
         return false;
     }
 
     if (autoColl.getCollection()->uuid() != deletionTask.getCollectionUuid()) {
-        LOG(0) << "Collection UUID doesn't match the one marked for deletion: "
-               << autoColl.getCollection()->uuid() << " != " << deletionTask.getCollectionUuid();
+        LOGV2("Collection UUID doesn't match the one marked for deletion: {} != {}", "autoColl_getCollection_uuid"_attr = autoColl.getCollection()->uuid(), "deletionTask_getCollectionUuid"_attr = deletionTask.getCollectionUuid());
 
         return false;
     }
 
-    LOG(0) << "Scheduling range " << deletionTask.getRange() << " in namespace "
-           << deletionTask.getNss() << " for deletion.";
+    LOGV2("Scheduling range {} in namespace {} for deletion.", "deletionTask_getRange"_attr = deletionTask.getRange(), "deletionTask_getNss"_attr = deletionTask.getNss());
 
     auto css = CollectionShardingRuntime::get(opCtx, deletionTask.getNss());
 
     // TODO (SERVER-44554): This is needed for now because of the invariant that throws on cleanup
     // if the metadata is not set.
     if (!css->getCurrentMetadataIfKnown()) {
-        LOG(0) << "Current metadata is not available";
+        LOGV2("Current metadata is not available");
         return false;
     }
 
     auto notification = css->cleanUpRange(deletionTask.getRange(), whenToClean);
 
     if (notification.ready() && !notification.waitStatus(opCtx).isOK()) {
-        LOG(0) << "Failed to resubmit range for deletion: "
-               << causedBy(notification.waitStatus(opCtx));
+        LOGV2("Failed to resubmit range for deletion: {}", "causedBy_notification_waitStatus_opCtx"_attr = causedBy(notification.waitStatus(opCtx)));
     } else {
         notification.abandon();
     }
@@ -183,7 +181,7 @@ void submitPendingDeletions(OperationContext* opCtx) {
 }
 
 void resubmitRangeDeletionsOnStepUp(ServiceContext* serviceContext) {
-    LOG(0) << "Starting pending deletion submission thread.";
+    LOGV2("Starting pending deletion submission thread.");
 
     auto executor = Grid::get(serviceContext)->getExecutorPool()->getFixedExecutor();
 
@@ -216,8 +214,7 @@ void forEachOrphanRange(OperationContext* opCtx, const NamespaceString& nss, Cal
         RangeMap{SimpleBSONObjComparator::kInstance.makeBSONObjIndexedMap<BSONObj>()};
 
     if (!metadata->isSharded()) {
-        LOG(0) << "Upgrade: skipping orphaned range enumeration for " << nss
-               << ", collection is not sharded";
+        LOGV2("Upgrade: skipping orphaned range enumeration for {}, collection is not sharded", "nss"_attr = nss);
         return;
     }
 
@@ -226,8 +223,7 @@ void forEachOrphanRange(OperationContext* opCtx, const NamespaceString& nss, Cal
     while (true) {
         auto range = metadata->getNextOrphanRange(emptyChunkMap, startingKey);
         if (!range) {
-            LOG(2) << "Upgrade: Completed orphaned range enumeration for " << nss.toString()
-                   << " starting from " << redact(startingKey) << ", no orphan ranges remain";
+            LOGV2_DEBUG(2, "Upgrade: Completed orphaned range enumeration for {} starting from {}, no orphan ranges remain", "nss_toString"_attr = nss.toString(), "redact_startingKey"_attr = redact(startingKey));
 
             return;
         }
@@ -245,7 +241,7 @@ void submitOrphanRanges(OperationContext* opCtx, const NamespaceString& nss, con
         if (version == ChunkVersion::UNSHARDED())
             return;
 
-        LOG(2) << "Upgrade: Cleaning up existing orphans for " << nss << " : " << uuid;
+        LOGV2_DEBUG(2, "Upgrade: Cleaning up existing orphans for {} : {}", "nss"_attr = nss, "uuid"_attr = uuid);
 
         std::vector<RangeDeletionTask> deletions;
         forEachOrphanRange(opCtx, nss, [&deletions, &opCtx, &nss, &uuid](const auto& range) {
@@ -263,14 +259,11 @@ void submitOrphanRanges(OperationContext* opCtx, const NamespaceString& nss, con
                                                      NamespaceString::kRangeDeletionNamespace);
 
         for (const auto& task : deletions) {
-            LOG(2) << "Upgrade: Submitting range for cleanup: " << task.getRange() << " from "
-                   << nss;
+            LOGV2_DEBUG(2, "Upgrade: Submitting range for cleanup: {} from {}", "task_getRange"_attr = task.getRange(), "nss"_attr = nss);
             store.add(opCtx, task);
         }
     } catch (ExceptionFor<ErrorCodes::NamespaceNotFound>& e) {
-        LOG(0) << "Upgrade: Failed to cleanup orphans for " << nss
-               << " because the namespace was not found: " << e.what()
-               << ", the collection must have been dropped";
+        LOGV2("Upgrade: Failed to cleanup orphans for {} because the namespace was not found: {}, the collection must have been dropped", "nss"_attr = nss, "e_what"_attr = e.what());
     }
 }
 
@@ -287,7 +280,7 @@ void submitOrphanRangesForCleanup(OperationContext* opCtx) {
         for (auto collIt = catalog.begin(dbName); collIt != catalog.end(); ++collIt) {
             auto uuid = collIt.uuid().get();
             auto nss = catalog.lookupNSSByUUID(opCtx, uuid).get();
-            LOG(2) << "Upgrade: processing collection: " << nss;
+            LOGV2_DEBUG(2, "Upgrade: processing collection: {}", "nss"_attr = nss);
 
             submitOrphanRanges(opCtx, nss, uuid);
         }
diff --git a/src/mongo/db/s/move_primary_source_manager.cpp b/src/mongo/db/s/move_primary_source_manager.cpp
index 409bbb5d94..f94e98da75 100644
--- a/src/mongo/db/s/move_primary_source_manager.cpp
+++ b/src/mongo/db/s/move_primary_source_manager.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/s/sharding_logging.h"
 #include "mongo/db/s/sharding_state_recovery.h"
 #include "mongo/db/s/sharding_statistics.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog/type_shard_database.h"
 #include "mongo/s/catalog_cache.h"
@@ -74,7 +75,7 @@ Status MovePrimarySourceManager::clone(OperationContext* opCtx) {
     invariant(_state == kCreated);
     auto scopedGuard = makeGuard([&] { cleanupOnError(opCtx); });
 
-    log() << "Moving " << _dbname << " primary from: " << _fromShard << " to: " << _toShard;
+    LOGV2("Moving {} primary from: {} to: {}", "_dbname"_attr = _dbname, "_fromShard"_attr = _fromShard, "_toShard"_attr = _toShard);
 
     // Record start in changelog
     uassertStatusOK(ShardingLogging::get(opCtx)->logChangeChecked(
@@ -195,7 +196,7 @@ Status MovePrimarySourceManager::enterCriticalSection(OperationContext* opCtx) {
                           << signalStatus.toString()};
     }
 
-    log() << "movePrimary successfully entered critical section";
+    LOGV2("movePrimary successfully entered critical section");
 
     scopedGuard.dismiss();
     return Status::OK();
@@ -244,9 +245,8 @@ Status MovePrimarySourceManager::commitOnConfig(OperationContext* opCtx) {
         // Need to get the latest optime in case the refresh request goes to a secondary --
         // otherwise the read won't wait for the write that _configsvrCommitMovePrimary may have
         // done
-        log() << "Error occurred while committing the movePrimary. Performing a majority write "
-                 "against the config server to obtain its latest optime"
-              << causedBy(redact(commitStatus));
+        LOGV2("Error occurred while committing the movePrimary. Performing a majority write "
+                 "against the config server to obtain its latest optime{}", "causedBy_redact_commitStatus"_attr = causedBy(redact(commitStatus)));
 
         Status validateStatus = ShardingLogging::get(opCtx)->logChangeChecked(
             opCtx,
@@ -337,7 +337,7 @@ Status MovePrimarySourceManager::cleanStaleData(OperationContext* opCtx) {
         client.runCommand(_dbname.toString(), BSON("drop" << coll.coll()), dropCollResult);
         Status dropStatus = getStatusFromCommandResult(dropCollResult);
         if (!dropStatus.isOK()) {
-            log() << "failed to drop cloned collection " << coll << causedBy(redact(dropStatus));
+            LOGV2("failed to drop cloned collection {}{}", "coll"_attr = coll, "causedBy_redact_dropStatus"_attr = causedBy(redact(dropStatus)));
         }
     }
 
diff --git a/src/mongo/db/s/periodic_balancer_config_refresher.cpp b/src/mongo/db/s/periodic_balancer_config_refresher.cpp
index f9cab569d8..56ad23f367 100644
--- a/src/mongo/db/s/periodic_balancer_config_refresher.cpp
+++ b/src/mongo/db/s/periodic_balancer_config_refresher.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
@@ -60,7 +61,7 @@ PeriodicJobAnchor launchBalancerConfigRefresher(ServiceContext* serviceContext)
 
             Status status = balancerConfig->refreshAndCheck(opCtx.get());
             if (!status.isOK()) {
-                log() << "Failed to refresh balancer configuration" << causedBy(status);
+                LOGV2("Failed to refresh balancer configuration{}", "causedBy_status"_attr = causedBy(status));
             }
         },
         Seconds(30));
diff --git a/src/mongo/db/s/scoped_operation_completion_sharding_actions.cpp b/src/mongo/db/s/scoped_operation_completion_sharding_actions.cpp
index 4d54494869..a15f15030f 100644
--- a/src/mongo/db/s/scoped_operation_completion_sharding_actions.cpp
+++ b/src/mongo/db/s/scoped_operation_completion_sharding_actions.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/s/operation_sharding_state.h"
 #include "mongo/db/s/shard_filtering_metadata_refresh.h"
 #include "mongo/db/s/sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/cannot_implicitly_create_collection_info.h"
 #include "mongo/s/stale_exception.h"
 #include "mongo/util/log.h"
@@ -83,24 +84,21 @@ ScopedOperationCompletionShardingActions::~ScopedOperationCompletionShardingActi
         auto handleMismatchStatus = onShardVersionMismatchNoExcept(
             _opCtx, staleInfo->getNss(), staleInfo->getVersionReceived());
         if (!handleMismatchStatus.isOK())
-            log() << "Failed to handle stale version exception"
-                  << causedBy(redact(handleMismatchStatus));
+            LOGV2("Failed to handle stale version exception{}", "causedBy_redact_handleMismatchStatus"_attr = causedBy(redact(handleMismatchStatus)));
     } else if (auto staleInfo = status->extraInfo<StaleDbRoutingVersion>()) {
         auto handleMismatchStatus = onDbVersionMismatchNoExcept(_opCtx,
                                                                 staleInfo->getDb(),
                                                                 staleInfo->getVersionReceived(),
                                                                 staleInfo->getVersionWanted());
         if (!handleMismatchStatus.isOK())
-            log() << "Failed to handle database version exception"
-                  << causedBy(redact(handleMismatchStatus));
+            LOGV2("Failed to handle database version exception{}", "causedBy_redact_handleMismatchStatus"_attr = causedBy(redact(handleMismatchStatus)));
     } else if (auto cannotImplicitCreateCollInfo =
                    status->extraInfo<CannotImplicitlyCreateCollectionInfo>()) {
         if (ShardingState::get(_opCtx)->enabled()) {
             auto handleCannotImplicitCreateStatus =
                 onCannotImplicitlyCreateCollection(_opCtx, cannotImplicitCreateCollInfo->getNss());
             if (!handleCannotImplicitCreateStatus.isOK())
-                log() << "Failed to handle CannotImplicitlyCreateCollection exception"
-                      << causedBy(redact(handleCannotImplicitCreateStatus));
+                LOGV2("Failed to handle CannotImplicitlyCreateCollection exception{}", "causedBy_redact_handleCannotImplicitCreateStatus"_attr = causedBy(redact(handleCannotImplicitCreateStatus)));
         }
     }
 }
diff --git a/src/mongo/db/s/set_shard_version_command.cpp b/src/mongo/db/s/set_shard_version_command.cpp
index 839c87ea60..8d3b504b50 100644
--- a/src/mongo/db/s/set_shard_version_command.cpp
+++ b/src/mongo/db/s/set_shard_version_command.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/s/sharded_connection_info.h"
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/request_types/set_shard_version_request.h"
@@ -305,7 +306,7 @@ public:
                     if (critSecSignal) {
                         collLock.reset();
                         autoDb.reset();
-                        log() << "waiting till out of critical section";
+                        LOGV2("waiting till out of critical section");
                         critSecSignal->waitFor(opCtx, Seconds(10));
                     }
 
@@ -326,7 +327,7 @@ public:
                     if (critSecSignal) {
                         collLock.reset();
                         autoDb.reset();
-                        log() << "waiting till out of critical section";
+                        LOGV2("waiting till out of critical section");
                         critSecSignal->waitFor(opCtx, Seconds(10));
                     }
 
diff --git a/src/mongo/db/s/shard_filtering_metadata_refresh.cpp b/src/mongo/db/s/shard_filtering_metadata_refresh.cpp
index 5926ddcb45..9904851ba6 100644
--- a/src/mongo/db/s/shard_filtering_metadata_refresh.cpp
+++ b/src/mongo/db/s/shard_filtering_metadata_refresh.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/s/operation_sharding_state.h"
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/s/sharding_statistics.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/fail_point.h"
@@ -63,8 +64,7 @@ void onShardVersionMismatch(OperationContext* opCtx,
 
     invariant(ShardingState::get(opCtx)->canAcceptShardedCommands());
 
-    LOG(2) << "Metadata refresh requested for " << nss.ns() << " at shard version "
-           << shardVersionReceived;
+    LOGV2_DEBUG(2, "Metadata refresh requested for {} at shard version {}", "nss_ns"_attr = nss.ns(), "shardVersionReceived"_attr = shardVersionReceived);
 
     ShardingStatistics::get(opCtx).countStaleConfigErrors.addAndFetch(1);
 
@@ -134,7 +134,7 @@ Status onShardVersionMismatchNoExcept(OperationContext* opCtx,
         onShardVersionMismatch(opCtx, nss, shardVersionReceived, forceRefreshFromThisThread);
         return Status::OK();
     } catch (const DBException& ex) {
-        log() << "Failed to refresh metadata for collection " << nss << causedBy(redact(ex));
+        LOGV2("Failed to refresh metadata for collection {}{}", "nss"_attr = nss, "causedBy_redact_ex"_attr = causedBy(redact(ex)));
         return ex.toStatus();
     }
 }
@@ -179,8 +179,7 @@ ChunkVersion forceShardFilteringMetadataRefresh(OperationContext* opCtx,
             if (metadata->isSharded() &&
                 metadata->getCollVersion().epoch() == cm->getVersion().epoch() &&
                 metadata->getCollVersion() >= cm->getVersion()) {
-                LOG(1) << "Skipping refresh of metadata for " << nss << " "
-                       << metadata->getCollVersion() << " with an older " << cm->getVersion();
+                LOGV2_DEBUG(1, "Skipping refresh of metadata for {} {} with an older {}", "nss"_attr = nss, "metadata_getCollVersion"_attr = metadata->getCollVersion(), "cm_getVersion"_attr = cm->getVersion());
                 return metadata->getShardVersion();
             }
         }
@@ -202,8 +201,7 @@ ChunkVersion forceShardFilteringMetadataRefresh(OperationContext* opCtx,
             if (metadata->isSharded() &&
                 metadata->getCollVersion().epoch() == cm->getVersion().epoch() &&
                 metadata->getCollVersion() >= cm->getVersion()) {
-                LOG(1) << "Skipping refresh of metadata for " << nss << " "
-                       << metadata->getCollVersion() << " with an older " << cm->getVersion();
+                LOGV2_DEBUG(1, "Skipping refresh of metadata for {} {} with an older {}", "nss"_attr = nss, "metadata_getCollVersion"_attr = metadata->getCollVersion(), "cm_getVersion"_attr = cm->getVersion());
                 return metadata->getShardVersion();
             }
         }
@@ -225,8 +223,7 @@ Status onDbVersionMismatchNoExcept(
         onDbVersionMismatch(opCtx, dbName, clientDbVersion, serverDbVersion);
         return Status::OK();
     } catch (const DBException& ex) {
-        log() << "Failed to refresh databaseVersion for database " << dbName
-              << causedBy(redact(ex));
+        LOGV2("Failed to refresh databaseVersion for database {}{}", "dbName"_attr = dbName, "causedBy_redact_ex"_attr = causedBy(redact(ex)));
         return ex.toStatus();
     }
 }
@@ -266,10 +263,7 @@ void forceDatabaseRefresh(OperationContext* opCtx, const StringData dbName) {
         const auto cachedDbVersion = dss->getDbVersion(opCtx, dssLock);
         if (cachedDbVersion && cachedDbVersion->getUuid() == refreshedDbVersion.getUuid() &&
             cachedDbVersion->getLastMod() >= refreshedDbVersion.getLastMod()) {
-            LOG(2) << "Skipping setting cached databaseVersion for " << dbName
-                   << " to refreshed version " << refreshedDbVersion.toBSON()
-                   << " because current cached databaseVersion is already "
-                   << cachedDbVersion->toBSON();
+            LOGV2_DEBUG(2, "Skipping setting cached databaseVersion for {} to refreshed version {} because current cached databaseVersion is already {}", "dbName"_attr = dbName, "refreshedDbVersion_toBSON"_attr = refreshedDbVersion.toBSON(), "cachedDbVersion_toBSON"_attr = cachedDbVersion->toBSON());
             return;
         }
     }
diff --git a/src/mongo/db/s/shard_metadata_util.cpp b/src/mongo/db/s/shard_metadata_util.cpp
index d08c5f4cd7..2dfddb90e4 100644
--- a/src/mongo/db/s/shard_metadata_util.cpp
+++ b/src/mongo/db/s/shard_metadata_util.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/dbdirectclient.h"
 #include "mongo/db/ops/write_ops.h"
 #include "mongo/db/write_concern_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/unique_message.h"
 #include "mongo/s/catalog/type_chunk.h"
@@ -425,7 +426,7 @@ Status dropChunksAndDeleteCollectionsEntry(OperationContext* opCtx, const Namesp
             }
         }
 
-        LOG(1) << "Successfully cleared persisted chunk metadata for collection '" << nss << "'.";
+        LOGV2_DEBUG(1, "Successfully cleared persisted chunk metadata for collection '{}'.", "nss"_attr = nss);
         return Status::OK();
     } catch (const DBException& ex) {
         return ex.toStatus();
@@ -444,7 +445,7 @@ void dropChunks(OperationContext* opCtx, const NamespaceString& nss) {
         }
     }
 
-    LOG(1) << "Successfully cleared persisted chunk metadata for collection '" << nss << "'.";
+    LOGV2_DEBUG(1, "Successfully cleared persisted chunk metadata for collection '{}'.", "nss"_attr = nss);
 }
 
 Status deleteDatabasesEntry(OperationContext* opCtx, StringData dbName) {
@@ -464,7 +465,7 @@ Status deleteDatabasesEntry(OperationContext* opCtx, StringData dbName) {
         uassertStatusOK(
             getStatusFromWriteCommandResponse(deleteCommandResponse->getCommandReply()));
 
-        LOG(1) << "Successfully cleared persisted metadata for db '" << dbName.toString() << "'.";
+        LOGV2_DEBUG(1, "Successfully cleared persisted metadata for db '{}'.", "dbName_toString"_attr = dbName.toString());
         return Status::OK();
     } catch (const DBException& ex) {
         return ex.toStatus();
diff --git a/src/mongo/db/s/shard_server_catalog_cache_loader.cpp b/src/mongo/db/s/shard_server_catalog_cache_loader.cpp
index 682954e7b4..3b91609d34 100644
--- a/src/mongo/db/s/shard_server_catalog_cache_loader.cpp
+++ b/src/mongo/db/s/shard_server_catalog_cache_loader.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/s/shard_metadata_util.h"
 #include "mongo/db/s/sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_shard_collection.h"
 #include "mongo/s/catalog/type_shard_database.h"
 #include "mongo/s/client/shard_registry.h"
@@ -90,7 +91,7 @@ void dropChunksIfEpochChanged(OperationContext* opCtx,
         dropChunks(opCtx, nss);
 
         if (MONGO_unlikely(hangPersistCollectionAndChangedChunksAfterDropChunks.shouldFail())) {
-            log() << "Hit hangPersistCollectionAndChangedChunksAfterDropChunks failpoint";
+            LOGV2("Hit hangPersistCollectionAndChangedChunksAfterDropChunks failpoint");
             hangPersistCollectionAndChangedChunksAfterDropChunks.pauseWhileSet(opCtx);
         }
     }
@@ -954,12 +955,10 @@ void ShardServerCatalogCacheLoader::_runCollAndChunksTasks(const NamespaceString
         _updatePersistedCollAndChunksMetadata(context.opCtx(), nss);
         taskFinished = true;
     } catch (const ExceptionForCat<ErrorCategory::ShutdownError>&) {
-        LOG(0) << "Failed to persist chunk metadata update for collection '" << nss
-               << "' due to shutdown.";
+        LOGV2("Failed to persist chunk metadata update for collection '{}' due to shutdown.", "nss"_attr = nss);
         inShutdown = true;
     } catch (const DBException& ex) {
-        LOG(0) << "Failed to persist chunk metadata update for collection '" << nss
-               << causedBy(redact(ex));
+        LOGV2("Failed to persist chunk metadata update for collection '{}{}", "nss"_attr = nss, "causedBy_redact_ex"_attr = causedBy(redact(ex)));
     }
 
     {
@@ -988,10 +987,7 @@ void ShardServerCatalogCacheLoader::_runCollAndChunksTasks(const NamespaceString
 
     _threadPool.schedule([this, nss](auto status) {
         if (ErrorCodes::isCancelationError(status.code())) {
-            LOG(0) << "Cache loader failed to schedule a persisted metadata update"
-                   << " task for namespace '" << nss << "' due to '" << redact(status)
-                   << "'. Clearing task list so that scheduling will be attempted by the next"
-                   << " caller to refresh this namespace.";
+            LOGV2("Cache loader failed to schedule a persisted metadata update task for namespace '{}' due to '{}'. Clearing task list so that scheduling will be attempted by the next caller to refresh this namespace.", "nss"_attr = nss, "redact_status"_attr = redact(status));
 
             {
                 stdx::lock_guard<Latch> lock(_mutex);
@@ -1014,11 +1010,10 @@ void ShardServerCatalogCacheLoader::_runDbTasks(StringData dbName) {
         _updatePersistedDbMetadata(context.opCtx(), dbName);
         taskFinished = true;
     } catch (const ExceptionForCat<ErrorCategory::ShutdownError>&) {
-        LOG(0) << "Failed to persist metadata update for db '" << dbName << "' due to shutdown.";
+        LOGV2("Failed to persist metadata update for db '{}' due to shutdown.", "dbName"_attr = dbName);
         inShutdown = true;
     } catch (const DBException& ex) {
-        LOG(0) << "Failed to persist chunk metadata update for database " << dbName
-               << causedBy(redact(ex));
+        LOGV2("Failed to persist chunk metadata update for database {}{}", "dbName"_attr = dbName, "causedBy_redact_ex"_attr = causedBy(redact(ex)));
     }
 
     {
@@ -1047,10 +1042,7 @@ void ShardServerCatalogCacheLoader::_runDbTasks(StringData dbName) {
 
     _threadPool.schedule([this, name = dbName.toString()](auto status) {
         if (ErrorCodes::isCancelationError(status.code())) {
-            LOG(0) << "Cache loader failed to schedule a persisted metadata update"
-                   << " task for namespace '" << name << "' due to '" << redact(status)
-                   << "'. Clearing task list so that scheduling will be attempted by the next"
-                   << " caller to refresh this namespace.";
+            LOGV2("Cache loader failed to schedule a persisted metadata update task for namespace '{}' due to '{}'. Clearing task list so that scheduling will be attempted by the next caller to refresh this namespace.", "name"_attr = name, "redact_status"_attr = redact(status));
 
             {
                 stdx::lock_guard<Latch> lock(_mutex);
diff --git a/src/mongo/db/s/sharded_connection_info.cpp b/src/mongo/db/s/sharded_connection_info.cpp
index 228572e135..38bad66a3d 100644
--- a/src/mongo/db/s/sharded_connection_info.cpp
+++ b/src/mongo/db/s/sharded_connection_info.cpp
@@ -34,6 +34,7 @@
 #include "mongo/db/s/sharded_connection_info.h"
 
 #include "mongo/db/client.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -51,7 +52,7 @@ ShardedConnectionInfo* ShardedConnectionInfo::get(Client* client, bool create) {
     auto& current = clientSCI(client);
 
     if (!current && create) {
-        LOG(1) << "entering shard mode for connection";
+        LOGV2_DEBUG(1, "entering shard mode for connection");
         current.emplace();
     }
 
diff --git a/src/mongo/db/s/sharding_initialization_mongod.cpp b/src/mongo/db/s/sharding_initialization_mongod.cpp
index 46631bb89b..484dd226c3 100644
--- a/src/mongo/db/s/sharding_initialization_mongod.cpp
+++ b/src/mongo/db/s/sharding_initialization_mongod.cpp
@@ -54,6 +54,7 @@
 #include "mongo/db/s/transaction_coordinator_service.h"
 #include "mongo/db/server_options.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata/egress_metadata_hook_list.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_connection.h"
@@ -102,13 +103,13 @@ public:
             ->getFixedExecutor()
             ->schedule([serviceContext = _serviceContext, connStr = state.connStr](Status status) {
                 if (ErrorCodes::isCancelationError(status.code())) {
-                    LOG(2) << "Unable to schedule confirmed set update due to " << status;
+                    LOGV2_DEBUG(2, "Unable to schedule confirmed set update due to {}", "status"_attr = status);
                     return;
                 }
                 invariant(status);
 
                 try {
-                    LOG(0) << "Updating config server with confirmed set " << connStr;
+                    LOGV2("Updating config server with confirmed set {}", "connStr"_attr = connStr);
                     Grid::get(serviceContext)->shardRegistry()->updateReplSetHosts(connStr);
 
                     if (MONGO_unlikely(failUpdateShardIdentityConfigString.shouldFail())) {
@@ -130,7 +131,7 @@ public:
                     ShardingInitializationMongoD::updateShardIdentityConfigString(opCtx.get(),
                                                                                   connStr);
                 } catch (const ExceptionForCat<ErrorCategory::ShutdownError>& e) {
-                    LOG(0) << "Unable to update config server due to " << e;
+                    LOGV2("Unable to update config server due to {}", "e"_attr = e);
                 }
             });
     }
@@ -172,8 +173,7 @@ void ShardingInitializationMongoD::initializeShardingEnvironmentOnShardServer(
 
     Grid::get(opCtx)->setShardingInitialized();
 
-    LOG(0) << "Finished initializing sharding components for "
-           << (isStandaloneOrPrimary ? "primary" : "secondary") << " node.";
+    LOGV2("Finished initializing sharding components for {} node.", "isStandaloneOrPrimary_primary_secondary"_attr = (isStandaloneOrPrimary ? "primary" : "secondary"));
 }
 
 ShardingInitializationMongoD::ShardingInitializationMongoD()
@@ -306,7 +306,7 @@ void ShardingInitializationMongoD::initializeFromShardIdentity(
         shardIdentity.validate(),
         "Invalid shard identity document found when initializing sharding state");
 
-    log() << "initializing sharding state with: " << shardIdentity;
+    LOGV2("initializing sharding state with: {}", "shardIdentity"_attr = shardIdentity);
 
     const auto& configSvrConnStr = shardIdentity.getConfigsvrConnectionString();
 
@@ -360,8 +360,7 @@ void ShardingInitializationMongoD::updateShardIdentityConfigString(
             warning() << "failed to update config string of shard identity document because "
                       << "it does not exist. This shard could have been removed from the cluster";
         } else {
-            LOG(2) << "Updated config server connection string in shardIdentity document to"
-                   << newConnectionString;
+            LOGV2_DEBUG(2, "Updated config server connection string in shardIdentity document to{}", "newConnectionString"_attr = newConnectionString);
         }
     } catch (const DBException& exception) {
         auto status = exception.toStatus();
diff --git a/src/mongo/db/s/sharding_logging.cpp b/src/mongo/db/s/sharding_logging.cpp
index c3d07903ce..98340a3074 100644
--- a/src/mongo/db/s/sharding_logging.cpp
+++ b/src/mongo/db/s/sharding_logging.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/server_options.h"
 #include "mongo/executor/network_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_changelog.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
@@ -80,7 +81,7 @@ Status ShardingLogging::logAction(OperationContext* opCtx,
         if (result.isOK()) {
             _actionLogCollectionCreated.store(1);
         } else {
-            log() << "couldn't create config.actionlog collection:" << causedBy(result);
+            LOGV2("couldn't create config.actionlog collection:{}", "causedBy_result"_attr = causedBy(result));
             return result;
         }
     }
@@ -106,7 +107,7 @@ Status ShardingLogging::logChangeChecked(OperationContext* opCtx,
         if (result.isOK()) {
             _changeLogCollectionCreated.store(1);
         } else {
-            log() << "couldn't create config.changelog collection:" << causedBy(result);
+            LOGV2("couldn't create config.changelog collection:{}", "causedBy_result"_attr = causedBy(result));
             return result;
         }
     }
@@ -144,7 +145,7 @@ Status ShardingLogging::_log(OperationContext* opCtx,
     changeLog.setDetails(detail);
 
     BSONObj changeLogBSON = changeLog.toBSON();
-    log() << "about to log metadata event into " << logCollName << ": " << redact(changeLogBSON);
+    LOGV2("about to log metadata event into {}: {}", "logCollName"_attr = logCollName, "redact_changeLogBSON"_attr = redact(changeLogBSON));
 
     const NamespaceString nss("config", logCollName);
     Status result = Grid::get(opCtx)->catalogClient()->insertConfigDocument(
diff --git a/src/mongo/db/s/sharding_state.cpp b/src/mongo/db/s/sharding_state.cpp
index 37e5f8930f..0f85554d13 100644
--- a/src/mongo/db/s/sharding_state.cpp
+++ b/src/mongo/db/s/sharding_state.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/operation_context.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -69,7 +70,7 @@ void ShardingState::setInitialized(ShardId shardId, OID clusterId) {
 
 void ShardingState::setInitialized(Status failedStatus) {
     invariant(!failedStatus.isOK());
-    log() << "Failed to initialize sharding components" << causedBy(failedStatus);
+    LOGV2("Failed to initialize sharding components{}", "causedBy_failedStatus"_attr = causedBy(failedStatus));
 
     stdx::unique_lock<Latch> ul(_mutex);
     invariant(_getInitializationState() == InitializationState::kNew);
diff --git a/src/mongo/db/s/sharding_state_recovery.cpp b/src/mongo/db/s/sharding_state_recovery.cpp
index f8a869564c..09a0c1b63a 100644
--- a/src/mongo/db/s/sharding_state_recovery.cpp
+++ b/src/mongo/db/s/sharding_state_recovery.cpp
@@ -50,6 +50,7 @@
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/write_concern.h"
 #include "mongo/db/write_concern_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
@@ -151,7 +152,7 @@ Status modifyRecoveryDocument(OperationContext* opCtx,
         auto const grid = Grid::get(opCtx);
         BSONObj updateObj = RecoveryDocument::createChangeObj(grid->configOpTime(), change);
 
-        LOG(1) << "Changing sharding recovery document " << redact(updateObj);
+        LOGV2_DEBUG(1, "Changing sharding recovery document {}", "redact_updateObj"_attr = redact(updateObj));
 
         UpdateRequest updateReq(NamespaceString::kServerConfigurationNamespace);
         updateReq.setQuery(RecoveryDocument::getQuery());
@@ -223,24 +224,20 @@ Status ShardingStateRecovery::recover(OperationContext* opCtx) {
 
     const auto recoveryDoc = std::move(recoveryDocStatus.getValue());
 
-    log() << "Sharding state recovery process found document " << redact(recoveryDoc.toBSON());
+    LOGV2("Sharding state recovery process found document {}", "redact_recoveryDoc_toBSON"_attr = redact(recoveryDoc.toBSON()));
 
     if (!recoveryDoc.getMinOpTimeUpdaters()) {
         // Treat the minOpTime as up-to-date
         const auto prevOpTime = grid->advanceConfigOpTime(
             opCtx, recoveryDoc.getMinOpTime(), "sharding state recovery document");
         if (prevOpTime) {
-            log()
-                << "No in flight metadata change operations, so config server optime updated from "
-                << *prevOpTime << " to " << recoveryDoc.getMinOpTime();
+            LOGV2("No in flight metadata change operations, so config server optime updated from {} to {}", "prevOpTime"_attr = *prevOpTime, "recoveryDoc_getMinOpTime"_attr = recoveryDoc.getMinOpTime());
         }
         return Status::OK();
     }
 
-    log() << "Sharding state recovery document indicates there were "
-          << recoveryDoc.getMinOpTimeUpdaters()
-          << " metadata change operations in flight. Contacting the config server primary in order "
-             "to retrieve the most recent opTime.";
+    LOGV2("Sharding state recovery document indicates there were {} metadata change operations in flight. Contacting the config server primary in order "
+             "to retrieve the most recent opTime.", "recoveryDoc_getMinOpTimeUpdaters"_attr = recoveryDoc.getMinOpTimeUpdaters());
 
     // Need to fetch the latest uptime from the config server, so do a logging write
     Status status = ShardingLogging::get(opCtx)->logChangeChecked(
@@ -252,7 +249,7 @@ Status ShardingStateRecovery::recover(OperationContext* opCtx) {
     if (!status.isOK())
         return status;
 
-    log() << "Sharding state recovered. New config server opTime is " << grid->configOpTime();
+    LOGV2("Sharding state recovered. New config server opTime is {}", "grid_configOpTime"_attr = grid->configOpTime());
 
     // Finally, clear the recovery document so next time we don't need to recover
     status = modifyRecoveryDocument(opCtx, RecoveryDocument::Clear, kLocalWriteConcern);
diff --git a/src/mongo/db/s/shardsvr_rename_collection.cpp b/src/mongo/db/s/shardsvr_rename_collection.cpp
index ec61672284..22e9645544 100644
--- a/src/mongo/db/s/shardsvr_rename_collection.cpp
+++ b/src/mongo/db/s/shardsvr_rename_collection.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/repl/repl_client_info.h"
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/s/active_rename_collection_registry.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/request_types/rename_collection_gen.h"
 #include "mongo/util/log.h"
@@ -73,7 +74,7 @@ public:
                     incomingRequest));
 
             if (MONGO_unlikely(hangRenameCollectionAfterGettingRename.shouldFail())) {
-                log() << "Hit hangRenameCollectionAfterGettingRename";
+                LOGV2("Hit hangRenameCollectionAfterGettingRename");
                 hangRenameCollectionAfterGettingRename.pauseWhileSet(opCtx);
             }
 
diff --git a/src/mongo/db/s/shardsvr_shard_collection.cpp b/src/mongo/db/s/shardsvr_shard_collection.cpp
index bf04f45e47..5ca65baf68 100644
--- a/src/mongo/db/s/shardsvr_shard_collection.cpp
+++ b/src/mongo/db/s/shardsvr_shard_collection.cpp
@@ -51,6 +51,7 @@
 #include "mongo/db/s/shard_filtering_metadata_refresh.h"
 #include "mongo/db/s/sharding_logging.h"
 #include "mongo/db/s/sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog/sharding_catalog_client_impl.h"
@@ -515,7 +516,7 @@ void logStartShardCollection(OperationContext* opCtx,
                              const ShardsvrShardCollection& request,
                              const ShardCollectionTargetState& prerequisites,
                              const ShardId& dbPrimaryShardId) {
-    LOG(0) << "CMD: shardcollection: " << cmdObj;
+    LOGV2("CMD: shardcollection: {}", "cmdObj"_attr = cmdObj);
 
     audit::logShardCollection(
         opCtx->getClient(), nss.ns(), prerequisites.shardKeyPattern.toBSON(), request.getUnique());
@@ -769,8 +770,7 @@ UUID shardCollection(OperationContext* opCtx,
         writeChunkDocumentsAndRefreshShards(*targetState, initialChunks);
     }
 
-    LOG(0) << "Created " << initialChunks.chunks.size() << " chunk(s) for: " << nss
-           << ", producing collection version " << initialChunks.collVersion();
+    LOGV2("Created {} chunk(s) for: {}, producing collection version {}", "initialChunks_chunks_size"_attr = initialChunks.chunks.size(), "nss"_attr = nss, "initialChunks_collVersion"_attr = initialChunks.collVersion());
 
 
     ShardingLogging::get(opCtx)->logChange(
@@ -859,7 +859,7 @@ public:
                     uuid);
 
             if (MONGO_unlikely(pauseShardCollectionBeforeReturning.shouldFail())) {
-                log() << "Hit pauseShardCollectionBeforeReturning";
+                LOGV2("Hit pauseShardCollectionBeforeReturning");
                 pauseShardCollectionBeforeReturning.pauseWhileSet(opCtx);
             }
 
diff --git a/src/mongo/db/s/split_chunk_command.cpp b/src/mongo/db/s/split_chunk_command.cpp
index 4ddc478c40..8748d21387 100644
--- a/src/mongo/db/s/split_chunk_command.cpp
+++ b/src/mongo/db/s/split_chunk_command.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/s/operation_sharding_state.h"
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/s/split_chunk.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -120,7 +121,7 @@ public:
         auto parseShardNameStatus = bsonExtractStringField(cmdObj, "from", &shardName);
         uassertStatusOK(parseShardNameStatus);
 
-        log() << "received splitChunk request: " << redact(cmdObj);
+        LOGV2("received splitChunk request: {}", "redact_cmdObj"_attr = redact(cmdObj));
 
         vector<BSONObj> splitKeys;
         {
diff --git a/src/mongo/db/s/split_chunk_test.cpp b/src/mongo/db/s/split_chunk_test.cpp
index 5adb6c0b35..e419834da7 100644
--- a/src/mongo/db/s/split_chunk_test.cpp
+++ b/src/mongo/db/s/split_chunk_test.cpp
@@ -42,6 +42,7 @@
 #include "mongo/executor/remote_command_request.h"
 #include "mongo/executor/remote_command_response.h"
 #include "mongo/executor/task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/dist_lock_manager_mock.h"
 #include "mongo/s/catalog/type_chunk.h"
 #include "mongo/s/catalog/type_collection.h"
@@ -169,8 +170,8 @@ void SplitChunkTest::expectLock() {
     dynamic_cast<DistLockManagerMock*>(distLock())
         ->expectLock(
             [this](StringData name, StringData whyMessage, Milliseconds) {
-                LOG(0) << name;
-                LOG(0) << whyMessage;
+                LOGV2("{}", "name"_attr = name);
+                LOGV2("{}", "whyMessage"_attr = whyMessage);
             },
             Status::OK());
 }
diff --git a/src/mongo/db/s/split_vector.cpp b/src/mongo/db/s/split_vector.cpp
index 14ad3ecdc3..92fc9637bb 100644
--- a/src/mongo/db/s/split_vector.cpp
+++ b/src/mongo/db/s/split_vector.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/namespace_string.h"
 #include "mongo/db/query/internal_plans.h"
 #include "mongo/db/query/plan_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -137,8 +138,7 @@ StatusWith<std::vector<BSONObj>> splitVector(OperationContext* opCtx,
             return emptyVector;
         }
 
-        log() << "request split points lookup for chunk " << nss.toString() << " " << redact(minKey)
-              << " -->> " << redact(maxKey);
+        LOGV2("request split points lookup for chunk {} {} -->> {}", "nss_toString"_attr = nss.toString(), "redact_minKey"_attr = redact(minKey), "redact_maxKey"_attr = redact(maxKey));
 
         // We'll use the average object size and number of object to find approximately how many
         // keys each chunk should have. We'll split at half the maxChunkSize or maxChunkObjects,
@@ -148,8 +148,7 @@ StatusWith<std::vector<BSONObj>> splitVector(OperationContext* opCtx,
         long long keyCount = maxChunkSize.get() / (2 * avgRecSize);
 
         if (maxChunkObjects.get() && (maxChunkObjects.get() < keyCount)) {
-            log() << "limiting split vector to " << maxChunkObjects.get() << " (from " << keyCount
-                  << ") objects ";
+            LOGV2("limiting split vector to {} (from {}) objects ", "maxChunkObjects_get"_attr = maxChunkObjects.get(), "keyCount"_attr = keyCount);
             keyCount = maxChunkObjects.get();
         }
 
@@ -239,9 +238,7 @@ StatusWith<std::vector<BSONObj>> splitVector(OperationContext* opCtx,
                                 continue;
                             }
 
-                            log() << "Max BSON response size reached for split vector before the"
-                                  << " end of chunk " << nss.toString() << " " << redact(minKey)
-                                  << " -->> " << redact(maxKey);
+                            LOGV2("Max BSON response size reached for split vector before the end of chunk {} {} -->> {}", "nss_toString"_attr = nss.toString(), "redact_minKey"_attr = redact(minKey), "redact_maxKey"_attr = redact(maxKey));
                             break;
                         }
 
@@ -249,15 +246,13 @@ StatusWith<std::vector<BSONObj>> splitVector(OperationContext* opCtx,
                         splitKeys.push_back(currKey.getOwned());
                         currCount = 0;
                         numChunks++;
-                        LOG(4) << "picked a split key: " << redact(currKey);
+                        LOGV2_DEBUG(4, "picked a split key: {}", "redact_currKey"_attr = redact(currKey));
                     }
                 }
 
                 // Stop if we have enough split points.
                 if (maxSplitPoints && maxSplitPoints.get() && (numChunks >= maxSplitPoints.get())) {
-                    log() << "max number of requested split points reached (" << numChunks
-                          << ") before the end of chunk " << nss.toString() << " " << redact(minKey)
-                          << " -->> " << redact(maxKey);
+                    LOGV2("max number of requested split points reached ({}) before the end of chunk {} {} -->> {}", "numChunks"_attr = numChunks, "nss_toString"_attr = nss.toString(), "redact_minKey"_attr = redact(minKey), "redact_maxKey"_attr = redact(maxKey));
                     break;
                 }
 
@@ -280,7 +275,7 @@ StatusWith<std::vector<BSONObj>> splitVector(OperationContext* opCtx,
             force = false;
             keyCount = currCount / 2;
             currCount = 0;
-            log() << "splitVector doing another cycle because of force, keyCount now: " << keyCount;
+            LOGV2("splitVector doing another cycle because of force, keyCount now: {}", "keyCount"_attr = keyCount);
 
             exec = InternalPlanner::indexScan(opCtx,
                                               collection,
diff --git a/src/mongo/db/s/transaction_coordinator.cpp b/src/mongo/db/s/transaction_coordinator.cpp
index 9393168a86..0e49a7656c 100644
--- a/src/mongo/db/s/transaction_coordinator.cpp
+++ b/src/mongo/db/s/transaction_coordinator.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/s/transaction_coordinator_metrics_observer.h"
 #include "mongo/db/s/wait_for_majority_service.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -63,7 +64,7 @@ ExecutorFuture<void> waitForMajorityWithHangFailpoint(ServiceContext* service,
 
     if (auto sfp = failpoint.scoped(); MONGO_unlikely(sfp.isActive())) {
         const BSONObj& data = sfp.getData();
-        LOG(0) << "Hit " << failPointName << " failpoint";
+        LOGV2("Hit {} failpoint", "failPointName"_attr = failPointName);
 
         // Run the hang failpoint asynchronously on a different thread to avoid self deadlocks.
         return ExecutorFuture<void>(executor).then(
@@ -200,9 +201,7 @@ TransactionCoordinator::TransactionCoordinator(OperationContext* operationContex
                     }
 
                     if (_decision->getDecision() == CommitDecision::kCommit) {
-                        LOG(3) << txn::txnIdToString(_lsid, _txnNumber)
-                               << " Advancing cluster time to the commit timestamp "
-                               << *_decision->getCommitTimestamp();
+                        LOGV2_DEBUG(3, "{} Advancing cluster time to the commit timestamp {}", "txn_txnIdToString__lsid__txnNumber"_attr = txn::txnIdToString(_lsid, _txnNumber), "_decision_getCommitTimestamp"_attr = *_decision->getCommitTimestamp());
 
                         uassertStatusOK(LogicalClock::get(_serviceContext)
                                             ->advanceClusterTime(
@@ -382,8 +381,7 @@ void TransactionCoordinator::_done(Status status) {
                         str::stream() << "Coordinator " << _lsid.getId() << ':' << _txnNumber
                                       << " stopped due to: " << status.reason());
 
-    LOG(3) << txn::txnIdToString(_lsid, _txnNumber) << " Two-phase commit completed with "
-           << redact(status);
+    LOGV2_DEBUG(3, "{} Two-phase commit completed with {}", "txn_txnIdToString__lsid__txnNumber"_attr = txn::txnIdToString(_lsid, _txnNumber), "redact_status"_attr = redact(status));
 
     stdx::unique_lock<Latch> ul(_mutex);
 
@@ -413,7 +411,7 @@ void TransactionCoordinator::_done(Status status) {
 
 void TransactionCoordinator::_logSlowTwoPhaseCommit(
     const txn::CoordinatorCommitDecision& decision) {
-    log() << _twoPhaseCommitInfoForLog(decision);
+    LOGV2("{}", "_twoPhaseCommitInfoForLog_decision"_attr = _twoPhaseCommitInfoForLog(decision));
 }
 
 std::string TransactionCoordinator::_twoPhaseCommitInfoForLog(
diff --git a/src/mongo/db/s/transaction_coordinator_catalog.cpp b/src/mongo/db/s/transaction_coordinator_catalog.cpp
index fc0612515b..e8d3743f42 100644
--- a/src/mongo/db/s/transaction_coordinator_catalog.cpp
+++ b/src/mongo/db/s/transaction_coordinator_catalog.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/db/s/transaction_coordinator_catalog.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
 
@@ -46,7 +47,7 @@ TransactionCoordinatorCatalog::~TransactionCoordinatorCatalog() {
 
 void TransactionCoordinatorCatalog::exitStepUp(Status status) {
     if (status.isOK()) {
-        LOG(0) << "Incoming coordinateCommit requests are now enabled";
+        LOGV2("Incoming coordinateCommit requests are now enabled");
     } else {
         warning() << "Coordinator recovery failed and coordinateCommit requests will not be allowed"
                   << causedBy(status);
@@ -80,8 +81,7 @@ void TransactionCoordinatorCatalog::insert(OperationContext* opCtx,
                                            TxnNumber txnNumber,
                                            std::shared_ptr<TransactionCoordinator> coordinator,
                                            bool forStepUp) {
-    LOG(3) << "Inserting coordinator " << lsid.getId() << ':' << txnNumber
-           << " into in-memory catalog";
+    LOGV2_DEBUG(3, "Inserting coordinator {}:{} into in-memory catalog", "lsid_getId"_attr = lsid.getId(), "txnNumber"_attr = txnNumber);
 
     stdx::unique_lock<Latch> ul(_mutex);
     if (!forStepUp) {
@@ -153,8 +153,7 @@ TransactionCoordinatorCatalog::getLatestOnSession(OperationContext* opCtx,
 }
 
 void TransactionCoordinatorCatalog::_remove(const LogicalSessionId& lsid, TxnNumber txnNumber) {
-    LOG(3) << "Removing coordinator " << lsid.getId() << ':' << txnNumber
-           << " from in-memory catalog";
+    LOGV2_DEBUG(3, "Removing coordinator {}:{} from in-memory catalog", "lsid_getId"_attr = lsid.getId(), "txnNumber"_attr = txnNumber);
 
     stdx::lock_guard<Latch> lk(_mutex);
 
@@ -175,7 +174,7 @@ void TransactionCoordinatorCatalog::_remove(const LogicalSessionId& lsid, TxnNum
     }
 
     if (_coordinatorsBySession.empty()) {
-        LOG(3) << "Signaling last active coordinator removed";
+        LOGV2_DEBUG(3, "Signaling last active coordinator removed");
         _noActiveCoordinatorsCV.notify_all();
     }
 }
@@ -185,9 +184,8 @@ void TransactionCoordinatorCatalog::join() {
 
     while (!_noActiveCoordinatorsCV.wait_for(
         ul, stdx::chrono::seconds{5}, [this] { return _coordinatorsBySession.empty(); })) {
-        LOG(0) << "After 5 seconds of wait there are still " << _coordinatorsBySession.size()
-               << " sessions left with active coordinators which have not yet completed";
-        LOG(0) << _toString(ul);
+        LOGV2("After 5 seconds of wait there are still {} sessions left with active coordinators which have not yet completed", "_coordinatorsBySession_size"_attr = _coordinatorsBySession.size());
+        LOGV2("{}", "_toString_ul"_attr = _toString(ul));
     }
 }
 
diff --git a/src/mongo/db/s/transaction_coordinator_futures_util.cpp b/src/mongo/db/s/transaction_coordinator_futures_util.cpp
index 5f19b0eeb4..95feb50f87 100644
--- a/src/mongo/db/s/transaction_coordinator_futures_util.cpp
+++ b/src/mongo/db/s/transaction_coordinator_futures_util.cpp
@@ -36,6 +36,7 @@
 #include "mongo/client/remote_command_targeter.h"
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/s/sharding_state.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/grid.h"
 #include "mongo/transport/service_entry_point.h"
@@ -96,7 +97,7 @@ Future<executor::TaskExecutor::ResponseStatus> AsyncWorkScheduler::scheduleRemot
                 ->grantInternalAuthorization(opCtx->getClient());
 
             if (MONGO_unlikely(hangWhileTargetingLocalHost.shouldFail())) {
-                LOG(0) << "Hit hangWhileTargetingLocalHost failpoint";
+                LOGV2("Hit hangWhileTargetingLocalHost failpoint");
                 hangWhileTargetingLocalHost.pauseWhileSet(opCtx);
             }
 
@@ -232,7 +233,7 @@ Future<AsyncWorkScheduler::HostAndShard> AsyncWorkScheduler::_targetHostAsync(
         const auto shard = uassertStatusOK(shardRegistry->getShard(opCtx, shardId));
 
         if (MONGO_unlikely(hangWhileTargetingRemoteHost.shouldFail())) {
-            LOG(0) << "Hit hangWhileTargetingRemoteHost failpoint for shard " << shardId;
+            LOGV2("Hit hangWhileTargetingRemoteHost failpoint for shard {}", "shardId"_attr = shardId);
             hangWhileTargetingRemoteHost.pauseWhileSet(opCtx);
         }
 
diff --git a/src/mongo/db/s/transaction_coordinator_service.cpp b/src/mongo/db/s/transaction_coordinator_service.cpp
index 3ac1212a46..2be5602401 100644
--- a/src/mongo/db/s/transaction_coordinator_service.cpp
+++ b/src/mongo/db/s/transaction_coordinator_service.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/s/transaction_coordinator_document_gen.h"
 #include "mongo/db/transaction_participant_gen.h"
 #include "mongo/db/write_concern.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
 
@@ -184,8 +185,7 @@ void TransactionCoordinatorService::onStepUp(OperationContext* opCtx,
                     replClientInfo.setLastOpToSystemLastOpTime(opCtx);
 
                     const auto lastOpTime = replClientInfo.getLastOp();
-                    LOG(3) << "Waiting for OpTime " << lastOpTime
-                           << " to become majority committed";
+                    LOGV2_DEBUG(3, "Waiting for OpTime {} to become majority committed", "lastOpTime"_attr = lastOpTime);
 
                     WriteConcernResult unusedWCResult;
                     uassertStatusOK(waitForWriteConcern(
@@ -198,8 +198,7 @@ void TransactionCoordinatorService::onStepUp(OperationContext* opCtx,
 
                     auto coordinatorDocs = txn::readAllCoordinatorDocs(opCtx);
 
-                    LOG(0) << "Need to resume coordinating commit for " << coordinatorDocs.size()
-                           << " transactions";
+                    LOGV2("Need to resume coordinating commit for {} transactions", "coordinatorDocs_size"_attr = coordinatorDocs.size());
 
                     const auto service = opCtx->getServiceContext();
                     const auto clockSource = service->getFastClockSource();
@@ -208,7 +207,7 @@ void TransactionCoordinatorService::onStepUp(OperationContext* opCtx,
                     auto& scheduler = catalogAndScheduler->scheduler;
 
                     for (const auto& doc : coordinatorDocs) {
-                        LOG(3) << "Going to resume coordinating commit for " << doc.toBSON();
+                        LOGV2_DEBUG(3, "Going to resume coordinating commit for {}", "doc_toBSON"_attr = doc.toBSON());
 
                         const auto lsid = *doc.getId().getSessionId();
                         const auto txnNumber = *doc.getId().getTxnNumber();
@@ -274,7 +273,7 @@ void TransactionCoordinatorService::joinPreviousRound() {
     if (!_catalogAndSchedulerToCleanup)
         return;
 
-    LOG(0) << "Waiting for coordinator tasks from previous term to complete";
+    LOGV2("Waiting for coordinator tasks from previous term to complete");
 
     // Block until all coordinators scheduled the previous time the service was primary to have
     // drained. Because the scheduler was interrupted, it should be extremely rare for there to be
diff --git a/src/mongo/db/s/transaction_coordinator_test.cpp b/src/mongo/db/s/transaction_coordinator_test.cpp
index d21e4caf34..cf03ad1578 100644
--- a/src/mongo/db/s/transaction_coordinator_test.cpp
+++ b/src/mongo/db/s/transaction_coordinator_test.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/s/transaction_coordinator_document_gen.h"
 #include "mongo/db/s/transaction_coordinator_metrics_observer.h"
 #include "mongo/db/s/transaction_coordinator_test_fixture.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/clock_source_mock.h"
 #include "mongo/util/log.h"
@@ -1513,7 +1514,7 @@ TEST_F(TransactionCoordinatorMetricsTest, SimpleTwoPhaseCommitRealCoordinator) {
 
     checkMetrics(expectedMetrics);
 
-    log() << "Create the coordinator.";
+    LOGV2("Create the coordinator.");
 
     expectedStats.createTime = advanceClockSourceAndReturnNewNow();
     expectedStats.totalDuration = Microseconds(0);
@@ -1531,8 +1532,8 @@ TEST_F(TransactionCoordinatorMetricsTest, SimpleTwoPhaseCommitRealCoordinator) {
     checkStats(stats, expectedStats);
     checkMetrics(expectedMetrics);
 
-    log() << "Start two-phase commit (allow the coordinator to progress to writing the participant "
-             "list).";
+    LOGV2("Start two-phase commit (allow the coordinator to progress to writing the participant "
+             "list).");
 
     expectedStats.writingParticipantListStartTime = advanceClockSourceAndReturnNewNow();
     tickSource()->advance(Microseconds(100));
@@ -1552,7 +1553,7 @@ TEST_F(TransactionCoordinatorMetricsTest, SimpleTwoPhaseCommitRealCoordinator) {
     checkStats(stats, expectedStats);
     checkMetrics(expectedMetrics);
 
-    log() << "Allow the coordinator to progress to waiting for votes.";
+    LOGV2("Allow the coordinator to progress to waiting for votes.");
 
     expectedStats.waitingForVotesStartTime = advanceClockSourceAndReturnNewNow();
     tickSource()->advance(Microseconds(100));
@@ -1573,7 +1574,7 @@ TEST_F(TransactionCoordinatorMetricsTest, SimpleTwoPhaseCommitRealCoordinator) {
     checkStats(stats, expectedStats);
     checkMetrics(expectedMetrics);
 
-    log() << "Allow the coordinator to progress to writing the decision.";
+    LOGV2("Allow the coordinator to progress to writing the decision.");
 
     expectedStats.writingDecisionStartTime = advanceClockSourceAndReturnNewNow();
     tickSource()->advance(Microseconds(100));
@@ -1599,7 +1600,7 @@ TEST_F(TransactionCoordinatorMetricsTest, SimpleTwoPhaseCommitRealCoordinator) {
     checkStats(stats, expectedStats);
     checkMetrics(expectedMetrics);
 
-    log() << "Allow the coordinator to progress to waiting for acks.";
+    LOGV2("Allow the coordinator to progress to waiting for acks.");
 
     expectedStats.waitingForDecisionAcksStartTime = advanceClockSourceAndReturnNewNow();
     tickSource()->advance(Microseconds(100));
@@ -1623,7 +1624,7 @@ TEST_F(TransactionCoordinatorMetricsTest, SimpleTwoPhaseCommitRealCoordinator) {
     checkStats(stats, expectedStats);
     checkMetrics(expectedMetrics);
 
-    log() << "Allow the coordinator to progress to deleting the coordinator doc.";
+    LOGV2("Allow the coordinator to progress to deleting the coordinator doc.");
 
     expectedStats.deletingCoordinatorDocStartTime = advanceClockSourceAndReturnNewNow();
     tickSource()->advance(Microseconds(100));
@@ -1649,7 +1650,7 @@ TEST_F(TransactionCoordinatorMetricsTest, SimpleTwoPhaseCommitRealCoordinator) {
     checkStats(stats, expectedStats);
     checkMetrics(expectedMetrics);
 
-    log() << "Allow the coordinator to complete.";
+    LOGV2("Allow the coordinator to complete.");
 
     expectedStats.endTime = advanceClockSourceAndReturnNewNow();
     tickSource()->advance(Microseconds(100));
diff --git a/src/mongo/db/s/transaction_coordinator_util.cpp b/src/mongo/db/s/transaction_coordinator_util.cpp
index 7d98befd9d..95a36a22e7 100644
--- a/src/mongo/db/s/transaction_coordinator_util.cpp
+++ b/src/mongo/db/s/transaction_coordinator_util.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/s/transaction_coordinator_futures_util.h"
 #include "mongo/db/s/transaction_coordinator_worker_curop_repository.h"
 #include "mongo/db/write_concern.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -105,10 +106,10 @@ repl::OpTime persistParticipantListBlocking(OperationContext* opCtx,
                                             const LogicalSessionId& lsid,
                                             TxnNumber txnNumber,
                                             const std::vector<ShardId>& participantList) {
-    LOG(3) << txnIdToString(lsid, txnNumber) << " Going to write participant list";
+    LOGV2_DEBUG(3, "{} Going to write participant list", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber));
 
     if (MONGO_unlikely(hangBeforeWritingParticipantList.shouldFail())) {
-        LOG(0) << "Hit hangBeforeWritingParticipantList failpoint";
+        LOGV2("Hit hangBeforeWritingParticipantList failpoint");
         hangBeforeWritingParticipantList.pauseWhileSet(opCtx);
     }
 
@@ -167,7 +168,7 @@ repl::OpTime persistParticipantListBlocking(OperationContext* opCtx,
     // Throw any other error.
     uassertStatusOK(upsertStatus);
 
-    LOG(3) << txnIdToString(lsid, txnNumber) << " Wrote participant list";
+    LOGV2_DEBUG(3, "{} Wrote participant list", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber));
 
     return repl::ReplClientInfo::forClient(opCtx->getClient()).getLastOp();
 }
@@ -240,7 +241,7 @@ Future<PrepareVoteConsensus> sendPrepare(ServiceContext* service,
             opCtx, lsid, txnNumber, CoordinatorAction::kSendingPrepare);
 
         if (MONGO_unlikely(hangBeforeSendingPrepare.shouldFail())) {
-            LOG(0) << "Hit hangBeforeSendingPrepare failpoint";
+            LOGV2("Hit hangBeforeSendingPrepare failpoint");
             hangBeforeSendingPrepare.pauseWhileSet(opCtx);
         }
     };
@@ -289,11 +290,10 @@ repl::OpTime persistDecisionBlocking(OperationContext* opCtx,
                                      const std::vector<ShardId>& participantList,
                                      const txn::CoordinatorCommitDecision& decision) {
     const bool isCommit = decision.getDecision() == txn::CommitDecision::kCommit;
-    LOG(3) << txnIdToString(lsid, txnNumber) << " Going to write decision "
-           << (isCommit ? "commit" : "abort");
+    LOGV2_DEBUG(3, "{} Going to write decision {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "isCommit_commit_abort"_attr = (isCommit ? "commit" : "abort"));
 
     if (MONGO_unlikely(hangBeforeWritingDecision.shouldFail())) {
-        LOG(0) << "Hit hangBeforeWritingDecision failpoint";
+        LOGV2("Hit hangBeforeWritingDecision failpoint");
         hangBeforeWritingDecision.pauseWhileSet(opCtx);
     }
 
@@ -357,8 +357,7 @@ repl::OpTime persistDecisionBlocking(OperationContext* opCtx,
                                 << doc);
     }
 
-    LOG(3) << txnIdToString(lsid, txnNumber) << " Wrote decision "
-           << (isCommit ? "commit" : "abort");
+    LOGV2_DEBUG(3, "{} Wrote decision {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "isCommit_commit_abort"_attr = (isCommit ? "commit" : "abort"));
 
     return repl::ReplClientInfo::forClient(opCtx->getClient()).getLastOp();
 }
@@ -402,7 +401,7 @@ Future<void> sendCommit(ServiceContext* service,
             opCtx, lsid, txnNumber, CoordinatorAction::kSendingCommit);
 
         if (MONGO_unlikely(hangBeforeSendingCommit.shouldFail())) {
-            LOG(0) << "Hit hangBeforeSendingCommit failpoint";
+            LOGV2("Hit hangBeforeSendingCommit failpoint");
             hangBeforeSendingCommit.pauseWhileSet(opCtx);
         }
     };
@@ -432,7 +431,7 @@ Future<void> sendAbort(ServiceContext* service,
             opCtx, lsid, txnNumber, CoordinatorAction::kSendingAbort);
 
         if (MONGO_unlikely(hangBeforeSendingAbort.shouldFail())) {
-            LOG(0) << "Hit hangBeforeSendingAbort failpoint";
+            LOGV2("Hit hangBeforeSendingAbort failpoint");
             hangBeforeSendingAbort.pauseWhileSet(opCtx);
         }
     };
@@ -449,10 +448,10 @@ namespace {
 void deleteCoordinatorDocBlocking(OperationContext* opCtx,
                                   const LogicalSessionId& lsid,
                                   TxnNumber txnNumber) {
-    LOG(3) << txnIdToString(lsid, txnNumber) << " Going to delete coordinator doc";
+    LOGV2_DEBUG(3, "{} Going to delete coordinator doc", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber));
 
     if (MONGO_unlikely(hangBeforeDeletingCoordinatorDoc.shouldFail())) {
-        LOG(0) << "Hit hangBeforeDeletingCoordinatorDoc failpoint";
+        LOGV2("Hit hangBeforeDeletingCoordinatorDoc failpoint");
         hangBeforeDeletingCoordinatorDoc.pauseWhileSet(opCtx);
     }
 
@@ -504,10 +503,10 @@ void deleteCoordinatorDocBlocking(OperationContext* opCtx,
                                 << doc);
     }
 
-    LOG(3) << txnIdToString(lsid, txnNumber) << " Deleted coordinator doc";
+    LOGV2_DEBUG(3, "{} Deleted coordinator doc", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber));
 
     hangAfterDeletingCoordinatorDoc.execute([&](const BSONObj& data) {
-        LOG(0) << "Hit hangAfterDeletingCoordinatorDoc failpoint";
+        LOGV2("Hit hangAfterDeletingCoordinatorDoc failpoint");
         if (!data["useUninterruptibleSleep"].eoo()) {
             hangAfterDeletingCoordinatorDoc.pauseWhileSet();
         } else {
@@ -576,8 +575,7 @@ Future<PrepareResponse> sendPrepareToShard(ServiceContext* service,
          isLocalShard,
          commandObj = commandObj.getOwned(),
          operationContextFn] {
-            LOG(3) << txnIdToString(lsid, txnNumber) << " Coordinator going to send command "
-                   << commandObj << " to " << (isLocalShard ? "local " : "") << "shard " << shardId;
+            LOGV2_DEBUG(3, "{} Coordinator going to send command {} to {}shard {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "commandObj"_attr = commandObj, "isLocalShard_local"_attr = (isLocalShard ? "local " : ""), "shardId"_attr = shardId);
 
             return scheduler
                 .scheduleRemoteCommand(
@@ -605,16 +603,13 @@ Future<PrepareResponse> sendPrepareToShard(ServiceContext* service,
                                                    << shardId
                                                    << ", which is not an expected behavior. "
                                                       "Interpreting the response as vote to abort");
-                            LOG(0) << txnIdToString(lsid, txnNumber) << " " << redact(abortStatus);
+                            LOGV2("{} {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "redact_abortStatus"_attr = redact(abortStatus));
 
                             return PrepareResponse{
                                 shardId, PrepareVote::kAbort, boost::none, abortStatus};
                         }
 
-                        LOG(3) << txnIdToString(lsid, txnNumber)
-                               << " Coordinator shard received a vote to commit from shard "
-                               << shardId
-                               << " with prepareTimestamp: " << prepareTimestampField.timestamp();
+                        LOGV2_DEBUG(3, "{} Coordinator shard received a vote to commit from shard {} with prepareTimestamp: {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "shardId"_attr = shardId, "prepareTimestampField_timestamp"_attr = prepareTimestampField.timestamp());
 
                         return PrepareResponse{shardId,
                                                PrepareVote::kCommit,
@@ -622,8 +617,7 @@ Future<PrepareResponse> sendPrepareToShard(ServiceContext* service,
                                                boost::none};
                     }
 
-                    LOG(3) << txnIdToString(lsid, txnNumber) << " Coordinator shard received "
-                           << status << " from shard " << shardId << " for " << commandObj;
+                    LOGV2_DEBUG(3, "{} Coordinator shard received {} from shard {} for {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "status"_attr = status, "shardId"_attr = shardId, "commandObj"_attr = commandObj);
 
                     if (ErrorCodes::isVoteAbortError(status.code())) {
                         return PrepareResponse{
@@ -652,8 +646,7 @@ Future<PrepareResponse> sendPrepareToShard(ServiceContext* service,
 
     return std::move(f).onError<ErrorCodes::TransactionCoordinatorReachedAbortDecision>(
         [lsid, txnNumber, shardId](const Status& status) {
-            LOG(3) << txnIdToString(lsid, txnNumber)
-                   << " Prepare stopped retrying due to retrying being cancelled";
+            LOGV2_DEBUG(3, "{} Prepare stopped retrying due to retrying being cancelled", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber));
             return PrepareResponse{shardId, boost::none, boost::none, status};
         });
 }
@@ -682,8 +675,7 @@ Future<void> sendDecisionToShard(ServiceContext* service,
          isLocalShard,
          operationContextFn,
          commandObj = commandObj.getOwned()] {
-            LOG(3) << txnIdToString(lsid, txnNumber) << " Coordinator going to send command "
-                   << commandObj << " to " << (isLocalShard ? "local " : "") << "shard " << shardId;
+            LOGV2_DEBUG(3, "{} Coordinator going to send command {} to {}shard {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "commandObj"_attr = commandObj, "isLocalShard_local"_attr = (isLocalShard ? "local " : ""), "shardId"_attr = shardId);
 
             return scheduler
                 .scheduleRemoteCommand(
@@ -699,9 +691,7 @@ Future<void> sendDecisionToShard(ServiceContext* service,
                         status = wcStatus;
                     }
 
-                    LOG(3) << txnIdToString(lsid, txnNumber) << " Coordinator shard received "
-                           << status << " in response to " << commandObj << " from shard "
-                           << shardId;
+                    LOGV2_DEBUG(3, "{} Coordinator shard received {} in response to {} from shard {}", "txnIdToString_lsid_txnNumber"_attr = txnIdToString(lsid, txnNumber), "status"_attr = status, "commandObj"_attr = commandObj, "shardId"_attr = shardId);
 
                     if (ErrorCodes::isVoteAbortError(status.code())) {
                         // Interpret voteAbort errors as an ack.
diff --git a/src/mongo/db/s/txn_two_phase_commit_cmds.cpp b/src/mongo/db/s/txn_two_phase_commit_cmds.cpp
index 21293128b5..db30402388 100644
--- a/src/mongo/db/s/txn_two_phase_commit_cmds.cpp
+++ b/src/mongo/db/s/txn_two_phase_commit_cmds.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/s/transaction_coordinator_service.h"
 #include "mongo/db/session_catalog_mongod.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/util/log.h"
 
@@ -99,10 +100,7 @@ public:
                     "prepareTransaction must be run within a transaction",
                     txnParticipant);
 
-            LOG(3)
-                << "Participant shard received prepareTransaction for transaction with txnNumber "
-                << opCtx->getTxnNumber() << " on session "
-                << opCtx->getLogicalSessionId()->toBSON();
+            LOGV2_DEBUG(3, "Participant shard received prepareTransaction for transaction with txnNumber {} on session {}", "opCtx_getTxnNumber"_attr = opCtx->getTxnNumber(), "opCtx_getLogicalSessionId_toBSON"_attr = opCtx->getLogicalSessionId()->toBSON());
 
             uassert(ErrorCodes::NoSuchTransaction,
                     "Transaction isn't in progress",
@@ -200,10 +198,8 @@ std::set<ShardId> validateParticipants(OperationContext* opCtx,
     }
     ss << ']';
 
-    LOG(3) << "Coordinator shard received request to coordinate commit with "
-              "participant list "
-           << ss.str() << " for " << opCtx->getLogicalSessionId()->getId() << ':'
-           << opCtx->getTxnNumber();
+    LOGV2_DEBUG(3, "Coordinator shard received request to coordinate commit with "
+              "participant list {} for {}:{}", "ss_str"_attr = ss.str(), "opCtx_getLogicalSessionId_getId"_attr = opCtx->getLogicalSessionId()->getId(), "opCtx_getTxnNumber"_attr = opCtx->getTxnNumber());
 
     return participantsSet;
 }
@@ -235,7 +231,7 @@ public:
                                         validateParticipants(opCtx, cmd.getParticipants()));
 
             if (MONGO_unlikely(hangAfterStartingCoordinateCommit.shouldFail())) {
-                LOG(0) << "Hit hangAfterStartingCoordinateCommit failpoint";
+                LOGV2("Hit hangAfterStartingCoordinateCommit failpoint");
                 hangAfterStartingCoordinateCommit.pauseWhileSet(opCtx);
             }
 
@@ -275,8 +271,7 @@ public:
 
             // No coordinator was found in memory. Recover the decision from the local participant.
 
-            LOG(3) << "Going to recover decision from local participant for "
-                   << opCtx->getLogicalSessionId()->getId() << ':' << opCtx->getTxnNumber();
+            LOGV2_DEBUG(3, "Going to recover decision from local participant for {}:{}", "opCtx_getLogicalSessionId_getId"_attr = opCtx->getLogicalSessionId()->getId(), "opCtx_getTxnNumber"_attr = opCtx->getTxnNumber());
 
             boost::optional<SharedSemiFuture<void>> participantExitPrepareFuture;
             {
diff --git a/src/mongo/db/s/wait_for_majority_service.cpp b/src/mongo/db/s/wait_for_majority_service.cpp
index 1864335150..8ea3b1807d 100644
--- a/src/mongo/db/s/wait_for_majority_service.cpp
+++ b/src/mongo/db/s/wait_for_majority_service.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/write_concern.h"
 #include "mongo/executor/network_interface_factory.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/concurrency/thread_pool.h"
 #include "mongo/util/log.h"
 
@@ -184,7 +185,7 @@ void WaitForMajorityService::_periodicallyWaitForMajority(ServiceContext* servic
             _opCtx->waitForConditionOrInterrupt(
                 _hasNewOpTimeCV, lk, [&] { return !_queuedOpTimes.empty() || _inShutDown; });
         } catch (const DBException& e) {
-            LOG(1) << "Unable to wait for new op time due to: " << e;
+            LOGV2_DEBUG(1, "Unable to wait for new op time due to: {}", "e"_attr = e);
         }
 
         _opCtx = nullptr;
diff --git a/src/mongo/db/server_options_server_helpers.cpp b/src/mongo/db/server_options_server_helpers.cpp
index 4cf1a4164d..8dee872521 100644
--- a/src/mongo/db/server_options_server_helpers.cpp
+++ b/src/mongo/db/server_options_server_helpers.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/server_options_helpers.h"
 #include "mongo/logger/log_component.h"
 #include "mongo/logger/message_event_utf8_encoder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/message_compressor_registry.h"
 #include "mongo/util/cmdline_utils/censor_cmdline.h"
 #include "mongo/util/fail_point.h"
@@ -114,7 +115,7 @@ Status setParsedOpts(const moe::Environment& params) {
 }  // namespace
 
 void printCommandLineOpts() {
-    log() << "options: " << serverGlobalParams.parsedOpts << endl;
+    LOGV2("options: {}", "serverGlobalParams_parsedOpts"_attr = serverGlobalParams.parsedOpts);
 }
 
 Status validateServerOptions(const moe::Environment& params) {
diff --git a/src/mongo/db/service_entry_point_common.cpp b/src/mongo/db/service_entry_point_common.cpp
index ea792fa18a..45cd21ba05 100644
--- a/src/mongo/db/service_entry_point_common.cpp
+++ b/src/mongo/db/service_entry_point_common.cpp
@@ -81,6 +81,7 @@
 #include "mongo/db/stats/top.h"
 #include "mongo/db/transaction_participant.h"
 #include "mongo/db/transaction_validation.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/factory.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/message.h"
@@ -125,14 +126,11 @@ void generateLegacyQueryErrorResponse(const AssertionException& exception,
                                       Message* response) {
     curop->debug().errInfo = exception.toStatus();
 
-    log(LogComponent::kQuery) << "assertion " << exception.toString() << " ns:" << queryMessage.ns
-                              << " query:"
-                              << (queryMessage.query.valid(BSONVersion::kLatest)
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kQuery).toInt(), "assertion {} ns:{} query:{}", "exception_toString"_attr = exception.toString(), "queryMessage_ns"_attr = queryMessage.ns, "queryMessage_query_valid_BSONVersion_kLatest_redact_queryMessage_query_query_object_is_corrupt"_attr = (queryMessage.query.valid(BSONVersion::kLatest)
                                       ? redact(queryMessage.query)
-                                      : "query object is corrupt");
+                                      : "query object is corrupt"));
     if (queryMessage.ntoskip || queryMessage.ntoreturn) {
-        log(LogComponent::kQuery) << " ntoskip:" << queryMessage.ntoskip
-                                  << " ntoreturn:" << queryMessage.ntoreturn;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kQuery).toInt(), " ntoskip:{} ntoreturn:{}", "queryMessage_ntoskip"_attr = queryMessage.ntoskip, "queryMessage_ntoreturn"_attr = queryMessage.ntoreturn);
     }
 
     BSONObjBuilder err;
@@ -147,8 +145,7 @@ void generateLegacyQueryErrorResponse(const AssertionException& exception,
 
     const bool isStaleConfig = exception.code() == ErrorCodes::StaleConfig;
     if (isStaleConfig) {
-        log(LogComponent::kQuery) << "stale version detected during query over " << queryMessage.ns
-                                  << " : " << errObj;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kQuery).toInt(), "stale version detected during query over {} : {}", "queryMessage_ns"_attr = queryMessage.ns, "errObj"_attr = errObj);
     }
 
     BufBuilder bb;
@@ -251,7 +248,7 @@ StatusWith<repl::ReadConcernArgs> _extractReadConcern(OperationContext* opCtx,
             // shard/config server.
             if (!readConcernArgs.isSpecified()) {
                 // TODO: Disabled until after SERVER-44539, to avoid log spam.
-                // log() << "Missing readConcern on " << invocation->definition()->getName();
+                // LOGV2("Missing readConcern on {}", "invocation_definition_getName"_attr = invocation->definition()->getName());
             }
         } else {
             // A member in a regular replica set.  Since these servers receive client queries, in
@@ -263,8 +260,7 @@ StatusWith<repl::ReadConcernArgs> _extractReadConcern(OperationContext* opCtx,
                                            .getDefaultReadConcern(opCtx);
                 if (rcDefault) {
                     readConcernArgs = std::move(*rcDefault);
-                    LOG(2) << "Applying default readConcern on "
-                           << invocation->definition()->getName() << " of " << *rcDefault;
+                    LOGV2_DEBUG(2, "Applying default readConcern on {} of {}", "invocation_definition_getName"_attr = invocation->definition()->getName(), "rcDefault"_attr = *rcDefault);
                     // Update the readConcernSupport, since the default RC was applied.
                     readConcernSupport =
                         invocation->supportsReadConcern(readConcernArgs.getLevel());
@@ -350,7 +346,7 @@ LogicalTime computeOperationTime(OperationContext* opCtx, LogicalTime startOpera
     invariant(isReplSet);
 
     if (startOperationTime == LogicalTime::kUninitialized) {
-        LOG(5) << "startOperationTime is uninitialized";
+        LOGV2_DEBUG(5, "startOperationTime is uninitialized");
         return LogicalTime(replCoord->getMyLastAppliedOpTime().getTimestamp());
     }
 
@@ -399,8 +395,7 @@ void appendClusterAndOperationTime(OperationContext* opCtx,
         dassert(signedTime.getTime() >= operationTime);
         rpc::LogicalTimeMetadata(signedTime).writeToMetadata(metadataBob);
 
-        LOG(5) << "Appending operationTime to cmd response for authorized client: "
-               << operationTime;
+        LOGV2_DEBUG(5, "Appending operationTime to cmd response for authorized client: {}", "operationTime"_attr = operationTime);
         operationTime.appendAsOperationTime(commandBodyFieldsBob);
 
         return;
@@ -424,7 +419,7 @@ void appendClusterAndOperationTime(OperationContext* opCtx,
     dassert(signedTime.getTime() >= operationTime);
     rpc::LogicalTimeMetadata(signedTime).writeToMetadata(metadataBob);
 
-    LOG(5) << "Appending operationTime to cmd response: " << operationTime;
+    LOGV2_DEBUG(5, "Appending operationTime to cmd response: {}", "operationTime"_attr = operationTime);
     operationTime.appendAsOperationTime(commandBodyFieldsBob);
 }
 
@@ -617,7 +612,7 @@ bool runCommandImpl(OperationContext* opCtx,
                  serverGlobalParams.clusterRole == ClusterRole::ConfigServer) &&
                 !request.body.hasField(WriteConcernOptions::kWriteConcernField)) {
                 // TODO: Disabled until after SERVER-43712, to avoid log spam.
-                // log() << "Missing writeConcern on " << command->getName();
+                // LOGV2("Missing writeConcern on {}", "command_getName"_attr = command->getName());
             }
             extractedWriteConcern.emplace(
                 uassertStatusOK(extractWriteConcern(opCtx, request.body)));
@@ -894,7 +889,7 @@ void execCommandDatabase(OperationContext* opCtx,
         }
 
         if (command->adminOnly()) {
-            LOG(2) << "command: " << request.getCommandName();
+            LOGV2_DEBUG(2, "command: {}", "request_getCommandName"_attr = request.getCommandName());
         }
 
         if (command->maintenanceMode()) {
@@ -1063,11 +1058,7 @@ void execCommandDatabase(OperationContext* opCtx,
         }
         appendClusterAndOperationTime(opCtx, &extraFieldsBuilder, &metadataBob, startOperationTime);
 
-        LOG(1) << "assertion while executing command '" << request.getCommandName() << "' "
-               << "on database '" << request.getDatabase() << "' "
-               << "with arguments '"
-               << redact(ServiceEntryPointCommon::getRedactedCopyForLogging(command, request.body))
-               << "': " << redact(e.toString());
+        LOGV2_DEBUG(1, "assertion while executing command '{}' on database '{}' with arguments '{}': {}", "request_getCommandName"_attr = request.getCommandName(), "request_getDatabase"_attr = request.getDatabase(), "redact_ServiceEntryPointCommon_getRedactedCopyForLogging_command_request_body"_attr = redact(ServiceEntryPointCommon::getRedactedCopyForLogging(command, request.body)), "redact_e_toString"_attr = redact(e.toString()));
 
         generateErrorResponse(opCtx, replyBuilder, e, metadataBob.obj(), extraFieldsBuilder.obj());
     }
@@ -1113,7 +1104,7 @@ DbResponse receivedCommands(OperationContext* opCtx,
             // Otherwise, reply with the parse error. This is useful for cases where parsing fails
             // due to user-supplied input, such as the document too deep error. Since we failed
             // during parsing, we can't log anything about the command.
-            LOG(1) << "assertion while parsing command: " << ex.toString();
+            LOGV2_DEBUG(1, "assertion while parsing command: {}", "ex_toString"_attr = ex.toString());
 
             generateErrorResponse(
                 opCtx, replyBuilder.get(), ex, metadataBob.obj(), extraFieldsBuilder.obj());
@@ -1133,12 +1124,11 @@ DbResponse receivedCommands(OperationContext* opCtx,
                 globalCommandRegistry()->incrementUnknownCommands();
                 std::string msg = str::stream()
                     << "no such command: '" << request.getCommandName() << "'";
-                LOG(2) << msg;
+                LOGV2_DEBUG(2, "{}", "msg"_attr = msg);
                 uasserted(ErrorCodes::CommandNotFound, str::stream() << msg);
             }
 
-            LOG(2) << "run command " << request.getDatabase() << ".$cmd" << ' '
-                   << redact(ServiceEntryPointCommon::getRedactedCopyForLogging(c, request.body));
+            LOGV2_DEBUG(2, "run command {}.$cmd {}", "request_getDatabase"_attr = request.getDatabase(), "redact_ServiceEntryPointCommon_getRedactedCopyForLogging_c_request_body"_attr = redact(ServiceEntryPointCommon::getRedactedCopyForLogging(c, request.body)));
 
             {
                 // Try to set this as early as possible, as soon as we have figured out the command.
@@ -1157,8 +1147,7 @@ DbResponse receivedCommands(OperationContext* opCtx,
             appendClusterAndOperationTime(
                 opCtx, &extraFieldsBuilder, &metadataBob, LogicalTime::kUninitialized);
 
-            LOG(1) << "assertion while executing command '" << request.getCommandName() << "' "
-                   << "on database '" << request.getDatabase() << "': " << ex.toString();
+            LOGV2_DEBUG(1, "assertion while executing command '{}' on database '{}': {}", "request_getCommandName"_attr = request.getCommandName(), "request_getDatabase"_attr = request.getDatabase(), "ex_toString"_attr = ex.toString());
 
             generateErrorResponse(
                 opCtx, replyBuilder.get(), ex, metadataBob.obj(), extraFieldsBuilder.obj());
@@ -1252,7 +1241,7 @@ void receivedKillCursors(OperationContext* opCtx, const Message& m) {
     int found = runOpKillCursors(opCtx, static_cast<size_t>(n), cursorArray);
 
     if (shouldLog(logger::LogSeverity::Debug(1)) || found != n) {
-        LOG(found == n ? 1 : 0) << "killcursors: found " << found << " of " << n;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(found == n ? 1 : 0).toInt(), "killcursors: found {} of {}", "found"_attr = found, "n"_attr = n);
     }
 }
 
@@ -1467,7 +1456,7 @@ DbResponse ServiceEntryPointCommon::handleRequest(OperationContext* opCtx,
                 slowMsOverride = 10;
                 receivedKillCursors(opCtx, m);
             } else if (op != dbInsert && op != dbUpdate && op != dbDelete) {
-                log() << "    operation isn't supported: " << static_cast<int>(op);
+                LOGV2("    operation isn't supported: {}", "static_cast_int_op"_attr = static_cast<int>(op));
                 currentOp.done();
                 forceLog = true;
             } else {
@@ -1493,8 +1482,7 @@ DbResponse ServiceEntryPointCommon::handleRequest(OperationContext* opCtx,
             }
         } catch (const AssertionException& ue) {
             LastError::get(c).setLastError(ue.code(), ue.reason());
-            LOG(3) << " Caught Assertion in " << networkOpToString(op) << ", continuing "
-                   << redact(ue);
+            LOGV2_DEBUG(3, " Caught Assertion in {}, continuing {}", "networkOpToString_op"_attr = networkOpToString(op), "redact_ue"_attr = redact(ue));
             debug.errInfo = ue.toStatus();
         }
         // A NotMaster error can be set either within receivedInsert/receivedUpdate/receivedDelete
@@ -1524,15 +1512,15 @@ DbResponse ServiceEntryPointCommon::handleRequest(OperationContext* opCtx,
     if (currentOp.shouldDBProfile(shouldSample)) {
         // Performance profiling is on
         if (opCtx->lockState()->isReadLocked()) {
-            LOG(1) << "note: not profiling because recursive read lock";
+            LOGV2_DEBUG(1, "note: not profiling because recursive read lock");
         } else if (c.isInDirectClient()) {
-            LOG(1) << "note: not profiling because we are in DBDirectClient";
+            LOGV2_DEBUG(1, "note: not profiling because we are in DBDirectClient");
         } else if (behaviors.lockedForWriting()) {
             // TODO SERVER-26825: Fix race condition where fsyncLock is acquired post
             // lockedForWriting() call but prior to profile collection lock acquisition.
-            LOG(1) << "note: not profiling because doing fsync+lock";
+            LOGV2_DEBUG(1, "note: not profiling because doing fsync+lock");
         } else if (storageGlobalParams.readOnly) {
-            LOG(1) << "note: not profiling because server is read-only";
+            LOGV2_DEBUG(1, "note: not profiling because server is read-only");
         } else {
             invariant(!opCtx->lockState()->inAWriteUnitOfWork());
             profile(opCtx, op);
diff --git a/src/mongo/db/service_entry_point_mongod.cpp b/src/mongo/db/service_entry_point_mongod.cpp
index 178b912a9f..1943d1ea88 100644
--- a/src/mongo/db/service_entry_point_mongod.cpp
+++ b/src/mongo/db/service_entry_point_mongod.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/s/sharding_state.h"
 #include "mongo/db/service_entry_point_common.h"
 #include "mongo/logger/redaction.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/config_server_metadata.h"
 #include "mongo/rpc/metadata/sharding_metadata.h"
@@ -84,11 +85,8 @@ public:
             if (ErrorCodes::isExceededTimeLimitError(rcStatus.code())) {
                 const int debugLevel =
                     serverGlobalParams.clusterRole == ClusterRole::ConfigServer ? 0 : 2;
-                LOG(debugLevel) << "Command on database " << request.getDatabase()
-                                << " timed out waiting for read concern to be satisfied. Command: "
-                                << redact(ServiceEntryPointCommon::getRedactedCopyForLogging(
-                                       invocation->definition(), request.body))
-                                << ". Info: " << redact(rcStatus);
+                LOGV2_DEBUG(::mongo::logger::LogSeverity(debugLevel).toInt(), "Command on database {} timed out waiting for read concern to be satisfied. Command: {}. Info: {}", "request_getDatabase"_attr = request.getDatabase(), "redact_ServiceEntryPointCommon_getRedactedCopyForLogging_invocation_definition_request_body"_attr = redact(ServiceEntryPointCommon::getRedactedCopyForLogging(
+                                       invocation->definition(), request.body)), "redact_rcStatus"_attr = redact(rcStatus));
             }
 
             uassertStatusOK(rcStatus);
diff --git a/src/mongo/db/session_catalog.cpp b/src/mongo/db/session_catalog.cpp
index 97fbff47f8..d6f9d5075b 100644
--- a/src/mongo/db/session_catalog.cpp
+++ b/src/mongo/db/session_catalog.cpp
@@ -36,6 +36,7 @@
 #include <memory>
 
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -153,7 +154,7 @@ void SessionCatalog::scanSessions(const SessionKiller::Matcher& matcher,
     {
         stdx::lock_guard<Latch> lg(_mutex);
 
-        LOG(2) << "Beginning scanSessions. Scanning " << _sessions.size() << " sessions.";
+        LOGV2_DEBUG(2, "Beginning scanSessions. Scanning {} sessions.", "_sessions_size"_attr = _sessions.size());
 
         for (auto it = _sessions.begin(); it != _sessions.end(); ++it) {
             if (matcher.match(it->first)) {
diff --git a/src/mongo/db/session_catalog_mongod.cpp b/src/mongo/db/session_catalog_mongod.cpp
index 9094e585b3..32881b03de 100644
--- a/src/mongo/db/session_catalog_mongod.cpp
+++ b/src/mongo/db/session_catalog_mongod.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/session_txn_record_gen.h"
 #include "mongo/db/sessions_collection.h"
 #include "mongo/db/transaction_participant.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/write_ops/batched_command_response.h"
 #include "mongo/util/concurrency/thread_pool.h"
@@ -195,7 +196,7 @@ void abortInProgressTransactions(OperationContext* opCtx) {
                      << DurableTxnState_serializer(DurableTxnStateEnum::kInProgress)));
     auto cursor = client.query(NamespaceString::kSessionTransactionsTableNamespace, query);
     if (cursor->more()) {
-        LOG(3) << "Aborting in-progress transactions on stepup.";
+        LOGV2_DEBUG(3, "Aborting in-progress transactions on stepup.");
     }
     while (cursor->more()) {
         auto txnRecord = SessionTxnRecord::parse(
@@ -205,8 +206,7 @@ void abortInProgressTransactions(OperationContext* opCtx) {
         opCtx->setInMultiDocumentTransaction();
         MongoDOperationContextSessionWithoutRefresh ocs(opCtx);
         auto txnParticipant = TransactionParticipant::get(opCtx);
-        LOG(3) << "Aborting transaction sessionId: " << txnRecord.getSessionId().toBSON()
-               << " txnNumber " << txnRecord.getTxnNum();
+        LOGV2_DEBUG(3, "Aborting transaction sessionId: {} txnNumber {}", "txnRecord_getSessionId_toBSON"_attr = txnRecord.getSessionId().toBSON(), "txnRecord_getTxnNum"_attr = txnRecord.getTxnNum());
         txnParticipant.abortTransaction(opCtx);
     }
 }
@@ -248,8 +248,7 @@ void MongoDSessionCatalog::onStepUp(OperationContext* opCtx) {
             newOpCtx->setLogicalSessionId(sessionId);
             MongoDOperationContextSession ocs(newOpCtx.get());
             auto txnParticipant = TransactionParticipant::get(newOpCtx.get());
-            LOG(3) << "Restoring locks of prepared transaction. SessionId: " << sessionId.getId()
-                   << " TxnNumber: " << txnParticipant.getActiveTxnNumber();
+            LOGV2_DEBUG(3, "Restoring locks of prepared transaction. SessionId: {} TxnNumber: {}", "sessionId_getId"_attr = sessionId.getId(), "txnParticipant_getActiveTxnNumber"_attr = txnParticipant.getActiveTxnNumber());
             txnParticipant.refreshLocksForPreparedTransaction(newOpCtx.get(), false);
         }
     }
diff --git a/src/mongo/db/sorter/sorter_test.cpp b/src/mongo/db/sorter/sorter_test.cpp
index e8c534db10..f790ec76ca 100644
--- a/src/mongo/db/sorter/sorter_test.cpp
+++ b/src/mongo/db/sorter/sorter_test.cpp
@@ -66,6 +66,7 @@ std::string nextFileName() {
 
 // Need access to internal classes
 #include "mongo/db/sorter/sorter.cpp"
+#include "mongo/logv2/log.h"
 
 namespace mongo {
 
@@ -204,8 +205,7 @@ void _assertIteratorsEquivalent(It1 it1, It2 it2, int line) {
         it1->closeSource();
         it2->closeSource();
     } catch (...) {
-        mongo::unittest::log() << "Failure from line " << line << " on iteration " << iteration
-                               << std::endl;
+        mongo::unittest::LOGV2("Failure from line {} on iteration {}", "line"_attr = line, "iteration"_attr = iteration);
         it1->closeSource();
         it2->closeSource();
         throw;
diff --git a/src/mongo/db/startup_warnings_common.cpp b/src/mongo/db/startup_warnings_common.cpp
index 099df94cea..4b6262e8fa 100644
--- a/src/mongo/db/startup_warnings_common.cpp
+++ b/src/mongo/db/startup_warnings_common.cpp
@@ -39,6 +39,7 @@
 #include "mongo/client/authenticate.h"
 #include "mongo/config.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/ssl_options.h"
 #include "mongo/util/processinfo.h"
@@ -56,46 +57,40 @@ void logCommonStartupWarnings(const ServerGlobalParams& serverParams) {
     {
         auto&& vii = VersionInfoInterface::instance();
         if ((vii.minorVersion() % 2) != 0) {
-            log() << startupWarningsLog;
-            log() << "** NOTE: This is a development version (" << vii.version() << ") of MongoDB."
-                  << startupWarningsLog;
-            log() << "**       Not recommended for production." << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** NOTE: This is a development version ({}) of MongoDB.", "vii_version"_attr = vii.version());
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**       Not recommended for production.");
             warned = true;
         }
     }
 
     if (serverParams.authState == ServerGlobalParams::AuthState::kUndefined) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: Access control is not enabled for the database."
-              << startupWarningsLog;
-        log() << "**          Read and write access to data and configuration is "
-                 "unrestricted."
-              << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: Access control is not enabled for the database.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          Read and write access to data and configuration is "
+                 "unrestricted.");
         warned = true;
     }
 
     const bool is32bit = sizeof(int*) == 4;
     if (is32bit) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: This 32-bit MongoDB binary is deprecated" << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: This 32-bit MongoDB binary is deprecated");
         warned = true;
     }
 
 #ifdef MONGO_CONFIG_SSL
     if (sslGlobalParams.sslAllowInvalidCertificates) {
-        log() << "** WARNING: While invalid X509 certificates may be used to" << startupWarningsLog;
-        log() << "**          connect to this server, they will not be considered"
-              << startupWarningsLog;
-        log() << "**          permissible for authentication." << startupWarningsLog;
-        log() << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: While invalid X509 certificates may be used to");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          connect to this server, they will not be considered");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          permissible for authentication.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
     }
 
     if (sslGlobalParams.sslAllowInvalidHostnames) {
-        log() << "** WARNING: This server will not perform X.509 hostname validation"
-              << startupWarningsLog;
-        log() << "** This may allow your server to make or accept connections to"
-              << startupWarningsLog;
-        log() << "** untrusted parties" << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: This server will not perform X.509 hostname validation");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** This may allow your server to make or accept connections to");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** untrusted parties");
     }
 #endif
 
@@ -108,13 +103,13 @@ void logCommonStartupWarnings(const ServerGlobalParams& serverParams) {
         sslGlobalParams.sslCertificateSelector.empty() &&
 #endif
         sslGlobalParams.sslCAFile.empty()) {
-        log() << "";
-        log() << "** WARNING: No client certificate validation can be performed since"
-                 " no CA file has been provided";
+        LOGV2("");
+        LOGV2("** WARNING: No client certificate validation can be performed since"
+                 " no CA file has been provided");
 #ifdef MONGO_CONFIG_SSL_CERTIFICATE_SELECTORS
-        log() << "**          and no sslCertificateSelector has been specified.";
+        LOGV2("**          and no sslCertificateSelector has been specified.");
 #endif
-        log() << "**          Please specify an sslCAFile parameter.";
+        LOGV2("**          Please specify an sslCAFile parameter.");
     }
 
 #if defined(_WIN32) && !defined(_WIN64)
@@ -122,50 +117,41 @@ void logCommonStartupWarnings(const ServerGlobalParams& serverParams) {
     BOOL wow64Process;
     BOOL retWow64 = IsWow64Process(GetCurrentProcess(), &wow64Process);
     if (retWow64 && wow64Process) {
-        log() << "** NOTE: This is a 32-bit MongoDB binary running on a 64-bit operating"
-              << startupWarningsLog;
-        log() << "**      system. Switch to a 64-bit build of MongoDB to" << startupWarningsLog;
-        log() << "**      support larger databases." << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** NOTE: This is a 32-bit MongoDB binary running on a 64-bit operating");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**      system. Switch to a 64-bit build of MongoDB to");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**      support larger databases.");
         warned = true;
     }
 #endif
 
 #if !defined(_WIN32)
     if (getuid() == 0) {
-        log() << "** WARNING: You are running this process as the root user, "
-              << "which is not recommended." << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: You are running this process as the root user, which is not recommended.");
         warned = true;
     }
 #endif
 
     if (serverParams.bind_ips.empty()) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: This server is bound to localhost." << startupWarningsLog;
-        log() << "**          Remote systems will be unable to connect to this server. "
-              << startupWarningsLog;
-        log() << "**          Start the server with --bind_ip <address> to specify which IP "
-              << startupWarningsLog;
-        log() << "**          addresses it should serve responses from, or with --bind_ip_all to"
-              << startupWarningsLog;
-        log() << "**          bind to all interfaces. If this behavior is desired, start the"
-              << startupWarningsLog;
-        log() << "**          server with --bind_ip 127.0.0.1 to disable this warning."
-              << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: This server is bound to localhost.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          Remote systems will be unable to connect to this server. ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          Start the server with --bind_ip <address> to specify which IP ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          addresses it should serve responses from, or with --bind_ip_all to");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          bind to all interfaces. If this behavior is desired, start the");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          server with --bind_ip 127.0.0.1 to disable this warning.");
         warned = true;
     }
 
     if (auth::hasMultipleInternalAuthKeys()) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: Multiple keys specified in security key file. If cluster key file"
-              << startupWarningsLog;
-        log() << "            rollover is not in progress, only one key should be specified in"
-              << startupWarningsLog;
-        log() << "            the key file" << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: Multiple keys specified in security key file. If cluster key file");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "            rollover is not in progress, only one key should be specified in");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "            the key file");
         warned = true;
     }
 
     if (warned) {
-        log() << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
     }
 }
 }  // namespace mongo
diff --git a/src/mongo/db/startup_warnings_mongod.cpp b/src/mongo/db/startup_warnings_mongod.cpp
index 29a452f687..a6abf003bb 100644
--- a/src/mongo/db/startup_warnings_mongod.cpp
+++ b/src/mongo/db/startup_warnings_mongod.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/db/startup_warnings_common.h"
 #include "mongo/db/storage/storage_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/processinfo.h"
 #include "mongo/util/str.h"
@@ -141,32 +142,27 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
     bool warned = false;
 
     if (sizeof(int*) == 4) {
-        log() << startupWarningsLog;
-        log() << "** NOTE: This is a 32 bit MongoDB binary." << startupWarningsLog;
-        log() << "**       32 bit builds are limited to less than 2GB of data "
-              << "(or less with --journal)." << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** NOTE: This is a 32 bit MongoDB binary.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**       32 bit builds are limited to less than 2GB of data (or less with --journal).");
         if (!storageParams.dur) {
-            log() << "**       Note that journaling defaults to off for 32 bit "
-                  << "and is currently off." << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**       Note that journaling defaults to off for 32 bit and is currently off.");
         }
-        log() << "**       See http://dochub.mongodb.org/core/32bit" << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**       See http://dochub.mongodb.org/core/32bit");
         warned = true;
     }
 
     if (!ProcessInfo::blockCheckSupported()) {
-        log() << startupWarningsLog;
-        log() << "** NOTE: your operating system version does not support the method that "
-              << "MongoDB" << startupWarningsLog;
-        log() << "**       uses to detect impending page faults." << startupWarningsLog;
-        log() << "**       This may result in slower performance for certain use "
-              << "cases" << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** NOTE: your operating system version does not support the method that MongoDB");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**       uses to detect impending page faults.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**       This may result in slower performance for certain use cases");
         warned = true;
     }
 #ifdef __linux__
     if (boost::filesystem::exists("/proc/vz") && !boost::filesystem::exists("/proc/bc")) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: You are running in OpenVZ which can cause issues on versions "
-              << "of RHEL older than RHEL6." << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: You are running in OpenVZ which can cause issues on versions of RHEL older than RHEL6.");
         warned = true;
     }
 
@@ -174,10 +170,8 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
     try {
         hasMultipleNumaNodes = boost::filesystem::exists("/sys/devices/system/node/node1");
     } catch (boost::filesystem::filesystem_error& e) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: Cannot detect if NUMA interleaving is enabled. "
-              << "Failed to probe \"" << e.path1().string() << "\": " << e.code().message()
-              << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: Cannot detect if NUMA interleaving is enabled. Failed to probe \"{}\": {}", "e_path1_string"_attr = e.path1().string(), "e_code_message"_attr = e.code().message());
     }
     if (hasMultipleNumaNodes) {
         // We are on a box with a NUMA enabled kernel and more than 1 numa node (they start at
@@ -204,20 +198,17 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
                 // skip over pointer
                 std::string::size_type where = line.find(' ');
                 if ((where == std::string::npos) || (++where == line.size())) {
-                    log() << startupWarningsLog;
-                    log() << "** WARNING: cannot parse numa_maps line: '" << line << "'"
-                          << startupWarningsLog;
+                    LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+                    LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: cannot parse numa_maps line: '{}'", "line"_attr = line);
                     warned = true;
                 }
                 // if the text following the space doesn't begin with 'interleave', then
                 // issue the warning.
                 else if (line.find("interleave", where) != where) {
-                    log() << startupWarningsLog;
-                    log() << "** WARNING: You are running on a NUMA machine." << startupWarningsLog;
-                    log() << "**          We suggest launching mongod like this to avoid "
-                          << "performance problems:" << startupWarningsLog;
-                    log() << "**              numactl --interleave=all mongod [other options]"
-                          << startupWarningsLog;
+                    LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+                    LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: You are running on a NUMA machine.");
+                    LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          We suggest launching mongod like this to avoid performance problems:");
+                    LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**              numactl --interleave=all mongod [other options]");
                     warned = true;
                 }
             }
@@ -230,10 +221,9 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
         f >> val;
 
         if (val == 2) {
-            log() << startupWarningsLog;
-            log() << "** WARNING: /proc/sys/vm/overcommit_memory is " << val << startupWarningsLog;
-            log() << "**          Journaling works best with it set to 0 or 1"
-                  << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: /proc/sys/vm/overcommit_memory is {}", "val"_attr = val);
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          Journaling works best with it set to 0 or 1");
         }
     }
 
@@ -243,11 +233,10 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
         f >> val;
 
         if (val != 0) {
-            log() << startupWarningsLog;
-            log() << "** WARNING: /proc/sys/vm/zone_reclaim_mode is " << val << startupWarningsLog;
-            log() << "**          We suggest setting it to 0" << startupWarningsLog;
-            log() << "**          http://www.kernel.org/doc/Documentation/sysctl/vm.txt"
-                  << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: /proc/sys/vm/zone_reclaim_mode is {}", "val"_attr = val);
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          We suggest setting it to 0");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          http://www.kernel.org/doc/Documentation/sysctl/vm.txt");
         }
     }
 
@@ -260,10 +249,9 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
             // If we do not have hugepages enabled, we don't need to warn about its features
             shouldWarnAboutDefragAlways = true;
 
-            log() << startupWarningsLog;
-            log() << "** WARNING: " << kTransparentHugePagesDirectory << "/enabled is 'always'."
-                  << startupWarningsLog;
-            log() << "**        We suggest setting it to 'never'" << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: {}/enabled is 'always'.", "kTransparentHugePagesDirectory"_attr = kTransparentHugePagesDirectory);
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**        We suggest setting it to 'never'");
             warned = true;
         }
     } else if (transparentHugePagesEnabledResult.getStatus().code() !=
@@ -278,10 +266,9 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
     if (transparentHugePagesDefragResult.isOK()) {
         if (shouldWarnAboutDefragAlways &&
             transparentHugePagesDefragResult.getValue() == "always") {
-            log() << startupWarningsLog;
-            log() << "** WARNING: " << kTransparentHugePagesDirectory << "/defrag is 'always'."
-                  << startupWarningsLog;
-            log() << "**        We suggest setting it to 'never'" << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: {}/defrag is 'always'.", "kTransparentHugePagesDirectory"_attr = kTransparentHugePagesDirectory);
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**        We suggest setting it to 'never'");
             warned = true;
         }
     } else if (transparentHugePagesDefragResult.getStatus().code() != ErrorCodes::NonExistentPath) {
@@ -298,14 +285,13 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
 
     if (!getrlimit(RLIMIT_NOFILE, &rlnofile)) {
         if (rlnofile.rlim_cur < minNumFiles) {
-            log() << startupWarningsLog;
-            log() << "** WARNING: soft rlimits too low. Number of files is " << rlnofile.rlim_cur
-                  << ", should be at least " << minNumFiles << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: soft rlimits too low. Number of files is {}, should be at least {}", "rlnofile_rlim_cur"_attr = rlnofile.rlim_cur, "minNumFiles"_attr = minNumFiles);
         }
     } else {
         const auto errmsg = errnoWithDescription();
-        log() << startupWarningsLog;
-        log() << "** WARNING: getrlimit failed. " << errmsg << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: getrlimit failed. {}", "errmsg"_attr = errmsg);
     }
 
 // Solaris does not have RLIMIT_MEMLOCK, these are exposed via getrctl(2) instead
@@ -317,15 +303,13 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
 
     if (!getrlimit(RLIMIT_MEMLOCK, &rlmemlock)) {
         if ((rlmemlock.rlim_cur / ProcessInfo::getPageSize()) < minLockedPages) {
-            log() << startupWarningsLog;
-            log() << "** WARNING: soft rlimits too low. The locked memory size is "
-                  << rlmemlock.rlim_cur << " bytes, it should be at least "
-                  << minLockedPages * ProcessInfo::getPageSize() << " bytes" << startupWarningsLog;
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+            LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: soft rlimits too low. The locked memory size is {} bytes, it should be at least {} bytes", "rlmemlock_rlim_cur"_attr = rlmemlock.rlim_cur, "minLockedPages_ProcessInfo_getPageSize"_attr = minLockedPages * ProcessInfo::getPageSize());
         }
     } else {
         const auto errmsg = errnoWithDescription();
-        log() << startupWarningsLog;
-        log() << "** WARNING: getrlimit failed. " << errmsg << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: getrlimit failed. {}", "errmsg"_attr = errmsg);
     }
 #endif
 #endif
@@ -334,28 +318,25 @@ void logMongodStartupWarnings(const StorageGlobalParams& storageParams,
     ProcessInfo p;
 
     if (p.hasNumaEnabled()) {
-        log() << startupWarningsLog;
-        log() << "** WARNING: You are running on a NUMA machine." << startupWarningsLog;
-        log() << "**          We suggest disabling NUMA in the machine BIOS " << startupWarningsLog;
-        log() << "**          by enabling interleaving to avoid performance problems. "
-              << startupWarningsLog;
-        log() << "**          See your BIOS documentation for more information."
-              << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: You are running on a NUMA machine.");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          We suggest disabling NUMA in the machine BIOS ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          by enabling interleaving to avoid performance problems. ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          See your BIOS documentation for more information.");
         warned = true;
     }
 
 #endif  // #ifdef _WIN32
 
     if (storageParams.engine == "ephemeralForTest") {
-        log() << startupWarningsLog;
-        log() << "** NOTE: The ephemeralForTest storage engine is for testing only. "
-              << startupWarningsLog;
-        log() << "**       Do not use in production." << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** NOTE: The ephemeralForTest storage engine is for testing only. ");
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**       Do not use in production.");
         warned = true;
     }
 
     if (warned) {
-        log() << startupWarningsLog;
+        LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
     }
 }
 }  // namespace mongo
diff --git a/src/mongo/db/stats/counters.cpp b/src/mongo/db/stats/counters.cpp
index 5e667340d1..41f50a502e 100644
--- a/src/mongo/db/stats/counters.cpp
+++ b/src/mongo/db/stats/counters.cpp
@@ -34,6 +34,7 @@
 #include "mongo/db/stats/counters.h"
 
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -62,7 +63,7 @@ void OpCounters::gotOp(int op, bool isCommand) {
         case opReply:
             break;
         default:
-            log() << "OpCounters::gotOp unknown op: " << op << std::endl;
+            LOGV2("OpCounters::gotOp unknown op: {}", "op"_attr = op);
     }
 }
 
diff --git a/src/mongo/db/storage/durable_catalog_impl.cpp b/src/mongo/db/storage/durable_catalog_impl.cpp
index 38f9db61e5..83faad53fe 100644
--- a/src/mongo/db/storage/durable_catalog_impl.cpp
+++ b/src/mongo/db/storage/durable_catalog_impl.cpp
@@ -49,6 +49,7 @@
 #include "mongo/db/storage/record_store.h"
 #include "mongo/db/storage/recovery_unit.h"
 #include "mongo/db/storage/storage_engine_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/bits.h"
 #include "mongo/platform/random.h"
 #include "mongo/util/log.h"
@@ -213,9 +214,7 @@ public:
         // Intentionally ignoring failure here. Since we've removed the metadata pointing to the
         // index, we should never see it again anyway.
         if (_engine->getStorageEngine()->supportsPendingDrops() && commitTimestamp) {
-            log() << "Deferring table drop for index '" << _indexName << "' on collection '"
-                  << _indexNss << (_uuid ? " (" + _uuid->toString() + ")'" : "") << ". Ident: '"
-                  << _ident << "', commit timestamp: '" << commitTimestamp << "'";
+            LOGV2("Deferring table drop for index '{}' on collection '{}{}. Ident: '{}', commit timestamp: '{}'", "_indexName"_attr = _indexName, "_indexNss"_attr = _indexNss, "_uuid__uuid_toString"_attr = (_uuid ? " (" + _uuid->toString() + ")'" : ""), "_ident"_attr = _ident, "commitTimestamp"_attr = commitTimestamp);
             _engine->addDropPendingIdent(*commitTimestamp, _indexNss, _ident);
         } else {
             auto kvEngine = _engine->getEngine();
@@ -531,7 +530,7 @@ StatusWith<DurableCatalog::Entry> DurableCatalogImpl::_addEntry(OperationContext
     _catalogIdToEntryMap[res.getValue()] = {res.getValue(), ident, nss};
     opCtx->recoveryUnit()->registerChange(std::make_unique<AddIdentChange>(this, res.getValue()));
 
-    LOG(1) << "stored meta data for " << nss.ns() << " @ " << res.getValue();
+    LOGV2_DEBUG(1, "stored meta data for {} @ {}", "nss_ns"_attr = nss.ns(), "res_getValue"_attr = res.getValue());
     return {{res.getValue(), ident, nss}};
 }
 
@@ -544,7 +543,7 @@ std::string DurableCatalogImpl::getIndexIdent(OperationContext* opCtx,
 }
 
 BSONObj DurableCatalogImpl::_findEntry(OperationContext* opCtx, RecordId catalogId) const {
-    LOG(3) << "looking up metadata for: " << catalogId;
+    LOGV2_DEBUG(3, "looking up metadata for: {}", "catalogId"_attr = catalogId);
     RecordData data;
     if (!_rs->findRecord(opCtx, catalogId, &data)) {
         // since the in memory meta data isn't managed with mvcc
@@ -559,11 +558,11 @@ BSONObj DurableCatalogImpl::_findEntry(OperationContext* opCtx, RecordId catalog
 BSONCollectionCatalogEntry::MetaData DurableCatalogImpl::getMetaData(OperationContext* opCtx,
                                                                      RecordId catalogId) const {
     BSONObj obj = _findEntry(opCtx, catalogId);
-    LOG(3) << " fetched CCE metadata: " << obj;
+    LOGV2_DEBUG(3, " fetched CCE metadata: {}", "obj"_attr = obj);
     BSONCollectionCatalogEntry::MetaData md;
     const BSONElement mdElement = obj["md"];
     if (mdElement.isABSONObj()) {
-        LOG(3) << "returning metadata: " << mdElement;
+        LOGV2_DEBUG(3, "returning metadata: {}", "mdElement"_attr = mdElement);
         md.parse(mdElement.Obj());
     }
     return md;
@@ -624,7 +623,7 @@ void DurableCatalogImpl::putMetaData(OperationContext* opCtx,
         opCtx->recoveryUnit()->setMustBeTimestamped();
     }
 
-    LOG(3) << "recording new metadata: " << obj;
+    LOGV2_DEBUG(3, "recording new metadata: {}", "obj"_attr = obj);
     Status status = _rs->updateRecord(opCtx, catalogId, obj.objdata(), obj.objsize());
     fassert(28521, status);
 }
@@ -685,7 +684,7 @@ Status DurableCatalogImpl::_removeEntry(OperationContext* opCtx, RecordId catalo
     opCtx->recoveryUnit()->registerChange(
         std::make_unique<RemoveIdentChange>(this, catalogId, it->second));
 
-    LOG(1) << "deleting metadata for " << it->second.nss << " @ " << catalogId;
+    LOGV2_DEBUG(1, "deleting metadata for {} @ {}", "it_second_nss"_attr = it->second.nss, "catalogId"_attr = catalogId);
     _rs->deleteRecord(opCtx, catalogId);
     _catalogIdToEntryMap.erase(it);
 
@@ -773,7 +772,7 @@ StatusWith<std::string> DurableCatalogImpl::newOrphanedIdent(OperationContext* o
     _catalogIdToEntryMap[res.getValue()] = Entry(res.getValue(), ident, ns);
     opCtx->recoveryUnit()->registerChange(std::make_unique<AddIdentChange>(this, res.getValue()));
 
-    LOG(1) << "stored meta data for orphaned collection " << ns << " @ " << res.getValue();
+    LOGV2_DEBUG(1, "stored meta data for orphaned collection {} @ {}", "ns"_attr = ns, "res_getValue"_attr = res.getValue());
     return {ns.ns()};
 }
 
@@ -860,8 +859,7 @@ Status DurableCatalogImpl::dropCollection(OperationContext* opCtx, RecordId cata
             StorageEngineInterface* engine = catalog->_engine;
             auto storageEngine = engine->getStorageEngine();
             if (storageEngine->supportsPendingDrops() && commitTimestamp) {
-                log() << "Deferring table drop for collection '" << entry.nss
-                      << "'. Ident: " << entry.ident << ", commit timestamp: " << commitTimestamp;
+                LOGV2("Deferring table drop for collection '{}'. Ident: {}, commit timestamp: {}", "entry_nss"_attr = entry.nss, "entry_ident"_attr = entry.ident, "commitTimestamp"_attr = commitTimestamp);
                 engine->addDropPendingIdent(*commitTimestamp, entry.nss, entry.ident);
             } else {
                 // Intentionally ignoring failure here. Since we've removed the metadata pointing to
diff --git a/src/mongo/db/storage/ephemeral_for_test/ephemeral_for_test_recovery_unit.cpp b/src/mongo/db/storage/ephemeral_for_test/ephemeral_for_test_recovery_unit.cpp
index 4c74286c82..88b352d46c 100644
--- a/src/mongo/db/storage/ephemeral_for_test/ephemeral_for_test_recovery_unit.cpp
+++ b/src/mongo/db/storage/ephemeral_for_test/ephemeral_for_test_recovery_unit.cpp
@@ -34,6 +34,7 @@
 #include "mongo/db/storage/ephemeral_for_test/ephemeral_for_test_recovery_unit.h"
 
 #include "mongo/db/storage/sorted_data_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -78,7 +79,7 @@ void EphemeralForTestRecoveryUnit::doAbortUnitOfWork() {
         for (Changes::reverse_iterator it = _changes.rbegin(), end = _changes.rend(); it != end;
              ++it) {
             auto change = *it;
-            LOG(2) << "CUSTOM ROLLBACK " << demangleName(typeid(*change));
+            LOGV2_DEBUG(2, "CUSTOM ROLLBACK {}", "demangleName_typeid_change"_attr = demangleName(typeid(*change)));
             change->rollback();
         }
         _changes.clear();
diff --git a/src/mongo/db/storage/flow_control.cpp b/src/mongo/db/storage/flow_control.cpp
index 0552357f45..51bf25629c 100644
--- a/src/mongo/db/storage/flow_control.cpp
+++ b/src/mongo/db/storage/flow_control.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/repl/replication_coordinator.h"
 #include "mongo/db/server_options.h"
 #include "mongo/db/storage/flow_control_parameters_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/background.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -240,9 +241,7 @@ int FlowControl::_calculateNewTicketsForLag(const std::vector<repl::MemberData>&
 
     const std::int64_t sustainerAppliedCount =
         _approximateOpsBetween(prevSustainerAppliedTs, currSustainerAppliedTs);
-    LOG(DEBUG_LOG_LEVEL) << " PrevApplied: " << prevSustainerAppliedTs
-                         << " CurrApplied: " << currSustainerAppliedTs
-                         << " NumSustainerApplied: " << sustainerAppliedCount;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(DEBUG_LOG_LEVEL).toInt(), " PrevApplied: {} CurrApplied: {} NumSustainerApplied: {}", "prevSustainerAppliedTs"_attr = prevSustainerAppliedTs, "currSustainerAppliedTs"_attr = currSustainerAppliedTs, "sustainerAppliedCount"_attr = sustainerAppliedCount);
     if (sustainerAppliedCount > 0) {
         _lastTimeSustainerAdvanced = Date_t::now();
     } else {
@@ -285,9 +284,7 @@ int FlowControl::_calculateNewTicketsForLag(const std::vector<repl::MemberData>&
     // an environment where secondaries consistently process operations slower than the primary.
     double sustainerAppliedPenalty =
         sustainerAppliedCount * reduce * gFlowControlFudgeFactor.load();
-    LOG(DEBUG_LOG_LEVEL) << "Sustainer: " << sustainerAppliedCount << " LagMillis: " << lagMillis
-                         << " Threshold lag: " << thresholdLagMillis << " Exponent: " << exponent
-                         << " Reduce: " << reduce << " Penalty: " << sustainerAppliedPenalty;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(DEBUG_LOG_LEVEL).toInt(), "Sustainer: {} LagMillis: {} Threshold lag: {} Exponent: {} Reduce: {} Penalty: {}", "sustainerAppliedCount"_attr = sustainerAppliedCount, "lagMillis"_attr = lagMillis, "thresholdLagMillis"_attr = thresholdLagMillis, "exponent"_attr = exponent, "reduce"_attr = reduce, "sustainerAppliedPenalty"_attr = sustainerAppliedPenalty);
 
     return multiplyWithOverflowCheck(locksPerOp, sustainerAppliedPenalty, _kMaxTickets);
 }
@@ -375,19 +372,8 @@ int FlowControl::getNumTickets() {
 
     ret = std::max(ret, gFlowControlMinTicketsPerSecond.load());
 
-    LOG(DEBUG_LOG_LEVEL) << "Are lagged? " << (_isLagged.load() ? "true" : "false")
-                         << " Curr lag millis: "
-                         << getLagMillis(myLastApplied.wallTime, lastCommitted.wallTime)
-                         << " OpsLagged: "
-                         << _approximateOpsBetween(lastCommitted.opTime.getTimestamp(),
-                                                   myLastApplied.opTime.getTimestamp())
-                         << " Granting: " << ret
-                         << " Last granted: " << _lastTargetTicketsPermitted.load()
-                         << " Last sustainer applied: " << _lastSustainerAppliedCount.load()
-                         << " Acquisitions since last check: " << locksUsedLastPeriod
-                         << " Locks per op: " << _lastLocksPerOp.load()
-                         << " Count of lagged periods: " << _isLaggedCount.load()
-                         << " Total duration of lagged periods: " << _isLaggedTimeMicros.load();
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(DEBUG_LOG_LEVEL).toInt(), "Are lagged? {} Curr lag millis: {} OpsLagged: {} Granting: {} Last granted: {} Last sustainer applied: {} Acquisitions since last check: {} Locks per op: {} Count of lagged periods: {} Total duration of lagged periods: {}", "_isLagged_load_true_false"_attr = (_isLagged.load() ? "true" : "false"), "getLagMillis_myLastApplied_wallTime_lastCommitted_wallTime"_attr = getLagMillis(myLastApplied.wallTime, lastCommitted.wallTime), "_approximateOpsBetween_lastCommitted_opTime_getTimestamp_myLastApplied_opTime_getTimestamp"_attr = _approximateOpsBetween(lastCommitted.opTime.getTimestamp(),
+                                                   myLastApplied.opTime.getTimestamp()), "ret"_attr = ret, "_lastTargetTicketsPermitted_load"_attr = _lastTargetTicketsPermitted.load(), "_lastSustainerAppliedCount_load"_attr = _lastSustainerAppliedCount.load(), "locksUsedLastPeriod"_attr = locksUsedLastPeriod, "_lastLocksPerOp_load"_attr = _lastLocksPerOp.load(), "_isLaggedCount_load"_attr = _isLaggedCount.load(), "_isLaggedTimeMicros_load"_attr = _isLaggedTimeMicros.load());
 
     _lastTargetTicketsPermitted.store(ret);
 
@@ -449,8 +435,7 @@ void FlowControl::sample(Timestamp timestamp, std::uint64_t opsApplied) {
     _lastSample = _numOpsSinceStartup;
 
     const auto lockAcquisitions = stats.get(resourceIdGlobal, LockMode::MODE_IX).numAcquisitions;
-    LOG(DEBUG_LOG_LEVEL) << "Sampling. Time: " << timestamp << " Applied: " << _numOpsSinceStartup
-                         << " LockAcquisitions: " << lockAcquisitions;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(DEBUG_LOG_LEVEL).toInt(), "Sampling. Time: {} Applied: {} LockAcquisitions: {}", "timestamp"_attr = timestamp, "_numOpsSinceStartup"_attr = _numOpsSinceStartup, "lockAcquisitions"_attr = lockAcquisitions);
 
     if (_sampledOpsApplied.size() <
         static_cast<std::deque<Sample>::size_type>(gFlowControlMaxSamples)) {
@@ -479,7 +464,7 @@ void FlowControl::_trimSamples(const Timestamp trimTo) {
         ++numTrimmed;
     }
 
-    LOG(DEBUG_LOG_LEVEL) << "Trimmed samples. Num: " << numTrimmed;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(DEBUG_LOG_LEVEL).toInt(), "Trimmed samples. Num: {}", "numTrimmed"_attr = numTrimmed);
 }
 
 int64_t FlowControl::_getLocksUsedLastPeriod() {
diff --git a/src/mongo/db/storage/key_string_test.cpp b/src/mongo/db/storage/key_string_test.cpp
index db6ceb39e2..f1babe2fe1 100644
--- a/src/mongo/db/storage/key_string_test.cpp
+++ b/src/mongo/db/storage/key_string_test.cpp
@@ -48,6 +48,7 @@
 #include "mongo/bson/simple_bsonobj_comparator.h"
 #include "mongo/config.h"
 #include "mongo/db/storage/key_string.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/decimal128.h"
 #include "mongo/stdx/future.h"
 #include "mongo/unittest/death_test.h"
@@ -97,8 +98,7 @@ public:
             version = KeyString::Version::V1;
             base->run();
         } catch (...) {
-            log() << "exception while testing KeyStringBuilder version "
-                  << mongo::KeyString::keyStringVersionToString(version);
+            LOGV2("exception while testing KeyStringBuilder version {}", "mongo_KeyString_keyStringVersionToString_version"_attr = mongo::KeyString::keyStringVersionToString(version));
             throw;
         }
     }
@@ -351,8 +351,7 @@ TEST_F(KeyStringBuilderTest, ActualBytesDouble) {
 
     BSONObj a = BSON("" << 5.5);
     KeyString::Builder ks(version, a, ALL_ASCENDING);
-    log() << keyStringVersionToString(version) << " size: " << ks.getSize() << " hex ["
-          << toHex(ks.getBuffer(), ks.getSize()) << "]";
+    LOGV2("{} size: {} hex [{}]", "keyStringVersionToString_version"_attr = keyStringVersionToString(version), "ks_getSize"_attr = ks.getSize(), "toHex_ks_getBuffer_ks_getSize"_attr = toHex(ks.getBuffer(), ks.getSize()));
 
     ASSERT_EQUALS(10U, ks.getSize());
 
@@ -484,7 +483,7 @@ TEST_F(KeyStringBuilderTest, NumbersNearInt32Max) {
 
 TEST_F(KeyStringBuilderTest, DecimalNumbers) {
     if (version == KeyString::Version::V0) {
-        log() << "not testing DecimalNumbers for KeyStringBuilder V0";
+        LOGV2("not testing DecimalNumbers for KeyStringBuilder V0");
         return;
     }
 
@@ -1172,7 +1171,7 @@ void testPermutation(KeyString::Version version,
                 BSONObj orderObj = orderings[k];
                 Ordering ordering = Ordering::make(orderObj);
                 if (debug)
-                    log() << "ordering: " << orderObj;
+                    LOGV2("ordering: {}", "orderObj"_attr = orderObj);
 
                 std::vector<BSONObj> elements = elementsOrig;
                 BSONObjComparator bsonCmp(orderObj,
@@ -1183,7 +1182,7 @@ void testPermutation(KeyString::Version version,
                 for (size_t i = 0; i < elements.size(); i++) {
                     const BSONObj& o1 = elements[i];
                     if (debug)
-                        log() << "\to1: " << o1;
+                        LOGV2("\to1: {}", "o1"_attr = o1);
                     ROUNDTRIP_ORDER(version, o1, ordering);
 
                     KeyString::Builder k1(version, o1, ordering);
@@ -1191,7 +1190,7 @@ void testPermutation(KeyString::Version version,
                     if (i + 1 < elements.size()) {
                         const BSONObj& o2 = elements[i + 1];
                         if (debug)
-                            log() << "\t\t o2: " << o2;
+                            LOGV2("\t\t o2: {}", "o2"_attr = o2);
                         KeyString::Builder k2(version, o2, ordering);
 
                         int bsonCmp = o1.woCompare(o2, ordering);
@@ -1225,7 +1224,7 @@ std::mt19937_64 seedGen(rd());
 // To be used by perf test for seeding, so that the entire test is repeatable in case of error.
 unsigned newSeed() {
     unsigned int seed = seedGen();  // Replace by the reported number to repeat test execution.
-    log() << "Initializing random number generator using seed " << seed;
+    LOGV2("Initializing random number generator using seed {}", "seed"_attr = seed);
     return seed;
 };
 
@@ -1237,8 +1236,7 @@ std::vector<BSONObj> thinElements(std::vector<BSONObj> elements,
     if (elements.size() <= maxElements)
         return elements;
 
-    log() << "only keeping " << maxElements << " of " << elements.size()
-          << " elements using random selection";
+    LOGV2("only keeping {} of {} elements using random selection", "maxElements"_attr = maxElements, "elements_size"_attr = elements.size());
     std::shuffle(elements.begin(), elements.end(), gen);
     elements.resize(maxElements);
     return elements;
@@ -1284,7 +1282,7 @@ TEST_F(KeyStringBuilderTest, AllPerm2Compare) {
         }
     }
 
-    log() << "AllPerm2Compare " << keyStringVersionToString(version) << " size:" << elements.size();
+    LOGV2("AllPerm2Compare {} size:{}", "keyStringVersionToString_version"_attr = keyStringVersionToString(version), "elements_size"_attr = elements.size());
 
     for (size_t i = 0; i < elements.size(); i++) {
         const BSONObj& o = elements[i];
@@ -1443,7 +1441,7 @@ TEST_F(KeyStringBuilderTest, NumberOrderLots) {
 
             if (a.compare(b) !=
                 compareNumbers(numbers[i].firstElement(), numbers[j].firstElement())) {
-                log() << numbers[i] << " " << numbers[j];
+                LOGV2("{} {}", "numbers_i"_attr = numbers[i], "numbers_j"_attr = numbers[j]);
             }
 
             ASSERT_EQUALS(a.compare(b),
@@ -1755,10 +1753,7 @@ void perfTest(KeyString::Version version, const Numbers& numbers) {
     auto minmax = std::minmax_element(
         numbers.begin(), numbers.end(), SimpleBSONObjComparator::kInstance.makeLessThan());
 
-    log() << 1E3 * micros / static_cast<double>(iters * numbers.size()) << " ns per "
-          << mongo::KeyString::keyStringVersionToString(version) << " roundtrip"
-          << (kDebugBuild ? " (DEBUG BUILD!)" : "") << " min " << (*minmax.first)[""] << ", max"
-          << (*minmax.second)[""];
+    LOGV2("{} ns per {} roundtrip{} min {}, max{}", "1E3_micros_static_cast_double_iters_numbers_size"_attr = 1E3 * micros / static_cast<double>(iters * numbers.size()), "mongo_KeyString_keyStringVersionToString_version"_attr = mongo::KeyString::keyStringVersionToString(version), "kDebugBuild_DEBUG_BUILD"_attr = (kDebugBuild ? " (DEBUG BUILD!)" : ""), "minmax_first"_attr = (*minmax.first)[""], "minmax_second"_attr = (*minmax.second)[""]);
 }
 }  // namespace
 
diff --git a/src/mongo/db/storage/kv/kv_drop_pending_ident_reaper.cpp b/src/mongo/db/storage/kv/kv_drop_pending_ident_reaper.cpp
index 44337fffc4..43d30ed628 100644
--- a/src/mongo/db/storage/kv/kv_drop_pending_ident_reaper.cpp
+++ b/src/mongo/db/storage/kv/kv_drop_pending_ident_reaper.cpp
@@ -37,6 +37,7 @@
 
 #include "mongo/db/concurrency/d_concurrency.h"
 #include "mongo/db/storage/write_unit_of_work.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -109,8 +110,7 @@ void KVDropPendingIdentReaper::dropIdentsOlderThan(OperationContext* opCtx, cons
             const auto& identInfo = timestampAndIdentInfo.second;
             const auto& nss = identInfo.nss;
             const auto& ident = identInfo.ident;
-            log() << "Completing drop for ident " << ident << " (ns: " << nss
-                  << ") with drop timestamp " << dropTimestamp;
+            LOGV2("Completing drop for ident {} (ns: {}) with drop timestamp {}", "ident"_attr = ident, "nss"_attr = nss, "dropTimestamp"_attr = dropTimestamp);
             WriteUnitOfWork wuow(opCtx);
             auto status = _engine->dropIdent(opCtx, ident);
             if (!status.isOK()) {
diff --git a/src/mongo/db/storage/mobile/mobile_kv_engine.cpp b/src/mongo/db/storage/mobile/mobile_kv_engine.cpp
index 648ac3612a..cc4cc5b89d 100644
--- a/src/mongo/db/storage/mobile/mobile_kv_engine.cpp
+++ b/src/mongo/db/storage/mobile/mobile_kv_engine.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/storage/mobile/mobile_session.h"
 #include "mongo/db/storage/mobile/mobile_sqlite_statement.h"
 #include "mongo/db/storage/mobile/mobile_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 
@@ -80,16 +81,15 @@ MobileKVEngine::MobileKVEngine(const std::string& path,
     auto session = _sessionPool->getSession(nullptr);
 
     fassert(37001, queryPragmaStr(*session, "journal_mode"_sd) == "wal");
-    LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Confirmed SQLite database opened in WAL mode";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Confirmed SQLite database opened in WAL mode");
 
     fassert(50869, queryPragmaInt(*session, "synchronous"_sd) == _options.durabilityLevel);
-    LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Confirmed SQLite database has synchronous set to: "
-                              << _options.durabilityLevel;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Confirmed SQLite database has synchronous set to: {}", "_options_durabilityLevel"_attr = _options.durabilityLevel);
 
     fassert(50868, queryPragmaInt(*session, "fullfsync"_sd) == 1);
-    LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Confirmed SQLite database is set to fsync with "
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Confirmed SQLite database is set to fsync with "
                                  "F_FULLFSYNC if the platform supports it (currently only darwin "
-                                 "kernels). Value: 1";
+                                 "kernels). Value: 1");
 
     if (!_options.disableVacuumJob) {
         _vacuumJob = serviceContext->getPeriodicRunner()->makeJob(
@@ -109,8 +109,7 @@ void MobileKVEngine::cleanShutdown() {
         if (!_options.disableVacuumJob)
             maybeVacuum(Client::getCurrent(), Date_t());
     } catch (const std::exception& e) {
-        LOG(MOBILE_LOG_LEVEL_LOW)
-            << "MobileSE: Exception while doing vacuum at shutdown, surpressing. " << e.what();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Exception while doing vacuum at shutdown, surpressing. {}", "e_what"_attr = e.what());
     }
 }
 
@@ -139,11 +138,10 @@ void MobileKVEngine::maybeVacuum(Client* client, Date_t deadline) {
     }
 
     constexpr int kPageSize = 4096;  // SQLite default
-    LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Evaluating if we need to vacuum. page_count = "
-                              << pageCount << ", freelist_count = " << freelistCount;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Evaluating if we need to vacuum. page_count = {}, freelist_count = {}", "pageCount"_attr = pageCount, "freelistCount"_attr = freelistCount);
     if ((pageCount > 0 && (float)freelistCount / pageCount >= _options.vacuumFreePageRatio) ||
         (freelistCount * kPageSize >= _options.vacuumFreeSizeMB * 1024 * 1024)) {
-        LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Performing incremental vacuum";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Performing incremental vacuum");
         // Data will we moved on the file system, take an exclusive lock
         Lock::GlobalLock lk(opCtx, MODE_X, deadline, Lock::InterruptBehavior::kThrow);
         if (!lk.isLocked())
@@ -253,9 +251,8 @@ Status MobileKVEngine::dropIdent(OperationContext* opCtx, StringData ident) {
     } catch (const WriteConflictException&) {
         // It is possible that this drop fails because of transaction running in parallel.
         // We pretend that it succeeded, queue it for now and keep retrying later.
-        LOG(MOBILE_LOG_LEVEL_LOW)
-            << "MobileSE: Caught WriteConflictException while dropping table, "
-               "queuing to retry later";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Caught WriteConflictException while dropping table, "
+               "queuing to retry later");
         MobileRecoveryUnit::get(opCtx)->enqueueFailedDrop(dropQuery);
     }
     return Status::OK();
diff --git a/src/mongo/db/storage/mobile/mobile_session_pool.cpp b/src/mongo/db/storage/mobile/mobile_session_pool.cpp
index a8a211bcc6..5ee814fb8f 100644
--- a/src/mongo/db/storage/mobile/mobile_session_pool.cpp
+++ b/src/mongo/db/storage/mobile/mobile_session_pool.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/storage/mobile/mobile_session_pool.h"
 #include "mongo/db/storage/mobile/mobile_sqlite_statement.h"
 #include "mongo/db/storage/mobile/mobile_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/util/log.h"
 
@@ -56,7 +57,7 @@ void MobileDelayedOpQueue::enqueueOp(std::string& opQuery) {
     if (_opQueryQueue.empty())
         _isEmpty.store(false);
     _opQueryQueue.push(opQuery);
-    LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Enqueued operation for delayed execution: " << opQuery;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Enqueued operation for delayed execution: {}", "opQuery"_attr = opQuery);
     _queueMutex.unlock();
 }
 
@@ -73,14 +74,14 @@ void MobileDelayedOpQueue::execAndDequeueOp(MobileSession* session) {
     }
     _queueMutex.unlock();
 
-    LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Retrying previously enqueued operation: " << opQuery;
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Retrying previously enqueued operation: {}", "opQuery"_attr = opQuery);
     try {
         SqliteStatement::execQuery(session, opQuery);
     } catch (const WriteConflictException&) {
         // It is possible that this operation fails because of a transaction running in parallel.
         // We re-enqueue it for now and keep retrying later.
-        LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Caught WriteConflictException while executing "
-                                     " previously enqueued operation, re-enquing it";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Caught WriteConflictException while executing "
+                                     " previously enqueued operation, re-enquing it");
         enqueueOp(opQuery);
     }
 }
@@ -171,7 +172,7 @@ void MobileSessionPool::shutDown() {
         int status = sqlite3_open(_path.c_str(), &session);
         embedded::checkStatus(status, SQLITE_OK, "sqlite3_open");
         std::unique_ptr<MobileSession> mobSession = std::make_unique<MobileSession>(session, this);
-        LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE: Executing queued drops at shutdown";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE: Executing queued drops at shutdown");
         failedDropsQueue.execAndDequeueAllOps(mobSession.get());
         sqlite3_close(session);
     }
diff --git a/src/mongo/db/storage/mobile/mobile_util.cpp b/src/mongo/db/storage/mobile/mobile_util.cpp
index 3159dd169f..5b30087017 100644
--- a/src/mongo/db/storage/mobile/mobile_util.cpp
+++ b/src/mongo/db/storage/mobile/mobile_util.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/storage/mobile/mobile_recovery_unit.h"
 #include "mongo/db/storage/mobile/mobile_sqlite_statement.h"
 #include "mongo/db/storage/mobile/mobile_util.h"
+#include "mongo/logv2/log.h"
 
 namespace mongo {
 namespace embedded {
@@ -185,7 +186,7 @@ void doValidate(OperationContext* opCtx, ValidateResults* results) {
 void configureSession(sqlite3* session, const MobileOptions& options) {
     auto executePragma = [session](auto pragma, auto value) {
         SqliteStatement::execQuery(session, "PRAGMA ", pragma, " = ", value, ";");
-        LOG(MOBILE_LOG_LEVEL_LOW) << "MobileSE session configuration: " << pragma << " = " << value;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(MOBILE_LOG_LEVEL_LOW).toInt(), "MobileSE session configuration: {} = {}", "pragma"_attr = pragma, "value"_attr = value);
     };
     // We don't manually use VACUUM so set incremental(2) mode to reclaim space
     // This need to be set the first thing we do, before any internal tables are created.
diff --git a/src/mongo/db/storage/oplog_cap_maintainer_thread.cpp b/src/mongo/db/storage/oplog_cap_maintainer_thread.cpp
index a418badd57..04178d3af5 100644
--- a/src/mongo/db/storage/oplog_cap_maintainer_thread.cpp
+++ b/src/mongo/db/storage/oplog_cap_maintainer_thread.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/service_context.h"
 #include "mongo/db/storage/record_store.h"
 #include "mongo/logger/logstream_builder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/exit.h"
 #include "mongo/util/log.h"
@@ -56,7 +57,7 @@ namespace mongo {
 
 bool OplogCapMaintainerThread::_deleteExcessDocuments() {
     if (!getGlobalServiceContext()->getStorageEngine()) {
-        LOG(2) << "OplogCapMaintainerThread: no global storage engine yet";
+        LOGV2_DEBUG(2, "OplogCapMaintainerThread: no global storage engine yet");
         return false;
     }
 
@@ -81,7 +82,7 @@ bool OplogCapMaintainerThread::_deleteExcessDocuments() {
             auto databaseHolder = DatabaseHolder::get(opCtx.get());
             auto db = databaseHolder->getDb(opCtx.get(), oplogNss.db());
             if (!db) {
-                LOG(2) << "no local database yet";
+                LOGV2_DEBUG(2, "no local database yet");
                 return false;
             }
             // We need to hold the database lock while getting the collection. Otherwise a
@@ -90,7 +91,7 @@ bool OplogCapMaintainerThread::_deleteExcessDocuments() {
             Collection* collection = CollectionCatalog::get(opCtx.get())
                                          .lookupCollectionByNamespace(opCtx.get(), oplogNss);
             if (!collection) {
-                LOG(2) << "no collection " << oplogNss;
+                LOGV2_DEBUG(2, "no collection {}", "oplogNss"_attr = oplogNss);
                 return false;
             }
             rs = collection->getRecordStore();
diff --git a/src/mongo/db/storage/recovery_unit.cpp b/src/mongo/db/storage/recovery_unit.cpp
index 0e0951c63e..a72cfeddbb 100644
--- a/src/mongo/db/storage/recovery_unit.cpp
+++ b/src/mongo/db/storage/recovery_unit.cpp
@@ -32,6 +32,7 @@
 #include "mongo/platform/basic.h"
 
 #include "mongo/db/storage/recovery_unit.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 
@@ -74,7 +75,7 @@ void RecoveryUnit::commitRegisteredChanges(boost::optional<Timestamp> commitTime
     for (auto& change : _changes) {
         try {
             // Log at higher level because commits occur far more frequently than rollbacks.
-            LOG(3) << "CUSTOM COMMIT " << redact(demangleName(typeid(*change)));
+            LOGV2_DEBUG(3, "CUSTOM COMMIT {}", "redact_demangleName_typeid_change"_attr = redact(demangleName(typeid(*change))));
             change->commit(commitTimestamp);
         } catch (...) {
             std::terminate();
@@ -90,7 +91,7 @@ void RecoveryUnit::abortRegisteredChanges() {
              it != end;
              ++it) {
             Change* change = it->get();
-            LOG(2) << "CUSTOM ROLLBACK " << redact(demangleName(typeid(*change)));
+            LOGV2_DEBUG(2, "CUSTOM ROLLBACK {}", "redact_demangleName_typeid_change"_attr = redact(demangleName(typeid(*change))));
             change->rollback();
         }
         _changes.clear();
diff --git a/src/mongo/db/storage/storage_engine_impl.cpp b/src/mongo/db/storage/storage_engine_impl.cpp
index ff05522296..4770ac3a9e 100644
--- a/src/mongo/db/storage/storage_engine_impl.cpp
+++ b/src/mongo/db/storage/storage_engine_impl.cpp
@@ -50,6 +50,7 @@
 #include "mongo/db/storage/kv/temporary_kv_record_store.h"
 #include "mongo/db/storage/storage_repair_observer.h"
 #include "mongo/db/unclean_shutdown.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/unordered_map.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
@@ -90,7 +91,7 @@ void StorageEngineImpl::loadCatalog(OperationContext* opCtx) {
         auto repairObserver = StorageRepairObserver::get(getGlobalServiceContext());
         invariant(repairObserver->isIncomplete());
 
-        log() << "Repairing catalog metadata";
+        LOGV2("Repairing catalog metadata");
         Status status = _engine->repairIdent(opCtx, catalogInfo);
 
         if (status.code() == ErrorCodes::DataModifiedByRepair) {
@@ -159,9 +160,8 @@ void StorageEngineImpl::loadCatalog(OperationContext* opCtx) {
                     if (statusWithNs.isOK()) {
                         wuow.commit();
                         auto orphanCollNs = statusWithNs.getValue();
-                        log() << "Successfully created an entry in the catalog for the orphaned "
-                                 "collection: "
-                              << orphanCollNs;
+                        LOGV2("Successfully created an entry in the catalog for the orphaned "
+                                 "collection: {}", "orphanCollNs"_attr = orphanCollNs);
                         warning() << orphanCollNs
                                   << " does not have the _id index. Please manually "
                                      "build the index.";
@@ -223,7 +223,7 @@ void StorageEngineImpl::loadCatalog(OperationContext* opCtx) {
         maxSeenPrefix = std::max(maxSeenPrefix, maxPrefixForCollection);
 
         if (entry.nss.isOrphanCollection()) {
-            log() << "Orphaned collection found: " << entry.nss;
+            LOGV2("Orphaned collection found: {}", "entry_nss"_attr = entry.nss);
         }
     }
 
@@ -284,9 +284,7 @@ Status StorageEngineImpl::_recoverOrphanedCollection(OperationContext* opCtx,
     if (!_options.forRepair) {
         return {ErrorCodes::IllegalOperation, "Orphan recovery only supported in repair"};
     }
-    log() << "Storage engine is missing collection '" << collectionName
-          << "' from its metadata. Attempting to locate and recover the data for "
-          << collectionIdent;
+    LOGV2("Storage engine is missing collection '{}' from its metadata. Attempting to locate and recover the data for {}", "collectionName"_attr = collectionName, "collectionIdent"_attr = collectionIdent);
 
     WriteUnitOfWork wuow(opCtx);
     const auto metadata = _catalog->getMetaData(opCtx, catalogId);
@@ -376,12 +374,12 @@ StatusWith<StorageEngine::ReconcileResult> StorageEngineImpl::reconcileCatalogAn
         // These idents have to be retained as long as the corresponding drops are not part of a
         // checkpoint.
         if (dropPendingIdents.find(it) != dropPendingIdents.cend()) {
-            log() << "Not removing ident for uncheckpointed collection or index drop: " << it;
+            LOGV2("Not removing ident for uncheckpointed collection or index drop: {}", "it"_attr = it);
             continue;
         }
 
         const auto& toRemove = it;
-        log() << "Dropping unknown ident: " << toRemove;
+        LOGV2("Dropping unknown ident: {}", "toRemove"_attr = toRemove);
         WriteUnitOfWork wuow(opCtx);
         fassert(40591, _engine->dropIdent(opCtx, toRemove));
         wuow.commit();
@@ -440,8 +438,7 @@ StatusWith<StorageEngine::ReconcileResult> StorageEngineImpl::reconcileCatalogAn
             // majority of nodes. The code will rebuild the index, despite potentially
             // encountering another `dropIndex` command.
             if (indexMetaData.ready && !foundIdent) {
-                log() << "Expected index data is missing, rebuilding. Collection: " << coll
-                      << " Index: " << indexName;
+                LOGV2("Expected index data is missing, rebuilding. Collection: {} Index: {}", "coll"_attr = coll, "indexName"_attr = indexName);
                 ret.indexesToRebuild.push_back({entry.catalogId, coll, indexName});
                 continue;
             }
@@ -456,8 +453,7 @@ StatusWith<StorageEngine::ReconcileResult> StorageEngineImpl::reconcileCatalogAn
                 invariant(collUUID);
                 auto buildUUID = *indexMetaData.buildUUID;
 
-                log() << "Found index from unfinished build. Collection: " << coll << " ("
-                      << *collUUID << "), index: " << indexName << ", build UUID: " << buildUUID;
+                LOGV2("Found index from unfinished build. Collection: {} ({}), index: {}, build UUID: {}", "coll"_attr = coll, "collUUID"_attr = *collUUID, "indexName"_attr = indexName, "buildUUID"_attr = buildUUID);
 
                 // Insert in the map if a build has not already been registered.
                 auto existingIt = ret.indexBuildsToRestart.find(buildUUID);
@@ -476,17 +472,15 @@ StatusWith<StorageEngine::ReconcileResult> StorageEngineImpl::reconcileCatalogAn
             // will return the index to be rebuilt.
             if (indexMetaData.isBackgroundSecondaryBuild && (!foundIdent || !indexMetaData.ready)) {
                 if (!serverGlobalParams.indexBuildRetry) {
-                    log() << "Dropping an unfinished index because --noIndexBuildRetry is set. "
-                             "Collection: "
-                          << coll << " Index: " << indexName;
+                    LOGV2("Dropping an unfinished index because --noIndexBuildRetry is set. "
+                             "Collection: {} Index: {}", "coll"_attr = coll, "indexName"_attr = indexName);
                     fassert(51197, _engine->dropIdent(opCtx, indexIdent));
                     indexesToDrop.push_back(indexName);
                     continue;
                 }
 
-                log() << "Expected background index build did not complete, rebuilding. "
-                         "Collection: "
-                      << coll << " Index: " << indexName;
+                LOGV2("Expected background index build did not complete, rebuilding. "
+                         "Collection: {} Index: {}", "coll"_attr = coll, "indexName"_attr = indexName);
                 ret.indexesToRebuild.push_back({entry.catalogId, coll, indexName});
                 continue;
             }
@@ -498,8 +492,7 @@ StatusWith<StorageEngine::ReconcileResult> StorageEngineImpl::reconcileCatalogAn
             // index when it replays the oplog. In these cases the index entry in the catalog
             // should be dropped.
             if (!indexMetaData.ready && !indexMetaData.isBackgroundSecondaryBuild) {
-                log() << "Dropping unfinished index. Collection: " << coll
-                      << " Index: " << indexName;
+                LOGV2("Dropping unfinished index. Collection: {} Index: {}", "coll"_attr = coll, "indexName"_attr = indexName);
                 // Ensure the `ident` is dropped while we have the `indexIdent` value.
                 fassert(50713, _engine->dropIdent(opCtx, indexIdent));
                 indexesToDrop.push_back(indexName);
@@ -520,7 +513,7 @@ StatusWith<StorageEngine::ReconcileResult> StorageEngineImpl::reconcileCatalogAn
     }
 
     for (auto&& temp : internalIdentsToDrop) {
-        log() << "Dropping internal ident: " << temp;
+        LOGV2("Dropping internal ident: {}", "temp"_attr = temp);
         WriteUnitOfWork wuow(opCtx);
         fassert(51067, _engine->dropIdent(opCtx, temp));
         wuow.commit();
@@ -725,7 +718,7 @@ std::unique_ptr<TemporaryRecordStore> StorageEngineImpl::makeTemporaryRecordStor
     OperationContext* opCtx) {
     std::unique_ptr<RecordStore> rs =
         _engine->makeTemporaryRecordStore(opCtx, _catalog->newInternalIdent());
-    LOG(1) << "created temporary record store: " << rs->getIdent();
+    LOGV2_DEBUG(1, "created temporary record store: {}", "rs_getIdent"_attr = rs->getIdent());
     return std::make_unique<TemporaryKVRecordStore>(getEngine(), std::move(rs));
 }
 
@@ -794,7 +787,7 @@ StatusWith<Timestamp> StorageEngineImpl::recoverToStableTimestamp(OperationConte
 
     catalog::openCatalog(opCtx, state);
 
-    log() << "recoverToStableTimestamp successful. Stable Timestamp: " << swTimestamp.getValue();
+    LOGV2("recoverToStableTimestamp successful. Stable Timestamp: {}", "swTimestamp_getValue"_attr = swTimestamp.getValue());
     return {swTimestamp.getValue()};
 }
 
@@ -894,8 +887,7 @@ void StorageEngineImpl::_onMinOfCheckpointAndOldestTimestampChanged(const Timest
     // No drop-pending idents present if getEarliestDropTimestamp() returns boost::none.
     if (auto earliestDropTimestamp = _dropPendingIdentReaper.getEarliestDropTimestamp()) {
         if (timestamp > *earliestDropTimestamp) {
-            log() << "Removing drop-pending idents with drop timestamps before timestamp "
-                  << timestamp;
+            LOGV2("Removing drop-pending idents with drop timestamps before timestamp {}", "timestamp"_attr = timestamp);
             auto opCtx = cc().getOperationContext();
             invariant(opCtx);
 
@@ -917,7 +909,7 @@ StorageEngineImpl::TimestampMonitor::TimestampMonitor(KVEngine* engine, Periodic
 }
 
 StorageEngineImpl::TimestampMonitor::~TimestampMonitor() {
-    log() << "Timestamp monitor shutting down";
+    LOGV2("Timestamp monitor shutting down");
     stdx::lock_guard<Latch> lock(_monitorMutex);
     invariant(_listeners.empty());
 }
@@ -925,7 +917,7 @@ StorageEngineImpl::TimestampMonitor::~TimestampMonitor() {
 void StorageEngineImpl::TimestampMonitor::startup() {
     invariant(!_running);
 
-    log() << "Timestamp monitor starting";
+    LOGV2("Timestamp monitor starting");
     PeriodicRunner::PeriodicJob job(
         "TimestampMonitor",
         [&](Client* client) {
@@ -985,7 +977,7 @@ void StorageEngineImpl::TimestampMonitor::startup() {
                 }
             } catch (const ExceptionFor<ErrorCodes::InterruptedAtShutdown>& ex) {
                 // If we're interrupted at shutdown, it's fine to give up on future notifications
-                log() << "Timestamp monitor is stopping due to: " + ex.reason();
+                LOGV2("{}", "Timestamp_monitor_is_stopping_due_to_ex_reason"_attr = "Timestamp monitor is stopping due to: " + ex.reason());
                 return;
             }
         },
diff --git a/src/mongo/db/storage/storage_engine_init.cpp b/src/mongo/db/storage/storage_engine_init.cpp
index 9be4103120..d6f3feded6 100644
--- a/src/mongo/db/storage/storage_engine_init.cpp
+++ b/src/mongo/db/storage/storage_engine_init.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/storage/storage_options.h"
 #include "mongo/db/storage/storage_repair_observer.h"
 #include "mongo/db/unclean_shutdown.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -104,9 +105,7 @@ void initializeStorageEngine(ServiceContext* service, const StorageEngineInitFla
             }
         } else {
             // Otherwise set the active storage engine as the contents of the metadata file.
-            log() << "Detected data files in " << dbpath << " created by the '"
-                  << *existingStorageEngine << "' storage engine, so setting the active"
-                  << " storage engine to '" << *existingStorageEngine << "'.";
+            LOGV2("Detected data files in {} created by the '{}' storage engine, so setting the active storage engine to '{}'.", "dbpath"_attr = dbpath, "existingStorageEngine"_attr = *existingStorageEngine, "existingStorageEngine"_attr = *existingStorageEngine);
             storageGlobalParams.engine = *existingStorageEngine;
         }
     }
diff --git a/src/mongo/db/storage/storage_engine_lock_file_posix.cpp b/src/mongo/db/storage/storage_engine_lock_file_posix.cpp
index c0398eddec..1d107346b5 100644
--- a/src/mongo/db/storage/storage_engine_lock_file_posix.cpp
+++ b/src/mongo/db/storage/storage_engine_lock_file_posix.cpp
@@ -42,6 +42,7 @@
 #include <sys/types.h>
 #include <unistd.h>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 
@@ -56,14 +57,14 @@ void flushMyDirectory(const boost::filesystem::path& file) {
     // so make a warning. need a better solution longer term.
     // massert(40389, str::stream() << "Couldn't find parent dir for file: " << file.string(),);
     if (!file.has_branch_path()) {
-        log() << "warning flushMyDirectory couldn't find parent dir for file: " << file.string();
+        LOGV2("warning flushMyDirectory couldn't find parent dir for file: {}", "file_string"_attr = file.string());
         return;
     }
 
 
     boost::filesystem::path dir = file.branch_path();  // parent_path in new boosts
 
-    LOG(1) << "flushing directory " << dir.string();
+    LOGV2_DEBUG(1, "flushing directory {}", "dir_string"_attr = dir.string());
 
     int fd = ::open(dir.string().c_str(), O_RDONLY);  // DO NOT THROW OR ASSERT BEFORE CLOSING
     massert(40387,
@@ -74,12 +75,9 @@ void flushMyDirectory(const boost::filesystem::path& file) {
         int e = errno;
         if (e == EINVAL) {  // indicates filesystem does not support synchronization
             if (!_warnedAboutFilesystem) {
-                log() << "\tWARNING: This file system is not supported. For further information"
-                      << " see:" << startupWarningsLog;
-                log() << "\t\t\thttp://dochub.mongodb.org/core/unsupported-filesystems"
-                      << startupWarningsLog;
-                log() << "\t\tPlease notify MongoDB, Inc. if an unlisted filesystem generated "
-                      << "this warning." << startupWarningsLog;
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "\tWARNING: This file system is not supported. For further information see:");
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "\t\t\thttp://dochub.mongodb.org/core/unsupported-filesystems");
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "\t\tPlease notify MongoDB, Inc. if an unlisted filesystem generated this warning.");
                 _warnedAboutFilesystem = true;
             }
         } else {
@@ -225,13 +223,13 @@ void StorageEngineLockFile::clearPidAndUnlock() {
     if (!_lockFileHandle->isValid()) {
         return;
     }
-    log() << "shutdown: removing fs lock...";
+    LOGV2("shutdown: removing fs lock...");
     // This ought to be an unlink(), but Eliot says the last
     // time that was attempted, there was a race condition
     // with StorageEngineLockFile::open().
     if (::ftruncate(_lockFileHandle->_fd, 0)) {
         int errorcode = errno;
-        log() << "couldn't remove fs lock " << errnoWithDescription(errorcode);
+        LOGV2("couldn't remove fs lock {}", "errnoWithDescription_errorcode"_attr = errnoWithDescription(errorcode));
     }
     close();
 }
diff --git a/src/mongo/db/storage/storage_engine_lock_file_windows.cpp b/src/mongo/db/storage/storage_engine_lock_file_windows.cpp
index 4055318d1d..edbef30531 100644
--- a/src/mongo/db/storage/storage_engine_lock_file_windows.cpp
+++ b/src/mongo/db/storage/storage_engine_lock_file_windows.cpp
@@ -38,6 +38,7 @@
 #include <ostream>
 #include <sstream>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 #include "mongo/util/text.h"
@@ -184,13 +185,13 @@ void StorageEngineLockFile::clearPidAndUnlock() {
     if (!_lockFileHandle->isValid()) {
         return;
     }
-    log() << "shutdown: removing fs lock...";
+    LOGV2("shutdown: removing fs lock...");
     // This ought to be an unlink(), but Eliot says the last
     // time that was attempted, there was a race condition
     // with StorageEngineLockFile::open().
     Status status = _truncateFile(_lockFileHandle->_handle);
     if (!status.isOK()) {
-        log() << "couldn't remove fs lock " << status.toString();
+        LOGV2("couldn't remove fs lock {}", "status_toString"_attr = status.toString());
     }
     CloseHandle(_lockFileHandle->_handle);
     _lockFileHandle->clear();
diff --git a/src/mongo/db/storage/storage_engine_metadata.cpp b/src/mongo/db/storage/storage_engine_metadata.cpp
index ecf401f3ee..9280dba702 100644
--- a/src/mongo/db/storage/storage_engine_metadata.cpp
+++ b/src/mongo/db/storage/storage_engine_metadata.cpp
@@ -51,6 +51,7 @@
 #include "mongo/base/data_type_validated.h"
 #include "mongo/db/bson/dotted_path_support.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/object_check.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/file.h"
@@ -219,14 +220,14 @@ void flushMyDirectory(const boost::filesystem::path& file) {
     // so make a warning. need a better solution longer term.
     // massert(13652, str::stream() << "Couldn't find parent dir for file: " << file.string(),);
     if (!file.has_branch_path()) {
-        log() << "warning flushMyDirectory couldn't find parent dir for file: " << file.string();
+        LOGV2("warning flushMyDirectory couldn't find parent dir for file: {}", "file_string"_attr = file.string());
         return;
     }
 
 
     boost::filesystem::path dir = file.branch_path();  // parent_path in new boosts
 
-    LOG(1) << "flushing directory " << dir.string();
+    LOGV2_DEBUG(1, "flushing directory {}", "dir_string"_attr = dir.string());
 
     int fd = ::open(dir.string().c_str(), O_RDONLY);  // DO NOT THROW OR ASSERT BEFORE CLOSING
     massert(13650,
@@ -237,12 +238,9 @@ void flushMyDirectory(const boost::filesystem::path& file) {
         int e = errno;
         if (e == EINVAL) {  // indicates filesystem does not support synchronization
             if (!_warnedAboutFilesystem) {
-                log() << "\tWARNING: This file system is not supported. For further information"
-                      << " see:" << startupWarningsLog;
-                log() << "\t\t\thttp://dochub.mongodb.org/core/unsupported-filesystems"
-                      << startupWarningsLog;
-                log() << "\t\tPlease notify MongoDB, Inc. if an unlisted filesystem generated "
-                      << "this warning." << startupWarningsLog;
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "\tWARNING: This file system is not supported. For further information see:");
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "\t\t\thttp://dochub.mongodb.org/core/unsupported-filesystems");
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "\t\tPlease notify MongoDB, Inc. if an unlisted filesystem generated this warning.");
                 _warnedAboutFilesystem = true;
             }
         } else {
diff --git a/src/mongo/db/storage/storage_file_util.cpp b/src/mongo/db/storage/storage_file_util.cpp
index dd47a85642..ee967a8853 100644
--- a/src/mongo/db/storage/storage_file_util.cpp
+++ b/src/mongo/db/storage/storage_file_util.cpp
@@ -42,6 +42,7 @@
 
 #include <boost/filesystem/path.hpp>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/file.h"
 #include "mongo/util/log.h"
 
@@ -67,7 +68,7 @@ Status fsyncParentDirectory(const boost::filesystem::path& file) {
 
     boost::filesystem::path dir = file.parent_path();
 
-    LOG(1) << "flushing directory " << dir.string();
+    LOGV2_DEBUG(1, "flushing directory {}", "dir_string"_attr = dir.string());
 
     int fd = ::open(dir.string().c_str(), O_RDONLY);
     if (fd < 0) {
diff --git a/src/mongo/db/storage/storage_repair_observer_test.cpp b/src/mongo/db/storage/storage_repair_observer_test.cpp
index b9bb17e818..e79d81574a 100644
--- a/src/mongo/db/storage/storage_repair_observer_test.cpp
+++ b/src/mongo/db/storage/storage_repair_observer_test.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/repl/replication_coordinator_mock.h"
 #include "mongo/db/service_context_d_test_fixture.h"
 #include "mongo/db/storage/storage_repair_observer.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/death_test.h"
 #include "mongo/unittest/unittest.h"
 
@@ -107,9 +108,9 @@ public:
         }
 
         if (repairObserver->isDone() && repairObserver->isDataInvalidated()) {
-            unittest::log() << "Modifications: ";
+            unittest::LOGV2("Modifications: ");
             for (const auto& mod : repairObserver->getModifications()) {
-                unittest::log() << "  " << mod.getDescription();
+                unittest::LOGV2("  {}", "mod_getDescription"_attr = mod.getDescription());
             }
         }
     }
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_global_options.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_global_options.cpp
index 7e708bfded..c23b0fd7e1 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_global_options.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_global_options.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/db/storage/wiredtiger/wiredtiger_global_options.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace moe = mongo::optionenvironment;
@@ -49,15 +50,15 @@ Status WiredTigerGlobalOptions::store(const moe::Environment& params) {
     }
 
     if (!wiredTigerGlobalOptions.engineConfig.empty()) {
-        log() << "Engine custom option: " << wiredTigerGlobalOptions.engineConfig;
+        LOGV2("Engine custom option: {}", "wiredTigerGlobalOptions_engineConfig"_attr = wiredTigerGlobalOptions.engineConfig);
     }
 
     if (!wiredTigerGlobalOptions.collectionConfig.empty()) {
-        log() << "Collection custom option: " << wiredTigerGlobalOptions.collectionConfig;
+        LOGV2("Collection custom option: {}", "wiredTigerGlobalOptions_collectionConfig"_attr = wiredTigerGlobalOptions.collectionConfig);
     }
 
     if (!wiredTigerGlobalOptions.indexConfig.empty()) {
-        log() << "Index custom option: " << wiredTigerGlobalOptions.indexConfig;
+        LOGV2("Index custom option: {}", "wiredTigerGlobalOptions_indexConfig"_attr = wiredTigerGlobalOptions.indexConfig);
     }
 
     return Status::OK();
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_init.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_init.cpp
index ee9c8ea602..7c3af88b69 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_init.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_init.cpp
@@ -51,6 +51,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_record_store.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_server_status.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/processinfo.h"
 
@@ -79,13 +80,11 @@ public:
             int ret = statfs(params.dbpath.c_str(), &fs_stats);
 
             if (ret == 0 && fs_stats.f_type == EXT4_SUPER_MAGIC) {
-                log() << startupWarningsLog;
-                log() << "** WARNING: Using the XFS filesystem is strongly recommended with the "
-                         "WiredTiger storage engine"
-                      << startupWarningsLog;
-                log() << "**          See "
-                         "http://dochub.mongodb.org/core/prodnotes-filesystem"
-                      << startupWarningsLog;
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: Using the XFS filesystem is strongly recommended with the "
+                         "WiredTiger storage engine");
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          See "
+                         "http://dochub.mongodb.org/core/prodnotes-filesystem");
             }
         }
 #endif
@@ -95,13 +94,10 @@ public:
         ProcessInfo p;
         if (p.supported()) {
             if (cacheMB > memoryThresholdPercentage * p.getMemSizeMB()) {
-                log() << startupWarningsLog;
-                log() << "** WARNING: The configured WiredTiger cache size is more than "
-                      << memoryThresholdPercentage * 100 << "% of available RAM."
-                      << startupWarningsLog;
-                log() << "**          See "
-                         "http://dochub.mongodb.org/core/faq-memory-diagnostics-wt"
-                      << startupWarningsLog;
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "");
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "** WARNING: The configured WiredTiger cache size is more than {}% of available RAM.", "memoryThresholdPercentage_100"_attr = memoryThresholdPercentage * 100);
+                LOGV2_OPTIONS({logv2::LogTag::kStartupWarnings}, "**          See "
+                         "http://dochub.mongodb.org/core/faq-memory-diagnostics-wt");
             }
         }
         const bool ephemeral = false;
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine.cpp
index 5f06686a2d..77de02a073 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine.cpp
@@ -82,6 +82,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_recovery_unit.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_session_cache.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_size_storer.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/util/background.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
@@ -195,7 +196,7 @@ public:
 
     virtual void run() {
         ThreadClient tc(name(), getGlobalServiceContext());
-        LOG(1) << "starting " << name() << " thread";
+        LOGV2_DEBUG(1, "starting {} thread", "name"_attr = name());
 
         while (!_shuttingDown.load()) {
             {
@@ -208,7 +209,7 @@ public:
             _sessionCache->closeExpiredIdleSessions(gWiredTigerSessionCloseIdleTimeSecs.load() *
                                                     1000);
         }
-        LOG(1) << "stopping " << name() << " thread";
+        LOGV2_DEBUG(1, "stopping {} thread", "name"_attr = name());
     }
 
     void shutdown() {
@@ -243,7 +244,7 @@ public:
 
     virtual void run() {
         ThreadClient tc(name(), getGlobalServiceContext());
-        LOG(1) << "starting " << name() << " thread";
+        LOGV2_DEBUG(1, "starting {} thread", "name"_attr = name());
 
         while (true) {
             auto opCtx = tc->makeOperationContext();
@@ -269,7 +270,7 @@ public:
             _flushJournalNow = false;
 
             if (_shuttingDown) {
-                LOG(1) << "stopping " << name() << " thread";
+                LOGV2_DEBUG(1, "stopping {} thread", "name"_attr = name());
                 return;
             }
         }
@@ -367,7 +368,7 @@ public:
 
     virtual void run() {
         ThreadClient tc(name(), getGlobalServiceContext());
-        LOG(1) << "starting " << name() << " thread";
+        LOGV2_DEBUG(1, "starting {} thread", "name"_attr = name());
 
         while (!_shuttingDown.load()) {
             auto opCtx = tc->makeOperationContext();
@@ -460,7 +461,7 @@ public:
 
                 const auto secondsElapsed = durationCount<Seconds>(Date_t::now() - startTime);
                 if (secondsElapsed >= 30) {
-                    LOG(1) << "Checkpoint took " << secondsElapsed << " seconds to complete.";
+                    LOGV2_DEBUG(1, "Checkpoint took {} seconds to complete.", "secondsElapsed"_attr = secondsElapsed);
                 }
             } catch (const WriteConflictException&) {
                 // Temporary: remove this after WT-3483
@@ -469,7 +470,7 @@ public:
                 invariant(ErrorCodes::isShutdownError(exc.code()), exc.what());
             }
         }
-        LOG(1) << "stopping " << name() << " thread";
+        LOGV2_DEBUG(1, "stopping {} thread", "name"_attr = name());
     }
 
     /**
@@ -495,8 +496,7 @@ public:
         invariant(!_hasTriggeredFirstStableCheckpoint);
         if (prevStable < initialData && currStable >= initialData) {
             _hasTriggeredFirstStableCheckpoint = true;
-            log() << "Triggering the first stable checkpoint. Initial Data: " << initialData
-                  << " PrevStable: " << prevStable << " CurrStable: " << currStable;
+            LOGV2("Triggering the first stable checkpoint. Initial Data: {} PrevStable: {} CurrStable: {}", "initialData"_attr = initialData, "prevStable"_attr = prevStable, "currStable"_attr = currStable);
             stdx::unique_lock<Latch> lock(_mutex);
             _condvar.notify_one();
         }
@@ -659,7 +659,7 @@ WiredTigerKVEngine::WiredTigerKVEngine(const std::string& canonicalName,
             try {
                 boost::filesystem::create_directory(journalPath);
             } catch (std::exception& e) {
-                log() << "error creating journal dir " << journalPath.string() << ' ' << e.what();
+                LOGV2("error creating journal dir {} {}", "journalPath_string"_attr = journalPath.string(), "e_what"_attr = e.what());
                 throw;
             }
         }
@@ -724,8 +724,8 @@ WiredTigerKVEngine::WiredTigerKVEngine(const std::string& canonicalName,
         // the normal path without the journal.
         if (boost::filesystem::exists(journalPath)) {
             string config = ss.str();
-            log() << "Detected WT journal files.  Running recovery from last checkpoint.";
-            log() << "journal to nojournal transition config: " << config;
+            LOGV2("Detected WT journal files.  Running recovery from last checkpoint.");
+            LOGV2("journal to nojournal transition config: {}", "config"_attr = config);
             int ret = wiredtiger_open(
                 path.c_str(), _eventHandler.getWtEventHandler(), config.c_str(), &_conn);
             if (ret == EINVAL) {
@@ -748,7 +748,7 @@ WiredTigerKVEngine::WiredTigerKVEngine(const std::string& canonicalName,
     }
 
     string config = ss.str();
-    log() << "wiredtiger_open config: " << config;
+    LOGV2("wiredtiger_open config: {}", "config"_attr = config);
     _openWiredTiger(path, config);
     _eventHandler.setStartupSuccessful();
     _wtOpenConfig = config;
@@ -790,7 +790,7 @@ WiredTigerKVEngine::WiredTigerKVEngine(const std::string& canonicalName,
     _sizeStorerUri = _uri("sizeStorer");
     WiredTigerSession session(_conn);
     if (!_readOnly && repair && _hasUri(session.getSession(), _sizeStorerUri)) {
-        log() << "Repairing size cache";
+        LOGV2("Repairing size cache");
 
         auto status = _salvageIfNeeded(_sizeStorerUri.c_str());
         if (status.code() != ErrorCodes::DataModifiedByRepair)
@@ -906,7 +906,7 @@ void WiredTigerKVEngine::_openWiredTiger(const std::string& path, const std::str
 }
 
 void WiredTigerKVEngine::cleanShutdown() {
-    log() << "WiredTigerKVEngine shutting down";
+    LOGV2("WiredTigerKVEngine shutting down");
     if (!_readOnly)
         syncSizeInfo(true);
     if (!_conn) {
@@ -915,19 +915,19 @@ void WiredTigerKVEngine::cleanShutdown() {
 
     // these must be the last things we do before _conn->close();
     if (_sessionSweeper) {
-        log() << "Shutting down session sweeper thread";
+        LOGV2("Shutting down session sweeper thread");
         _sessionSweeper->shutdown();
-        log() << "Finished shutting down session sweeper thread";
+        LOGV2("Finished shutting down session sweeper thread");
     }
     if (_journalFlusher) {
-        log() << "Shutting down journal flusher thread";
+        LOGV2("Shutting down journal flusher thread");
         _journalFlusher->shutdown();
-        log() << "Finished shutting down journal flusher thread";
+        LOGV2("Finished shutting down journal flusher thread");
     }
     if (_checkpointThread) {
-        log() << "Shutting down checkpoint thread";
+        LOGV2("Shutting down checkpoint thread");
         _checkpointThread->shutdown();
-        log() << "Finished shutting down checkpoint thread";
+        LOGV2("Finished shutting down checkpoint thread");
     }
     LOG_FOR_RECOVERY(2) << "Shutdown timestamps. StableTimestamp: " << _stableTimestamp.load()
                         << " Initial data timestamp: " << _initialDataTimestamp.load();
@@ -953,12 +953,12 @@ void WiredTigerKVEngine::cleanShutdown() {
     }
 
     if (_fileVersion.shouldDowngrade(_readOnly, _inRepairMode, !_recoveryTimestamp.isNull())) {
-        log() << "Downgrading WiredTiger datafiles.";
+        LOGV2("Downgrading WiredTiger datafiles.");
         invariantWTOK(_conn->close(_conn, closeConfig.c_str()));
 
         invariantWTOK(wiredtiger_open(
             _path.c_str(), _eventHandler.getWtEventHandler(), _wtOpenConfig.c_str(), &_conn));
-        LOG(1) << "Downgrade compatibility configuration: " << _fileVersion.getDowngradeString();
+        LOGV2_DEBUG(1, "Downgrade compatibility configuration: {}", "_fileVersion_getDowngradeString"_attr = _fileVersion.getDowngradeString());
         invariantWTOK(_conn->reconfigure(_conn, _fileVersion.getDowngradeString().c_str()));
     }
 
@@ -1004,7 +1004,7 @@ Status WiredTigerKVEngine::_salvageIfNeeded(const char* uri) {
 
     int rc = (session->verify)(session, uri, nullptr);
     if (rc == 0) {
-        log() << "Verify succeeded on uri " << uri << ". Not salvaging.";
+        LOGV2("Verify succeeded on uri {}. Not salvaging.", "uri"_attr = uri);
         return Status::OK();
     }
 
@@ -1026,7 +1026,7 @@ Status WiredTigerKVEngine::_salvageIfNeeded(const char* uri) {
         return _rebuildIdent(session, uri);
     }
 
-    log() << "Verify failed on uri " << uri << ". Running a salvage operation.";
+    LOGV2("Verify failed on uri {}. Running a salvage operation.", "uri"_attr = uri);
     auto status = wtRCToStatus(session->salvage(session, uri, nullptr), "Salvage failed:");
     if (status.isOK()) {
         return {ErrorCodes::DataModifiedByRepair, str::stream() << "Salvaged data for " << uri};
@@ -1078,13 +1078,13 @@ Status WiredTigerKVEngine::_rebuildIdent(WT_SESSION* session, const char* uri) {
         error() << "Failed to create " << uri << " with config: " << swMetadata.getValue();
         return wtRCToStatus(rc);
     }
-    log() << "Successfully re-created " << uri << ".";
+    LOGV2("Successfully re-created {}.", "uri"_attr = uri);
     return {ErrorCodes::DataModifiedByRepair,
             str::stream() << "Re-created empty data file for " << uri};
 }
 
 int WiredTigerKVEngine::flushAllFiles(OperationContext* opCtx, bool sync) {
-    LOG(1) << "WiredTigerKVEngine::flushAllFiles";
+    LOGV2_DEBUG(1, "WiredTigerKVEngine::flushAllFiles");
     if (_ephemeral) {
         return 0;
     }
@@ -1256,8 +1256,7 @@ Status WiredTigerKVEngine::createGroupedRecordStore(OperationContext* opCtx,
 
     string uri = _uri(ident);
     WT_SESSION* s = session.getSession();
-    LOG(2) << "WiredTigerKVEngine::createRecordStore ns: " << ns << " uri: " << uri
-           << " config: " << config;
+    LOGV2_DEBUG(2, "WiredTigerKVEngine::createRecordStore ns: {} uri: {} config: {}", "ns"_attr = ns, "uri"_attr = uri, "config"_attr = config);
     return wtRCToStatus(s->create(s, uri.c_str(), config.c_str()));
 }
 
@@ -1285,21 +1284,21 @@ Status WiredTigerKVEngine::recoverOrphanedIdent(OperationContext* opCtx,
     boost::filesystem::path tmpFile{*identFilePath};
     tmpFile += ".tmp";
 
-    log() << "Renaming data file " + identFilePath->string() + " to temporary file " +
-            tmpFile.string();
+    LOGV2("{}", "Renaming_data_file_identFilePath_string_to_temporary_file_tmpFile_string"_attr = "Renaming data file " + identFilePath->string() + " to temporary file " +
+            tmpFile.string());
     auto status = fsyncRename(identFilePath.get(), tmpFile);
     if (!status.isOK()) {
         return status;
     }
 
-    log() << "Creating new RecordStore for collection " << nss << " with UUID: " << options.uuid;
+    LOGV2("Creating new RecordStore for collection {} with UUID: {}", "nss"_attr = nss, "options_uuid"_attr = options.uuid);
 
     status = createGroupedRecordStore(opCtx, nss.ns(), ident, options, KVPrefix::kNotPrefixed);
     if (!status.isOK()) {
         return status;
     }
 
-    log() << "Moving orphaned data file back as " + identFilePath->string();
+    LOGV2("{}", "Moving_orphaned_data_file_back_as_identFilePath_string"_attr = "Moving orphaned data file back as " + identFilePath->string());
 
     boost::filesystem::remove(*identFilePath, ec);
     if (ec) {
@@ -1315,7 +1314,7 @@ Status WiredTigerKVEngine::recoverOrphanedIdent(OperationContext* opCtx,
         return status;
     }
 
-    log() << "Salvaging ident " + ident;
+    LOGV2("{}", "Salvaging_ident_ident"_attr = "Salvaging ident " + ident);
 
     WiredTigerSession sessionWrapper(_conn);
     WT_SESSION* session = sessionWrapper.getSession();
@@ -1417,8 +1416,7 @@ Status WiredTigerKVEngine::createGroupedSortedDataInterface(OperationContext* op
 
     std::string config = result.getValue();
 
-    LOG(2) << "WiredTigerKVEngine::createSortedDataInterface ns: " << collection->ns()
-           << " ident: " << ident << " config: " << config;
+    LOGV2_DEBUG(2, "WiredTigerKVEngine::createSortedDataInterface ns: {} ident: {} config: {}", "collection_ns"_attr = collection->ns(), "ident"_attr = ident, "config"_attr = config);
     return wtRCToStatus(WiredTigerIndex::Create(opCtx, _uri(ident), config));
 }
 
@@ -1447,8 +1445,7 @@ std::unique_ptr<RecordStore> WiredTigerKVEngine::makeTemporaryRecordStore(Operat
 
     std::string uri = _uri(ident);
     WT_SESSION* session = wtSession.getSession();
-    LOG(2) << "WiredTigerKVEngine::createTemporaryRecordStore uri: " << uri
-           << " config: " << config;
+    LOGV2_DEBUG(2, "WiredTigerKVEngine::createTemporaryRecordStore uri: {} config: {}", "uri"_attr = uri, "config"_attr = config);
     uassertStatusOK(wtRCToStatus(session->create(session, uri.c_str(), config.c_str())));
 
     WiredTigerRecordStore::Params params;
@@ -1485,7 +1482,7 @@ Status WiredTigerKVEngine::dropIdent(OperationContext* opCtx, StringData ident)
 
     int ret = session.getSession()->drop(
         session.getSession(), uri.c_str(), "force,checkpoint_wait=false");
-    LOG(1) << "WT drop of " << uri << " res " << ret;
+    LOGV2_DEBUG(1, "WT drop of {} res {}", "uri"_attr = uri, "ret"_attr = ret);
 
     if (ret == 0) {
         // yay, it worked
@@ -1567,7 +1564,7 @@ void WiredTigerKVEngine::dropSomeQueuedIdents() {
     if (tenPercentQueue > 10)
         numToDelete = tenPercentQueue;
 
-    LOG(1) << "WT Queue is: " << numInQueue << " attempting to drop: " << numToDelete << " tables";
+    LOGV2_DEBUG(1, "WT Queue is: {} attempting to drop: {} tables", "numInQueue"_attr = numInQueue, "numToDelete"_attr = numToDelete);
     for (int i = 0; i < numToDelete; i++) {
         string uri;
         {
@@ -1579,7 +1576,7 @@ void WiredTigerKVEngine::dropSomeQueuedIdents() {
         }
         int ret = session.getSession()->drop(
             session.getSession(), uri.c_str(), "force,checkpoint_wait=false");
-        LOG(1) << "WT queued drop of  " << uri << " res " << ret;
+        LOGV2_DEBUG(1, "WT queued drop of  {} res {}", "uri"_attr = uri, "ret"_attr = ret);
 
         if (ret == EBUSY) {
             stdx::lock_guard<Latch> lk(_identToDropMutex);
@@ -1673,7 +1670,7 @@ void WiredTigerKVEngine::_ensureIdentPath(StringData ident) {
         boost::filesystem::path subdir = _path;
         subdir /= dir.toString();
         if (!boost::filesystem::exists(subdir)) {
-            LOG(1) << "creating subdirectory: " << dir;
+            LOGV2_DEBUG(1, "creating subdirectory: {}", "dir"_attr = dir);
             try {
                 boost::filesystem::create_directory(subdir);
             } catch (const std::exception& e) {
@@ -1778,14 +1775,14 @@ void WiredTigerKVEngine::setOldestTimestamp(Timestamp newOldestTimestamp, bool f
                 newOldestTimestamp.asULL());
         invariantWTOK(_conn->set_timestamp(_conn, oldestTSConfigString.c_str()));
         _oldestTimestamp.store(newOldestTimestamp.asULL());
-        LOG(2) << "oldest_timestamp and commit_timestamp force set to " << newOldestTimestamp;
+        LOGV2_DEBUG(2, "oldest_timestamp and commit_timestamp force set to {}", "newOldestTimestamp"_attr = newOldestTimestamp);
     } else {
         auto oldestTSConfigString = "oldest_timestamp={:x}"_format(newOldestTimestamp.asULL());
         invariantWTOK(_conn->set_timestamp(_conn, oldestTSConfigString.c_str()));
         // set_timestamp above ignores backwards in time if 'force' is not set.
         if (_oldestTimestamp.load() < newOldestTimestamp.asULL())
             _oldestTimestamp.store(newOldestTimestamp.asULL());
-        LOG(2) << "oldest_timestamp set to " << newOldestTimestamp;
+        LOGV2_DEBUG(2, "oldest_timestamp set to {}", "newOldestTimestamp"_attr = newOldestTimestamp);
     }
 }
 
@@ -1820,7 +1817,7 @@ Timestamp WiredTigerKVEngine::_calculateHistoryLagFromStableTimestamp(Timestamp
 }
 
 void WiredTigerKVEngine::setInitialDataTimestamp(Timestamp initialDataTimestamp) {
-    LOG(2) << "Setting initial data timestamp. Value: " << initialDataTimestamp;
+    LOGV2_DEBUG(2, "Setting initial data timestamp. Value: {}", "initialDataTimestamp"_attr = initialDataTimestamp);
     _initialDataTimestamp.store(initialDataTimestamp.asULL());
 }
 
@@ -1965,7 +1962,7 @@ StatusWith<Timestamp> WiredTigerKVEngine::getOplogNeededForRollback() const {
         if (status.isOK()) {
             oldestActiveTransactionTimestamp.swap(status.getValue());
         } else {
-            LOG(1) << "getting oldest active transaction timestamp: " << status.getStatus();
+            LOGV2_DEBUG(1, "getting oldest active transaction timestamp: {}", "status_getStatus"_attr = status.getStatus());
             return status.getStatus();
         }
     }
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine_test.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine_test.cpp
index 76ab123904..ccccab8905 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine_test.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_kv_engine_test.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_kv_engine.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_record_store.h"
 #include "mongo/logger/logger.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/temp_dir.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/clock_source_mock.h"
@@ -294,8 +295,7 @@ TEST_F(WiredTigerKVEngineTest, TestOplogTruncation) {
             sleepmillis(100);
         }
 
-        unittest::log() << "Expected the pinned oplog to advance. Expected value: " << newPinned
-                        << " Published value: " << _engine->getOplogNeededForCrashRecovery();
+        unittest::LOGV2("Expected the pinned oplog to advance. Expected value: {} Published value: {}", "newPinned"_attr = newPinned, "_engine_getOplogNeededForCrashRecovery"_attr = _engine->getOplogNeededForCrashRecovery());
         FAIL("");
     };
 
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_oplog_manager.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_oplog_manager.cpp
index 8d4599d5e3..7105762dfa 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_oplog_manager.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_oplog_manager.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_kv_engine.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_oplog_manager.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/log.h"
@@ -69,7 +70,7 @@ void WiredTigerOplogManager::start(OperationContext* opCtx,
         // rollback before servicing oplog reads.
         auto oplogVisibility = Timestamp(lastRecord->id.repr());
         setOplogReadTimestamp(oplogVisibility);
-        LOG(1) << "Setting oplog visibility at startup. Val: " << oplogVisibility;
+        LOGV2_DEBUG(1, "Setting oplog visibility at startup. Val: {}", "oplogVisibility"_attr = oplogVisibility);
     } else {
         // Avoid setting oplog visibility to 0. That means "everything is visible".
         setOplogReadTimestamp(Timestamp(kMinimumTimestamp));
@@ -115,7 +116,7 @@ void WiredTigerOplogManager::waitForAllEarlierOplogWritesToBeVisible(
         oplogRecordStore->getCursor(opCtx, false /* false = reverse cursor */);
     auto lastRecord = cursor->next();
     if (!lastRecord) {
-        LOG(2) << "Trying to query an empty oplog";
+        LOGV2_DEBUG(2, "Trying to query an empty oplog");
         opCtx->recoveryUnit()->abandonSnapshot();
         return;
     }
@@ -133,9 +134,7 @@ void WiredTigerOplogManager::waitForAllEarlierOplogWritesToBeVisible(
     opCtx->waitForConditionOrInterrupt(_opsBecameVisibleCV, lk, [&] {
         auto newLatestVisibleTimestamp = getOplogReadTimestamp();
         if (newLatestVisibleTimestamp < currentLatestVisibleTimestamp) {
-            LOG(1) << "Oplog latest visible timestamp went backwards. newLatestVisibleTimestamp: "
-                   << Timestamp(newLatestVisibleTimestamp) << " currentLatestVisibleTimestamp: "
-                   << Timestamp(currentLatestVisibleTimestamp);
+            LOGV2_DEBUG(1, "Oplog latest visible timestamp went backwards. newLatestVisibleTimestamp: {} currentLatestVisibleTimestamp: {}", "Timestamp_newLatestVisibleTimestamp"_attr = Timestamp(newLatestVisibleTimestamp), "Timestamp_currentLatestVisibleTimestamp"_attr = Timestamp(currentLatestVisibleTimestamp));
             // If the visibility went backwards, this means a rollback occurred.
             // Thus, we are finished waiting.
             return true;
@@ -215,7 +214,7 @@ void WiredTigerOplogManager::_oplogJournalThreadLoop(WiredTigerSessionCache* ses
         }
 
         if (_shuttingDown) {
-            log() << "Oplog journal thread loop shutting down";
+            LOGV2("Oplog journal thread loop shutting down");
             return;
         }
         invariant(_opsWaitingForJournal);
@@ -228,7 +227,7 @@ void WiredTigerOplogManager::_oplogJournalThreadLoop(WiredTigerSessionCache* ses
         // where we commit data file changes separately from oplog changes, so ignore
         // a non-incrementing timestamp.
         if (newTimestamp <= _oplogReadTimestamp.load()) {
-            LOG(2) << "No new oplog entries were made visible: " << Timestamp(newTimestamp);
+            LOGV2_DEBUG(2, "No new oplog entries were made visible: {}", "Timestamp_newTimestamp"_attr = Timestamp(newTimestamp));
             continue;
         }
 
@@ -277,7 +276,7 @@ void WiredTigerOplogManager::setOplogReadTimestamp(Timestamp ts) {
 void WiredTigerOplogManager::_setOplogReadTimestamp(WithLock, uint64_t newTimestamp) {
     _oplogReadTimestamp.store(newTimestamp);
     _opsBecameVisibleCV.notify_all();
-    LOG(2) << "Setting new oplogReadTimestamp: " << Timestamp(newTimestamp);
+    LOGV2_DEBUG(2, "Setting new oplogReadTimestamp: {}", "Timestamp_newTimestamp"_attr = Timestamp(newTimestamp));
 }
 
 uint64_t WiredTigerOplogManager::fetchAllDurableValue(WT_CONNECTION* conn) {
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_parameters.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_parameters.cpp
index d2a25c55a4..33b0317d1e 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_parameters.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_parameters.cpp
@@ -32,6 +32,7 @@
 
 #include "mongo/db/storage/wiredtiger/wiredtiger_parameters_gen.h"
 #include "mongo/logger/parse_log_component_settings.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 
@@ -50,7 +51,7 @@ Status applyMaxCacheOverflowSizeGBParameter(WiredTigerMaxCacheOverflowSizeGBPara
 
     const auto valueMB = static_cast<size_t>(1024 * value);
 
-    log() << "Reconfiguring WiredTiger max cache overflow size with value: \"" << valueMB << "MB\'";
+    LOGV2("Reconfiguring WiredTiger max cache overflow size with value: \"{}MB\'", "valueMB"_attr = valueMB);
 
     invariant(param._data.second);
     int ret = param._data.second->reconfigure(
@@ -85,7 +86,7 @@ Status WiredTigerEngineRuntimeConfigParameter::setFromString(const std::string&
                        << pos));
     }
 
-    log() << "Reconfiguring WiredTiger storage engine with config string: \"" << str << "\"";
+    LOGV2("Reconfiguring WiredTiger storage engine with config string: \"{}\"", "str"_attr = str);
 
     invariant(_data.second);
     int ret = _data.second->reconfigure(str.c_str());
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_prepare_conflict.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_prepare_conflict.cpp
index c5533e62ed..856b938d5d 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_prepare_conflict.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_prepare_conflict.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/db/storage/wiredtiger/wiredtiger_prepare_conflict.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 
@@ -46,12 +47,11 @@ MONGO_FAIL_POINT_DEFINE(WTSkipPrepareConflictRetries);
 MONGO_FAIL_POINT_DEFINE(WTPrintPrepareConflictLog);
 
 void wiredTigerPrepareConflictLog(int attempts) {
-    LOG(1) << "Caught WT_PREPARE_CONFLICT, attempt " << attempts
-           << ". Waiting for unit of work to commit or abort.";
+    LOGV2_DEBUG(1, "Caught WT_PREPARE_CONFLICT, attempt {}. Waiting for unit of work to commit or abort.", "attempts"_attr = attempts);
 }
 
 void wiredTigerPrepareConflictFailPointLog() {
-    log() << "WTPrintPrepareConflictLog fail point enabled.";
+    LOGV2("WTPrintPrepareConflictLog fail point enabled.");
 }
 
 }  // namespace mongo
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_record_store.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_record_store.cpp
index efe60ad665..8e839851ab 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_record_store.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_record_store.cpp
@@ -61,6 +61,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_recovery_unit.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_session_cache.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/fail_point.h"
@@ -260,7 +261,7 @@ void WiredTigerRecordStore::OplogStones::createNewStoneIfNeeded(RecordId lastRec
         return;
     }
 
-    LOG(2) << "create new oplogStone, current stones:" << _stones.size();
+    LOGV2_DEBUG(2, "create new oplogStone, current stones:{}", "_stones_size"_attr = _stones.size());
     OplogStones::Stone stone = {_currentRecords.swap(0), _currentBytes.swap(0), lastRecord};
     _stones.push_back(stone);
 
@@ -324,14 +325,13 @@ void WiredTigerRecordStore::OplogStones::_calculateStones(OperationContext* opCt
     const std::uint64_t startWaitTime = curTimeMicros64();
     ON_BLOCK_EXIT([&] {
         auto waitTime = curTimeMicros64() - startWaitTime;
-        log() << "WiredTiger record store oplog processing took " << waitTime / 1000 << "ms";
+        LOGV2("WiredTiger record store oplog processing took {}ms", "waitTime_1000"_attr = waitTime / 1000);
         _totalTimeProcessing.fetchAndAdd(waitTime);
     });
     long long numRecords = _rs->numRecords(opCtx);
     long long dataSize = _rs->dataSize(opCtx);
 
-    log() << "The size storer reports that the oplog contains " << numRecords
-          << " records totaling to " << dataSize << " bytes";
+    LOGV2("The size storer reports that the oplog contains {} records totaling to {} bytes", "numRecords"_attr = numRecords, "dataSize"_attr = dataSize);
 
     // Don't calculate stones if this is a new collection. This is to prevent standalones from
     // attempting to get a forward scanning oplog cursor on an explicit create of the oplog
@@ -365,7 +365,7 @@ void WiredTigerRecordStore::OplogStones::_calculateStones(OperationContext* opCt
 
 void WiredTigerRecordStore::OplogStones::_calculateStonesByScanning(OperationContext* opCtx) {
     _processBySampling.store(false);  // process by scanning
-    log() << "Scanning the oplog to determine where to place markers for truncation";
+    LOGV2("Scanning the oplog to determine where to place markers for truncation");
 
     long long numRecords = 0;
     long long dataSize = 0;
@@ -375,8 +375,7 @@ void WiredTigerRecordStore::OplogStones::_calculateStonesByScanning(OperationCon
         _currentRecords.addAndFetch(1);
         int64_t newCurrentBytes = _currentBytes.addAndFetch(record->data.size());
         if (newCurrentBytes >= _minBytesPerStone) {
-            LOG(1) << "Placing a marker at optime "
-                   << Timestamp(record->id.repr()).toStringPretty();
+            LOGV2_DEBUG(1, "Placing a marker at optime {}", "Timestamp_record_id_repr_toStringPretty"_attr = Timestamp(record->id.repr()).toStringPretty());
 
             OplogStones::Stone stone = {_currentRecords.swap(0), _currentBytes.swap(0), record->id};
             _stones.push_back(stone);
@@ -392,7 +391,7 @@ void WiredTigerRecordStore::OplogStones::_calculateStonesByScanning(OperationCon
 void WiredTigerRecordStore::OplogStones::_calculateStonesBySampling(OperationContext* opCtx,
                                                                     int64_t estRecordsPerStone,
                                                                     int64_t estBytesPerStone) {
-    log() << "Sampling the oplog to determine where to place markers for truncation";
+    LOGV2("Sampling the oplog to determine where to place markers for truncation");
     _processBySampling.store(true);  // process by sampling
     Timestamp earliestOpTime;
     Timestamp latestOpTime;
@@ -404,7 +403,7 @@ void WiredTigerRecordStore::OplogStones::_calculateStonesBySampling(OperationCon
         if (!record) {
             // This shouldn't really happen unless the size storer values are far off from reality.
             // The collection is probably empty, but fall back to scanning the oplog just in case.
-            log() << "Failed to determine the earliest optime, falling back to scanning the oplog";
+            LOGV2("Failed to determine the earliest optime, falling back to scanning the oplog");
             _calculateStonesByScanning(opCtx);
             return;
         }
@@ -418,22 +417,19 @@ void WiredTigerRecordStore::OplogStones::_calculateStonesBySampling(OperationCon
         if (!record) {
             // This shouldn't really happen unless the size storer values are far off from reality.
             // The collection is probably empty, but fall back to scanning the oplog just in case.
-            log() << "Failed to determine the latest optime, falling back to scanning the oplog";
+            LOGV2("Failed to determine the latest optime, falling back to scanning the oplog");
             _calculateStonesByScanning(opCtx);
             return;
         }
         latestOpTime = Timestamp(record->id.repr());
     }
 
-    log() << "Sampling from the oplog between " << earliestOpTime.toStringPretty() << " and "
-          << latestOpTime.toStringPretty() << " to determine where to place markers for truncation";
+    LOGV2("Sampling from the oplog between {} and {} to determine where to place markers for truncation", "earliestOpTime_toStringPretty"_attr = earliestOpTime.toStringPretty(), "latestOpTime_toStringPretty"_attr = latestOpTime.toStringPretty());
 
     int64_t wholeStones = _rs->numRecords(opCtx) / estRecordsPerStone;
     int64_t numSamples = kRandomSamplesPerStone * _rs->numRecords(opCtx) / estRecordsPerStone;
 
-    log() << "Taking " << numSamples << " samples and assuming that each section of oplog contains"
-          << " approximately " << estRecordsPerStone << " records totaling to " << estBytesPerStone
-          << " bytes";
+    LOGV2("Taking {} samples and assuming that each section of oplog contains approximately {} records totaling to {} bytes", "numSamples"_attr = numSamples, "estRecordsPerStone"_attr = estRecordsPerStone, "estBytesPerStone"_attr = estBytesPerStone);
 
     // Inform the random cursor of the number of samples we intend to take. This allows it to
     // account for skew in the tree shape.
@@ -450,7 +446,7 @@ void WiredTigerRecordStore::OplogStones::_calculateStonesBySampling(OperationCon
         if (!record) {
             // This shouldn't really happen unless the size storer values are far off from reality.
             // The collection is probably empty, but fall back to scanning the oplog just in case.
-            log() << "Failed to get enough random samples, falling back to scanning the oplog";
+            LOGV2("Failed to get enough random samples, falling back to scanning the oplog");
             _calculateStonesByScanning(opCtx);
             return;
         }
@@ -464,7 +460,7 @@ void WiredTigerRecordStore::OplogStones::_calculateStonesBySampling(OperationCon
         int sampleIndex = kRandomSamplesPerStone * i - 1;
         RecordId lastRecord = oplogEstimates[sampleIndex];
 
-        log() << "Placing a marker at optime " << Timestamp(lastRecord.repr()).toStringPretty();
+        LOGV2("Placing a marker at optime {}", "Timestamp_lastRecord_repr_toStringPretty"_attr = Timestamp(lastRecord.repr()).toStringPretty());
         OplogStones::Stone stone = {estRecordsPerStone, estBytesPerStone, lastRecord};
         _stones.push_back(stone);
     }
@@ -741,9 +737,9 @@ WiredTigerRecordStore::~WiredTigerRecordStore() {
     }
 
     if (!isTemp()) {
-        LOG(1) << "~WiredTigerRecordStore for: " << ns();
+        LOGV2_DEBUG(1, "~WiredTigerRecordStore for: {}", "ns"_attr = ns());
     } else {
-        LOG(1) << "~WiredTigerRecordStore for temporary ident: " << getIdent();
+        LOGV2_DEBUG(1, "~WiredTigerRecordStore for temporary ident: {}", "getIdent"_attr = getIdent());
     }
 
     if (_oplogStones) {
@@ -1148,7 +1144,7 @@ int64_t WiredTigerRecordStore::_cappedDeleteAsNeeded_inlock(OperationContext* op
 
             if (ret == ENOENT || ret == WT_NOTFOUND) {
                 // TODO we should remove this case once SERVER-17141 is resolved
-                log() << "Soft failure truncating capped collection. Will try again later.";
+                LOGV2("Soft failure truncating capped collection. Will try again later.");
                 docsRemoved = 0;
             } else {
                 invariantWTOK(ret);
@@ -1162,7 +1158,7 @@ int64_t WiredTigerRecordStore::_cappedDeleteAsNeeded_inlock(OperationContext* op
     } catch (const WriteConflictException&) {
         opCtx->releaseRecoveryUnit();
         opCtx->setRecoveryUnit(std::unique_ptr<RecoveryUnit>(realRecoveryUnit), realRUstate);
-        log() << "got conflict truncating capped, ignoring";
+        LOGV2("got conflict truncating capped, ignoring");
         return 0;
     } catch (...) {
         opCtx->releaseRecoveryUnit();
@@ -1217,9 +1213,7 @@ void WiredTigerRecordStore::reclaimOplog(OperationContext* opCtx, Timestamp mayT
             return;
         }
 
-        LOG(1) << "Truncating the oplog between " << _oplogStones->firstRecord << " and "
-               << stone->lastRecord << " to remove approximately " << stone->records
-               << " records totaling to " << stone->bytes << " bytes";
+        LOGV2_DEBUG(1, "Truncating the oplog between {} and {} to remove approximately {} records totaling to {} bytes", "_oplogStones_firstRecord"_attr = _oplogStones->firstRecord, "stone_lastRecord"_attr = stone->lastRecord, "stone_records"_attr = stone->records, "stone_bytes"_attr = stone->bytes);
 
         WiredTigerRecoveryUnit* ru = WiredTigerRecoveryUnit::get(opCtx);
         WT_SESSION* session = ru->getSession()->getSession();
@@ -1252,18 +1246,16 @@ void WiredTigerRecordStore::reclaimOplog(OperationContext* opCtx, Timestamp mayT
             // Stash the truncate point for next time to cleanly skip over tombstones, etc.
             _oplogStones->firstRecord = stone->lastRecord;
         } catch (const WriteConflictException&) {
-            LOG(1) << "Caught WriteConflictException while truncating oplog entries, retrying";
+            LOGV2_DEBUG(1, "Caught WriteConflictException while truncating oplog entries, retrying");
         }
     }
 
-    LOG(1) << "Finished truncating the oplog, it now contains approximately "
-           << _sizeInfo->numRecords.load() << " records totaling to " << _sizeInfo->dataSize.load()
-           << " bytes";
+    LOGV2_DEBUG(1, "Finished truncating the oplog, it now contains approximately {} records totaling to {} bytes", "_sizeInfo_numRecords_load"_attr = _sizeInfo->numRecords.load(), "_sizeInfo_dataSize_load"_attr = _sizeInfo->dataSize.load());
     auto elapsedMicros = timer.micros();
     auto elapsedMillis = elapsedMicros / 1000;
     _totalTimeTruncating.fetchAndAdd(elapsedMicros);
     _truncateCount.fetchAndAdd(1);
-    log() << "WiredTiger record store oplog truncation finished in: " << elapsedMillis << "ms";
+    LOGV2("WiredTiger record store oplog truncation finished in: {}ms", "elapsedMillis"_attr = elapsedMillis);
 }
 
 Status WiredTigerRecordStore::insertRecords(OperationContext* opCtx,
@@ -1326,7 +1318,7 @@ Status WiredTigerRecordStore::_insertRecords(OperationContext* opCtx,
             ts = timestamps[i];
         }
         if (!ts.isNull()) {
-            LOG(4) << "inserting record with timestamp " << ts;
+            LOGV2_DEBUG(4, "inserting record with timestamp {}", "ts"_attr = ts);
             fassert(39001, opCtx->recoveryUnit()->setTimestamp(ts));
         }
         setKey(c, record.id);
@@ -1722,7 +1714,7 @@ public:
     NumRecordsChange(WiredTigerRecordStore* rs, int64_t diff) : _rs(rs), _diff(diff) {}
     virtual void commit(boost::optional<Timestamp>) {}
     virtual void rollback() {
-        LOG(3) << "WiredTigerRecordStore: rolling back NumRecordsChange " << -_diff;
+        LOGV2_DEBUG(3, "WiredTigerRecordStore: rolling back NumRecordsChange {}", "_diff"_attr = -_diff);
         _rs->_sizeInfo->numRecords.fetchAndAdd(-_diff);
     }
 
@@ -1856,7 +1848,7 @@ void WiredTigerRecordStore::cappedTruncateAfter(OperationContext* opCtx,
         }
 
         _kvEngine->getOplogManager()->setOplogReadTimestamp(truncTs);
-        LOG(1) << "truncation new read timestamp: " << truncTs;
+        LOGV2_DEBUG(1, "truncation new read timestamp: {}", "truncTs"_attr = truncTs);
     }
 
     if (_oplogStones) {
@@ -1936,9 +1928,7 @@ boost::optional<Record> WiredTigerRecordStoreCursorBase::next() {
     }
 
     if (_forward && _lastReturnedId >= id) {
-        log() << "WTCursor::next -- c->next_key ( " << id
-              << ") was not greater than _lastReturnedId (" << _lastReturnedId
-              << ") which is a bug.";
+        LOGV2("WTCursor::next -- c->next_key ( {}) was not greater than _lastReturnedId ({}) which is a bug.", "id"_attr = id, "_lastReturnedId"_attr = _lastReturnedId);
 
         // Crash when test commands are enabled.
         invariant(!getTestCommandsEnabled());
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_recovery_unit.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_recovery_unit.cpp
index 3bd2c4ba21..36b6f1046f 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_recovery_unit.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_recovery_unit.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_prepare_conflict.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_session_cache.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/hex.h"
 #include "mongo/util/log.h"
 
@@ -221,7 +222,7 @@ void WiredTigerRecoveryUnit::prepareUnitOfWork() {
     auto session = getSession();
     WT_SESSION* s = session->getSession();
 
-    LOG(1) << "preparing transaction at time: " << _prepareTimestamp;
+    LOGV2_DEBUG(1, "preparing transaction at time: {}", "_prepareTimestamp"_attr = _prepareTimestamp);
 
     const std::string conf = "prepare_timestamp=" + integerToHex(_prepareTimestamp.asULL());
     // Prepare the transaction.
@@ -322,9 +323,7 @@ void WiredTigerRecoveryUnit::_txnClose(bool commit) {
         // `serverGlobalParams.slowMs` can be set to values <= 0. In those cases, give logging a
         // break.
         if (transactionTime >= std::max(1, serverGlobalParams.slowMS)) {
-            LOG(kSlowTransactionSeverity)
-                << "Slow WT transaction. Lifetime of SnapshotId " << getSnapshotId().toNumber()
-                << " was " << transactionTime << "ms";
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(kSlowTransactionSeverity).toInt(), "Slow WT transaction. Lifetime of SnapshotId {} was {}ms", "getSnapshotId_toNumber"_attr = getSnapshotId().toNumber(), "transactionTime"_attr = transactionTime);
         }
     }
 
@@ -349,11 +348,11 @@ void WiredTigerRecoveryUnit::_txnClose(bool commit) {
         }
 
         wtRet = s->commit_transaction(s, conf.str().c_str());
-        LOG(3) << "WT commit_transaction for snapshot id " << getSnapshotId().toNumber();
+        LOGV2_DEBUG(3, "WT commit_transaction for snapshot id {}", "getSnapshotId_toNumber"_attr = getSnapshotId().toNumber());
     } else {
         wtRet = s->rollback_transaction(s, nullptr);
         invariant(!wtRet);
-        LOG(3) << "WT rollback_transaction for snapshot id " << getSnapshotId().toNumber();
+        LOGV2_DEBUG(3, "WT rollback_transaction for snapshot id {}", "getSnapshotId_toNumber"_attr = getSnapshotId().toNumber());
     }
 
     if (_isTimestamped) {
@@ -529,7 +528,7 @@ void WiredTigerRecoveryUnit::_txnOpen() {
         }
     }
 
-    LOG(3) << "WT begin_transaction for snapshot id " << getSnapshotId().toNumber();
+    LOGV2_DEBUG(3, "WT begin_transaction for snapshot id {}", "getSnapshotId_toNumber"_attr = getSnapshotId().toNumber());
 }
 
 Timestamp WiredTigerRecoveryUnit::_beginTransactionAtAllDurableTimestamp(WT_SESSION* session) {
@@ -605,7 +604,7 @@ Timestamp WiredTigerRecoveryUnit::_getTransactionReadTimestamp(WT_SESSION* sessi
 
 Status WiredTigerRecoveryUnit::setTimestamp(Timestamp timestamp) {
     _ensureSession();
-    LOG(3) << "WT set timestamp of future write operations to " << timestamp;
+    LOGV2_DEBUG(3, "WT set timestamp of future write operations to {}", "timestamp"_attr = timestamp);
     WT_SESSION* session = _session->getSession();
     invariant(_inUnitOfWork(), toString(getState()));
     invariant(_prepareTimestamp.isNull());
@@ -732,8 +731,7 @@ void WiredTigerRecoveryUnit::setRoundUpPreparedTimestamps(bool value) {
 
 void WiredTigerRecoveryUnit::setTimestampReadSource(ReadSource readSource,
                                                     boost::optional<Timestamp> provided) {
-    LOG(3) << "setting timestamp read source: " << static_cast<int>(readSource)
-           << ", provided timestamp: " << ((provided) ? provided->toString() : "none");
+    LOGV2_DEBUG(3, "setting timestamp read source: {}, provided timestamp: {}", "static_cast_int_readSource"_attr = static_cast<int>(readSource), "provided_provided_toString_none"_attr = ((provided) ? provided->toString() : "none"));
 
     invariant(!_isActive() || _timestampReadSource == readSource,
               str::stream() << "Current state: " << toString(getState())
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_session_cache.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_session_cache.cpp
index d56d6ebbf6..4a10f1b4b7 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_session_cache.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_session_cache.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_kv_engine.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_parameters_gen.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -280,7 +281,7 @@ void WiredTigerSessionCache::waitUntilDurable(OperationContext* opCtx,
             }
             _journalListener->onDurable(token);
         }
-        LOG(4) << "created checkpoint (forced)";
+        LOGV2_DEBUG(4, "created checkpoint (forced)");
         return;
     }
 
@@ -311,12 +312,12 @@ void WiredTigerSessionCache::waitUntilDurable(OperationContext* opCtx,
     // Use the journal when available, or a checkpoint otherwise.
     if (_engine && _engine->isDurable()) {
         invariantWTOK(_waitUntilDurableSession->log_flush(_waitUntilDurableSession, "sync=on"));
-        LOG(4) << "flushed journal";
+        LOGV2_DEBUG(4, "flushed journal");
     } else {
         auto checkpointLock = _engine->getCheckpointLock(opCtx);
         _engine->clearIndividuallyCheckpointedIndexesList();
         invariantWTOK(_waitUntilDurableSession->checkpoint(_waitUntilDurableSession, nullptr));
-        LOG(4) << "created checkpoint";
+        LOGV2_DEBUG(4, "created checkpoint");
     }
     _journalListener->onDurable(token);
 }
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_size_storer.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_size_storer.cpp
index e0847eb044..8bd7a6c5bc 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_size_storer.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_size_storer.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_session_cache.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_size_storer.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
 
@@ -82,9 +83,7 @@ void WiredTigerSizeStorer::store(StringData uri, std::shared_ptr<SizeInfo> sizeI
         entry->_dirty.store(false);
     entry = sizeInfo;
     entry->_dirty.store(true);
-    LOG(2) << "WiredTigerSizeStorer::store Marking " << uri
-           << " dirty, numRecords: " << sizeInfo->numRecords.load()
-           << ", dataSize: " << sizeInfo->dataSize.load() << ", use_count: " << entry.use_count();
+    LOGV2_DEBUG(2, "WiredTigerSizeStorer::store Marking {} dirty, numRecords: {}, dataSize: {}, use_count: {}", "uri"_attr = uri, "sizeInfo_numRecords_load"_attr = sizeInfo->numRecords.load(), "sizeInfo_dataSize_load"_attr = sizeInfo->dataSize.load(), "entry_use_count"_attr = entry.use_count());
 }
 
 std::shared_ptr<WiredTigerSizeStorer::SizeInfo> WiredTigerSizeStorer::load(StringData uri) const {
@@ -115,7 +114,7 @@ std::shared_ptr<WiredTigerSizeStorer::SizeInfo> WiredTigerSizeStorer::load(Strin
     invariantWTOK(_cursor->get_value(_cursor, &value));
     BSONObj data(reinterpret_cast<const char*>(value.data));
 
-    LOG(2) << "WiredTigerSizeStorer::load " << uri << " -> " << redact(data);
+    LOGV2_DEBUG(2, "WiredTigerSizeStorer::load {} -> {}", "uri"_attr = uri, "redact_data"_attr = redact(data));
     return std::make_shared<SizeInfo>(data["numRecords"].safeNumberLong(),
                                       data["dataSize"].safeNumberLong());
 }
@@ -157,7 +156,7 @@ void WiredTigerSizeStorer::flush(bool syncToDisk) {
                                              << sizeInfo.dataSize.load());
 
             auto& uri = it->first;
-            LOG(2) << "WiredTigerSizeStorer::flush " << uri << " -> " << redact(data);
+            LOGV2_DEBUG(2, "WiredTigerSizeStorer::flush {} -> {}", "uri"_attr = uri, "redact_data"_attr = redact(data));
             WiredTigerItem key(uri.c_str(), uri.size());
             WiredTigerItem value(data.objdata(), data.objsize());
             _cursor->set_key(_cursor, key.Get());
@@ -170,6 +169,6 @@ void WiredTigerSizeStorer::flush(bool syncToDisk) {
     }
 
     auto micros = t.micros();
-    LOG(2) << "WiredTigerSizeStorer flush took " << micros << " s";
+    LOGV2_DEBUG(2, "WiredTigerSizeStorer flush took {} s", "micros"_attr = micros);
 }
 }  // namespace mongo
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_snapshot_manager.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_snapshot_manager.cpp
index dd7c6ce52b..85ed113fba 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_snapshot_manager.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_snapshot_manager.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_begin_transaction_block.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_oplog_manager.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_util.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -101,7 +102,7 @@ Timestamp WiredTigerSnapshotManager::beginTransactionOnLocalSnapshot(
 
     stdx::lock_guard<Latch> lock(_localSnapshotMutex);
     invariant(_localSnapshot);
-    LOG(3) << "begin_transaction on local snapshot " << _localSnapshot.get().toString();
+    LOGV2_DEBUG(3, "begin_transaction on local snapshot {}", "_localSnapshot_get_toString"_attr = _localSnapshot.get().toString());
     auto status = txnOpen.setReadSnapshot(_localSnapshot.get());
     fassert(50775, status);
 
diff --git a/src/mongo/db/storage/wiredtiger/wiredtiger_util.cpp b/src/mongo/db/storage/wiredtiger/wiredtiger_util.cpp
index cdb40992c2..bc93b694d5 100644
--- a/src/mongo/db/storage/wiredtiger/wiredtiger_util.cpp
+++ b/src/mongo/db/storage/wiredtiger/wiredtiger_util.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/storage/wiredtiger/wiredtiger_kv_engine.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_recovery_unit.h"
 #include "mongo/db/storage/wiredtiger/wiredtiger_session_cache.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/processinfo.h"
@@ -291,9 +292,7 @@ StatusWith<int64_t> WiredTigerUtil::checkApplicationMetadataFormatVersion(Operat
                                     << " has unsupported format version: " << version << ".");
     }
 
-    LOG(2) << "WiredTigerUtil::checkApplicationMetadataFormatVersion "
-           << " uri: " << uri << " ok range " << minimumVersion << " -> " << maximumVersion
-           << " current: " << version;
+    LOGV2_DEBUG(2, "WiredTigerUtil::checkApplicationMetadataFormatVersion  uri: {} ok range {} -> {} current: {}", "uri"_attr = uri, "minimumVersion"_attr = minimumVersion, "maximumVersion"_attr = maximumVersion, "version"_attr = version);
 
     return version;
 }
@@ -452,7 +451,7 @@ int mdb_handle_error(WT_EVENT_HANDLER* handler,
 
 int mdb_handle_message(WT_EVENT_HANDLER* handler, WT_SESSION* session, const char* message) {
     try {
-        log() << "WiredTiger message " << redact(message);
+        LOGV2("WiredTiger message {}", "redact_message"_attr = redact(message));
     } catch (...) {
         std::terminate();
     }
@@ -464,7 +463,7 @@ int mdb_handle_progress(WT_EVENT_HANDLER* handler,
                         const char* operation,
                         uint64_t progress) {
     try {
-        log() << "WiredTiger progress " << redact(operation) << " " << progress;
+        LOGV2("WiredTiger progress {} {}", "redact_operation"_attr = redact(operation), "progress"_attr = progress);
     } catch (...) {
         std::terminate();
     }
@@ -603,7 +602,7 @@ Status WiredTigerUtil::setTableLogging(WT_SESSION* session, const std::string& u
         return Status::OK();
     }
 
-    LOG(1) << "Changing table logging settings. Uri: " << uri << " Enable? " << on;
+    LOGV2_DEBUG(1, "Changing table logging settings. Uri: {} Enable? {}", "uri"_attr = uri, "on"_attr = on);
     int ret = session->alter(session, uri.c_str(), setting.c_str());
     if (ret) {
         severe() << "Failed to update log setting. Uri: " << uri << " Enable? " << on
diff --git a/src/mongo/db/system_index.cpp b/src/mongo/db/system_index.cpp
index dfafa0e46a..e0fed6ee04 100644
--- a/src/mongo/db/system_index.cpp
+++ b/src/mongo/db/system_index.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/index_builds_coordinator.h"
 #include "mongo/db/jsobj.h"
 #include "mongo/db/storage/storage_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -106,8 +107,7 @@ void generateSystemIndexForExistingCollection(OperationContext* opCtx,
             opCtx, spec.toBSON(), serverGlobalParams.featureCompatibility);
         BSONObj indexSpec = fassert(40452, indexSpecStatus);
 
-        log() << "No authorization index detected on " << ns
-              << " collection. Attempting to recover by creating an index with spec: " << indexSpec;
+        LOGV2("No authorization index detected on {} collection. Attempting to recover by creating an index with spec: {}", "ns"_attr = ns, "indexSpec"_attr = indexSpec);
 
         auto indexConstraints = IndexBuildsManager::IndexConstraints::kEnforce;
         auto fromMigrate = false;
diff --git a/src/mongo/db/transaction_participant.cpp b/src/mongo/db/transaction_participant.cpp
index 77adb5d915..e18ee1af76 100644
--- a/src/mongo/db/transaction_participant.cpp
+++ b/src/mongo/db/transaction_participant.cpp
@@ -63,6 +63,7 @@
 #include "mongo/db/stats/fill_locker_info.h"
 #include "mongo/db/transaction_history_iterator.h"
 #include "mongo/db/transaction_participant_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/socket_utils.h"
@@ -652,9 +653,8 @@ TransactionParticipant::OplogSlotReserver::OplogSlotReserver(OperationContext* o
 
 TransactionParticipant::OplogSlotReserver::~OplogSlotReserver() {
     if (MONGO_unlikely(hangBeforeReleasingTransactionOplogHole.shouldFail())) {
-        log()
-            << "transaction - hangBeforeReleasingTransactionOplogHole fail point enabled. Blocking "
-               "until fail point is disabled.";
+        LOGV2("transaction - hangBeforeReleasingTransactionOplogHole fail point enabled. Blocking "
+               "until fail point is disabled.");
         hangBeforeReleasingTransactionOplogHole.pauseWhileSet();
     }
 
@@ -1130,9 +1130,8 @@ Timestamp TransactionParticipant::Participant::prepareTransaction(
 
         if (MONGO_unlikely(hangAfterReservingPrepareTimestamp.shouldFail())) {
             // This log output is used in js tests so please leave it.
-            log() << "transaction - hangAfterReservingPrepareTimestamp fail point "
-                     "enabled. Blocking until fail point is disabled. Prepare OpTime: "
-                  << prepareOplogSlot;
+            LOGV2("transaction - hangAfterReservingPrepareTimestamp fail point "
+                     "enabled. Blocking until fail point is disabled. Prepare OpTime: {}", "prepareOplogSlot"_attr = prepareOplogSlot);
             hangAfterReservingPrepareTimestamp.pauseWhileSet();
         }
     }
@@ -1158,8 +1157,8 @@ Timestamp TransactionParticipant::Participant::prepareTransaction(
     }
 
     if (MONGO_unlikely(hangAfterSettingPrepareStartTime.shouldFail())) {
-        log() << "transaction - hangAfterSettingPrepareStartTime fail point enabled. Blocking "
-                 "until fail point is disabled.";
+        LOGV2("transaction - hangAfterSettingPrepareStartTime fail point enabled. Blocking "
+                 "until fail point is disabled.");
         hangAfterSettingPrepareStartTime.pauseWhileSet();
     }
 
@@ -1901,9 +1900,7 @@ void TransactionParticipant::Participant::_logSlowTransaction(
         if (shouldLog(logger::LogComponent::kTransaction, logger::LogSeverity::Debug(1)) ||
             o().transactionMetricsObserver.getSingleTransactionStats().getDuration(
                 tickSource, tickSource->getTicks()) > Milliseconds(serverGlobalParams.slowMS)) {
-            log(logger::LogComponent::kTransaction)
-                << "transaction "
-                << _transactionInfoForLog(opCtx, lockStats, terminationCause, readConcernArgs);
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(logger::LogComponent::kTransaction).toInt(), "transaction {}", "_transactionInfoForLog_opCtx_lockStats_terminationCause_readConcernArgs"_attr = _transactionInfoForLog(opCtx, lockStats, terminationCause, readConcernArgs));
         }
     }
 }
diff --git a/src/mongo/db/ttl.cpp b/src/mongo/db/ttl.cpp
index be0ca3fd9c..709830e6e8 100644
--- a/src/mongo/db/ttl.cpp
+++ b/src/mongo/db/ttl.cpp
@@ -54,6 +54,7 @@
 #include "mongo/db/storage/durable_catalog.h"
 #include "mongo/db/ttl_collection_cache.h"
 #include "mongo/db/ttl_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/background.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/exit.h"
@@ -96,26 +97,26 @@ public:
                 sleepsecs(ttlMonitorSleepSecs.load());
             }
 
-            LOG(3) << "thread awake";
+            LOGV2_DEBUG(3, "thread awake");
 
             if (!ttlMonitorEnabled.load()) {
-                LOG(1) << "disabled";
+                LOGV2_DEBUG(1, "disabled");
                 continue;
             }
 
             if (lockedForWriting()) {
                 // Note: this is not perfect as you can go into fsync+lock between this and actually
                 // doing the delete later.
-                LOG(3) << "locked for writing";
+                LOGV2_DEBUG(3, "locked for writing");
                 continue;
             }
 
             try {
                 doTTLPass();
             } catch (const WriteConflictException&) {
-                LOG(1) << "got WriteConflictException";
+                LOGV2_DEBUG(1, "got WriteConflictException");
             } catch (const ExceptionForCat<ErrorCategory::Interruption>& interruption) {
-                LOG(1) << "TTLMonitor was interrupted: " << interruption;
+                LOGV2_DEBUG(1, "TTLMonitor was interrupted: {}", "interruption"_attr = interruption);
             }
         }
     }
@@ -213,11 +214,11 @@ private:
             return;
         }
 
-        LOG(1) << "ns: " << collectionNSS << " key: " << key << " name: " << name;
+        LOGV2_DEBUG(1, "ns: {} key: {} name: {}", "collectionNSS"_attr = collectionNSS, "key"_attr = key, "name"_attr = name);
 
         AutoGetCollection autoGetCollection(opCtx, collectionNSS, MODE_IX);
         if (MONGO_unlikely(hangTTLMonitorWithLock.shouldFail())) {
-            log() << "Hanging due to hangTTLMonitorWithLock fail point";
+            LOGV2("Hanging due to hangTTLMonitorWithLock fail point");
             hangTTLMonitorWithLock.pauseWhileSet(opCtx);
         }
 
@@ -234,8 +235,7 @@ private:
 
         const IndexDescriptor* desc = collection->getIndexCatalog()->findIndexByName(opCtx, name);
         if (!desc) {
-            LOG(1) << "index not found (index build in progress? index dropped?), skipping "
-                   << "ttl job for: " << idx;
+            LOGV2_DEBUG(1, "index not found (index build in progress? index dropped?), skipping ttl job for: {}", "idx"_attr = idx);
             return;
         }
 
@@ -302,7 +302,7 @@ private:
 
         const long long numDeleted = DeleteStage::getNumDeleted(*exec);
         ttlDeletedDocuments.increment(numDeleted);
-        LOG(1) << "deleted: " << numDeleted;
+        LOGV2_DEBUG(1, "deleted: {}", "numDeleted"_attr = numDeleted);
     }
 
     ServiceContext* _serviceContext;
diff --git a/src/mongo/db/views/durable_view_catalog.cpp b/src/mongo/db/views/durable_view_catalog.cpp
index 5d3e410cd4..52d1b1db5a 100644
--- a/src/mongo/db/views/durable_view_catalog.cpp
+++ b/src/mongo/db/views/durable_view_catalog.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/db/storage/record_data.h"
 #include "mongo/db/views/view_catalog.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/unordered_set.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
@@ -195,7 +196,7 @@ void DurableViewCatalogImpl::upsert(OperationContext* opCtx,
 
     Snapshotted<BSONObj> oldView;
     if (!id.isValid() || !systemViews->findDoc(opCtx, id, &oldView)) {
-        LOG(2) << "insert view " << view << " into " << _db->getSystemViewsName();
+        LOGV2_DEBUG(2, "insert view {} into {}", "view"_attr = view, "_db_getSystemViewsName"_attr = _db->getSystemViewsName());
         uassertStatusOK(
             systemViews->insertDocument(opCtx, InsertStatement(view), &CurOp::get(opCtx)->debug()));
     } else {
@@ -225,7 +226,7 @@ void DurableViewCatalogImpl::remove(OperationContext* opCtx, const NamespaceStri
     if (!id.isValid())
         return;
 
-    LOG(2) << "remove view " << name << " from " << _db->getSystemViewsName();
+    LOGV2_DEBUG(2, "remove view {} from {}", "name"_attr = name, "_db_getSystemViewsName"_attr = _db->getSystemViewsName());
     systemViews->deleteDocument(opCtx, kUninitializedStmtId, id, &CurOp::get(opCtx)->debug());
 }
 }  // namespace mongo
diff --git a/src/mongo/db/views/view_catalog.cpp b/src/mongo/db/views/view_catalog.cpp
index 5fce7a5119..efed0f3776 100644
--- a/src/mongo/db/views/view_catalog.cpp
+++ b/src/mongo/db/views/view_catalog.cpp
@@ -55,6 +55,7 @@
 #include "mongo/db/views/resolved_view.h"
 #include "mongo/db/views/view.h"
 #include "mongo/db/views/view_graph.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
 
@@ -94,7 +95,7 @@ Status ViewCatalog::reload(OperationContext* opCtx, ViewCatalogLookupBehavior lo
 Status ViewCatalog::_reload(WithLock,
                             OperationContext* opCtx,
                             ViewCatalogLookupBehavior lookupBehavior) {
-    LOG(1) << "reloading view catalog for database " << _durable->getName();
+    LOGV2_DEBUG(1, "reloading view catalog for database {}", "_durable_getName"_attr = _durable->getName());
 
     _viewMap.clear();
     _valid = false;
@@ -137,8 +138,7 @@ Status ViewCatalog::_reload(WithLock,
         }
     } catch (const DBException& ex) {
         auto status = ex.toStatus();
-        LOG(0) << "could not load view catalog for database " << _durable->getName() << ": "
-               << status;
+        LOGV2("could not load view catalog for database {}: {}", "_durable_getName"_attr = _durable->getName(), "status"_attr = status);
         return status;
     }
 
diff --git a/src/mongo/db/write_concern.cpp b/src/mongo/db/write_concern.cpp
index 2b532fed21..01ae766854 100644
--- a/src/mongo/db/write_concern.cpp
+++ b/src/mongo/db/write_concern.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/stats/timer_stats.h"
 #include "mongo/db/storage/storage_engine.h"
 #include "mongo/db/write_concern_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/protocol.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/log.h"
@@ -93,8 +94,7 @@ StatusWith<WriteConcernOptions> extractWriteConcern(OperationContext* opCtx,
                 auto wcDefault = ReadWriteConcernDefaults::get(opCtx->getServiceContext())
                                      .getDefaultWriteConcern(opCtx);
                 if (wcDefault) {
-                    LOG(2) << "Applying default writeConcern on " << cmdObj.firstElementFieldName()
-                           << " of " << wcDefault->toBSON();
+                    LOGV2_DEBUG(2, "Applying default writeConcern on {} of {}", "cmdObj_firstElementFieldName"_attr = cmdObj.firstElementFieldName(), "wcDefault_toBSON"_attr = wcDefault->toBSON());
                     return *wcDefault;
                 }
             }
@@ -190,8 +190,7 @@ Status waitForWriteConcern(OperationContext* opCtx,
                            const OpTime& replOpTime,
                            const WriteConcernOptions& writeConcern,
                            WriteConcernResult* result) {
-    LOG(2) << "Waiting for write concern. OpTime: " << replOpTime
-           << ", write concern: " << writeConcern.toBSON();
+    LOGV2_DEBUG(2, "Waiting for write concern. OpTime: {}, write concern: {}", "replOpTime"_attr = replOpTime, "writeConcern_toBSON"_attr = writeConcern.toBSON());
 
     auto const replCoord = repl::ReplicationCoordinator::get(opCtx);
 
diff --git a/src/mongo/dbtests/commandtests.cpp b/src/mongo/dbtests/commandtests.cpp
index efce5cb65e..4e0d2275da 100644
--- a/src/mongo/dbtests/commandtests.cpp
+++ b/src/mongo/dbtests/commandtests.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/dbdirectclient.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/op_msg.h"
 
 using namespace mongo;
@@ -177,7 +178,7 @@ public:
 
             BSONObj result;
             bool ok = db.runCommand(nsDb(), cmd.obj(), result);
-            log() << result.jsonString();
+            LOGV2("{}", "result_jsonString"_attr = result.jsonString());
             ASSERT(ok);
         }
     }
@@ -194,7 +195,7 @@ public:
 
         BSONObj result;
         bool ok = db.runCommand(nsDb(), cmd.obj(), result);
-        log() << result.jsonString();
+        LOGV2("{}", "result_jsonString"_attr = result.jsonString());
         ASSERT(ok);
     }
 };
@@ -215,7 +216,7 @@ public:
 
         BSONObj result;
         bool ok = db.runCommand(nsDb(), cmd.obj(), result);
-        log() << result.jsonString();
+        LOGV2("{}", "result_jsonString"_attr = result.jsonString());
         ASSERT(!ok);
     }
 };
@@ -237,7 +238,7 @@ public:
 
         BSONObj result;
         bool ok = db.runCommand(nsDb(), cmd.obj(), result);
-        log() << result.jsonString();
+        LOGV2("{}", "result_jsonString"_attr = result.jsonString());
         ASSERT(!ok);
     }
 };
@@ -262,7 +263,7 @@ public:
 
         BSONObj result;
         bool ok = db.runCommand(nsDb(), cmd.obj(), result);
-        log() << result.jsonString();
+        LOGV2("{}", "result_jsonString"_attr = result.jsonString());
         ASSERT(!ok);
     }
 };
@@ -286,7 +287,7 @@ public:
 
         BSONObj result;
         bool ok = db.runCommand(nsDb(), cmd.obj(), result);
-        log() << result.jsonString();
+        LOGV2("{}", "result_jsonString"_attr = result.jsonString());
         ASSERT(ok);
         // TODO(kangas) test that Tom's score is 1
     }
@@ -336,7 +337,7 @@ public:
 
             BSONObj result;
             bool ok = db.runCommand(nsDb(), cmd.obj(), result);
-            log() << result.jsonString();
+            LOGV2("{}", "result_jsonString"_attr = result.jsonString());
             ASSERT(ok);
         }
     }
diff --git a/src/mongo/dbtests/framework_options.cpp b/src/mongo/dbtests/framework_options.cpp
index d9743cb17b..79e7c4004f 100644
--- a/src/mongo/dbtests/framework_options.cpp
+++ b/src/mongo/dbtests/framework_options.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/storage/flow_control_parameters_gen.h"
 #include "mongo/db/storage/storage_options.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 #include "mongo/util/options_parser/startup_options.h"
@@ -119,7 +120,7 @@ Status storeTestFrameworkOptions(const moe::Environment& params,
     }
 
     if (kDebugBuild)
-        log() << "DEBUG build" << endl;
+        LOGV2("DEBUG build");
 
     string dbpathString = p.string();
     storageGlobalParams.dbpath = dbpathString.c_str();
@@ -128,7 +129,7 @@ Status storeTestFrameworkOptions(const moe::Environment& params,
     gFlowControlEnabled.store(params["enableFlowControl"].as<bool>());
 
     if (gFlowControlEnabled.load()) {
-        log() << "Flow Control enabled" << endl;
+        LOGV2("Flow Control enabled");
     }
 
     if (storageGlobalParams.engine == "wiredTiger" &&
diff --git a/src/mongo/dbtests/jsobjtests.cpp b/src/mongo/dbtests/jsobjtests.cpp
index 08ae278aa1..a8b2f71d28 100644
--- a/src/mongo/dbtests/jsobjtests.cpp
+++ b/src/mongo/dbtests/jsobjtests.cpp
@@ -46,6 +46,7 @@
 #include "mongo/db/jsobj.h"
 #include "mongo/db/json.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/decimal128.h"
 #include "mongo/util/allocator.h"
 #include "mongo/util/embedded_builder.h"
@@ -163,7 +164,7 @@ FieldCompareResult compareDottedFieldNames(const string& l,
             return LEFT_SUBFIELD;
     }
 
-    log() << "compareDottedFieldNames ERROR  l: " << l << " r: " << r << "  TOO MANY LOOPS" << endl;
+    LOGV2("compareDottedFieldNames ERROR  l: {} r: {}  TOO MANY LOOPS", "l"_attr = l, "r"_attr = r);
     verify(0);
     return SAME;  // will never get here
 }
diff --git a/src/mongo/dbtests/jsontests.cpp b/src/mongo/dbtests/jsontests.cpp
index f1b670e6bd..41f2a80dfa 100644
--- a/src/mongo/dbtests/jsontests.cpp
+++ b/src/mongo/dbtests/jsontests.cpp
@@ -45,6 +45,7 @@
 #include "mongo/db/jsobj.h"
 #include "mongo/db/json.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/decimal128.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
@@ -544,14 +545,12 @@ void assertEquals(const std::string& json,
                   const char* msg) {
     const bool bad = expected.woCompare(actual);
     if (bad) {
-        ::mongo::log() << "want:" << expected.jsonString() << " size: " << expected.objsize()
-                       << std::endl;
-        ::mongo::log() << "got :" << actual.jsonString() << " size: " << actual.objsize()
-                       << std::endl;
-        ::mongo::log() << expected.hexDump() << std::endl;
-        ::mongo::log() << actual.hexDump() << std::endl;
-        ::mongo::log() << msg << std::endl;
-        ::mongo::log() << "orig json:" << json;
+        ::mongo::LOGV2("want:{} size: {}", "expected_jsonString"_attr = expected.jsonString(), "expected_objsize"_attr = expected.objsize());
+        ::mongo::LOGV2("got :{} size: {}", "actual_jsonString"_attr = actual.jsonString(), "actual_objsize"_attr = actual.objsize());
+        ::mongo::LOGV2("{}", "expected_hexDump"_attr = expected.hexDump());
+        ::mongo::LOGV2("{}", "actual_hexDump"_attr = actual.hexDump());
+        ::mongo::LOGV2("{}", "msg"_attr = msg);
+        ::mongo::LOGV2("orig json:{}", "json"_attr = json);
     }
     ASSERT(!bad);
 }
diff --git a/src/mongo/dbtests/repltests.cpp b/src/mongo/dbtests/repltests.cpp
index 9b38d9d863..9eeb5c39a0 100644
--- a/src/mongo/dbtests/repltests.cpp
+++ b/src/mongo/dbtests/repltests.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/s/op_observer_sharding_impl.h"
 #include "mongo/dbtests/dbtests.h"
 #include "mongo/logger/logger.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/transport_layer_asio.h"
 #include "mongo/util/log.h"
 
@@ -202,8 +203,7 @@ protected:
     }
     void check(const BSONObj& expected, const BSONObj& got) const {
         if (expected.woCompare(got)) {
-            ::mongo::log() << "expected: " << expected.toString() << ", got: " << got.toString()
-                           << endl;
+            ::mongo::LOGV2("expected: {}, got: {}", "expected_toString"_attr = expected.toString(), "got_toString"_attr = got.toString());
         }
         ASSERT_BSONOBJ_EQ(expected, got);
     }
@@ -252,7 +252,7 @@ protected:
             OldClientContext ctx(&_opCtx, ns());
             for (vector<BSONObj>::iterator i = ops.begin(); i != ops.end(); ++i) {
                 if (0) {
-                    mongo::unittest::log() << "op: " << *i << endl;
+                    mongo::unittest::LOGV2("op: {}", "i"_attr = *i);
                 }
                 repl::UnreplicatedWritesBlock uwb(&_opCtx);
                 auto entry = uassertStatusOK(OplogEntry::parse(*i));
diff --git a/src/mongo/dbtests/storage_timestamp_tests.cpp b/src/mongo/dbtests/storage_timestamp_tests.cpp
index 270a04da7b..e68b78edec 100644
--- a/src/mongo/dbtests/storage_timestamp_tests.cpp
+++ b/src/mongo/dbtests/storage_timestamp_tests.cpp
@@ -80,6 +80,7 @@
 #include "mongo/db/transaction_participant.h"
 #include "mongo/db/transaction_participant_gen.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/future.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/stacktrace.h"
@@ -1524,9 +1525,9 @@ public:
         auto beforeTxnTs = beforeTxnTime.asTimestamp();
         auto commitEntryTs = beforeTxnTime.addTicks(1).asTimestamp();
 
-        unittest::log() << "Present TS: " << presentTs;
-        unittest::log() << "Before transaction TS: " << beforeTxnTs;
-        unittest::log() << "Commit entry TS: " << commitEntryTs;
+        unittest::LOGV2("Present TS: {}", "presentTs"_attr = presentTs);
+        unittest::LOGV2("Before transaction TS: {}", "beforeTxnTs"_attr = beforeTxnTs);
+        unittest::LOGV2("Commit entry TS: {}", "commitEntryTs"_attr = commitEntryTs);
 
         const auto sessionId = makeLogicalSessionIdForTest();
         _opCtx->setLogicalSessionId(sessionId);
@@ -2917,9 +2918,9 @@ public:
     }
 
     void logTimestamps() const {
-        unittest::log() << "Present TS: " << presentTs;
-        unittest::log() << "Before transaction TS: " << beforeTxnTs;
-        unittest::log() << "Commit entry TS: " << commitEntryTs;
+        unittest::LOGV2("Present TS: {}", "presentTs"_attr = presentTs);
+        unittest::LOGV2("Before transaction TS: {}", "beforeTxnTs"_attr = beforeTxnTs);
+        unittest::LOGV2("Commit entry TS: {}", "commitEntryTs"_attr = commitEntryTs);
     }
 
     BSONObj getSessionTxnInfoAtTimestamp(const Timestamp& ts, bool expected) {
@@ -3116,7 +3117,7 @@ public:
     void run() {
         auto txnParticipant = TransactionParticipant::get(_opCtx);
         ASSERT(txnParticipant);
-        unittest::log() << "PrepareTS: " << prepareEntryTs;
+        unittest::LOGV2("PrepareTS: {}", "prepareEntryTs"_attr = prepareEntryTs);
         logTimestamps();
 
         const auto prepareFilter = BSON("ts" << prepareEntryTs);
@@ -3310,8 +3311,8 @@ public:
     void run() {
         auto txnParticipant = TransactionParticipant::get(_opCtx);
         ASSERT(txnParticipant);
-        unittest::log() << "PrepareTS: " << prepareEntryTs;
-        unittest::log() << "AbortTS: " << abortEntryTs;
+        unittest::LOGV2("PrepareTS: {}", "prepareEntryTs"_attr = prepareEntryTs);
+        unittest::LOGV2("AbortTS: {}", "abortEntryTs"_attr = abortEntryTs);
 
         const auto prepareFilter = BSON("ts" << prepareEntryTs);
         const auto abortFilter = BSON("ts" << abortEntryTs);
@@ -3414,7 +3415,7 @@ public:
         const auto currentTime = _clock->getClusterTime();
         const auto prepareTs = currentTime.addTicks(1).asTimestamp();
         commitEntryTs = currentTime.addTicks(2).asTimestamp();
-        unittest::log() << "Prepare TS: " << prepareTs;
+        unittest::LOGV2("Prepare TS: {}", "prepareTs"_attr = prepareTs);
         logTimestamps();
 
         {
@@ -3515,7 +3516,7 @@ public:
         const auto currentTime = _clock->getClusterTime();
         const auto prepareTs = currentTime.addTicks(1).asTimestamp();
         const auto abortEntryTs = currentTime.addTicks(2).asTimestamp();
-        unittest::log() << "Prepare TS: " << prepareTs;
+        unittest::LOGV2("Prepare TS: {}", "prepareTs"_attr = prepareTs);
         logTimestamps();
 
         {
@@ -3610,8 +3611,7 @@ public:
         auto storageEngine = cc().getServiceContext()->getStorageEngine();
         if (!storageEngine->supportsReadConcernSnapshot() ||
             !mongo::serverGlobalParams.enableMajorityReadConcern) {
-            unittest::log() << "Skipping this test suite because storage engine "
-                            << storageGlobalParams.engine << " does not support timestamp writes.";
+            unittest::LOGV2("Skipping this test suite because storage engine {} does not support timestamp writes.", "storageGlobalParams_engine"_attr = storageGlobalParams.engine);
             return true;
         }
         return false;
diff --git a/src/mongo/dbtests/threadedtests.cpp b/src/mongo/dbtests/threadedtests.cpp
index 7395c8d506..c45a70fabe 100644
--- a/src/mongo/dbtests/threadedtests.cpp
+++ b/src/mongo/dbtests/threadedtests.cpp
@@ -38,6 +38,7 @@
 #include "mongo/config.h"
 #include "mongo/db/client.h"
 #include "mongo/dbtests/dbtests.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/platform/bits.h"
 #include "mongo/stdx/thread.h"
@@ -278,7 +279,7 @@ private:
             _hotel.checkOut();
 
             if ((i % (checkIns / 10)) == 0)
-                mongo::unittest::log() << "checked in " << i << " times..." << endl;
+                mongo::unittest::LOGV2("checked in {} times...", "i"_attr = i);
         }
     }
 
diff --git a/src/mongo/dbtests/wildcard_multikey_persistence_test.cpp b/src/mongo/dbtests/wildcard_multikey_persistence_test.cpp
index 25774af37a..a19c01c420 100644
--- a/src/mongo/dbtests/wildcard_multikey_persistence_test.cpp
+++ b/src/mongo/dbtests/wildcard_multikey_persistence_test.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/index/wildcard_access_method.h"
 #include "mongo/db/repl/storage_interface_impl.h"
 #include "mongo/db/storage/sorted_data_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 
@@ -116,9 +117,9 @@ protected:
             // Confirm that there are no further keys in the index.
             ASSERT(!indexKey);
         } catch (const TestAssertionFailureException& ex) {
-            log() << "Writing remaining index keys to debug log:";
+            LOGV2("Writing remaining index keys to debug log:");
             while (indexKey) {
-                log() << "{ key: " << indexKey->key << ", loc: " << indexKey->loc << " }";
+                LOGV2("{ key: {}, loc: {} }", "indexKey_key"_attr = indexKey->key, "indexKey_loc"_attr = indexKey->loc);
                 indexKey = indexCursor->next();
             }
             throw ex;
diff --git a/src/mongo/embedded/embedded.cpp b/src/mongo/embedded/embedded.cpp
index 69911b0fa2..e3feb8b74e 100644
--- a/src/mongo/embedded/embedded.cpp
+++ b/src/mongo/embedded/embedded.cpp
@@ -66,6 +66,7 @@
 #include "mongo/embedded/replication_coordinator_embedded.h"
 #include "mongo/embedded/service_entry_point_embedded.h"
 #include "mongo/logger/log_component.h"
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/dbdirectclient_factory.h"
 #include "mongo/util/background.h"
 #include "mongo/util/exit.h"
@@ -182,7 +183,7 @@ void shutdown(ServiceContext* srvContext) {
     }
     setGlobalServiceContext(nullptr);
 
-    log(LogComponent::kControl) << "now exiting";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kControl).toInt(), "now exiting");
 }
 
 
@@ -226,7 +227,7 @@ ServiceContext* initialize(const char* yaml_config) {
     }
 
     if (kDebugBuild)
-        log(LogComponent::kControl) << "DEBUG build (which is slower)" << endl;
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kControl).toInt(), "DEBUG build (which is slower)");
 
     // The periodic runner is required by the storage engine to be running beforehand.
     auto periodicRunner = std::make_unique<PeriodicRunnerEmbedded>(
@@ -300,7 +301,7 @@ ServiceContext* initialize(const char* yaml_config) {
     }
 
     if (storageGlobalParams.upgrade) {
-        log() << "finished checking dbs";
+        LOGV2("finished checking dbs");
         exitCleanly(EXIT_CLEAN);
     }
 
diff --git a/src/mongo/embedded/mongoc_embedded/mongoc_embedded_test.cpp b/src/mongo/embedded/mongoc_embedded/mongoc_embedded_test.cpp
index 2138c420e2..a13ff794cd 100644
--- a/src/mongo/embedded/mongoc_embedded/mongoc_embedded_test.cpp
+++ b/src/mongo/embedded/mongoc_embedded/mongoc_embedded_test.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/embedded/mongo_embedded/mongo_embedded.h"
 #include "mongo/embedded/mongoc_embedded/mongoc_embedded_test_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/temp_dir.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
@@ -87,7 +88,7 @@ bool insert_data(mongoc_collection_t* collection) {
     bool ret = mongoc_bulk_operation_execute(bulk, NULL, &error);
 
     if (!ret) {
-        ::mongo::log() << "Error inserting data: " << error.message;
+        ::mongo::LOGV2("Error inserting data: {}", "error_message"_attr = error.message);
     }
 
     mongoc_bulk_operation_destroy(bulk);
@@ -118,7 +119,7 @@ bool explain(mongoc_collection_t* collection) {
                        "}");
     res = mongoc_collection_command_simple(collection, command, NULL, &reply, &error);
     if (!res) {
-        ::mongo::log() << "Error with explain: " << error.message;
+        ::mongo::LOGV2("Error with explain: {}", "error_message"_attr = error.message);
         goto explain_cleanup;
     }
 
diff --git a/src/mongo/executor/connection_pool_tl.cpp b/src/mongo/executor/connection_pool_tl.cpp
index c3816eab43..ca37b024ea 100644
--- a/src/mongo/executor/connection_pool_tl.cpp
+++ b/src/mongo/executor/connection_pool_tl.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/client/authenticate.h"
 #include "mongo/db/auth/authorization_manager.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -58,7 +59,7 @@ void TLTypeFactory::shutdown() {
 
     stdx::lock_guard<Latch> lk(_mutex);
 
-    log() << "Killing all outstanding egress activity.";
+    LOGV2("Killing all outstanding egress activity.");
     for (auto collar : _collars) {
         collar->kill();
     }
@@ -94,7 +95,7 @@ void TLTimer::setTimeout(Milliseconds timeoutVal, TimeoutCallback cb) {
     // We will not wait on a timeout if we are in shutdown.
     // The clients will be canceled as an inevitable consequence of pools shutting down.
     if (inShutdown()) {
-        LOG(2) << "Skipping timeout due to impending shutdown.";
+        LOGV2_DEBUG(2, "Skipping timeout due to impending shutdown.");
         return;
     }
 
@@ -273,11 +274,11 @@ void TLConnection::setup(Milliseconds timeout, SetupCallback cb) {
             if (status.isOK()) {
                 handler->promise.emplaceValue();
             } else {
-                LOG(2) << "Failed to connect to " << _peer << " - " << redact(status);
+                LOGV2_DEBUG(2, "Failed to connect to {} - {}", "_peer"_attr = _peer, "redact_status"_attr = redact(status));
                 handler->promise.setError(status);
             }
         });
-    LOG(2) << "Finished connection setup.";
+    LOGV2_DEBUG(2, "Finished connection setup.");
 }
 
 void TLConnection::refresh(Milliseconds timeout, RefreshCallback cb) {
diff --git a/src/mongo/executor/network_interface_integration_fixture.cpp b/src/mongo/executor/network_interface_integration_fixture.cpp
index ad2e31fdb0..9fd1c2b3eb 100644
--- a/src/mongo/executor/network_interface_integration_fixture.cpp
+++ b/src/mongo/executor/network_interface_integration_fixture.cpp
@@ -38,6 +38,7 @@
 #include "mongo/executor/network_interface_integration_fixture.h"
 #include "mongo/executor/remote_command_response.h"
 #include "mongo/executor/task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/stdx/future.h"
 #include "mongo/unittest/integration_test.h"
@@ -109,9 +110,9 @@ RemoteCommandResponse NetworkInterfaceIntegrationFixture::runCommandSync(
     auto deferred = runCommand(makeCallbackHandle(), request);
     auto& res = deferred.get();
     if (res.isOK()) {
-        log() << "got command result: " << res.toString();
+        LOGV2("got command result: {}", "res_toString"_attr = res.toString());
     } else {
-        log() << "command failed: " << res.status;
+        LOGV2("command failed: {}", "res_status"_attr = res.status);
     }
     return res;
 }
diff --git a/src/mongo/executor/network_interface_mock.cpp b/src/mongo/executor/network_interface_mock.cpp
index 86e1144b81..9cf6067dac 100644
--- a/src/mongo/executor/network_interface_mock.cpp
+++ b/src/mongo/executor/network_interface_mock.cpp
@@ -39,6 +39,7 @@
 
 #include "mongo/executor/connection_pool_stats.h"
 #include "mongo/executor/network_connection_hook.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 #include "mongo/util/time_support.h"
@@ -77,9 +78,9 @@ void NetworkInterfaceMock::logQueues() {
             continue;
         }
 
-        log() << "**** queue: " << queue.first << " ****";
+        LOGV2("**** queue: {} ****", "queue_first"_attr = queue.first);
         for (auto&& item : *queue.second) {
-            log() << "\t\t " << item.getDiagnosticString();
+            LOGV2("\t\t {}", "item_getDiagnosticString"_attr = item.getDiagnosticString());
         }
     }
 }
diff --git a/src/mongo/executor/network_interface_perf_test.cpp b/src/mongo/executor/network_interface_perf_test.cpp
index 2f625301df..4026131e26 100644
--- a/src/mongo/executor/network_interface_perf_test.cpp
+++ b/src/mongo/executor/network_interface_perf_test.cpp
@@ -43,6 +43,7 @@
 #include "mongo/executor/network_interface_asio.h"
 #include "mongo/executor/network_interface_asio_test_utils.h"
 #include "mongo/executor/task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/integration_test.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/assert_util.h"
@@ -107,7 +108,7 @@ TEST(NetworkInterfaceASIO, SerialPerf) {
 
     int duration = timeNetworkTestMillis(numOperations, &netAsio);
     int result = numOperations * 1000 / duration;
-    log() << "THROUGHPUT asio ping ops/s: " << result;
+    LOGV2("THROUGHPUT asio ping ops/s: {}", "result"_attr = result);
 }
 
 }  // namespace
diff --git a/src/mongo/executor/network_interface_tl.cpp b/src/mongo/executor/network_interface_tl.cpp
index e932130b00..0d84ca599d 100644
--- a/src/mongo/executor/network_interface_tl.cpp
+++ b/src/mongo/executor/network_interface_tl.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/commands/test_commands_enabled.h"
 #include "mongo/db/server_options.h"
 #include "mongo/executor/connection_pool_tl.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/transport_layer_manager.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/log.h"
@@ -109,7 +110,7 @@ void NetworkInterfaceTL::startup() {
 }
 
 void NetworkInterfaceTL::_run() {
-    LOG(2) << "The NetworkInterfaceTL reactor thread is spinning up";
+    LOGV2_DEBUG(2, "The NetworkInterfaceTL reactor thread is spinning up");
 
     // This returns when the reactor is stopped in shutdown()
     _reactor->run();
@@ -122,14 +123,14 @@ void NetworkInterfaceTL::_run() {
     // Close out all remaining tasks in the reactor now that they've all been canceled.
     _reactor->drain();
 
-    LOG(2) << "NetworkInterfaceTL shutdown successfully";
+    LOGV2_DEBUG(2, "NetworkInterfaceTL shutdown successfully");
 }
 
 void NetworkInterfaceTL::shutdown() {
     if (_state.swap(kStopped) != kStarted)
         return;
 
-    LOG(2) << "Shutting down network interface.";
+    LOGV2_DEBUG(2, "Shutting down network interface.");
 
     // Stop the reactor/thread first so that nothing runs on a partially dtor'd pool.
     _reactor->stop();
@@ -215,7 +216,7 @@ Status NetworkInterfaceTL::startCommand(const TaskExecutor::CallbackHandle& cbHa
         return {ErrorCodes::ShutdownInProgress, "NetworkInterface shutdown in progress"};
     }
 
-    LOG(3) << "startCommand: " << redact(request.toString());
+    LOGV2_DEBUG(3, "startCommand: {}", "redact_request_toString"_attr = redact(request.toString()));
 
     if (_metadataHook) {
         BSONObjBuilder newMetadata(std::move(request.metadata));
@@ -262,8 +263,7 @@ Status NetworkInterfaceTL::startCommand(const TaskExecutor::CallbackHandle& cbHa
     std::move(pf.future)
         .onError([requestId = cmdState->requestOnAny.id](
                      auto error) -> StatusWith<RemoteCommandOnAnyResponse> {
-            LOG(2) << "Failed to get connection from pool for request " << requestId << ": "
-                   << redact(error);
+            LOGV2_DEBUG(2, "Failed to get connection from pool for request {}: {}", "requestId"_attr = requestId, "redact_error"_attr = redact(error));
 
             // The TransportLayer has, for historical reasons returned SocketException
             // for network errors, but sharding assumes HostUnreachable on network
@@ -280,14 +280,13 @@ Status NetworkInterfaceTL::startCommand(const TaskExecutor::CallbackHandle& cbHa
                 onFinish(RemoteCommandOnAnyResponse(boost::none, response.getStatus(), duration));
             } else {
                 const auto& rs = response.getValue();
-                LOG(2) << "Request " << cmdState->requestOnAny.id << " finished with response: "
-                       << redact(rs.isOK() ? rs.data.toString() : rs.status.toString());
+                LOGV2_DEBUG(2, "Request {} finished with response: {}", "cmdState_requestOnAny_id"_attr = cmdState->requestOnAny.id, "redact_rs_isOK_rs_data_toString_rs_status_toString"_attr = redact(rs.isOK() ? rs.data.toString() : rs.status.toString()));
                 onFinish(rs);
             }
         });
 
     if (MONGO_unlikely(networkInterfaceDiscardCommandsBeforeAcquireConn.shouldFail())) {
-        log() << "Discarding command due to failpoint before acquireConn";
+        LOGV2("Discarding command due to failpoint before acquireConn");
         return Status::OK();
     }
 
@@ -312,7 +311,7 @@ Status NetworkInterfaceTL::startCommand(const TaskExecutor::CallbackHandle& cbHa
         cmdState->request.emplace(cmdState->requestOnAny, idx);
 
         if (MONGO_unlikely(networkInterfaceDiscardCommandsAfterAcquireConn.shouldFail())) {
-            log() << "Discarding command due to failpoint after acquireConn";
+            LOGV2("Discarding command due to failpoint after acquireConn");
             return Status::OK();
         }
 
@@ -410,7 +409,7 @@ void NetworkInterfaceTL::_onAcquireConn(std::shared_ptr<CommandState> state,
                     << ", deadline was " << state->deadline.toString() << ", op was "
                     << redact(state->requestOnAny.toString());
 
-                LOG(2) << message;
+                LOGV2_DEBUG(2, "{}", "message"_attr = message);
                 state->promise.setError(
                     Status(ErrorCodes::NetworkInterfaceExceededTimeLimit, message));
 
@@ -588,8 +587,7 @@ void NetworkInterfaceTL::_answerAlarm(Status status, std::shared_ptr<AlarmState>
     // free and allows us to be resilient to a world where timers impls do have spurious wake ups.
     auto currentTime = now();
     if (status.isOK() && currentTime < state->when) {
-        LOG(2) << "Alarm returned early. Expected at: " << state->when
-               << ", fired at: " << currentTime;
+        LOGV2_DEBUG(2, "Alarm returned early. Expected at: {}, fired at: {}", "state_when"_attr = state->when, "currentTime"_attr = currentTime);
         state->timer->waitUntil(state->when, nullptr)
             .getAsync([this, state = std::move(state)](Status status) mutable {
                 _answerAlarm(status, state);
diff --git a/src/mongo/executor/thread_pool_mock.cpp b/src/mongo/executor/thread_pool_mock.cpp
index fb809990e4..d3ddba1323 100644
--- a/src/mongo/executor/thread_pool_mock.cpp
+++ b/src/mongo/executor/thread_pool_mock.cpp
@@ -34,6 +34,7 @@
 #include "mongo/executor/thread_pool_mock.h"
 
 #include "mongo/executor/network_interface_mock.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -52,7 +53,7 @@ ThreadPoolMock::~ThreadPoolMock() {
 }
 
 void ThreadPoolMock::startup() {
-    LOG(1) << "Starting pool";
+    LOGV2_DEBUG(1, "Starting pool");
     stdx::lock_guard<Latch> lk(_mutex);
     invariant(!_started);
     invariant(!_worker.joinable());
@@ -61,7 +62,7 @@ void ThreadPoolMock::startup() {
         _options.onCreateThread();
         stdx::unique_lock<Latch> lk(_mutex);
 
-        LOG(1) << "Starting to consume tasks";
+        LOGV2_DEBUG(1, "Starting to consume tasks");
         while (!_joining) {
             if (_tasks.empty()) {
                 lk.unlock();
@@ -72,7 +73,7 @@ void ThreadPoolMock::startup() {
 
             _consumeOneTask(lk);
         }
-        LOG(1) << "Done consuming tasks";
+        LOGV2_DEBUG(1, "Done consuming tasks");
     });
 }
 
@@ -115,14 +116,14 @@ void ThreadPoolMock::_consumeOneTask(stdx::unique_lock<Latch>& lk) {
 }
 
 void ThreadPoolMock::_shutdown(stdx::unique_lock<Latch>& lk) {
-    LOG(1) << "Shutting down pool";
+    LOGV2_DEBUG(1, "Shutting down pool");
 
     _inShutdown = true;
     _net->signalWorkAvailable();
 }
 
 void ThreadPoolMock::_join(stdx::unique_lock<Latch>& lk) {
-    LOG(1) << "Joining pool";
+    LOGV2_DEBUG(1, "Joining pool");
 
     _joining = true;
     _net->signalWorkAvailable();
diff --git a/src/mongo/executor/thread_pool_task_executor.cpp b/src/mongo/executor/thread_pool_task_executor.cpp
index 0ad34b4e6a..546a90b364 100644
--- a/src/mongo/executor/thread_pool_task_executor.cpp
+++ b/src/mongo/executor/thread_pool_task_executor.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/operation_context.h"
 #include "mongo/executor/connection_pool_stats.h"
 #include "mongo/executor/network_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/transport/baton.h"
 #include "mongo/util/concurrency/thread_pool_interface.h"
@@ -432,7 +433,7 @@ StatusWith<TaskExecutor::CallbackHandle> ThreadPoolTaskExecutor::scheduleRemoteC
     if (!swCbHandle.isOK())
         return swCbHandle;
     const auto cbState = _networkInProgressQueue.back();
-    LOG(3) << "Scheduling remote command request: " << redact(scheduledRequest.toString());
+    LOGV2_DEBUG(3, "Scheduling remote command request: {}", "redact_scheduledRequest_toString"_attr = redact(scheduledRequest.toString()));
     lk.unlock();
 
     auto commandStatus = _net->startCommand(
@@ -447,8 +448,7 @@ StatusWith<TaskExecutor::CallbackHandle> ThreadPoolTaskExecutor::scheduleRemoteC
             if (_inShutdown_inlock()) {
                 return;
             }
-            LOG(3) << "Received remote response: "
-                   << redact(response.isOK() ? response.toString() : response.status.toString());
+            LOGV2_DEBUG(3, "Received remote response: {}", "redact_response_isOK_response_toString_response_status_toString"_attr = redact(response.isOK() ? response.toString() : response.status.toString()));
             swap(cbState->callback, newCb);
             scheduleIntoPool_inlock(&_networkInProgressQueue, cbState->iter, std::move(lk));
         },
diff --git a/src/mongo/logger/logv2_appender.h b/src/mongo/logger/logv2_appender.h
index 86978ab30f..e5a677099c 100644
--- a/src/mongo/logger/logv2_appender.h
+++ b/src/mongo/logger/logv2_appender.h
@@ -46,7 +46,7 @@ namespace {
 
 auto findTeeTag(StringData teeName) {
     static constexpr std::pair<StringData, logv2::LogTag::Value> kTees[] = {
-        {"rs"_sd, logv2::LogTag::kRSLog},
+        {"rs"_sd, logv2::LogTag::kRS},
         {"startupWarnings"_sd, logv2::LogTag::kStartupWarnings},
     };
     if (teeName.empty())
diff --git a/src/mongo/logv2/log_test_v2.cpp b/src/mongo/logv2/log_test_v2.cpp
index 0fb7db66af..d089912907 100644
--- a/src/mongo/logv2/log_test_v2.cpp
+++ b/src/mongo/logv2/log_test_v2.cpp
@@ -543,6 +543,19 @@ TEST_F(LogTestV2, Types) {
         mongo::fromjson(json.back()).getField(kAttributesFieldName).Obj().getField("name").String(),
         withoutBSON.toString());
     ASSERT_EQUALS(lastBSONElement().String(), withoutBSON.toString());
+
+    // Duration
+    Milliseconds ms{12345};
+    LOGV2("Duration {}", "name"_attr = ms);
+    ASSERT_EQUALS(text.back(), std::string("Duration ") + ms.toString());
+    ASSERT_EQUALS(mongo::fromjson(json.back())
+                      .getField(kAttributesFieldName)
+                      .Obj()
+                      .getField("name")
+                      .Obj()
+                      .woCompare(ms.toBSON()),
+                  0);
+    ASSERT(lastBSONElement().Obj().woCompare(ms.toBSON()) == 0);
 }
 
 TEST_F(LogTestV2, TextFormat) {
diff --git a/src/mongo/platform/decimal128_bson_test.cpp b/src/mongo/platform/decimal128_bson_test.cpp
index dd6c2dd201..15cd07188e 100644
--- a/src/mongo/platform/decimal128_bson_test.cpp
+++ b/src/mongo/platform/decimal128_bson_test.cpp
@@ -42,6 +42,7 @@
 #include "mongo/bson/bsonobjbuilder.h"
 #include "mongo/config.h"
 #include "mongo/db/json.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/decimal128.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/hex.h"
@@ -94,7 +95,7 @@ TEST(Decimal128BSONTest, TestsConstructingDecimalWithBsonDump) {
             BSONElement extjson = b.getField("extjson");
             BSONElement canonical_extjson = b.getField("canonical_extjson");
 
-            log() << "Test - " << desc.str();
+            LOGV2("Test - {}", "desc_str"_attr = desc.str());
 
             StringData hexString = bson.valueStringData();
             BSONObj d = convertHexStringToBsonObj(hexString);
@@ -108,7 +109,7 @@ TEST(Decimal128BSONTest, TestsConstructingDecimalWithBsonDump) {
             }
 
             ASSERT_EQ(trimWhiteSpace(outputJson), trimWhiteSpace(expectedJson));
-            log() << "PASSED";
+            LOGV2("PASSED");
         }
     }
 }
diff --git a/src/mongo/platform/random_test.cpp b/src/mongo/platform/random_test.cpp
index c3271f8b92..fe46832c77 100644
--- a/src/mongo/platform/random_test.cpp
+++ b/src/mongo/platform/random_test.cpp
@@ -32,6 +32,7 @@
 
 #include "mongo/platform/random.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 
 namespace mongo {
@@ -233,11 +234,11 @@ TEST(RandomTest, NextInt32Uniformity) {
     if (kDebugBuild) {
         for (size_t i = 0; i < hist.size(); ++i) {
             double dev = std::pow(std::pow((hist[i] - mu) / mu, 2), .5);
-            unittest::log() << format(FMT_STRING("  [{:4}] count:{:4}, dev:{:6f}, {}"),
+            unittest::LOGV2("{}", "format_FMT_STRING_4_count_4_dev_6f_i_hist_i_dev_std_string_hist_i_256"_attr = format(FMT_STRING("  [{:4}] count:{:4}, dev:{:6f}, {}"),
                                       i,
                                       hist[i],
                                       dev,
-                                      std::string(hist[i] / 256, '*'));
+                                      std::string(hist[i] / 256, '*')));
         }
     }
     for (size_t i = 0; i < hist.size(); ++i) {
diff --git a/src/mongo/platform/shared_library_posix.cpp b/src/mongo/platform/shared_library_posix.cpp
index 871bd69701..9b18cd0ce5 100644
--- a/src/mongo/platform/shared_library_posix.cpp
+++ b/src/mongo/platform/shared_library_posix.cpp
@@ -36,6 +36,7 @@
 #include <dlfcn.h>
 #include <memory>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -45,14 +46,14 @@ namespace mongo {
 SharedLibrary::~SharedLibrary() {
     if (_handle) {
         if (dlclose(_handle) != 0) {
-            LOG(2) << "Load Library close failed " << dlerror();
+            LOGV2_DEBUG(2, "Load Library close failed {}", "dlerror"_attr = dlerror());
         }
     }
 }
 
 StatusWith<std::unique_ptr<SharedLibrary>> SharedLibrary::create(
     const boost::filesystem::path& full_path) {
-    LOG(1) << "Loading library: " << full_path.c_str();
+    LOGV2_DEBUG(1, "Loading library: {}", "full_path_c_str"_attr = full_path.c_str());
 
     void* handle = dlopen(full_path.c_str(), RTLD_NOW | RTLD_GLOBAL);
     if (handle == nullptr) {
diff --git a/src/mongo/platform/shared_library_windows.cpp b/src/mongo/platform/shared_library_windows.cpp
index 504b366ab2..a3c7a57e00 100644
--- a/src/mongo/platform/shared_library_windows.cpp
+++ b/src/mongo/platform/shared_library_windows.cpp
@@ -34,6 +34,7 @@
 
 #include <boost/filesystem.hpp>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -45,14 +46,14 @@ SharedLibrary::~SharedLibrary() {
     if (_handle) {
         if (FreeLibrary(static_cast<HMODULE>(_handle)) == 0) {
             DWORD lasterror = GetLastError();
-            LOG(2) << "Load library close failed: " << errnoWithDescription(lasterror);
+            LOGV2_DEBUG(2, "Load library close failed: {}", "errnoWithDescription_lasterror"_attr = errnoWithDescription(lasterror));
         }
     }
 }
 
 StatusWith<std::unique_ptr<SharedLibrary>> SharedLibrary::create(
     const boost::filesystem::path& full_path) {
-    LOG(1) << "Loading library: " << toUtf8String(full_path.c_str());
+    LOGV2_DEBUG(1, "Loading library: {}", "toUtf8String_full_path_c_str"_attr = toUtf8String(full_path.c_str()));
 
     HMODULE handle = LoadLibraryW(full_path.c_str());
     if (handle == nullptr) {
diff --git a/src/mongo/platform/source_location_test.cpp b/src/mongo/platform/source_location_test.cpp
index a702eda827..7961dc2336 100644
--- a/src/mongo/platform/source_location_test.cpp
+++ b/src/mongo/platform/source_location_test.cpp
@@ -29,6 +29,7 @@
 
 #include "mongo/platform/basic.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/platform/source_location_test.h"
 
 namespace mongo {
@@ -64,9 +65,9 @@ TEST(SourceLocation, InlineVariable) {
     ASSERT_LT(inlineLocation1.line(), inlineLocation2.line());
     ASSERT_LT(inlineLocation2.line(), inlineLocation3.line());
 
-    unittest::log() << inlineLocation1;
-    unittest::log() << inlineLocation2;
-    unittest::log() << inlineLocation3;
+    unittest::LOGV2("{}", "inlineLocation1"_attr = inlineLocation1);
+    unittest::LOGV2("{}", "inlineLocation2"_attr = inlineLocation2);
+    unittest::LOGV2("{}", "inlineLocation3"_attr = inlineLocation3);
 }
 
 TEST(SourceLocation, LocalFunction) {
@@ -81,9 +82,9 @@ TEST(SourceLocation, LocalFunction) {
     // The two local function locations should be identical
     ASSERT_EQ(localFunctionLocation1, localFunctionLocation2);
 
-    unittest::log() << inlineLocation1;
-    unittest::log() << localFunctionLocation1;
-    unittest::log() << localFunctionLocation2;
+    unittest::LOGV2("{}", "inlineLocation1"_attr = inlineLocation1);
+    unittest::LOGV2("{}", "localFunctionLocation1"_attr = localFunctionLocation1);
+    unittest::LOGV2("{}", "localFunctionLocation2"_attr = localFunctionLocation2);
 }
 
 TEST(SourceLocation, HeaderFunction) {
@@ -97,9 +98,9 @@ TEST(SourceLocation, HeaderFunction) {
     // The two header locations should be identical
     ASSERT_EQ(headerLocation1, headerLocation2);
 
-    unittest::log() << inlineLocation1;
-    unittest::log() << headerLocation1;
-    unittest::log() << headerLocation2;
+    unittest::LOGV2("{}", "inlineLocation1"_attr = inlineLocation1);
+    unittest::LOGV2("{}", "headerLocation1"_attr = headerLocation1);
+    unittest::LOGV2("{}", "headerLocation2"_attr = headerLocation2);
 }
 
 TEST(SourceLocation, GlobalVariable) {
@@ -109,8 +110,8 @@ TEST(SourceLocation, GlobalVariable) {
     ASSERT_EQ(inlineLocation1.file_name(), kLocation.file_name());
     ASSERT_GT(inlineLocation1.line(), kLocation.line());
 
-    unittest::log() << inlineLocation1;
-    unittest::log() << kLocation;
+    unittest::LOGV2("{}", "inlineLocation1"_attr = inlineLocation1);
+    unittest::LOGV2("{}", "kLocation"_attr = kLocation);
 }
 
 TEST(SourceLocation, DefaultStructMember) {
@@ -125,9 +126,9 @@ TEST(SourceLocation, DefaultStructMember) {
     // The two default ctor'd struct member locations should be identical
     ASSERT_EQ(obj1.location, obj2.location);
 
-    unittest::log() << inlineLocation1;
-    unittest::log() << obj1.location;
-    unittest::log() << obj2.location;
+    unittest::LOGV2("{}", "inlineLocation1"_attr = inlineLocation1);
+    unittest::LOGV2("{}", "obj1_location"_attr = obj1.location);
+    unittest::LOGV2("{}", "obj2_location"_attr = obj2.location);
 }
 
 TEST(SourceLocation, Macro) {
@@ -140,8 +141,8 @@ TEST(SourceLocation, Macro) {
     // The line numbers for each location should increase monotonically when inline
     ASSERT_LT(inlineLocation1.line(), inlineLocation2.line());
 
-    unittest::log() << inlineLocation1;
-    unittest::log() << inlineLocation2;
+    unittest::LOGV2("{}", "inlineLocation1"_attr = inlineLocation1);
+    unittest::LOGV2("{}", "inlineLocation2"_attr = inlineLocation2);
 }
 
 TEST(SourceLocation, Constexpr) {
diff --git a/src/mongo/rpc/metadata/client_metadata.cpp b/src/mongo/rpc/metadata/client_metadata.cpp
index 9b51a4bc75..93d1f8d5cf 100644
--- a/src/mongo/rpc/metadata/client_metadata.cpp
+++ b/src/mongo/rpc/metadata/client_metadata.cpp
@@ -41,6 +41,7 @@
 #include "mongo/bson/bsonobj.h"
 #include "mongo/bson/bsonobjbuilder.h"
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/is_mongos.h"
 #include "mongo/util/log.h"
 #include "mongo/util/processinfo.h"
@@ -435,8 +436,7 @@ const BSONObj& ClientMetadata::getDocument() const {
 
 void ClientMetadata::logClientMetadata(Client* client) const {
     invariant(!getDocument().isEmpty());
-    log() << "received client metadata from " << client->getRemote().toString() << " "
-          << client->desc() << ": " << getDocument();
+    LOGV2("received client metadata from {} {}: {}", "client_getRemote_toString"_attr = client->getRemote().toString(), "client_desc"_attr = client->desc(), "getDocument"_attr = getDocument());
 }
 
 StringData ClientMetadata::fieldName() {
diff --git a/src/mongo/rpc/op_msg.cpp b/src/mongo/rpc/op_msg.cpp
index e0a8d60881..5ef65f759f 100644
--- a/src/mongo/rpc/op_msg.cpp
+++ b/src/mongo/rpc/op_msg.cpp
@@ -39,6 +39,7 @@
 #include "mongo/base/data_type_endian.h"
 #include "mongo/config.h"
 #include "mongo/db/bson/dotted_path_support.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/object_check.h"
 #include "mongo/util/bufreader.h"
 #include "mongo/util/hex.h"
@@ -218,8 +219,7 @@ OpMsg OpMsg::parse(const Message& message) try {
 
     return msg;
 } catch (const DBException& ex) {
-    LOG(1) << "invalid message: " << ex.code() << " " << redact(ex) << " -- "
-           << redact(hexdump(message.singleData().view2ptr(), message.size()));
+    LOGV2_DEBUG(1, "invalid message: {} {} -- {}", "ex"_attr = ex, "redact_ex"_attr = redact(ex), "redact_hexdump_message_singleData_view2ptr_message_size"_attr = redact(hexdump(message.singleData().view2ptr(), message.size())));
     throw;
 }
 
diff --git a/src/mongo/rpc/op_msg_integration_test.cpp b/src/mongo/rpc/op_msg_integration_test.cpp
index 4edb0fab6f..9214fbec2e 100644
--- a/src/mongo/rpc/op_msg_integration_test.cpp
+++ b/src/mongo/rpc/op_msg_integration_test.cpp
@@ -33,6 +33,7 @@
 #include "mongo/client/dbclient_rs.h"
 #include "mongo/db/ops/write_ops.h"
 #include "mongo/db/query/getmore_request.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/op_msg.h"
 #include "mongo/unittest/integration_test.h"
@@ -585,14 +586,14 @@ TEST(OpMsg, ExhaustWithDBClientCursorBehavesCorrectly) {
     conn->dropCollection(nss.toString());
 
     const int nDocs = 5;
-    unittest::log() << "Inserting " << nDocs << " documents.";
+    unittest::LOGV2("Inserting {} documents.", "nDocs"_attr = nDocs);
     for (int i = 0; i < nDocs; i++) {
         auto doc = BSON("_id" << i);
         conn->insert(nss.toString(), doc, 0);
     }
 
     ASSERT_EQ(conn->count(nss), size_t(nDocs));
-    unittest::log() << "Finished document insertion.";
+    unittest::LOGV2("Finished document insertion.");
 
     // Open an exhaust cursor.
     int batchSize = 2;
diff --git a/src/mongo/rpc/op_msg_test.cpp b/src/mongo/rpc/op_msg_test.cpp
index c534dbdb70..c5958d577d 100644
--- a/src/mongo/rpc/op_msg_test.cpp
+++ b/src/mongo/rpc/op_msg_test.cpp
@@ -37,6 +37,7 @@
 #include "mongo/bson/json.h"
 #include "mongo/bson/util/builder.h"
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/op_msg.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/hex.h"
@@ -661,12 +662,10 @@ void testSerializer(const Message& fromSerializer, OpMsgBytes&& expected) {
         std::mismatch(gotSD.begin(), gotSD.end(), expectedSD.begin(), expectedSD.end()).first -
         gotSD.begin();
 
-    log() << "Mismatch after " << commonLength << " bytes.";
-    log() << "Common prefix: " << hexdump(gotSD.rawData(), commonLength);
-    log() << "Got suffix     : "
-          << hexdump(gotSD.rawData() + commonLength, gotSD.size() - commonLength);
-    log() << "Expected suffix: "
-          << hexdump(expectedSD.rawData() + commonLength, expectedSD.size() - commonLength);
+    LOGV2("Mismatch after {} bytes.", "commonLength"_attr = commonLength);
+    LOGV2("Common prefix: {}", "hexdump_gotSD_rawData_commonLength"_attr = hexdump(gotSD.rawData(), commonLength));
+    LOGV2("Got suffix     : {}", "hexdump_gotSD_rawData_commonLength_gotSD_size_commonLength"_attr = hexdump(gotSD.rawData() + commonLength, gotSD.size() - commonLength));
+    LOGV2("Expected suffix: {}", "hexdump_expectedSD_rawData_commonLength_expectedSD_size_commonLength"_attr = hexdump(expectedSD.rawData() + commonLength, expectedSD.size() - commonLength));
     FAIL("Serialization didn't match expected data. See above for details.");
 }
 
diff --git a/src/mongo/s/async_requests_sender.cpp b/src/mongo/s/async_requests_sender.cpp
index 5d6f0b21cc..2fa7a802af 100644
--- a/src/mongo/s/async_requests_sender.cpp
+++ b/src/mongo/s/async_requests_sender.cpp
@@ -38,6 +38,7 @@
 
 #include "mongo/client/remote_command_targeter.h"
 #include "mongo/executor/remote_command_request.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
@@ -241,13 +242,9 @@ auto AsyncRequestsSender::RemoteData::handleResponse(RemoteCommandOnAnyCallbackA
         if (!_ars->_stopRetrying && shard->isRetriableError(status.code(), _ars->_retryPolicy) &&
             _retryCount < kMaxNumFailedHostRetryAttempts) {
 
-            LOG(1) << "Command to remote " << _shardId
-                   << (failedTargets.empty()
+            LOGV2_DEBUG(1, "Command to remote {}{}{}failed with retriable error and will be retried {}", "_shardId"_attr = _shardId, "failedTargets_empty_failedTargets_size_1_for_hosts_at_host"_attr = (failedTargets.empty()
                            ? " "
-                           : (failedTargets.size() > 1 ? " for hosts " : " at host "))
-                   << "{}"_format(fmt::join(failedTargets, ", "))
-                   << "failed with retriable error and will be retried "
-                   << causedBy(redact(status));
+                           : (failedTargets.size() > 1 ? " for hosts " : " at host ")), "_format_fmt_join_failedTargets"_attr = "{}"_format(fmt::join(failedTargets, ", ")), "causedBy_redact_status"_attr = causedBy(redact(status)));
 
             ++_retryCount;
             _shardHostAndPort.reset();
diff --git a/src/mongo/s/balancer_configuration.cpp b/src/mongo/s/balancer_configuration.cpp
index 8197c03e19..fd52545685 100644
--- a/src/mongo/s/balancer_configuration.cpp
+++ b/src/mongo/s/balancer_configuration.cpp
@@ -43,6 +43,7 @@
 #include "mongo/bson/bsonobj.h"
 #include "mongo/bson/util/bson_extract.h"
 #include "mongo/db/namespace_string.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/sharding_catalog_client.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
@@ -242,8 +243,7 @@ Status BalancerConfiguration::_refreshChunkSizeSettings(OperationContext* opCtx)
     }
 
     if (settings.getMaxChunkSizeBytes() != getMaxChunkSizeBytes()) {
-        log() << "MaxChunkSize changing from " << getMaxChunkSizeBytes() / (1024 * 1024) << "MB"
-              << " to " << settings.getMaxChunkSizeBytes() / (1024 * 1024) << "MB";
+        LOGV2("MaxChunkSize changing from {}MB to {}MB", "getMaxChunkSizeBytes_1024_1024"_attr = getMaxChunkSizeBytes() / (1024 * 1024), "settings_getMaxChunkSizeBytes_1024_1024"_attr = settings.getMaxChunkSizeBytes() / (1024 * 1024));
 
         _maxChunkSizeBytes.store(settings.getMaxChunkSizeBytes());
     }
@@ -268,8 +268,7 @@ Status BalancerConfiguration::_refreshAutoSplitSettings(OperationContext* opCtx)
     }
 
     if (settings.getShouldAutoSplit() != getShouldAutoSplit()) {
-        log() << "ShouldAutoSplit changing from " << getShouldAutoSplit() << " to "
-              << settings.getShouldAutoSplit();
+        LOGV2("ShouldAutoSplit changing from {} to {}", "getShouldAutoSplit"_attr = getShouldAutoSplit(), "settings_getShouldAutoSplit"_attr = settings.getShouldAutoSplit());
 
         _shouldAutoSplit.store(settings.getShouldAutoSplit());
     }
diff --git a/src/mongo/s/catalog/replset_dist_lock_manager.cpp b/src/mongo/s/catalog/replset_dist_lock_manager.cpp
index a7c5d6221b..418a7cac13 100644
--- a/src/mongo/s/catalog/replset_dist_lock_manager.cpp
+++ b/src/mongo/s/catalog/replset_dist_lock_manager.cpp
@@ -39,6 +39,7 @@
 #include "mongo/base/status_with.h"
 #include "mongo/db/operation_context_noop.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/dist_lock_catalog.h"
 #include "mongo/s/catalog/type_lockpings.h"
 #include "mongo/s/catalog/type_locks.h"
@@ -123,8 +124,7 @@ bool ReplSetDistLockManager::isShutDown() {
 }
 
 void ReplSetDistLockManager::doTask() {
-    LOG(0) << "creating distributed lock ping thread for process " << _processID
-           << " (sleeping for " << _pingInterval << ")";
+    LOGV2("creating distributed lock ping thread for process {} (sleeping for {})", "_processID"_attr = _processID, "_pingInterval"_attr = _pingInterval);
 
     Timer elapsedSincelastPing(_serviceContext->getTickSource());
     Client::initThread("replSetDistLockPinger");
@@ -171,8 +171,7 @@ void ReplSetDistLockManager::doTask() {
                         queueUnlock(toUnlock.first, toUnlock.second);
                     }
                 } else {
-                    LOG(0) << "distributed lock with " << LocksType::lockID() << ": "
-                           << toUnlock.first << nameMessage << " unlocked.";
+                    LOGV2("distributed lock with {}: {}{} unlocked.", "LocksType_lockID"_attr = LocksType::lockID(), "toUnlock_first"_attr = toUnlock.first, "nameMessage"_attr = nameMessage);
                 }
 
                 if (isShutDown()) {
@@ -246,8 +245,7 @@ StatusWith<bool> ReplSetDistLockManager::isLockExpired(OperationContext* opCtx,
 
     auto* pingInfo = &pingIter->second;
 
-    LOG(1) << "checking last ping for lock '" << lockDoc.getName() << "' against last seen process "
-           << pingInfo->processId << " and ping " << pingInfo->lastPing;
+    LOGV2_DEBUG(1, "checking last ping for lock '{}' against last seen process {} and ping {}", "lockDoc_getName"_attr = lockDoc.getName(), "pingInfo_processId"_attr = pingInfo->processId, "pingInfo_lastPing"_attr = pingInfo->lastPing);
 
     if (pingInfo->lastPing != pingValue ||  // ping is active
 
@@ -273,14 +271,11 @@ StatusWith<bool> ReplSetDistLockManager::isLockExpired(OperationContext* opCtx,
 
     Milliseconds elapsedSinceLastPing(configServerLocalTime - pingInfo->configLocalTime);
     if (elapsedSinceLastPing >= lockExpiration) {
-        LOG(0) << "forcing lock '" << lockDoc.getName() << "' because elapsed time "
-               << elapsedSinceLastPing << " >= takeover time " << lockExpiration;
+        LOGV2("forcing lock '{}' because elapsed time {} >= takeover time {}", "lockDoc_getName"_attr = lockDoc.getName(), "elapsedSinceLastPing"_attr = elapsedSinceLastPing, "lockExpiration"_attr = lockExpiration);
         return true;
     }
 
-    LOG(1) << "could not force lock '" << lockDoc.getName() << "' because elapsed time "
-           << durationCount<Milliseconds>(elapsedSinceLastPing) << " < takeover time "
-           << durationCount<Milliseconds>(lockExpiration) << " ms";
+    LOGV2_DEBUG(1, "could not force lock '{}' because elapsed time {} < takeover time {} ms", "lockDoc_getName"_attr = lockDoc.getName(), "durationCount_Milliseconds_elapsedSinceLastPing"_attr = durationCount<Milliseconds>(elapsedSinceLastPing), "durationCount_Milliseconds_lockExpiration"_attr = durationCount<Milliseconds>(lockExpiration));
     return false;
 }
 
@@ -311,11 +306,7 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::lockWithSessionID(OperationCo
             lockExpiration = Milliseconds(data["timeoutMs"].numberInt());
         });
 
-        LOG(1) << "trying to acquire new distributed lock for " << name
-               << " ( lock timeout : " << durationCount<Milliseconds>(lockExpiration)
-               << " ms, ping interval : " << durationCount<Milliseconds>(_pingInterval)
-               << " ms, process : " << _processID << " )"
-               << " with lockSessionID: " << lockSessionID << ", why: " << whyMessage.toString();
+        LOGV2_DEBUG(1, "trying to acquire new distributed lock for {} ( lock timeout : {} ms, ping interval : {} ms, process : {} ) with lockSessionID: {}, why: {}", "name"_attr = name, "durationCount_Milliseconds_lockExpiration"_attr = durationCount<Milliseconds>(lockExpiration), "durationCount_Milliseconds__pingInterval"_attr = durationCount<Milliseconds>(_pingInterval), "_processID"_attr = _processID, "lockSessionID"_attr = lockSessionID, "whyMessage_toString"_attr = whyMessage.toString());
 
         auto lockResult = _catalog->grabLock(
             opCtx, name, lockSessionID, who, _processID, Date_t::now(), whyMessage.toString());
@@ -325,17 +316,15 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::lockWithSessionID(OperationCo
         if (status.isOK()) {
             // Lock is acquired since findAndModify was able to successfully modify
             // the lock document.
-            log() << "distributed lock '" << name << "' acquired for '" << whyMessage.toString()
-                  << "', ts : " << lockSessionID;
+            LOGV2("distributed lock '{}' acquired for '{}', ts : {}", "name"_attr = name, "whyMessage_toString"_attr = whyMessage.toString(), "lockSessionID"_attr = lockSessionID);
             return lockSessionID;
         }
 
         // If a network error occurred, unlock the lock synchronously and try again
         if (configShard->isRetriableError(status.code(), Shard::RetryPolicy::kIdempotent) &&
             networkErrorRetries < kMaxNumLockAcquireRetries) {
-            LOG(1) << "Failed to acquire distributed lock because of retriable error. Retrying "
-                      "acquisition by first unlocking the stale entry, which possibly exists now"
-                   << causedBy(redact(status));
+            LOGV2_DEBUG(1, "Failed to acquire distributed lock because of retriable error. Retrying "
+                      "acquisition by first unlocking the stale entry, which possibly exists now{}", "causedBy_redact_status"_attr = causedBy(redact(status)));
 
             networkErrorRetries++;
 
@@ -348,9 +337,7 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::lockWithSessionID(OperationCo
             // Fall-through to the error checking logic below
             invariant(status != ErrorCodes::LockStateChangeFailed);
 
-            LOG(1)
-                << "Failed to retry acquisition of distributed lock. No more attempts will be made"
-                << causedBy(redact(status));
+            LOGV2_DEBUG(1, "Failed to retry acquisition of distributed lock. No more attempts will be made{}", "causedBy_redact_status"_attr = causedBy(redact(status)));
         }
 
         if (status != ErrorCodes::LockStateChangeFailed) {
@@ -394,8 +381,8 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::lockWithSessionID(OperationCo
                     // Lock is acquired since findAndModify was able to successfully modify
                     // the lock document.
 
-                    LOG(0) << "lock '" << name << "' successfully forced";
-                    LOG(0) << "distributed lock '" << name << "' acquired, ts : " << lockSessionID;
+                    LOGV2("lock '{}' successfully forced", "name"_attr = name);
+                    LOGV2("distributed lock '{}' acquired, ts : {}", "name"_attr = name, "lockSessionID"_attr = lockSessionID);
                     return lockSessionID;
                 }
 
@@ -408,7 +395,7 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::lockWithSessionID(OperationCo
             }
         }
 
-        LOG(1) << "distributed lock '" << name << "' was not acquired.";
+        LOGV2_DEBUG(1, "distributed lock '{}' was not acquired.", "name"_attr = name);
 
         if (waitFor == Milliseconds::zero()) {
             break;
@@ -416,8 +403,7 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::lockWithSessionID(OperationCo
 
         // Periodically message for debugging reasons
         if (msgTimer.seconds() > 10) {
-            LOG(0) << "waited " << timer.seconds() << "s for distributed lock " << name << " for "
-                   << whyMessage.toString();
+            LOGV2("waited {}s for distributed lock {} for {}", "timer_seconds"_attr = timer.seconds(), "name"_attr = name, "whyMessage_toString"_attr = whyMessage.toString());
 
             msgTimer.reset();
         }
@@ -438,11 +424,7 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::tryLockWithLocalWriteConcern(
     OperationContext* opCtx, StringData name, StringData whyMessage, const OID& lockSessionID) {
     const string who = str::stream() << _processID << ":" << getThreadName();
 
-    LOG(1) << "trying to acquire new distributed lock for " << name
-           << " ( lock timeout : " << durationCount<Milliseconds>(_lockExpiration)
-           << " ms, ping interval : " << durationCount<Milliseconds>(_pingInterval)
-           << " ms, process : " << _processID << " )"
-           << " with lockSessionID: " << lockSessionID << ", why: " << whyMessage.toString();
+    LOGV2_DEBUG(1, "trying to acquire new distributed lock for {} ( lock timeout : {} ms, ping interval : {} ms, process : {} ) with lockSessionID: {}, why: {}", "name"_attr = name, "durationCount_Milliseconds__lockExpiration"_attr = durationCount<Milliseconds>(_lockExpiration), "durationCount_Milliseconds__pingInterval"_attr = durationCount<Milliseconds>(_pingInterval), "_processID"_attr = _processID, "lockSessionID"_attr = lockSessionID, "whyMessage_toString"_attr = whyMessage.toString());
 
     auto lockStatus = _catalog->grabLock(opCtx,
                                          name,
@@ -454,12 +436,11 @@ StatusWith<DistLockHandle> ReplSetDistLockManager::tryLockWithLocalWriteConcern(
                                          DistLockCatalog::kLocalWriteConcern);
 
     if (lockStatus.isOK()) {
-        log() << "distributed lock '" << name << "' acquired for '" << whyMessage.toString()
-              << "', ts : " << lockSessionID;
+        LOGV2("distributed lock '{}' acquired for '{}', ts : {}", "name"_attr = name, "whyMessage_toString"_attr = whyMessage.toString(), "lockSessionID"_attr = lockSessionID);
         return lockSessionID;
     }
 
-    LOG(1) << "distributed lock '" << name << "' was not acquired.";
+    LOGV2_DEBUG(1, "distributed lock '{}' was not acquired.", "name"_attr = name);
 
     if (lockStatus == ErrorCodes::LockStateChangeFailed) {
         return {ErrorCodes::LockBusy, str::stream() << "Unable to acquire " << name};
@@ -474,8 +455,7 @@ void ReplSetDistLockManager::unlock(OperationContext* opCtx, const DistLockHandl
     if (!unlockStatus.isOK()) {
         queueUnlock(lockSessionID, boost::none);
     } else {
-        LOG(0) << "distributed lock with " << LocksType::lockID() << ": " << lockSessionID
-               << "' unlocked.";
+        LOGV2("distributed lock with {}: {}' unlocked.", "LocksType_lockID"_attr = LocksType::lockID(), "lockSessionID"_attr = lockSessionID);
     }
 }
 
@@ -487,8 +467,7 @@ void ReplSetDistLockManager::unlock(OperationContext* opCtx,
     if (!unlockStatus.isOK()) {
         queueUnlock(lockSessionID, name.toString());
     } else {
-        LOG(0) << "distributed lock with " << LocksType::lockID() << ": '" << lockSessionID
-               << "' and " << LocksType::name() << ": '" << name.toString() << "' unlocked.";
+        LOGV2("distributed lock with {}: '{}' and {}: '{}' unlocked.", "LocksType_lockID"_attr = LocksType::lockID(), "lockSessionID"_attr = lockSessionID, "LocksType_name"_attr = LocksType::name(), "name_toString"_attr = name.toString());
     }
 }
 
diff --git a/src/mongo/s/catalog/sharding_catalog_client_impl.cpp b/src/mongo/s/catalog/sharding_catalog_client_impl.cpp
index 04d88a1183..567ab5da21 100644
--- a/src/mongo/s/catalog/sharding_catalog_client_impl.cpp
+++ b/src/mongo/s/catalog/sharding_catalog_client_impl.cpp
@@ -48,6 +48,7 @@
 #include "mongo/db/repl/read_concern_args.h"
 #include "mongo/db/repl/repl_client_info.h"
 #include "mongo/executor/network_interface.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/s/catalog/config_server_version.h"
@@ -154,7 +155,7 @@ void ShardingCatalogClientImpl::startup() {
 }
 
 void ShardingCatalogClientImpl::shutDown(OperationContext* opCtx) {
-    LOG(1) << "ShardingCatalogClientImpl::shutDown() called.";
+    LOGV2_DEBUG(1, "ShardingCatalogClientImpl::shutDown() called.");
     {
         stdx::lock_guard<Latch> lk(_mutex);
         _inShutdown = true;
@@ -810,7 +811,7 @@ Status ShardingCatalogClientImpl::insertConfigDocument(OperationContext* opCtx,
         // or it is because we failed to wait for write concern on the first attempt. In order to
         // differentiate, fetch the entry and check.
         if (retry > 1 && status == ErrorCodes::DuplicateKey) {
-            LOG(1) << "Insert retry failed because of duplicate key error, rechecking.";
+            LOGV2_DEBUG(1, "Insert retry failed because of duplicate key error, rechecking.");
 
             auto fetchDuplicate =
                 _exhaustiveFindOnConfig(opCtx,
diff --git a/src/mongo/s/catalog_cache.cpp b/src/mongo/s/catalog_cache.cpp
index 918e2cb1f2..3a69f6f7b4 100644
--- a/src/mongo/s/catalog_cache.cpp
+++ b/src/mongo/s/catalog_cache.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/logical_clock.h"
 #include "mongo/db/query/collation/collator_factory_interface.h"
 #include "mongo/db/repl/optime_with.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog/type_collection.h"
 #include "mongo/s/catalog/type_database.h"
 #include "mongo/s/client/shard_registry.h"
@@ -324,7 +325,7 @@ void CatalogCache::onStaleDatabaseVersion(const StringData dbName,
     } else if (!itDbEntry->second->dbt ||
                databaseVersion::equal(itDbEntry->second->dbt->getVersion(), databaseVersion)) {
         // If the versions match, the cached database info is stale, so mark it as needs refresh.
-        log() << "Marking cached database entry for '" << dbName << "' as stale";
+        LOGV2("Marking cached database entry for '{}' as stale", "dbName"_attr = dbName);
         itDbEntry->second->needsRefresh = true;
     }
 }
@@ -423,14 +424,13 @@ void CatalogCache::invalidateShardedCollection(const NamespaceString& nss) {
 void CatalogCache::invalidateEntriesThatReferenceShard(const ShardId& shardId) {
     stdx::lock_guard<Latch> lg(_mutex);
 
-    log() << "Starting to invalidate databases and collections with data on shard: " << shardId;
+    LOGV2("Starting to invalidate databases and collections with data on shard: {}", "shardId"_attr = shardId);
 
     // Invalidate databases with this shard as their primary.
     for (const auto& [dbNs, dbInfoEntry] : _databases) {
-        LOG(3) << "Checking if database " << dbNs << "has primary shard: " << shardId;
+        LOGV2_DEBUG(3, "Checking if database {}has primary shard: {}", "dbNs"_attr = dbNs, "shardId"_attr = shardId);
         if (!dbInfoEntry->needsRefresh && dbInfoEntry->dbt->getPrimary() == shardId) {
-            LOG(3) << "Database " << dbNs << "has primary shard " << shardId
-                   << ", invalidating cache entry";
+            LOGV2_DEBUG(3, "Database {}has primary shard {}, invalidating cache entry", "dbNs"_attr = dbNs, "shardId"_attr = shardId);
             dbInfoEntry->needsRefresh = true;
         }
     }
@@ -439,7 +439,7 @@ void CatalogCache::invalidateEntriesThatReferenceShard(const ShardId& shardId) {
     for (const auto& [db, collInfoMap] : _collectionsByDb) {
         for (const auto& [collNs, collRoutingInfoEntry] : collInfoMap) {
 
-            LOG(3) << "Checking if " << collNs << "has data on shard: " << shardId;
+            LOGV2_DEBUG(3, "Checking if {}has data on shard: {}", "collNs"_attr = collNs, "shardId"_attr = shardId);
 
             if (!collRoutingInfoEntry->needsRefresh) {
                 // The set of shards on which this collection contains chunks.
@@ -448,8 +448,7 @@ void CatalogCache::invalidateEntriesThatReferenceShard(const ShardId& shardId) {
 
                 if (shardsOwningDataForCollection.find(shardId) !=
                     shardsOwningDataForCollection.end()) {
-                    LOG(3) << collNs << "has data on shard " << shardId
-                           << ", invalidating cache entry";
+                    LOGV2_DEBUG(3, "{}has data on shard {}, invalidating cache entry", "collNs"_attr = collNs, "shardId"_attr = shardId);
 
                     collRoutingInfoEntry->needsRefresh = true;
                 }
@@ -457,7 +456,7 @@ void CatalogCache::invalidateEntriesThatReferenceShard(const ShardId& shardId) {
         }
     }
 
-    log() << "Finished invalidating databases and collections with data on shard: " << shardId;
+    LOGV2("Finished invalidating databases and collections with data on shard: {}", "shardId"_attr = shardId);
 }
 
 void CatalogCache::purgeCollection(const NamespaceString& nss) {
diff --git a/src/mongo/s/chunk_manager_index_bounds_test.cpp b/src/mongo/s/chunk_manager_index_bounds_test.cpp
index 3ff2dd03cb..e5cb8b3001 100644
--- a/src/mongo/s/chunk_manager_index_bounds_test.cpp
+++ b/src/mongo/s/chunk_manager_index_bounds_test.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/namespace_string.h"
 #include "mongo/db/pipeline/expression_context_for_test.h"
 #include "mongo/db/query/canonical_query.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/chunk_manager.h"
 #include "mongo/s/shard_key_pattern.h"
 #include "mongo/s/sharding_router_test_fixture.h"
@@ -88,7 +89,7 @@ protected:
             for (size_t i = 0; i < oil.intervals.size(); i++) {
                 if (Interval::INTERVAL_EQUALS !=
                     oil.intervals[i].compare(expectedOil.intervals[i])) {
-                    log() << oil.intervals[i] << " != " << expectedOil.intervals[i];
+                    LOGV2("{} != {}", "oil_intervals_i"_attr = oil.intervals[i], "expectedOil_intervals_i"_attr = expectedOil.intervals[i]);
                 }
                 ASSERT_EQUALS(Interval::INTERVAL_EQUALS,
                               oil.intervals[i].compare(expectedOil.intervals[i]));
@@ -109,7 +110,7 @@ protected:
 
         if (oil.intervals.size() != expectedOil.intervals.size()) {
             for (size_t i = 0; i < oil.intervals.size(); i++) {
-                log() << oil.intervals[i];
+                LOGV2("{}", "oil_intervals_i"_attr = oil.intervals[i]);
             }
         }
 
diff --git a/src/mongo/s/client/parallel.cpp b/src/mongo/s/client/parallel.cpp
index c532d4b5a2..82e6a36fc9 100644
--- a/src/mongo/s/client/parallel.cpp
+++ b/src/mongo/s/client/parallel.cpp
@@ -39,6 +39,7 @@
 #include "mongo/client/replica_set_monitor.h"
 #include "mongo/db/bson/dotted_path_support.h"
 #include "mongo/db/query/query_request.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_connection.h"
@@ -387,8 +388,7 @@ void ParallelSortClusteredCursor::setupVersionAndHandleSlaveOk(
 
     try {
         if (state->conn->setVersion()) {
-            LOG(2) << "pcursor: needed to set remote version on connection to value "
-                   << "compatible with " << vinfo;
+            LOGV2_DEBUG(2, "pcursor: needed to set remote version on connection to value compatible with {}", "vinfo"_attr = vinfo);
         }
     } catch (const DBException& dbExcep) {
         auto errCode = dbExcep.code();
@@ -425,7 +425,7 @@ void ParallelSortClusteredCursor::startInit(OperationContext* opCtx) {
             prefix = "creating";
         }
     }
-    LOG(2) << "pcursor: " << prefix << " pcursor over " << _qSpec << " and " << _cInfo;
+    LOGV2_DEBUG(2, "pcursor: {} pcursor over {} and {}", "prefix"_attr = prefix, "_qSpec"_attr = _qSpec, "_cInfo"_attr = _cInfo);
 
     shared_ptr<ChunkManager> manager;
     shared_ptr<Shard> primary;
@@ -470,14 +470,13 @@ void ParallelSortClusteredCursor::startInit(OperationContext* opCtx) {
         const auto& shardId = cmEntry.first;
 
         if (shardIds.find(shardId) == shardIds.end()) {
-            LOG(2) << "pcursor: closing cursor on shard " << shardId
-                   << " as the connection is no longer required by " << vinfo;
+            LOGV2_DEBUG(2, "pcursor: closing cursor on shard {} as the connection is no longer required by {}", "shardId"_attr = shardId, "vinfo"_attr = vinfo);
 
             cmEntry.second.cleanup(true);
         }
     }
 
-    LOG(2) << "pcursor: initializing over " << shardIds.size() << " shards required by " << vinfo;
+    LOGV2_DEBUG(2, "pcursor: initializing over {} shards required by {}", "shardIds_size"_attr = shardIds.size(), "vinfo"_attr = vinfo);
 
     // Don't retry indefinitely for whatever reason
     _totalTries++;
@@ -486,8 +485,7 @@ void ParallelSortClusteredCursor::startInit(OperationContext* opCtx) {
     for (const ShardId& shardId : shardIds) {
         auto& mdata = _cursorMap[shardId];
 
-        LOG(2) << "pcursor: initializing on shard " << shardId << ", current connection state is "
-               << mdata.toBSON();
+        LOGV2_DEBUG(2, "pcursor: initializing on shard {}, current connection state is {}", "shardId"_attr = shardId, "mdata_toBSON"_attr = mdata.toBSON());
 
         // This may be the first time connecting to this shard, if so we can get an error here
         try {
@@ -609,9 +607,7 @@ void ParallelSortClusteredCursor::startInit(OperationContext* opCtx) {
                 mdata.finished = true;
             }
 
-            LOG(2) << "pcursor: initialized " << (isCommand() ? "command " : "query ")
-                   << (lazyInit ? "(lazily) " : "(full) ") << "on shard " << shardId
-                   << ", current connection state is " << mdata.toBSON();
+            LOGV2_DEBUG(2, "pcursor: initialized {}{}on shard {}, current connection state is {}", "isCommand_command_query"_attr = (isCommand() ? "command " : "query "), "lazyInit_lazily_full"_attr = (lazyInit ? "(lazily) " : "(full) "), "shardId"_attr = shardId, "mdata_toBSON"_attr = mdata.toBSON());
         } catch (StaleConfigException& e) {
             // Our version isn't compatible with the current version anymore on at least one shard,
             // need to retry immediately
@@ -620,8 +616,7 @@ void ParallelSortClusteredCursor::startInit(OperationContext* opCtx) {
 
             Grid::get(opCtx)->catalogCache()->invalidateShardedCollection(staleNS);
 
-            LOG(1) << "stale config of ns " << staleNS << " during initialization, will retry"
-                   << causedBy(redact(e));
+            LOGV2_DEBUG(1, "stale config of ns {} during initialization, will retry{}", "staleNS"_attr = staleNS, "causedBy_redact_e"_attr = causedBy(redact(e)));
 
             // This is somewhat strange
             if (staleNS != nss) {
@@ -706,14 +701,13 @@ void ParallelSortClusteredCursor::finishInit(OperationContext* opCtx) {
     bool retry = false;
     map<string, StaleConfigException> staleNSExceptions;
 
-    LOG(2) << "pcursor: finishing over " << _cursorMap.size() << " shards";
+    LOGV2_DEBUG(2, "pcursor: finishing over {} shards", "_cursorMap_size"_attr = _cursorMap.size());
 
     for (auto& cmEntry : _cursorMap) {
         const auto& shardId = cmEntry.first;
         auto& mdata = cmEntry.second;
 
-        LOG(2) << "pcursor: finishing on shard " << shardId << ", current connection state is "
-               << mdata.toBSON();
+        LOGV2_DEBUG(2, "pcursor: finishing on shard {}, current connection state is {}", "shardId"_attr = shardId, "mdata_toBSON"_attr = mdata.toBSON());
 
         // Ignore empty conns for now
         if (!mdata.pcState)
@@ -760,8 +754,7 @@ void ParallelSortClusteredCursor::finishInit(OperationContext* opCtx) {
                 // Finalize state
                 state->cursor->attach(state->conn.get());  // Closes connection for us
 
-                LOG(2) << "pcursor: finished on shard " << shardId
-                       << ", current connection state is " << mdata.toBSON();
+                LOGV2_DEBUG(2, "pcursor: finished on shard {}, current connection state is {}", "shardId"_attr = shardId, "mdata_toBSON"_attr = mdata.toBSON());
             }
         } catch (StaleConfigException& e) {
             retry = true;
@@ -834,8 +827,7 @@ void ParallelSortClusteredCursor::finishInit(OperationContext* opCtx) {
                 _markStaleNS(staleNS, ex);
                 Grid::get(opCtx)->catalogCache()->invalidateShardedCollection(staleNS);
 
-                LOG(1) << "stale config of ns " << staleNS << " on finishing query, will retry"
-                       << causedBy(redact(ex));
+                LOGV2_DEBUG(1, "stale config of ns {} on finishing query, will retry{}", "staleNS"_attr = staleNS, "causedBy_redact_ex"_attr = causedBy(redact(ex)));
 
                 // This is somewhat strange
                 if (staleNS.ns() != ns) {
@@ -857,7 +849,7 @@ void ParallelSortClusteredCursor::finishInit(OperationContext* opCtx) {
 
         // Erase empty stuff
         if (!mdata.pcState) {
-            log() << "PCursor erasing empty state " << mdata.toBSON();
+            LOGV2("PCursor erasing empty state {}", "mdata_toBSON"_attr = mdata.toBSON());
             _cursorMap.erase(i++);
             continue;
         } else {
@@ -947,13 +939,12 @@ void ParallelSortClusteredCursor::_oldInit(OperationContext* opCtx) {
         bool firstPass = retryQueries.size() == 0;
 
         if (!firstPass) {
-            log() << "retrying " << (returnPartial ? "(partial) " : "")
-                  << "parallel connection to ";
+            LOGV2("retrying {}parallel connection to ", "returnPartial_partial"_attr = (returnPartial ? "(partial) " : ""));
             for (set<int>::const_iterator it = retryQueries.begin(); it != retryQueries.end();
                  ++it) {
-                log() << serverHosts[*it] << ", ";
+                LOGV2("{}, ", "serverHosts_it"_attr = serverHosts[*it]);
             }
-            log() << finishedQueries << " finished queries.";
+            LOGV2("{} finished queries.", "finishedQueries"_attr = finishedQueries);
         }
 
         size_t num = 0;
@@ -998,9 +989,7 @@ void ParallelSortClusteredCursor::_oldInit(OperationContext* opCtx) {
                 break;
             }
 
-            LOG(5) << "ParallelSortClusteredCursor::init server:" << serverHost << " ns:" << _ns
-                   << " query:" << redact(_query) << " fields:" << redact(_fields)
-                   << " options: " << _options;
+            LOGV2_DEBUG(5, "ParallelSortClusteredCursor::init server:{} ns:{} query:{} fields:{} options: {}", "serverHost"_attr = serverHost, "_ns"_attr = _ns, "redact__query"_attr = redact(_query), "redact__fields"_attr = redact(_fields), "_options"_attr = _options);
 
             if (!_cursors[i].get())
                 _cursors[i].reset(
@@ -1160,7 +1149,7 @@ void ParallelSortClusteredCursor::_oldInit(OperationContext* opCtx) {
     }
 
     if (retries > 0)
-        log() << "successfully finished parallel query after " << retries << " retries";
+        LOGV2("successfully finished parallel query after {} retries", "retries"_attr = retries);
 }
 
 bool ParallelSortClusteredCursor::more() {
diff --git a/src/mongo/s/client/shard.cpp b/src/mongo/s/client/shard.cpp
index 0ee5444dc5..b19e8f4fba 100644
--- a/src/mongo/s/client/shard.cpp
+++ b/src/mongo/s/client/shard.cpp
@@ -38,6 +38,7 @@
 #include "mongo/s/write_ops/batched_command_request.h"
 #include "mongo/s/write_ops/batched_command_response.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -125,9 +126,7 @@ StatusWith<Shard::CommandResponse> Shard::runCommand(OperationContext* opCtx,
         auto swResponse = _runCommand(opCtx, readPref, dbName, maxTimeMSOverride, cmdObj);
         auto status = CommandResponse::getEffectiveStatus(swResponse);
         if (isRetriableError(status.code(), retryPolicy)) {
-            LOG(2) << "Command " << redact(cmdObj)
-                   << " failed with retriable error and will be retried"
-                   << causedBy(redact(status));
+            LOGV2_DEBUG(2, "Command {} failed with retriable error and will be retried{}", "redact_cmdObj"_attr = redact(cmdObj), "causedBy_redact_status"_attr = causedBy(redact(status)));
             continue;
         }
 
@@ -162,9 +161,7 @@ StatusWith<Shard::CommandResponse> Shard::runCommandWithFixedRetryAttempts(
         auto swResponse = _runCommand(opCtx, readPref, dbName, maxTimeMSOverride, cmdObj);
         auto status = CommandResponse::getEffectiveStatus(swResponse);
         if (retry < kOnErrorNumRetries && isRetriableError(status.code(), retryPolicy)) {
-            LOG(2) << "Command " << redact(cmdObj)
-                   << " failed with retriable error and will be retried"
-                   << causedBy(redact(status));
+            LOGV2_DEBUG(2, "Command {} failed with retriable error and will be retried{}", "redact_cmdObj"_attr = redact(cmdObj), "causedBy_redact_status"_attr = causedBy(redact(status)));
             continue;
         }
 
@@ -207,9 +204,7 @@ BatchedCommandResponse Shard::runBatchWriteCommand(OperationContext* opCtx,
         BatchedCommandResponse batchResponse;
         auto writeStatus = CommandResponse::processBatchWriteResponse(swResponse, &batchResponse);
         if (retry < kOnErrorNumRetries && isRetriableError(writeStatus.code(), retryPolicy)) {
-            LOG(2) << "Batch write command to " << getId()
-                   << " failed with retriable error and will be retried"
-                   << causedBy(redact(writeStatus));
+            LOGV2_DEBUG(2, "Batch write command to {} failed with retriable error and will be retried{}", "getId"_attr = getId(), "causedBy_redact_writeStatus"_attr = causedBy(redact(writeStatus)));
             continue;
         }
 
diff --git a/src/mongo/s/client/shard_connection.cpp b/src/mongo/s/client/shard_connection.cpp
index b78e4aefee..32ec200eed 100644
--- a/src/mongo/s/client/shard_connection.cpp
+++ b/src/mongo/s/client/shard_connection.cpp
@@ -37,6 +37,7 @@
 
 #include "mongo/base/init.h"
 #include "mongo/db/lasterror.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/chunk_manager.h"
 #include "mongo/s/client/shard.h"
 #include "mongo/s/client/shard_connection_gen.h"
@@ -399,8 +400,7 @@ ShardConnection::~ShardConnection() {
             }
         } else {
             // see done() comments above for why we log this line
-            log() << "sharded connection to " << _conn->getServerAddress()
-                  << " not being returned to the pool";
+            LOGV2("sharded connection to {} not being returned to the pool", "_conn_getServerAddress"_attr = _conn->getServerAddress());
 
             kill();
         }
diff --git a/src/mongo/s/client/shard_registry.cpp b/src/mongo/s/client/shard_registry.cpp
index 16b1f8bf5f..0a55c17d48 100644
--- a/src/mongo/s/client/shard_registry.cpp
+++ b/src/mongo/s/client/shard_registry.cpp
@@ -50,6 +50,7 @@
 #include "mongo/executor/task_executor.h"
 #include "mongo/executor/task_executor_pool.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/rpc/metadata/egress_metadata_hook_list.h"
 #include "mongo/s/catalog/sharding_catalog_client.h"
@@ -99,7 +100,7 @@ ShardRegistry::~ShardRegistry() {
 
 void ShardRegistry::shutdown() {
     if (_executor && !_isShutdown) {
-        LOG(1) << "Shutting down task executor for reloading shard registry";
+        LOGV2_DEBUG(1, "Shutting down task executor for reloading shard registry");
         _executor->shutdown();
         _executor->join();
         _isShutdown = true;
@@ -228,15 +229,14 @@ void ShardRegistry::startup(OperationContext* opCtx) {
     auto netPtr = net.get();
     _executor = std::make_unique<ThreadPoolTaskExecutor>(
         std::make_unique<NetworkInterfaceThreadPool>(netPtr), std::move(net));
-    LOG(1) << "Starting up task executor for periodic reloading of ShardRegistry";
+    LOGV2_DEBUG(1, "Starting up task executor for periodic reloading of ShardRegistry");
     _executor->startup();
 
     auto status =
         _executor->scheduleWork([this](const CallbackArgs& cbArgs) { _internalReload(cbArgs); });
 
     if (status.getStatus() == ErrorCodes::ShutdownInProgress) {
-        LOG(1) << "Cant schedule Shard Registry reload. "
-               << "Executor shutdown in progress";
+        LOGV2_DEBUG(1, "Cant schedule Shard Registry reload. Executor shutdown in progress");
         return;
     }
 
@@ -247,7 +247,7 @@ void ShardRegistry::startup(OperationContext* opCtx) {
 }
 
 void ShardRegistry::_internalReload(const CallbackArgs& cbArgs) {
-    LOG(1) << "Reloading shardRegistry";
+    LOGV2_DEBUG(1, "Reloading shardRegistry");
     if (!cbArgs.status.isOK()) {
         warning() << "cant reload ShardRegistry " << causedBy(cbArgs.status);
         return;
@@ -270,8 +270,7 @@ void ShardRegistry::_internalReload(const CallbackArgs& cbArgs) {
                                   [this](const CallbackArgs& cbArgs) { _internalReload(cbArgs); });
 
     if (status.getStatus() == ErrorCodes::ShutdownInProgress) {
-        LOG(1) << "Cant schedule ShardRegistry reload. "
-               << "Executor shutdown in progress";
+        LOGV2_DEBUG(1, "Cant schedule ShardRegistry reload. Executor shutdown in progress");
         return;
     }
 
@@ -298,7 +297,7 @@ bool ShardRegistry::reload(OperationContext* opCtx) {
             opCtx->waitForConditionOrInterrupt(
                 _inReloadCV, reloadLock, [&] { return _reloadState != ReloadState::Reloading; });
         } catch (const DBException& e) {
-            LOG(1) << "ShardRegistry reload is interrupted due to: " << redact(e.toStatus());
+            LOGV2_DEBUG(1, "ShardRegistry reload is interrupted due to: {}", "redact_e_toStatus"_attr = redact(e.toStatus()));
             return false;
         }
 
@@ -365,8 +364,7 @@ void ShardRegistry::updateReplicaSetOnConfigServer(ServiceContext* serviceContex
 
     std::shared_ptr<Shard> s = grid->shardRegistry()->lookupRSName(connStr.getSetName());
     if (!s) {
-        LOG(1) << "shard not found for set: " << connStr
-               << " when attempting to inform config servers of updated set membership";
+        LOGV2_DEBUG(1, "shard not found for set: {} when attempting to inform config servers of updated set membership", "connStr"_attr = connStr);
         return;
     }
 
@@ -410,9 +408,7 @@ ShardRegistryData::ShardRegistryData(OperationContext* opCtx, ShardFactory* shar
     auto shards = std::move(shardsAndOpTime.value);
     auto reloadOpTime = std::move(shardsAndOpTime.opTime);
 
-    LOG(1) << "found " << shards.size()
-           << " shards listed on config server(s) with lastVisibleOpTime: "
-           << reloadOpTime.toBSON();
+    LOGV2_DEBUG(1, "found {} shards listed on config server(s) with lastVisibleOpTime: {}", "shards_size"_attr = shards.size(), "reloadOpTime_toBSON"_attr = reloadOpTime.toBSON());
 
     // Ensure targeter exists for all shards and take shard connection string from the targeter.
     // Do this before re-taking the mutex to avoid deadlock with the ReplicaSetMonitor updating
@@ -561,8 +557,7 @@ void ShardRegistryData::_addShard(WithLock lk,
         auto oldConnString = currentShard->originalConnString();
 
         if (oldConnString.toString() != connString.toString()) {
-            log() << "Updating ShardRegistry connection string for shard " << currentShard->getId()
-                  << " from: " << oldConnString.toString() << " to: " << connString.toString();
+            LOGV2("Updating ShardRegistry connection string for shard {} from: {} to: {}", "currentShard_getId"_attr = currentShard->getId(), "oldConnString_toString"_attr = oldConnString.toString(), "connString_toString"_attr = connString.toString());
         }
 
         for (const auto& host : oldConnString.getServers()) {
@@ -574,7 +569,7 @@ void ShardRegistryData::_addShard(WithLock lk,
 
     _lookup[shard->getId()] = shard;
 
-    LOG(3) << "Adding shard " << shard->getId() << ", with CS " << connString.toString();
+    LOGV2_DEBUG(3, "Adding shard {}, with CS {}", "shard_getId"_attr = shard->getId(), "connString_toString"_attr = connString.toString());
     if (connString.type() == ConnectionString::SET) {
         _rsLookup[connString.getSetName()] = shard;
     } else if (connString.type() == ConnectionString::CUSTOM) {
diff --git a/src/mongo/s/client/shard_remote.cpp b/src/mongo/s/client/shard_remote.cpp
index c28a962636..bb0f106a5d 100644
--- a/src/mongo/s/client/shard_remote.cpp
+++ b/src/mongo/s/client/shard_remote.cpp
@@ -47,6 +47,7 @@
 #include "mongo/db/query/query_request.h"
 #include "mongo/db/repl/read_concern_args.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/repl_set_metadata.h"
 #include "mongo/rpc/metadata/tracking_metadata.h"
@@ -229,7 +230,7 @@ StatusWith<Shard::CommandResponse> ShardRemote::_runCommand(OperationContext* op
 
     if (!response.status.isOK()) {
         if (ErrorCodes::isExceededTimeLimitError(response.status.code())) {
-            LOG(0) << "Operation timed out with status " << redact(response.status);
+            LOGV2("Operation timed out with status {}", "redact_response_status"_attr = redact(response.status));
         }
         return response.status;
     }
@@ -327,7 +328,7 @@ StatusWith<Shard::QueryResponse> ShardRemote::_runExhaustiveCursorCommand(
 
     if (!status.isOK()) {
         if (ErrorCodes::isExceededTimeLimitError(status.code())) {
-            LOG(0) << "Operation timed out " << causedBy(status);
+            LOGV2("Operation timed out {}", "causedBy_status"_attr = causedBy(status));
         }
         return status;
     }
diff --git a/src/mongo/s/client/sharding_connection_hook.cpp b/src/mongo/s/client/sharding_connection_hook.cpp
index cbdad3a125..5ff19b03d0 100644
--- a/src/mongo/s/client/sharding_connection_hook.cpp
+++ b/src/mongo/s/client/sharding_connection_hook.cpp
@@ -38,6 +38,7 @@
 #include "mongo/bson/util/bson_extract.h"
 #include "mongo/client/authenticate.h"
 #include "mongo/db/client.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/client/version_manager.h"
 #include "mongo/util/log.h"
@@ -58,7 +59,7 @@ void ShardingConnectionHook::onCreate(DBClientBase* conn) {
     // Authenticate as the first thing we do
     // NOTE: Replica set authentication allows authentication against *any* online host
     if (auth::isInternalAuthSet()) {
-        LOG(2) << "calling onCreate auth for " << conn->toString();
+        LOGV2_DEBUG(2, "calling onCreate auth for {}", "conn_toString"_attr = conn->toString());
 
         uassertStatusOKWithContext(conn->authenticateInternalUser(),
                                    str::stream() << "can't authenticate to server "
diff --git a/src/mongo/s/commands/cluster_coll_stats_cmd.cpp b/src/mongo/s/commands/cluster_coll_stats_cmd.cpp
index 3d4667879f..40ae735297 100644
--- a/src/mongo/s/commands/cluster_coll_stats_cmd.cpp
+++ b/src/mongo/s/commands/cluster_coll_stats_cmd.cpp
@@ -32,6 +32,7 @@
 #include "mongo/platform/basic.h"
 
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/grid.h"
@@ -173,7 +174,7 @@ public:
                         }
                     }
                 } else {
-                    log() << "mongos collstats doesn't know about: " << e.fieldName();
+                    LOGV2("mongos collstats doesn't know about: {}", "e_fieldName"_attr = e.fieldName());
                 }
             }
 
diff --git a/src/mongo/s/commands/cluster_collection_mod_cmd.cpp b/src/mongo/s/commands/cluster_collection_mod_cmd.cpp
index 21c8dc7a14..70996875a7 100644
--- a/src/mongo/s/commands/cluster_collection_mod_cmd.cpp
+++ b/src/mongo/s/commands/cluster_collection_mod_cmd.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
@@ -69,7 +70,7 @@ public:
                    std::string& errmsg,
                    BSONObjBuilder& output) override {
         const NamespaceString nss(CommandHelpers::parseNsCollectionRequired(dbName, cmdObj));
-        LOG(1) << "collMod: " << nss << " cmd:" << redact(cmdObj);
+        LOGV2_DEBUG(1, "collMod: {} cmd:{}", "nss"_attr = nss, "redact_cmdObj"_attr = redact(cmdObj));
 
         auto routingInfo =
             uassertStatusOK(Grid::get(opCtx)->catalogCache()->getCollectionRoutingInfo(opCtx, nss));
diff --git a/src/mongo/s/commands/cluster_create_indexes_cmd.cpp b/src/mongo/s/commands/cluster_create_indexes_cmd.cpp
index cffbd636e7..ea9fd470c6 100644
--- a/src/mongo/s/commands/cluster_create_indexes_cmd.cpp
+++ b/src/mongo/s/commands/cluster_create_indexes_cmd.cpp
@@ -32,6 +32,7 @@
 #include "mongo/platform/basic.h"
 
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/grid.h"
@@ -70,7 +71,7 @@ public:
                    std::string& errmsg,
                    BSONObjBuilder& output) override {
         const NamespaceString nss(CommandHelpers::parseNsCollectionRequired(dbName, cmdObj));
-        LOG(1) << "createIndexes: " << nss << " cmd:" << redact(cmdObj);
+        LOGV2_DEBUG(1, "createIndexes: {} cmd:{}", "nss"_attr = nss, "redact_cmdObj"_attr = redact(cmdObj));
 
         createShardDatabase(opCtx, dbName);
 
diff --git a/src/mongo/s/commands/cluster_drop_indexes_cmd.cpp b/src/mongo/s/commands/cluster_drop_indexes_cmd.cpp
index 2b45943c3b..268655dc05 100644
--- a/src/mongo/s/commands/cluster_drop_indexes_cmd.cpp
+++ b/src/mongo/s/commands/cluster_drop_indexes_cmd.cpp
@@ -32,6 +32,7 @@
 #include "mongo/platform/basic.h"
 
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/grid.h"
 #include "mongo/util/log.h"
@@ -69,7 +70,7 @@ public:
                    std::string& errmsg,
                    BSONObjBuilder& output) override {
         const NamespaceString nss(CommandHelpers::parseNsCollectionRequired(dbName, cmdObj));
-        LOG(1) << "dropIndexes: " << nss << " cmd:" << redact(cmdObj);
+        LOGV2_DEBUG(1, "dropIndexes: {} cmd:{}", "nss"_attr = nss, "redact_cmdObj"_attr = redact(cmdObj));
 
         // If the collection is sharded, we target only the primary shard and the shards that own
         // chunks for the collection. We ignore IndexNotFound errors, because the index may have
diff --git a/src/mongo/s/commands/cluster_get_last_error_cmd.cpp b/src/mongo/s/commands/cluster_get_last_error_cmd.cpp
index 3d941e1ad3..91793308c1 100644
--- a/src/mongo/s/commands/cluster_get_last_error_cmd.cpp
+++ b/src/mongo/s/commands/cluster_get_last_error_cmd.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/commands.h"
 #include "mongo/db/lasterror.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/cluster_last_error_info.h"
@@ -105,9 +106,7 @@ Status enforceLegacyWriteConcern(OperationContext* opCtx,
             return swShard.getStatus();
         }
 
-        LOG(3) << "enforcing write concern " << options << " on " << shardConnStr.toString()
-               << " at opTime " << opTime.getTimestamp().toStringPretty() << " with electionID "
-               << electionId;
+        LOGV2_DEBUG(3, "enforcing write concern {} on {} at opTime {} with electionID {}", "options"_attr = options, "shardConnStr_toString"_attr = shardConnStr.toString(), "opTime_getTimestamp_toStringPretty"_attr = opTime.getTimestamp().toStringPretty(), "electionId"_attr = electionId);
 
         BSONObj gleCmd = buildGLECmdWithOpTime(options, opTime, electionId);
         requests.emplace_back(swShard.getValue()->getId(), gleCmd);
diff --git a/src/mongo/s/commands/cluster_get_shard_version_cmd.cpp b/src/mongo/s/commands/cluster_get_shard_version_cmd.cpp
index 78b3021a69..3e9d1611c3 100644
--- a/src/mongo/s/commands/cluster_get_shard_version_cmd.cpp
+++ b/src/mongo/s/commands/cluster_get_shard_version_cmd.cpp
@@ -35,6 +35,7 @@
 #include "mongo/db/auth/action_type.h"
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/database_version_gen.h"
@@ -114,7 +115,7 @@ public:
                 bool exceedsSizeLimit = false;
 
                 for (const auto& chunk : cm->chunks()) {
-                    log() << redact(chunk.toString());
+                    LOGV2("{}", "redact_chunk_toString"_attr = redact(chunk.toString()));
                     if (!exceedsSizeLimit) {
                         BSONArrayBuilder chunkBB(chunksArrBuilder.subarrayStart());
                         chunkBB.append(chunk.getMin());
diff --git a/src/mongo/s/commands/cluster_kill_op.cpp b/src/mongo/s/commands/cluster_kill_op.cpp
index 89e00b7d49..5cd6fe8c4f 100644
--- a/src/mongo/s/commands/cluster_kill_op.cpp
+++ b/src/mongo/s/commands/cluster_kill_op.cpp
@@ -42,6 +42,7 @@
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/commands.h"
 #include "mongo/db/commands/kill_op_cmd_base.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/metadata.h"
 #include "mongo/s/client/shard.h"
 #include "mongo/s/client/shard_registry.h"
@@ -93,7 +94,7 @@ private:
                     (opSepPos != (opToKill.size() - 1)));  // can't be NN:
 
         auto shardIdent = opToKill.substr(0, opSepPos);
-        log() << "want to kill op: " << redact(opToKill);
+        LOGV2("want to kill op: {}", "redact_opToKill"_attr = redact(opToKill));
 
         // Will throw if shard id is not found
         auto shardStatus = Grid::get(opCtx)->shardRegistry()->getShard(opCtx, shardIdent);
diff --git a/src/mongo/s/commands/cluster_move_chunk_cmd.cpp b/src/mongo/s/commands/cluster_move_chunk_cmd.cpp
index 434ba36fb2..971482a2e5 100644
--- a/src/mongo/s/commands/cluster_move_chunk_cmd.cpp
+++ b/src/mongo/s/commands/cluster_move_chunk_cmd.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/client.h"
 #include "mongo/db/commands.h"
 #include "mongo/db/write_concern_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_registry.h"
@@ -119,7 +120,7 @@ public:
             std::string msg(str::stream()
                             << "Could not move chunk in '" << nss.ns() << "' to shard '" << toString
                             << "' because that shard does not exist");
-            log() << msg;
+            LOGV2("{}", "msg"_attr = msg);
             uasserted(ErrorCodes::ShardNotFound, msg);
         }
 
diff --git a/src/mongo/s/commands/cluster_refine_collection_shard_key_cmd.cpp b/src/mongo/s/commands/cluster_refine_collection_shard_key_cmd.cpp
index 1bb76a72d1..58b54445a7 100644
--- a/src/mongo/s/commands/cluster_refine_collection_shard_key_cmd.cpp
+++ b/src/mongo/s/commands/cluster_refine_collection_shard_key_cmd.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/request_types/refine_collection_shard_key_gen.h"
 #include "mongo/util/fail_point.h"
@@ -59,7 +60,7 @@ public:
                                                                                              nss));
 
             if (MONGO_unlikely(hangRefineCollectionShardKeyAfterRefresh.shouldFail())) {
-                log() << "Hit hangRefineCollectionShardKeyAfterRefresh failpoint";
+                LOGV2("Hit hangRefineCollectionShardKeyAfterRefresh failpoint");
                 hangRefineCollectionShardKeyAfterRefresh.pauseWhileSet(opCtx);
             }
 
diff --git a/src/mongo/s/commands/cluster_set_index_commit_quorum_cmd.cpp b/src/mongo/s/commands/cluster_set_index_commit_quorum_cmd.cpp
index 5074b7da45..e690056d1d 100644
--- a/src/mongo/s/commands/cluster_set_index_commit_quorum_cmd.cpp
+++ b/src/mongo/s/commands/cluster_set_index_commit_quorum_cmd.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/commands.h"
 #include "mongo/db/commands/set_index_commit_quorum_gen.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/util/log.h"
 
@@ -85,8 +86,7 @@ public:
 
         void typedRun(OperationContext* opCtx) {
             BSONObj cmdObj = request().toBSON(BSONObj());
-            LOG(1) << "setIndexCommitQuorum: " << request().getNamespace()
-                   << " cmd:" << redact(cmdObj);
+            LOGV2_DEBUG(1, "setIndexCommitQuorum: {} cmd:{}", "request_getNamespace"_attr = request().getNamespace(), "redact_cmdObj"_attr = redact(cmdObj));
 
             scatterGatherOnlyVersionIfUnsharded(
                 opCtx,
diff --git a/src/mongo/s/commands/cluster_split_cmd.cpp b/src/mongo/s/commands/cluster_split_cmd.cpp
index 114d0f27bb..a0b670f2c5 100644
--- a/src/mongo/s/commands/cluster_split_cmd.cpp
+++ b/src/mongo/s/commands/cluster_split_cmd.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/auth/authorization_session.h"
 #include "mongo/db/commands.h"
 #include "mongo/db/field_parser.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/cluster_commands_helpers.h"
@@ -254,10 +255,7 @@ public:
                               cm->getShardKeyPattern(),
                               ChunkRange(chunk->getMin(), chunk->getMax()));
 
-        log() << "Splitting chunk "
-              << redact(ChunkRange(chunk->getMin(), chunk->getMax()).toString())
-              << " in collection " << nss.ns() << " on shard " << chunk->getShardId() << " at key "
-              << redact(splitPoint);
+        LOGV2("Splitting chunk {} in collection {} on shard {} at key {}", "redact_ChunkRange_chunk_getMin_chunk_getMax_toString"_attr = redact(ChunkRange(chunk->getMin(), chunk->getMax()).toString()), "nss_ns"_attr = nss.ns(), "chunk_getShardId"_attr = chunk->getShardId(), "redact_splitPoint"_attr = redact(splitPoint));
 
         uassertStatusOK(
             shardutil::splitChunkAtMultiplePoints(opCtx,
diff --git a/src/mongo/s/commands/cluster_write_cmd.cpp b/src/mongo/s/commands/cluster_write_cmd.cpp
index c0370d168b..d26e99499a 100644
--- a/src/mongo/s/commands/cluster_write_cmd.cpp
+++ b/src/mongo/s/commands/cluster_write_cmd.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/stats/counters.h"
 #include "mongo/db/storage/duplicate_key_error_info.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/client/num_hosts_targeted_metrics.h"
 #include "mongo/s/client/shard_registry.h"
@@ -206,7 +207,7 @@ bool handleWouldChangeOwningShardError(OperationContext* opCtx,
     boost::optional<BSONObj> upsertedId;
     if (isRetryableWrite) {
         if (MONGO_unlikely(hangAfterThrowWouldChangeOwningShardRetryableWrite.shouldFail())) {
-            log() << "Hit hangAfterThrowWouldChangeOwningShardRetryableWrite failpoint";
+            LOGV2("Hit hangAfterThrowWouldChangeOwningShardRetryableWrite failpoint");
             hangAfterThrowWouldChangeOwningShardRetryableWrite.pauseWhileSet(opCtx);
         }
         RouterOperationContextSession routerSession(opCtx);
diff --git a/src/mongo/s/commands/document_shard_key_update_util.cpp b/src/mongo/s/commands/document_shard_key_update_util.cpp
index d576e496ea..bc9e03565c 100644
--- a/src/mongo/s/commands/document_shard_key_update_util.cpp
+++ b/src/mongo/s/commands/document_shard_key_update_util.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/base/status_with.h"
 #include "mongo/db/namespace_string.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/would_change_owning_shard_exception.h"
 #include "mongo/s/write_ops/batched_command_request.h"
 #include "mongo/s/write_ops/batched_command_response.h"
@@ -78,7 +79,7 @@ bool executeOperationsAsPartOfShardKeyUpdate(OperationContext* opCtx,
     }
 
     if (MONGO_unlikely(hangBeforeInsertOnUpdateShardKey.shouldFail())) {
-        log() << "Hit hangBeforeInsertOnUpdateShardKey failpoint";
+        LOGV2("Hit hangBeforeInsertOnUpdateShardKey failpoint");
         hangBeforeInsertOnUpdateShardKey.pauseWhileSet(opCtx);
     }
 
diff --git a/src/mongo/s/commands/flush_router_config_cmd.cpp b/src/mongo/s/commands/flush_router_config_cmd.cpp
index 3c180ea36b..75571f7c17 100644
--- a/src/mongo/s/commands/flush_router_config_cmd.cpp
+++ b/src/mongo/s/commands/flush_router_config_cmd.cpp
@@ -32,6 +32,7 @@
 #include "mongo/platform/basic.h"
 
 #include "mongo/db/commands.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/is_mongos.h"
 #include "mongo/util/log.h"
@@ -86,16 +87,16 @@ public:
 
         const auto argumentElem = cmdObj.firstElement();
         if (argumentElem.isNumber() || argumentElem.isBoolean()) {
-            LOG(0) << "Routing metadata flushed for all databases";
+            LOGV2("Routing metadata flushed for all databases");
             catalogCache->purgeAllDatabases();
         } else {
             const auto ns = argumentElem.checkAndGetStringData();
             if (nsIsDbOnly(ns)) {
-                LOG(0) << "Routing metadata flushed for database " << ns;
+                LOGV2("Routing metadata flushed for database {}", "ns"_attr = ns);
                 catalogCache->purgeDatabase(ns);
             } else {
                 const NamespaceString nss(ns);
-                LOG(0) << "Routing metadata flushed for collection " << nss;
+                LOGV2("Routing metadata flushed for collection {}", "nss"_attr = nss);
                 catalogCache->purgeCollection(nss);
             }
         }
diff --git a/src/mongo/s/commands/strategy.cpp b/src/mongo/s/commands/strategy.cpp
index c80ed6e095..3faa7419fe 100644
--- a/src/mongo/s/commands/strategy.cpp
+++ b/src/mongo/s/commands/strategy.cpp
@@ -61,6 +61,7 @@
 #include "mongo/db/stats/counters.h"
 #include "mongo/db/transaction_validation.h"
 #include "mongo/db/views/resolved_view.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/factory.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/logical_time_metadata.h"
@@ -136,12 +137,12 @@ void appendRequiredFieldsToResponse(OperationContext* opCtx, BSONObjBuilder* res
         // Add operationTime.
         auto operationTime = OperationTimeTracker::get(opCtx)->getMaxOperationTime();
         if (operationTime != LogicalTime::kUninitialized) {
-            LOG(5) << "Appending operationTime: " << operationTime.asTimestamp();
+            LOGV2_DEBUG(5, "Appending operationTime: {}", "operationTime_asTimestamp"_attr = operationTime.asTimestamp());
             responseBuilder->append(kOperationTime, operationTime.asTimestamp());
         } else if (now != LogicalTime::kUninitialized) {
             // If we don't know the actual operation time, use the cluster time instead. This is
             // safe but not optimal because we can always return a later operation time than actual.
-            LOG(5) << "Appending clusterTime as operationTime " << now.asTimestamp();
+            LOGV2_DEBUG(5, "Appending clusterTime as operationTime {}", "now_asTimestamp"_attr = now.asTimestamp());
             responseBuilder->append(kOperationTime, now.asTimestamp());
         }
 
@@ -443,8 +444,7 @@ void runCommand(OperationContext* opCtx,
             if (const auto wcDefault = ReadWriteConcernDefaults::get(opCtx->getServiceContext())
                                            .getDefaultWriteConcern(opCtx)) {
                 wc = *wcDefault;
-                LOG(2) << "Applying default writeConcern on " << request.getCommandName() << " of "
-                       << wcDefault->toBSON();
+                LOGV2_DEBUG(2, "Applying default writeConcern on {} of {}", "request_getCommandName"_attr = request.getCommandName(), "wcDefault_toBSON"_attr = wcDefault->toBSON());
             }
         }
 
@@ -470,8 +470,7 @@ void runCommand(OperationContext* opCtx,
                         stdx::lock_guard<Client> lk(*opCtx->getClient());
                         readConcernArgs = std::move(*rcDefault);
                     }
-                    LOG(2) << "Applying default readConcern on "
-                           << invocation->definition()->getName() << " of " << *rcDefault;
+                    LOGV2_DEBUG(2, "Applying default readConcern on {} of {}", "invocation_definition_getName"_attr = invocation->definition()->getName(), "rcDefault"_attr = *rcDefault);
                     // Update the readConcernSupport, since the default RC was applied.
                     readConcernSupport =
                         invocation->supportsReadConcern(readConcernArgs.getLevel());
@@ -739,8 +738,7 @@ DbResponse Strategy::queryOp(OperationContext* opCtx, const NamespaceString& nss
     audit::logQueryAuthzCheck(client, nss, q.query, status.code());
     uassertStatusOK(status);
 
-    LOG(3) << "query: " << q.ns << " " << redact(q.query) << " ntoreturn: " << q.ntoreturn
-           << " options: " << q.queryOptions;
+    LOGV2_DEBUG(3, "query: {} {} ntoreturn: {} options: {}", "q_ns"_attr = q.ns, "redact_q_query"_attr = redact(q.query), "q_ntoreturn"_attr = q.ntoreturn, "q_queryOptions"_attr = q.queryOptions);
 
     if (q.queryOptions & QueryOption_Exhaust) {
         uasserted(18526,
@@ -838,7 +836,7 @@ DbResponse Strategy::clientCommand(OperationContext* opCtx, const Message& m) {
                 if (ErrorCodes::isConnectionFatalMessageParseError(ex.code()))
                     propagateException = true;
 
-                LOG(1) << "Exception thrown while parsing command " << causedBy(redact(ex));
+                LOGV2_DEBUG(1, "Exception thrown while parsing command {}", "causedBy_redact_ex"_attr = causedBy(redact(ex)));
                 throw;
             }
         }();
@@ -846,12 +844,11 @@ DbResponse Strategy::clientCommand(OperationContext* opCtx, const Message& m) {
         // Execute.
         std::string db = request.getDatabase().toString();
         try {
-            LOG(3) << "Command begin db: " << db << " msg id: " << m.header().getId();
+            LOGV2_DEBUG(3, "Command begin db: {} msg id: {}", "db"_attr = db, "m_header_getId"_attr = m.header().getId());
             runCommand(opCtx, request, m.operation(), reply.get(), &errorBuilder);
-            LOG(3) << "Command end db: " << db << " msg id: " << m.header().getId();
+            LOGV2_DEBUG(3, "Command end db: {} msg id: {}", "db"_attr = db, "m_header_getId"_attr = m.header().getId());
         } catch (const DBException& ex) {
-            LOG(1) << "Exception thrown while processing command on " << db
-                   << " msg id: " << m.header().getId() << causedBy(redact(ex));
+            LOGV2_DEBUG(1, "Exception thrown while processing command on {} msg id: {}{}", "db"_attr = db, "m_header_getId"_attr = m.header().getId(), "causedBy_redact_ex"_attr = causedBy(redact(ex)));
 
             // Record the exception in CurOp.
             CurOp::get(opCtx)->debug().errInfo = ex.toStatus();
@@ -991,7 +988,7 @@ void Strategy::killCursors(OperationContext* opCtx, DbMessage* dbm) {
 
         boost::optional<NamespaceString> nss = manager->getNamespaceForCursorId(cursorId);
         if (!nss) {
-            LOG(3) << "Can't find cursor to kill.  Cursor id: " << cursorId << ".";
+            LOGV2_DEBUG(3, "Can't find cursor to kill.  Cursor id: {}.", "cursorId"_attr = cursorId);
             continue;
         }
 
@@ -1002,19 +999,17 @@ void Strategy::killCursors(OperationContext* opCtx, DbMessage* dbm) {
         auto authzStatus = manager->checkAuthForKillCursors(opCtx, *nss, cursorId, authChecker);
         audit::logKillCursorsAuthzCheck(client, *nss, cursorId, authzStatus.code());
         if (!authzStatus.isOK()) {
-            LOG(3) << "Not authorized to kill cursor.  Namespace: '" << *nss
-                   << "', cursor id: " << cursorId << ".";
+            LOGV2_DEBUG(3, "Not authorized to kill cursor.  Namespace: '{}', cursor id: {}.", "nss"_attr = *nss, "cursorId"_attr = cursorId);
             continue;
         }
 
         Status killCursorStatus = manager->killCursor(opCtx, *nss, cursorId);
         if (!killCursorStatus.isOK()) {
-            LOG(3) << "Can't find cursor to kill.  Namespace: '" << *nss
-                   << "', cursor id: " << cursorId << ".";
+            LOGV2_DEBUG(3, "Can't find cursor to kill.  Namespace: '{}', cursor id: {}.", "nss"_attr = *nss, "cursorId"_attr = cursorId);
             continue;
         }
 
-        LOG(3) << "Killed cursor.  Namespace: '" << *nss << "', cursor id: " << cursorId << ".";
+        LOGV2_DEBUG(3, "Killed cursor.  Namespace: '{}', cursor id: {}.", "nss"_attr = *nss, "cursorId"_attr = cursorId);
     }
 }
 
diff --git a/src/mongo/s/grid.cpp b/src/mongo/s/grid.cpp
index bda2bc6e92..cbbe59d393 100644
--- a/src/mongo/s/grid.cpp
+++ b/src/mongo/s/grid.cpp
@@ -37,6 +37,7 @@
 #include "mongo/db/server_options.h"
 #include "mongo/executor/task_executor.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/shard_factory.h"
@@ -130,10 +131,8 @@ boost::optional<repl::OpTime> Grid::advanceConfigOpTime(OperationContext* opCtx,
         if (opCtx && opCtx->getClient()) {
             clientAddr = opCtx->getClient()->clientAddress(true);
         }
-        log() << "Received " << what << " " << clientAddr
-              << " indicating config server optime "
-                 "term has increased, previous optime "
-              << prevOpTime << ", now " << opTime;
+        LOGV2("Received {} {} indicating config server optime "
+                 "term has increased, previous optime {}, now {}", "what"_attr = what, "clientAddr"_attr = clientAddr, "prevOpTime"_attr = prevOpTime, "opTime"_attr = opTime);
     }
     return prevOpTime;
 }
diff --git a/src/mongo/s/query/cluster_cursor_manager.cpp b/src/mongo/s/query/cluster_cursor_manager.cpp
index ef0c3b0296..8b6ab5284e 100644
--- a/src/mongo/s/query/cluster_cursor_manager.cpp
+++ b/src/mongo/s/query/cluster_cursor_manager.cpp
@@ -38,6 +38,7 @@
 
 #include "mongo/db/kill_sessions_common.h"
 #include "mongo/db/logical_session_cache.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/clock_source.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -396,8 +397,7 @@ std::size_t ClusterCursorManager::killMortalCursorsInactiveSince(OperationContex
             !entry.getOperationUsingCursor() && entry.getLastActive() <= cutoff;
 
         if (res) {
-            log() << "Cursor id " << cursorId << " timed out, idle since "
-                  << entry.getLastActive().toString();
+            LOGV2("Cursor id {} timed out, idle since {}", "cursorId"_attr = cursorId, "entry_getLastActive_toString"_attr = entry.getLastActive().toString());
         }
 
         return res;
@@ -582,7 +582,7 @@ std::pair<Status, int> ClusterCursorManager::killCursorsWithMatchingSessions(
             return;
         }
         uassertStatusOK(mgr.killCursor(opCtx, *cursorNss, id));
-        log() << "killing cursor: " << id << " as part of killing session(s)";
+        LOGV2("killing cursor: {} as part of killing session(s)", "id"_attr = id);
     };
 
     auto bySessionCursorKiller = makeKillCursorsBySessionAdaptor(opCtx, matcher, std::move(eraser));
diff --git a/src/mongo/s/query/cluster_find.cpp b/src/mongo/s/query/cluster_find.cpp
index b4f8654112..32e609846f 100644
--- a/src/mongo/s/query/cluster_find.cpp
+++ b/src/mongo/s/query/cluster_find.cpp
@@ -51,6 +51,7 @@
 #include "mongo/db/query/getmore_request.h"
 #include "mongo/db/query/query_planner_common.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/overflow_arithmetic.h"
 #include "mongo/s/catalog_cache.h"
 #include "mongo/s/client/num_hosts_targeted_metrics.h"
@@ -518,8 +519,7 @@ CursorId ClusterFind::runQuery(OperationContext* opCtx,
                 throw;
             }
 
-            LOG(1) << "Received error status for query " << redact(query.toStringShort())
-                   << " on attempt " << retries << " of " << kMaxRetries << ": " << redact(ex);
+            LOGV2_DEBUG(1, "Received error status for query {} on attempt {} of {}: {}", "redact_query_toStringShort"_attr = redact(query.toStringShort()), "retries"_attr = retries, "kMaxRetries"_attr = kMaxRetries, "redact_ex"_attr = redact(ex));
 
             Grid::get(opCtx)->catalogCache()->onStaleDatabaseVersion(ex->getDb(),
                                                                      ex->getVersionReceived());
@@ -552,8 +552,7 @@ CursorId ClusterFind::runQuery(OperationContext* opCtx,
                 throw;
             }
 
-            LOG(1) << "Received error status for query " << redact(query.toStringShort())
-                   << " on attempt " << retries << " of " << kMaxRetries << ": " << redact(ex);
+            LOGV2_DEBUG(1, "Received error status for query {} on attempt {} of {}: {}", "redact_query_toStringShort"_attr = redact(query.toStringShort()), "retries"_attr = retries, "kMaxRetries"_attr = kMaxRetries, "redact_ex"_attr = redact(ex));
 
             catalogCache->onStaleShardVersion(std::move(routingInfo));
 
diff --git a/src/mongo/s/server.cpp b/src/mongo/s/server.cpp
index 020393769b..f5bb2aac2a 100644
--- a/src/mongo/s/server.cpp
+++ b/src/mongo/s/server.cpp
@@ -69,6 +69,7 @@
 #include "mongo/db/startup_warnings_common.h"
 #include "mongo/db/wire_version.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/process_id.h"
 #include "mongo/rpc/metadata/egress_metadata_hook_list.h"
 #include "mongo/s/balancer_configuration.h"
@@ -153,8 +154,7 @@ Status waitForSigningKeys(OperationContext* opCtx) {
         // mongod will set minWireVersion == maxWireVersion for isMaster requests from
         // internalClient.
         if (rsm && (rsm->getMaxWireVersion() < WireVersion::SUPPORTS_OP_MSG)) {
-            log() << "Not waiting for signing keys, not supported by the config shard "
-                  << configCS.getSetName();
+            LOGV2("Not waiting for signing keys, not supported by the config shard {}", "configCS_getSetName"_attr = configCS.getSetName());
             return Status::OK();
         }
         auto stopStatus = opCtx->checkForInterruptNoAssert();
@@ -166,8 +166,7 @@ Status waitForSigningKeys(OperationContext* opCtx) {
             if (LogicalTimeValidator::get(opCtx)->shouldGossipLogicalTime()) {
                 return Status::OK();
             }
-            log() << "Waiting for signing keys, sleeping for " << kSignKeysRetryInterval
-                  << " and trying again.";
+            LOGV2("Waiting for signing keys, sleeping for {} and trying again.", "kSignKeysRetryInterval"_attr = kSignKeysRetryInterval);
             sleepFor(kSignKeysRetryInterval);
             continue;
         } catch (const DBException& ex) {
@@ -261,7 +260,7 @@ void cleanupTask(ServiceContext* serviceContext) {
 
         // Shutdown the TransportLayer so that new connections aren't accepted
         if (auto tl = serviceContext->getTransportLayer()) {
-            log(LogComponent::kNetwork) << "shutdown: going to close all sockets...";
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "shutdown: going to close all sockets...");
 
             tl->shutdown();
         }
@@ -324,8 +323,7 @@ void cleanupTask(ServiceContext* serviceContext) {
         // Shutdown the Service Entry Point and its sessions and give it a grace period to complete.
         if (auto sep = serviceContext->getServiceEntryPoint()) {
             if (!sep->shutdown(Seconds(10))) {
-                log(LogComponent::kNetwork)
-                    << "Service entry point failed to shutdown within timelimit.";
+                LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "Service entry point failed to shutdown within timelimit.");
             }
         }
 
@@ -333,8 +331,7 @@ void cleanupTask(ServiceContext* serviceContext) {
         if (auto svcExec = serviceContext->getServiceExecutor()) {
             Status status = svcExec->shutdown(Seconds(5));
             if (!status.isOK()) {
-                log(LogComponent::kNetwork)
-                    << "Service executor failed to shutdown within timelimit: " << status.reason();
+                LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "Service executor failed to shutdown within timelimit: {}", "status_reason"_attr = status.reason());
             }
         }
 #endif
@@ -469,7 +466,7 @@ public:
             invariant(args.status);
 
             try {
-                LOG(0) << "Updating sharding state with confirmed set " << connStr;
+                LOGV2("Updating sharding state with confirmed set {}", "connStr"_attr = connStr);
 
                 Grid::get(serviceContext)->shardRegistry()->updateReplSetHosts(connStr);
 
@@ -478,14 +475,14 @@ public:
                 }
                 ShardRegistry::updateReplicaSetOnConfigServer(serviceContext, connStr);
             } catch (const ExceptionForCat<ErrorCategory::ShutdownError>& e) {
-                LOG(0) << "Unable to update sharding state due to " << e;
+                LOGV2("Unable to update sharding state due to {}", "e"_attr = e);
             }
         };
 
         auto executor = Grid::get(_serviceContext)->getExecutorPool()->getFixedExecutor();
         auto schedStatus = executor->scheduleWork(std::move(fun)).getStatus();
         if (ErrorCodes::isCancelationError(schedStatus.code())) {
-            LOG(2) << "Unable to schedule confirmed set update due to " << schedStatus;
+            LOGV2_DEBUG(2, "Unable to schedule confirmed set update due to {}", "schedStatus"_attr = schedStatus);
             return;
         }
         uassertStatusOK(schedStatus);
@@ -564,7 +561,7 @@ ExitCode runMongosServer(ServiceContext* serviceContext) {
         if (!status.isOK()) {
             if (status == ErrorCodes::CallbackCanceled) {
                 invariant(globalInShutdownDeprecated());
-                log() << "Shutdown called before mongos finished starting up";
+                LOGV2("Shutdown called before mongos finished starting up");
                 return EXIT_CLEAN;
             }
             error() << "Error initializing sharding system: " << status;
@@ -638,7 +635,7 @@ ExitCode runMongosServer(ServiceContext* serviceContext) {
 #else
     if (ntservice::shouldStartService()) {
         ntservice::reportStatus(SERVICE_RUNNING);
-        log() << "Service running";
+        LOGV2("Service running");
     }
 #endif
 
@@ -687,7 +684,7 @@ ExitCode main(ServiceContext* serviceContext) {
         }
 
         if (configAddr.isLocalHost() != shardingContext->allowLocalHost()) {
-            log(LogComponent::kDefault) << "cannot mix localhost and ip addresses in configdbs";
+            LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kDefault).toInt(), "cannot mix localhost and ip addresses in configdbs");
             return EXIT_BADOPTIONS;
         }
     }
diff --git a/src/mongo/s/service_entry_point_mongos.cpp b/src/mongo/s/service_entry_point_mongos.cpp
index 598d9a052f..af10788944 100644
--- a/src/mongo/s/service_entry_point_mongos.cpp
+++ b/src/mongo/s/service_entry_point_mongos.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/lasterror.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/message.h"
 #include "mongo/s/client/shard_connection.h"
 #include "mongo/s/cluster_last_error_info.h"
@@ -117,8 +118,7 @@ DbResponse ServiceEntryPointMongos::handleRequest(OperationContext* opCtx, const
         }
 
 
-        LOG(3) << "Request::process begin ns: " << nss << " msg id: " << msgId
-               << " op: " << networkOpToString(op);
+        LOGV2_DEBUG(3, "Request::process begin ns: {} msg id: {} op: {}", "nss"_attr = nss, "msgId"_attr = msgId, "networkOpToString_op"_attr = networkOpToString(op));
 
         switch (op) {
             case dbQuery:
@@ -146,12 +146,10 @@ DbResponse ServiceEntryPointMongos::handleRequest(OperationContext* opCtx, const
                 MONGO_UNREACHABLE;
         }
 
-        LOG(3) << "Request::process end ns: " << nss << " msg id: " << msgId
-               << " op: " << networkOpToString(op);
+        LOGV2_DEBUG(3, "Request::process end ns: {} msg id: {} op: {}", "nss"_attr = nss, "msgId"_attr = msgId, "networkOpToString_op"_attr = networkOpToString(op));
 
     } catch (const DBException& ex) {
-        LOG(1) << "Exception thrown while processing " << networkOpToString(op) << " op for "
-               << nss.ns() << causedBy(ex);
+        LOGV2_DEBUG(1, "Exception thrown while processing {} op for {}{}", "networkOpToString_op"_attr = networkOpToString(op), "nss_ns"_attr = nss.ns(), "causedBy_ex"_attr = causedBy(ex));
 
         if (op == dbQuery || op == dbGetMore) {
             dbResponse = replyToQuery(buildErrReply(ex), ResultFlag_ErrSet);
diff --git a/src/mongo/s/shard_util.cpp b/src/mongo/s/shard_util.cpp
index 1f430a0d7b..8bea13874a 100644
--- a/src/mongo/s/shard_util.cpp
+++ b/src/mongo/s/shard_util.cpp
@@ -38,6 +38,7 @@
 #include "mongo/client/read_preference.h"
 #include "mongo/client/remote_command_targeter.h"
 #include "mongo/db/namespace_string.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/shard_key_pattern.h"
@@ -203,7 +204,7 @@ StatusWith<boost::optional<ChunkRange>> splitChunkAtMultiplePoints(
     }
 
     if (!status.isOK()) {
-        log() << "Split chunk " << redact(cmdObj) << " failed" << causedBy(redact(status));
+        LOGV2("Split chunk {} failed{}", "redact_cmdObj"_attr = redact(cmdObj), "causedBy_redact_status"_attr = causedBy(redact(status)));
         return status.withContext("split failed");
     }
 
diff --git a/src/mongo/s/sharding_task_executor.cpp b/src/mongo/s/sharding_task_executor.cpp
index c8db2851af..990e199da9 100644
--- a/src/mongo/s/sharding_task_executor.cpp
+++ b/src/mongo/s/sharding_task_executor.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/logical_time.h"
 #include "mongo/db/operation_time_tracker.h"
 #include "mongo/executor/thread_pool_task_executor.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/rpc/metadata/sharding_metadata.h"
 #include "mongo/s/client/shard_registry.h"
@@ -180,7 +181,7 @@ StatusWith<TaskExecutor::CallbackHandle> ShardingTaskExecutor::scheduleRemoteCom
             auto shard = grid->shardRegistry()->getShardForHostNoReload(target);
 
             if (!shard) {
-                LOG(1) << "Could not find shard containing host: " << target;
+                LOGV2_DEBUG(1, "Could not find shard containing host: {}", "target"_attr = target);
             }
 
             if (isMongos() && args.response.status == ErrorCodes::IncompatibleWithUpgradedServer) {
@@ -197,7 +198,7 @@ StatusWith<TaskExecutor::CallbackHandle> ShardingTaskExecutor::scheduleRemoteCom
                 shard->updateReplSetMonitor(target, args.response.status);
             }
 
-            LOG(1) << "Error processing the remote request, not updating operationTime or gLE";
+            LOGV2_DEBUG(1, "Error processing the remote request, not updating operationTime or gLE");
 
             return;
         }
diff --git a/src/mongo/s/sharding_uptime_reporter.cpp b/src/mongo/s/sharding_uptime_reporter.cpp
index e1b7e57f7b..3805b392f6 100644
--- a/src/mongo/s/sharding_uptime_reporter.cpp
+++ b/src/mongo/s/sharding_uptime_reporter.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/client.h"
 #include "mongo/db/read_write_concern_defaults.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/balancer_configuration.h"
 #include "mongo/s/catalog/type_mongos.h"
 #include "mongo/s/grid.h"
@@ -85,7 +86,7 @@ void reportStatus(OperationContext* opCtx,
                                    ShardingCatalogClient::kMajorityWriteConcern)
             .status_with_transitional_ignore();
     } catch (const std::exception& e) {
-        log() << "Caught exception while reporting uptime: " << e.what();
+        LOGV2("Caught exception while reporting uptime: {}", "e_what"_attr = e.what());
     }
 }
 
diff --git a/src/mongo/s/transaction_router.cpp b/src/mongo/s/transaction_router.cpp
index 6fa39d62e9..d6dda4dfdd 100644
--- a/src/mongo/s/transaction_router.cpp
+++ b/src/mongo/s/transaction_router.cpp
@@ -44,6 +44,7 @@
 #include "mongo/db/repl/read_concern_args.h"
 #include "mongo/db/transaction_validation.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/get_status_from_command_result.h"
 #include "mongo/s/async_requests_sender.h"
 #include "mongo/s/cluster_commands_helpers.h"
@@ -482,7 +483,7 @@ void TransactionRouter::Router::processParticipantResponse(OperationContext* opC
 
     if (txnResponseMetadata.getReadOnly()) {
         if (participant->readOnly == Participant::ReadOnly::kUnset) {
-            LOG(3) << txnIdToString() << " Marking " << shardId << " as read-only";
+            LOGV2_DEBUG(3, "{} Marking {} as read-only", "txnIdToString"_attr = txnIdToString(), "shardId"_attr = shardId);
             _setReadOnlyForParticipant(opCtx, shardId, Participant::ReadOnly::kReadOnly);
             return;
         }
@@ -498,12 +499,12 @@ void TransactionRouter::Router::processParticipantResponse(OperationContext* opC
     // The shard reported readOnly:false on this statement.
 
     if (participant->readOnly != Participant::ReadOnly::kNotReadOnly) {
-        LOG(3) << txnIdToString() << " Marking " << shardId << " as having done a write";
+        LOGV2_DEBUG(3, "{} Marking {} as having done a write", "txnIdToString"_attr = txnIdToString(), "shardId"_attr = shardId);
 
         _setReadOnlyForParticipant(opCtx, shardId, Participant::ReadOnly::kNotReadOnly);
 
         if (!p().recoveryShardId) {
-            LOG(3) << txnIdToString() << " Choosing " << shardId << " as recovery shard";
+            LOGV2_DEBUG(3, "{} Choosing {} as recovery shard", "txnIdToString"_attr = txnIdToString(), "shardId"_attr = shardId);
             p().recoveryShardId = shardId;
         }
     }
@@ -551,13 +552,12 @@ BSONObj TransactionRouter::Router::attachTxnFieldsIfNeeded(OperationContext* opC
                                                            const BSONObj& cmdObj) {
     RouterTransactionsMetrics::get(opCtx)->incrementTotalRequestsTargeted();
     if (auto txnPart = getParticipant(shardId)) {
-        LOG(4) << txnIdToString()
-               << " Sending transaction fields to existing participant: " << shardId;
+        LOGV2_DEBUG(4, "{} Sending transaction fields to existing participant: {}", "txnIdToString"_attr = txnIdToString(), "shardId"_attr = shardId);
         return txnPart->attachTxnFieldsIfNeeded(cmdObj, false);
     }
 
     auto txnPart = _createParticipant(opCtx, shardId);
-    LOG(4) << txnIdToString() << " Sending transaction fields to new participant: " << shardId;
+    LOGV2_DEBUG(4, "{} Sending transaction fields to new participant: {}", "txnIdToString"_attr = txnIdToString(), "shardId"_attr = shardId);
     if (!p().isRecoveringCommit) {
         // Don't update participant stats during recovery since the participant list isn't known.
         RouterTransactionsMetrics::get(opCtx)->incrementTotalContactedParticipants();
@@ -739,8 +739,7 @@ void TransactionRouter::Router::onStaleShardOrDbError(OperationContext* opCtx,
                                                       const Status& errorStatus) {
     invariant(canContinueOnStaleShardOrDbError(cmdName));
 
-    LOG(3) << txnIdToString()
-           << " Clearing pending participants after stale version error: " << errorStatus;
+    LOGV2_DEBUG(3, "{} Clearing pending participants after stale version error: {}", "txnIdToString"_attr = txnIdToString(), "errorStatus"_attr = errorStatus);
 
     // Remove participants created during the current statement so they are sent the correct options
     // if they are targeted again by the retry.
@@ -751,8 +750,7 @@ void TransactionRouter::Router::onViewResolutionError(OperationContext* opCtx,
                                                       const NamespaceString& nss) {
     // The router can always retry on a view resolution error.
 
-    LOG(3) << txnIdToString()
-           << " Clearing pending participants after view resolution error on namespace: " << nss;
+    LOGV2_DEBUG(3, "{} Clearing pending participants after view resolution error on namespace: {}", "txnIdToString"_attr = txnIdToString(), "nss"_attr = nss);
 
     // Requests against views are always routed to the primary shard for its database, but the retry
     // on the resolved namespace does not have to re-target the primary, so pending participants
@@ -772,10 +770,8 @@ void TransactionRouter::Router::onSnapshotError(OperationContext* opCtx,
                                                 const Status& errorStatus) {
     invariant(canContinueOnSnapshotError());
 
-    LOG(3) << txnIdToString()
-           << " Clearing pending participants and resetting global snapshot "
-              "timestamp after snapshot error: "
-           << errorStatus << ", previous timestamp: " << o().atClusterTime->getTime();
+    LOGV2_DEBUG(3, "{} Clearing pending participants and resetting global snapshot "
+              "timestamp after snapshot error: {}, previous timestamp: {}", "txnIdToString"_attr = txnIdToString(), "errorStatus"_attr = errorStatus, "o_atClusterTime_getTime"_attr = o().atClusterTime->getTime());
 
     // The transaction must be restarted on all participants because a new read timestamp will be
     // selected, so clear all pending participants. Snapshot errors are only retryable on the first
@@ -813,8 +809,7 @@ void TransactionRouter::Router::_setAtClusterTime(
         return;
     }
 
-    LOG(2) << txnIdToString() << " Setting global snapshot timestamp to " << candidateTime
-           << " on statement " << p().latestStmtId;
+    LOGV2_DEBUG(2, "{} Setting global snapshot timestamp to {} on statement {}", "txnIdToString"_attr = txnIdToString(), "candidateTime"_attr = candidateTime, "p_latestStmtId"_attr = p().latestStmtId);
 
     o(lk).atClusterTime->setTime(candidateTime, p().latestStmtId);
 }
@@ -876,7 +871,7 @@ void TransactionRouter::Router::beginOrContinueTxn(OperationContext* opCtx,
                     o(lk).atClusterTime.emplace();
                 }
 
-                LOG(3) << txnIdToString() << " New transaction started";
+                LOGV2_DEBUG(3, "{} New transaction started", "txnIdToString"_attr = txnIdToString());
                 break;
             }
             case TransactionActions::kContinue: {
@@ -891,7 +886,7 @@ void TransactionRouter::Router::beginOrContinueTxn(OperationContext* opCtx,
                 // means that the client is attempting to recover a commit decision.
                 p().isRecoveringCommit = true;
 
-                LOG(3) << txnIdToString() << " Commit recovery started";
+                LOGV2_DEBUG(3, "{} Commit recovery started", "txnIdToString"_attr = txnIdToString());
                 break;
             }
         };
@@ -928,8 +923,7 @@ BSONObj TransactionRouter::Router::_handOffCommitToCoordinator(OperationContext*
     const auto coordinateCommitCmdObj = coordinateCommitCmd.toBSON(
         BSON(WriteConcernOptions::kWriteConcernField << opCtx->getWriteConcern().toBSON()));
 
-    LOG(3) << txnIdToString()
-           << " Committing using two-phase commit, coordinator: " << *o().coordinatorId;
+    LOGV2_DEBUG(3, "{} Committing using two-phase commit, coordinator: {}", "txnIdToString"_attr = txnIdToString(), "o_coordinatorId"_attr = *o().coordinatorId);
 
     MultiStatementTransactionRequestsSender ars(
         opCtx,
@@ -1030,8 +1024,7 @@ BSONObj TransactionRouter::Router::_commitTransaction(
 
     if (o().participants.size() == 1) {
         ShardId shardId = o().participants.cbegin()->first;
-        LOG(3) << txnIdToString()
-               << " Committing single-shard transaction, single participant: " << shardId;
+        LOGV2_DEBUG(3, "{} Committing single-shard transaction, single participant: {}", "txnIdToString"_attr = txnIdToString(), "shardId"_attr = shardId);
 
         {
             stdx::lock_guard<Client> lk(*opCtx->getClient());
@@ -1044,8 +1037,7 @@ BSONObj TransactionRouter::Router::_commitTransaction(
     }
 
     if (writeShards.size() == 0) {
-        LOG(3) << txnIdToString() << " Committing read-only transaction on "
-               << readOnlyShards.size() << " shards";
+        LOGV2_DEBUG(3, "{} Committing read-only transaction on {} shards", "txnIdToString"_attr = txnIdToString(), "readOnlyShards_size"_attr = readOnlyShards.size());
         {
             stdx::lock_guard<Client> lk(*opCtx->getClient());
             o(lk).commitType = CommitType::kReadOnly;
@@ -1056,9 +1048,7 @@ BSONObj TransactionRouter::Router::_commitTransaction(
     }
 
     if (writeShards.size() == 1) {
-        LOG(3) << txnIdToString() << " Committing single-write-shard transaction with "
-               << readOnlyShards.size()
-               << " read-only shards, write shard: " << writeShards.front();
+        LOGV2_DEBUG(3, "{} Committing single-write-shard transaction with {} read-only shards, write shard: {}", "txnIdToString"_attr = txnIdToString(), "readOnlyShards_size"_attr = readOnlyShards.size(), "writeShards_front"_attr = writeShards.front());
         {
             stdx::lock_guard<Client> lk(*opCtx->getClient());
             o(lk).commitType = CommitType::kSingleWriteShard;
@@ -1105,8 +1095,7 @@ BSONObj TransactionRouter::Router::abortTransaction(OperationContext* opCtx) {
         abortRequests.emplace_back(ShardId(participantEntry.first), abortCmd);
     }
 
-    LOG(3) << txnIdToString() << " Aborting transaction on " << o().participants.size()
-           << " shard(s)";
+    LOGV2_DEBUG(3, "{} Aborting transaction on {} shard(s)", "txnIdToString"_attr = txnIdToString(), "o_participants_size"_attr = o().participants.size());
 
     const auto responses = gatherResponses(opCtx,
                                            NamespaceString::kAdminDb,
@@ -1144,9 +1133,8 @@ void TransactionRouter::Router::implicitlyAbortTransaction(OperationContext* opC
 
     if (o().commitType == CommitType::kTwoPhaseCommit ||
         o().commitType == CommitType::kRecoverWithToken) {
-        LOG(3) << txnIdToString()
-               << " Router not sending implicit abortTransaction because commit "
-                  "may have been handed off to the coordinator";
+        LOGV2_DEBUG(3, "{} Router not sending implicit abortTransaction because commit "
+                  "may have been handed off to the coordinator", "txnIdToString"_attr = txnIdToString());
         return;
     }
 
@@ -1166,8 +1154,7 @@ void TransactionRouter::Router::implicitlyAbortTransaction(OperationContext* opC
         abortRequests.emplace_back(ShardId(participantEntry.first), abortCmd);
     }
 
-    LOG(3) << txnIdToString() << " Implicitly aborting transaction on " << o().participants.size()
-           << " shard(s) due to error: " << errorStatus;
+    LOGV2_DEBUG(3, "{} Implicitly aborting transaction on {} shard(s) due to error: {}", "txnIdToString"_attr = txnIdToString(), "o_participants_size"_attr = o().participants.size(), "errorStatus"_attr = errorStatus);
 
     try {
         // Ignore the responses.
@@ -1177,8 +1164,7 @@ void TransactionRouter::Router::implicitlyAbortTransaction(OperationContext* opC
                         Shard::RetryPolicy::kIdempotent,
                         abortRequests);
     } catch (const DBException& ex) {
-        LOG(3) << txnIdToString() << " Implicitly aborting transaction failed "
-               << causedBy(ex.toStatus());
+        LOGV2_DEBUG(3, "{} Implicitly aborting transaction failed {}", "txnIdToString"_attr = txnIdToString(), "causedBy_ex_toStatus"_attr = causedBy(ex.toStatus()));
         // Ignore any exceptions.
     }
 }
@@ -1261,7 +1247,7 @@ BSONObj TransactionRouter::Router::_commitWithRecoveryToken(OperationContext* op
 
 void TransactionRouter::Router::_logSlowTransaction(OperationContext* opCtx,
                                                     TerminationCause terminationCause) const {
-    log() << "transaction " << _transactionInfoForLog(opCtx, terminationCause);
+    LOGV2("transaction {}", "_transactionInfoForLog_opCtx_terminationCause"_attr = _transactionInfoForLog(opCtx, terminationCause));
 }
 
 std::string TransactionRouter::Router::_transactionInfoForLog(
diff --git a/src/mongo/s/version_mongos.cpp b/src/mongo/s/version_mongos.cpp
index 4e80a8e36f..59d600e43a 100644
--- a/src/mongo/s/version_mongos.cpp
+++ b/src/mongo/s/version_mongos.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/log_process_details.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/process_id.h"
 #include "mongo/util/debug_util.h"
 #include "mongo/util/log.h"
@@ -47,10 +48,10 @@ void printShardingVersionInfo(bool isForVersionReportingOnly) {
 
     if (isForVersionReportingOnly) {
         setPlainConsoleLogger();
-        log() << mongosVersion(vii);
+        LOGV2("{}", "mongosVersion_vii"_attr = mongosVersion(vii));
         vii.logBuildInfo();
     } else {
-        log() << mongosVersion(vii);
+        LOGV2("{}", "mongosVersion_vii"_attr = mongosVersion(vii));
         logProcessDetails();
     }
 }
diff --git a/src/mongo/s/write_ops/batch_write_exec.cpp b/src/mongo/s/write_ops/batch_write_exec.cpp
index 0020eb137f..ef749c7dd6 100644
--- a/src/mongo/s/write_ops/batch_write_exec.cpp
+++ b/src/mongo/s/write_ops/batch_write_exec.cpp
@@ -41,6 +41,7 @@
 #include "mongo/client/remote_command_targeter.h"
 #include "mongo/db/error_labels.h"
 #include "mongo/executor/task_executor_pool.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/grid.h"
 #include "mongo/s/multi_statement_transaction_requests_sender.h"
@@ -71,8 +72,7 @@ WriteErrorDetail errorFromStatus(const Status& status) {
 // Helper to note several stale shard errors from a response
 void noteStaleShardResponses(const std::vector<ShardError>& staleErrors, NSTargeter* targeter) {
     for (const auto& error : staleErrors) {
-        LOG(4) << "Noting stale config response " << error.error.getErrInfo() << " from shard "
-               << error.endpoint.shardName;
+        LOGV2_DEBUG(4, "Noting stale config response {} from shard {}", "error_error_getErrInfo"_attr = error.error.getErrInfo(), "error_endpoint_shardName"_attr = error.endpoint.shardName);
         targeter->noteStaleShardResponse(
             error.endpoint,
             StaleConfigInfo::parseFromCommandError(
@@ -83,8 +83,7 @@ void noteStaleShardResponses(const std::vector<ShardError>& staleErrors, NSTarge
 // Helper to note several stale db errors from a response
 void noteStaleDbResponses(const std::vector<ShardError>& staleErrors, NSTargeter* targeter) {
     for (const auto& error : staleErrors) {
-        LOG(4) << "Noting stale database response " << error.error.toBSON() << " from shard "
-               << error.endpoint.shardName;
+        LOGV2_DEBUG(4, "Noting stale database response {} from shard {}", "error_error_toBSON"_attr = error.error.toBSON(), "error_endpoint_shardName"_attr = error.endpoint.shardName);
         targeter->noteStaleDbResponse(
             error.endpoint, StaleDbRoutingVersion::parseFromCommandError(error.error.toBSON()));
     }
@@ -115,8 +114,7 @@ void BatchWriteExec::executeBatch(OperationContext* opCtx,
                                   BatchWriteExecStats* stats) {
     const auto& nss(clientRequest.getNS());
 
-    LOG(4) << "Starting execution of write batch of size "
-           << static_cast<int>(clientRequest.sizeWriteOps()) << " for " << nss.ns();
+    LOGV2_DEBUG(4, "Starting execution of write batch of size {} for {}", "static_cast_int_clientRequest_sizeWriteOps"_attr = static_cast<int>(clientRequest.sizeWriteOps()), "nss_ns"_attr = nss.ns());
 
     BatchWriteOp batchOp(opCtx, clientRequest);
 
@@ -233,7 +231,7 @@ void BatchWriteExec::executeBatch(OperationContext* opCtx,
                     return requestBuilder.obj();
                 }();
 
-                LOG(4) << "Sending write batch to " << targetShardId << ": " << redact(request);
+                LOGV2_DEBUG(4, "Sending write batch to {}: {}", "targetShardId"_attr = targetShardId, "redact_request"_attr = redact(request));
 
                 requests.emplace_back(targetShardId, request);
 
@@ -279,8 +277,7 @@ void BatchWriteExec::executeBatch(OperationContext* opCtx,
 
                     // TODO: It may be necessary to refresh the cache if stale, or maybe just cancel
                     // and retarget the batch
-                    LOG(4) << "Unable to send write batch to " << batch->getEndpoint().shardName
-                           << causedBy(response.swResponse.getStatus());
+                    LOGV2_DEBUG(4, "Unable to send write batch to {}{}", "batch_getEndpoint_shardName"_attr = batch->getEndpoint().shardName, "causedBy_response_swResponse_getStatus"_attr = causedBy(response.swResponse.getStatus()));
 
                     // We're done with this batch. Clean up when we can't resolve a host.
                     auto it = childBatches.find(batch->getEndpoint().shardName);
@@ -310,8 +307,7 @@ void BatchWriteExec::executeBatch(OperationContext* opCtx,
                     trackedErrors.startTracking(ErrorCodes::StaleDbVersion);
                     trackedErrors.startTracking(ErrorCodes::CannotImplicitlyCreateCollection);
 
-                    LOG(4) << "Write results received from " << shardHost.toString() << ": "
-                           << redact(batchedCommandResponse.toStatus());
+                    LOGV2_DEBUG(4, "Write results received from {}: {}", "shardHost_toString"_attr = shardHost.toString(), "redact_batchedCommandResponse_toStatus"_attr = redact(batchedCommandResponse.toStatus()));
 
                     // Dispatch was ok, note response
                     batchOp.noteBatchResponse(*batch, batchedCommandResponse, &trackedErrors);
@@ -387,8 +383,7 @@ void BatchWriteExec::executeBatch(OperationContext* opCtx,
 
                     batchOp.noteBatchError(*batch, errorFromStatus(status));
 
-                    LOG(4) << "Unable to receive write results from " << shardHost
-                           << causedBy(redact(status));
+                    LOGV2_DEBUG(4, "Unable to receive write results from {}{}", "shardHost"_attr = shardHost, "causedBy_redact_status"_attr = causedBy(redact(status)));
 
                     // If we are in a transaction, we must stop immediately (even for unordered).
                     if (TransactionRouter::get(opCtx)) {
@@ -424,7 +419,7 @@ void BatchWriteExec::executeBatch(OperationContext* opCtx,
         bool targeterChanged = false;
         Status refreshStatus = targeter.refreshIfNeeded(opCtx, &targeterChanged);
 
-        LOG(4) << "executeBatch targeter changed: " << targeterChanged;
+        LOGV2_DEBUG(4, "executeBatch targeter changed: {}", "targeterChanged"_attr = targeterChanged);
 
         if (!refreshStatus.isOK()) {
             // It's okay if we can't refresh, we'll just record errors for the ops if
@@ -461,13 +456,9 @@ void BatchWriteExec::executeBatch(OperationContext* opCtx,
 
     batchOp.buildClientResponse(clientResponse);
 
-    LOG(4) << "Finished execution of write batch"
-           << (clientResponse->isErrDetailsSet() ? " with write errors" : "")
-           << (clientResponse->isErrDetailsSet() && clientResponse->isWriteConcernErrorSet()
+    LOGV2_DEBUG(4, "Finished execution of write batch{}{}{} for {}", "clientResponse_isErrDetailsSet_with_write_errors"_attr = (clientResponse->isErrDetailsSet() ? " with write errors" : ""), "clientResponse_isErrDetailsSet_clientResponse_isWriteConcernErrorSet_and"_attr = (clientResponse->isErrDetailsSet() && clientResponse->isWriteConcernErrorSet()
                    ? " and"
-                   : "")
-           << (clientResponse->isWriteConcernErrorSet() ? " with write concern error" : "")
-           << " for " << clientRequest.getNS();
+                   : ""), "clientResponse_isWriteConcernErrorSet_with_write_concern_error"_attr = (clientResponse->isWriteConcernErrorSet() ? " with write concern error" : ""), "clientRequest_getNS"_attr = clientRequest.getNS());
 }
 
 void BatchWriteExecStats::noteTargetedShard(const ShardId& shardId) {
diff --git a/src/mongo/s/write_ops/chunk_manager_targeter.cpp b/src/mongo/s/write_ops/chunk_manager_targeter.cpp
index a36fb2b4fe..6c02be74e6 100644
--- a/src/mongo/s/write_ops/chunk_manager_targeter.cpp
+++ b/src/mongo/s/write_ops/chunk_manager_targeter.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/matcher/extensions_callback_noop.h"
 #include "mongo/db/query/canonical_query.h"
 #include "mongo/db/query/collation/collation_index_key.h"
+#include "mongo/logv2/log.h"
 #include "mongo/s/client/shard_registry.h"
 #include "mongo/s/cluster_commands_helpers.h"
 #include "mongo/s/database_version_helpers.h"
@@ -751,10 +752,7 @@ Status ChunkManagerTargeter::refreshIfNeeded(OperationContext* opCtx, bool* wasC
 
     *wasChanged = false;
 
-    LOG(4) << "ChunkManagerTargeter checking if refresh is needed, needsTargetingRefresh("
-           << _needsTargetingRefresh << ") remoteShardVersions empty ("
-           << _remoteShardVersions.empty() << ")"
-           << ") remoteDbVersion empty (" << !_remoteDbVersion << ")";
+    LOGV2_DEBUG(4, "ChunkManagerTargeter checking if refresh is needed, needsTargetingRefresh({}) remoteShardVersions empty ({})) remoteDbVersion empty ({})", "_needsTargetingRefresh"_attr = _needsTargetingRefresh, "_remoteShardVersions_empty"_attr = _remoteShardVersions.empty(), "_remoteDbVersion"_attr = !_remoteDbVersion);
 
     //
     // Did we have any stale config or targeting errors at all?
@@ -808,7 +806,7 @@ Status ChunkManagerTargeter::refreshIfNeeded(OperationContext* opCtx, bool* wasC
 
         CompareResult result = compareAllShardVersions(*_routingInfo, _remoteShardVersions);
 
-        LOG(4) << "ChunkManagerTargeter shard versions comparison result: " << (int)result;
+        LOGV2_DEBUG(4, "ChunkManagerTargeter shard versions comparison result: {}", "int_result"_attr = (int)result);
 
         // Reset the versions
         _remoteShardVersions.clear();
@@ -827,7 +825,7 @@ Status ChunkManagerTargeter::refreshIfNeeded(OperationContext* opCtx, bool* wasC
 
         CompareResult result = compareDbVersions(*_routingInfo, *_remoteDbVersion);
 
-        LOG(4) << "ChunkManagerTargeter database versions comparison result: " << (int)result;
+        LOGV2_DEBUG(4, "ChunkManagerTargeter database versions comparison result: {}", "int_result"_attr = (int)result);
 
         // Reset the version
         _remoteDbVersion = boost::none;
diff --git a/src/mongo/scripting/engine.cpp b/src/mongo/scripting/engine.cpp
index 77017f455a..a0dad2bc76 100644
--- a/src/mongo/scripting/engine.cpp
+++ b/src/mongo/scripting/engine.cpp
@@ -40,6 +40,7 @@
 #include "mongo/client/dbclient_cursor.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/dbdirectclient_factory.h"
 #include "mongo/util/fail_point.h"
 #include "mongo/util/file.h"
@@ -339,7 +340,7 @@ public:
 
         if (scope->hasOutOfMemoryException()) {
             // make some room
-            log() << "Clearing all idle JS contexts due to out of memory";
+            LOGV2("Clearing all idle JS contexts due to out of memory");
             _pools.clear();
             return;
         }
diff --git a/src/mongo/scripting/mozjs/cursor_handle.cpp b/src/mongo/scripting/mozjs/cursor_handle.cpp
index 101334a737..c14a41ae69 100644
--- a/src/mongo/scripting/mozjs/cursor_handle.cpp
+++ b/src/mongo/scripting/mozjs/cursor_handle.cpp
@@ -32,6 +32,7 @@
 #include "mongo/platform/basic.h"
 
 #include "mongo/client/dbclient_base.h"
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/mozjs/cursor_handle.h"
 #include "mongo/scripting/mozjs/implscope.h"
 #include "mongo/scripting/mozjs/scripting_util_gen.h"
@@ -77,7 +78,7 @@ void CursorHandleInfo::finalize(js::FreeOp* fop, JSObject* obj) {
                 auto status = exceptionToStatus();
 
                 try {
-                    LOG(0) << "Failed to kill cursor " << cursorId << " due to " << status;
+                    LOGV2("Failed to kill cursor {} due to {}", "cursorId"_attr = cursorId, "status"_attr = status);
                 } catch (...) {
                     // This is here in case logging fails.
                 }
diff --git a/src/mongo/scripting/mozjs/engine.cpp b/src/mongo/scripting/mozjs/engine.cpp
index 4a8427d7dd..d7ddd5ee23 100644
--- a/src/mongo/scripting/mozjs/engine.cpp
+++ b/src/mongo/scripting/mozjs/engine.cpp
@@ -36,6 +36,7 @@
 #include <js/Initialization.h>
 
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/mozjs/engine_gen.h"
 #include "mongo/scripting/mozjs/implscope.h"
 #include "mongo/scripting/mozjs/proxyscope.h"
@@ -86,11 +87,11 @@ void MozJSScriptEngine::interrupt(unsigned opId) {
     OpIdToScopeMap::iterator iScope = _opToScopeMap.find(opId);
     if (iScope == _opToScopeMap.end()) {
         // got interrupt request for a scope that no longer exists
-        LOG(1) << "received interrupt request for unknown op: " << opId << printKnownOps_inlock();
+        LOGV2_DEBUG(1, "received interrupt request for unknown op: {}{}", "opId"_attr = opId, "printKnownOps_inlock"_attr = printKnownOps_inlock());
         return;
     }
 
-    LOG(1) << "interrupting op: " << opId << printKnownOps_inlock();
+    LOGV2_DEBUG(1, "interrupting op: {}{}", "opId"_attr = opId, "printKnownOps_inlock"_attr = printKnownOps_inlock());
     iScope->second->kill();
 }
 
@@ -147,7 +148,7 @@ void MozJSScriptEngine::registerOperation(OperationContext* opCtx, MozJSImplScop
 
     _opToScopeMap[opId] = scope;
 
-    LOG(2) << "SMScope " << static_cast<const void*>(scope) << " registered for op " << opId;
+    LOGV2_DEBUG(2, "SMScope {} registered for op {}", "static_cast_const_void_scope"_attr = reinterpret_cast<uint64_t>(scope), "opId"_attr = opId);
     Status status = opCtx->checkForInterruptNoAssert();
     if (!status.isOK()) {
         scope->kill();
@@ -157,7 +158,7 @@ void MozJSScriptEngine::registerOperation(OperationContext* opCtx, MozJSImplScop
 void MozJSScriptEngine::unregisterOperation(unsigned int opId) {
     stdx::lock_guard<Latch> giLock(_globalInterruptLock);
 
-    LOG(2) << "ImplScope " << static_cast<const void*>(this) << " unregistered for op " << opId;
+    LOGV2_DEBUG(2, "ImplScope {} unregistered for op {}", "static_cast_const_void_this"_attr = reinterpret_cast<uint64_t>(this), "opId"_attr = opId);
 
     if (opId != 0) {
         // scope is currently associated with an operation id
diff --git a/src/mongo/scripting/mozjs/implscope.cpp b/src/mongo/scripting/mozjs/implscope.cpp
index e78d462d7e..8cbe985057 100644
--- a/src/mongo/scripting/mozjs/implscope.cpp
+++ b/src/mongo/scripting/mozjs/implscope.cpp
@@ -42,6 +42,7 @@
 #include "mongo/base/error_codes.h"
 #include "mongo/config.h"
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/decimal128.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/platform/stack_locator.h"
@@ -223,8 +224,7 @@ void MozJSImplScope::_gcCallback(JSContext* rt, JSGCStatus status, void* data) {
         return;
     }
 
-    log() << "MozJS GC " << (status == JSGC_BEGIN ? "prologue" : "epilogue") << " heap stats - "
-          << " total: " << mongo::sm::get_total_bytes() << " limit: " << mongo::sm::get_max_bytes();
+    LOGV2("MozJS GC {} heap stats -  total: {} limit: {}", "status_JSGC_BEGIN_prologue_epilogue"_attr = (status == JSGC_BEGIN ? "prologue" : "epilogue"), "mongo_sm_get_total_bytes"_attr = mongo::sm::get_total_bytes(), "mongo_sm_get_max_bytes"_attr = mongo::sm::get_max_bytes());
 }
 
 #if __has_feature(address_sanitizer)
diff --git a/src/mongo/scripting/mozjs/session.cpp b/src/mongo/scripting/mozjs/session.cpp
index f135374234..1f9985d43d 100644
--- a/src/mongo/scripting/mozjs/session.cpp
+++ b/src/mongo/scripting/mozjs/session.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/scripting/mozjs/session.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/mozjs/bson.h"
 #include "mongo/scripting/mozjs/implscope.h"
 #include "mongo/scripting/mozjs/mongo.h"
@@ -152,7 +153,7 @@ void SessionInfo::finalize(js::FreeOp* fop, JSObject* obj) {
             auto status = exceptionToStatus();
 
             try {
-                LOG(0) << "Failed to end session " << lsid << " due to " << status;
+                LOGV2("Failed to end session {} due to {}", "lsid"_attr = lsid, "status"_attr = status);
             } catch (...) {
                 // This is here in case logging fails.
             }
diff --git a/src/mongo/shell/bench.cpp b/src/mongo/shell/bench.cpp
index 765120a8f9..d44eb96cba 100644
--- a/src/mongo/shell/bench.cpp
+++ b/src/mongo/shell/bench.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/query/cursor_response.h"
 #include "mongo/db/query/getmore_request.h"
 #include "mongo/db/query/query_request.h"
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/bson_template_evaluator.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/util/log.h"
@@ -738,7 +739,7 @@ void BenchRunConfig::initializeFromBson(const BSONObj& args) {
                 ops.push_back(opFromBson(i.next().Obj()));
             }
         } else {
-            log() << "benchRun passed an unsupported field: " << name;
+            LOGV2("benchRun passed an unsupported field: {}", "name"_attr = name);
             uassert(34376, "benchRun passed an unsupported configuration field", false);
         }
     }
@@ -915,8 +916,7 @@ void BenchRunWorker::generateLoadOnConnection(DBClientBase* conn) {
                         (!_config->noWatchPattern && _config->watchPattern &&
                          yesWatch) ||  // If we're just watching things
                         (_config->watchPattern && _config->noWatchPattern && yesWatch && !noWatch))
-                        log() << "Error in benchRun thread for op "
-                              << kOpTypeNames.find(op.op)->second << causedBy(ex);
+                        LOGV2("Error in benchRun thread for op {}{}", "kOpTypeNames_find_op_op_second"_attr = kOpTypeNames.find(op.op)->second, "causedBy_ex"_attr = causedBy(ex));
                 }
 
                 bool yesTrap = (_config->trapPattern && _config->trapPattern->FullMatch(ex.what()));
@@ -942,8 +942,7 @@ void BenchRunWorker::generateLoadOnConnection(DBClientBase* conn) {
                 ++opState.stats->errCount;
             } catch (...) {
                 if (!_config->hideErrors || op.showError)
-                    log() << "Error in benchRun thread caused by unknown error for op "
-                          << kOpTypeNames.find(op.op)->second;
+                    LOGV2("Error in benchRun thread caused by unknown error for op {}", "kOpTypeNames_find_op_op_second"_attr = kOpTypeNames.find(op.op)->second);
                 if (!_config->handleErrors && !op.handleError)
                     return;
 
@@ -1013,7 +1012,7 @@ void BenchRunOp::executeOnce(DBClientBase* conn,
             }
 
             if (!config.hideResults || this->showResult)
-                log() << "Result from benchRun thread [findOne] : " << result;
+                LOGV2("Result from benchRun thread [findOne] : {}", "result"_attr = result);
         } break;
         case OpType::COMMAND: {
             bool ok;
@@ -1142,13 +1141,12 @@ void BenchRunOp::executeOnce(DBClientBase* conn,
             }
 
             if (this->expected >= 0 && count != this->expected) {
-                log() << "bench query on: " << this->ns << " expected: " << this->expected
-                      << " got: " << count;
+                LOGV2("bench query on: {} expected: {} got: {}", "this_ns"_attr = this->ns, "this_expected"_attr = this->expected, "count"_attr = count);
                 verify(false);
             }
 
             if (!config.hideResults || this->showResult)
-                log() << "Result from benchRun thread [query] : " << count;
+                LOGV2("Result from benchRun thread [query] : {}", "count"_attr = count);
         } break;
         case OpType::UPDATE: {
             BSONObj result;
@@ -1218,7 +1216,7 @@ void BenchRunOp::executeOnce(DBClientBase* conn,
 
             if (this->safe) {
                 if (!config.hideResults || this->showResult)
-                    log() << "Result from benchRun thread [safe update] : " << result;
+                    LOGV2("Result from benchRun thread [safe update] : {}", "result"_attr = result);
 
                 if (!result["err"].eoo() && result["err"].type() == String &&
                     (config.throwGLE || this->throwGLE))
@@ -1282,7 +1280,7 @@ void BenchRunOp::executeOnce(DBClientBase* conn,
 
             if (this->safe) {
                 if (!config.hideResults || this->showResult)
-                    log() << "Result from benchRun thread [safe insert] : " << result;
+                    LOGV2("Result from benchRun thread [safe insert] : {}", "result"_attr = result);
 
                 if (!result["err"].eoo() && result["err"].type() == String &&
                     (config.throwGLE || this->throwGLE))
@@ -1327,7 +1325,7 @@ void BenchRunOp::executeOnce(DBClientBase* conn,
 
             if (this->safe) {
                 if (!config.hideResults || this->showResult)
-                    log() << "Result from benchRun thread [safe remove] : " << result;
+                    LOGV2("Result from benchRun thread [safe remove] : {}", "result"_attr = result);
 
                 if (!result["err"].eoo() && result["err"].type() == String &&
                     (config.throwGLE || this->throwGLE))
diff --git a/src/mongo/shell/shell_options.cpp b/src/mongo/shell/shell_options.cpp
index f956caa164..f114dbe87f 100644
--- a/src/mongo/shell/shell_options.cpp
+++ b/src/mongo/shell/shell_options.cpp
@@ -27,7 +27,7 @@
  *    it in the license file.
  */
 
-#define MONGO_LOG_DEFAULT_COMPONENT ::mongo::logger::LogComponent::kDefault;
+#define MONGO_LOG_DEFAULT_COMPONENT ::mongo::logger::LogComponent::kDefault
 
 #include "mongo/platform/basic.h"
 
@@ -43,6 +43,7 @@
 #include "mongo/config.h"
 #include "mongo/db/auth/sasl_command_constants.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/protocol.h"
 #include "mongo/shell/shell_utils.h"
 #include "mongo/transport/message_compressor_options_client_gen.h"
@@ -87,9 +88,9 @@ bool handlePreValidationMongoShellOptions(const moe::Environment& params,
     auto&& vii = VersionInfoInterface::instance();
     if (params.count("version") || params.count("help")) {
         setPlainConsoleLogger();
-        log() << mongoShellVersion(vii);
+        LOGV2("{}", "mongoShellVersion_vii"_attr = mongoShellVersion(vii));
         if (params.count("help")) {
-            log() << getMongoShellHelp(args[0], moe::startupOptions);
+            LOGV2("{}", "getMongoShellHelp_args_0_moe_startupOptions"_attr = getMongoShellHelp(args[0], moe::startupOptions));
         } else {
             vii.logBuildInfo();
         }
diff --git a/src/mongo/shell/shell_utils_launcher.cpp b/src/mongo/shell/shell_utils_launcher.cpp
index 65a5207a6f..6caaa86972 100644
--- a/src/mongo/shell/shell_utils_launcher.cpp
+++ b/src/mongo/shell/shell_utils_launcher.cpp
@@ -63,6 +63,7 @@
 #include "mongo/base/environment_buffer.h"
 #include "mongo/client/dbclient_connection.h"
 #include "mongo/db/traffic_reader.h"
+#include "mongo/logv2/log.h"
 #include "mongo/scripting/engine.h"
 #include "mongo/shell/shell_options.h"
 #include "mongo/shell/shell_utils.h"
@@ -459,7 +460,7 @@ void ProgramRunner::start() {
         for (unsigned i = 0; i < _argv.size(); i++) {
             ss << " " << _argv[i];
         }
-        log() << ss.str();
+        LOGV2("{}", "ss_str"_attr = ss.str());
     }
 }
 
@@ -715,7 +716,7 @@ bool wait_for_pid(ProcessId pid, bool block = true, int* exit_code = nullptr) {
         return false;
     } else if (ret != WAIT_OBJECT_0) {
         const auto ewd = errnoWithDescription();
-        log() << "wait_for_pid: WaitForSingleObject failed: " << ewd;
+        LOGV2("wait_for_pid: WaitForSingleObject failed: {}", "ewd"_attr = ewd);
     }
 
     DWORD tmp;
@@ -734,7 +735,7 @@ bool wait_for_pid(ProcessId pid, bool block = true, int* exit_code = nullptr) {
         return true;
     } else {
         const auto ewd = errnoWithDescription();
-        log() << "GetExitCodeProcess failed: " << ewd;
+        LOGV2("GetExitCodeProcess failed: {}", "ewd"_attr = ewd);
         return false;
     }
 #else
@@ -796,7 +797,7 @@ BSONObj WaitMongoProgram(const BSONObj& a, void* data) {
     int exit_code = -123456;  // sentinel value
     invariant(port >= 0);
     if (!registry.isPortRegistered(port)) {
-        log() << "No db started on port: " << port;
+        LOGV2("No db started on port: {}", "port"_attr = port);
         return BSON(string("") << 0);
     }
     pid = registry.pidForPort(port);
@@ -892,8 +893,7 @@ void copyDir(const boost::filesystem::path& from, const boost::filesystem::path&
             boost::system::error_code ec;
             boost::filesystem::copy_file(p, to / p.leaf(), ec);
             if (ec) {
-                log() << "Skipping copying of file from '" << p.generic_string() << "' to '"
-                      << (to / p.leaf()).generic_string() << "' due to: " << ec.message();
+                LOGV2("Skipping copying of file from '{}' to '{}' due to: {}", "p_generic_string"_attr = p.generic_string(), "to_p_leaf_generic_string"_attr = (to / p.leaf()).generic_string(), "ec_message"_attr = ec.message());
             }
         } else if (p.leaf() != "mongod.lock" && p.leaf() != "WiredTiger.lock") {
             if (boost::filesystem::is_directory(p)) {
@@ -943,9 +943,7 @@ inline void kill_wrapper(ProcessId pid, int sig, int port, const BSONObj& opt) {
             const auto ewd = errnoWithDescription();
             warning() << "kill_wrapper OpenEvent failed: " << ewd;
         } else {
-            log() << "kill_wrapper OpenEvent failed to open event to the process " << pid.asUInt32()
-                  << ". It has likely died already or server is running an older version."
-                  << " Attempting to shutdown through admin command.";
+            LOGV2("kill_wrapper OpenEvent failed to open event to the process {}. It has likely died already or server is running an older version. Attempting to shutdown through admin command.", "pid_asUInt32"_attr = pid.asUInt32());
 
             // Back-off to the old way of shutting down the server on Windows, in case we
             // are managing a pre-2.6.0rc0 service, which did not have the event.
@@ -993,7 +991,7 @@ inline void kill_wrapper(ProcessId pid, int sig, int port, const BSONObj& opt) {
         if (errno == ESRCH) {
         } else {
             const auto ewd = errnoWithDescription();
-            log() << "killFailed: " << ewd;
+            LOGV2("killFailed: {}", "ewd"_attr = ewd);
             verify(x == 0);
         }
     }
@@ -1005,7 +1003,7 @@ int killDb(int port, ProcessId _pid, int signal, const BSONObj& opt, bool waitPi
     ProcessId pid;
     if (port > 0) {
         if (!registry.isPortRegistered(port)) {
-            log() << "No db started on port: " << port;
+            LOGV2("No db started on port: {}", "port"_attr = port);
             return 0;
         }
         pid = registry.pidForPort(port);
@@ -1017,13 +1015,13 @@ int killDb(int port, ProcessId _pid, int signal, const BSONObj& opt, bool waitPi
 
     // If we are not waiting for the process to end, then return immediately.
     if (!waitPid) {
-        log() << "skip waiting for pid " << pid << " to terminate";
+        LOGV2("skip waiting for pid {} to terminate", "pid"_attr = pid);
         return 0;
     }
 
     int exitCode = EXIT_FAILURE;
     try {
-        log() << "waiting for process " << pid << " to terminate.";
+        LOGV2("waiting for process {} to terminate.", "pid"_attr = pid);
         wait_for_pid(pid, true, &exitCode);
     } catch (...) {
         warning() << "process " << pid << " failed to terminate.";
@@ -1090,10 +1088,10 @@ BSONObj StopMongoProgram(const BSONObj& a, void* data) {
     uassert(ErrorCodes::FailedToParse, "wrong number of arguments", nFields >= 1 && nFields <= 4);
     uassert(ErrorCodes::BadValue, "stopMongoProgram needs a number", a.firstElement().isNumber());
     int port = int(a.firstElement().number());
-    log() << "shell: stopping mongo program, waitpid=" << getWaitPid(a);
+    LOGV2("shell: stopping mongo program, waitpid={}", "getWaitPid_a"_attr = getWaitPid(a));
     int code =
         killDb(port, ProcessId::fromNative(0), getSignal(a), getStopMongodOpts(a), getWaitPid(a));
-    log() << "shell: stopped mongo program on port " << port;
+    LOGV2("shell: stopped mongo program on port {}", "port"_attr = port);
     return BSON("" << (double)code);
 }
 
@@ -1104,7 +1102,7 @@ BSONObj StopMongoProgramByPid(const BSONObj& a, void* data) {
         ErrorCodes::BadValue, "stopMongoProgramByPid needs a number", a.firstElement().isNumber());
     ProcessId pid = ProcessId::fromNative(int(a.firstElement().number()));
     int code = killDb(0, pid, getSignal(a), getStopMongodOpts(a));
-    log() << "shell: stopped mongo program with pid " << pid;
+    LOGV2("shell: stopped mongo program with pid {}", "pid"_attr = pid);
     return BSON("" << (double)code);
 }
 
@@ -1124,7 +1122,7 @@ int KillMongoProgramInstances() {
         int port = registry.portForPid(pid);
         int code = killDb(port != -1 ? port : 0, pid, SIGTERM);
         if (code != EXIT_SUCCESS) {
-            log() << "Process with pid " << pid << " exited with error code " << code;
+            LOGV2("Process with pid {} exited with error code {}", "pid"_attr = pid, "code"_attr = code);
             returnCode = code;
         }
     }
diff --git a/src/mongo/tools/bridge.cpp b/src/mongo/tools/bridge.cpp
index 7a51f983fe..a99bba5cdf 100644
--- a/src/mongo/tools/bridge.cpp
+++ b/src/mongo/tools/bridge.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/dbmessage.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/platform/random.h"
@@ -93,7 +94,7 @@ public:
             return status.getStatus();
         }
 
-        log() << "Processing bridge command: " << cmdName;
+        LOGV2("Processing bridge command: {}", "cmdName"_attr = cmdName);
 
         BridgeCommand* command = status.getValue();
         return command->run(cmdObj, &_settingsMutex, &_settings);
@@ -277,8 +278,7 @@ DbResponse ServiceEntryPointBridge::handleRequest(OperationContext* opCtx, const
 
         dest.extractHostInfo(*cmdRequest);
 
-        LOG(1) << "Received \"" << cmdRequest->getCommandName() << "\" command with arguments "
-               << cmdRequest->body << " from " << dest;
+        LOGV2_DEBUG(1, "Received \"{}\" command with arguments {} from {}", "cmdRequest_getCommandName"_attr = cmdRequest->getCommandName(), "cmdRequest_body"_attr = cmdRequest->body, "dest"_attr = dest);
     }
 
     // Handle a message intended to configure the mongobridge and return a response.
@@ -304,8 +304,7 @@ DbResponse ServiceEntryPointBridge::handleRequest(OperationContext* opCtx, const
     switch (hostSettings.state) {
         // Close the connection to 'dest'.
         case HostSettings::State::kHangUp:
-            log() << "Rejecting connection from " << dest << ", end connection "
-                  << source->remote().toString();
+            LOGV2("Rejecting connection from {}, end connection {}", "dest"_attr = dest, "source_remote_toString"_attr = source->remote().toString());
             source->end();
             return {Message()};
         // Forward the message to 'dest' with probability '1 - hostSettings.loss'.
@@ -313,12 +312,9 @@ DbResponse ServiceEntryPointBridge::handleRequest(OperationContext* opCtx, const
             if (dest.nextCanonicalDouble() < hostSettings.loss) {
                 std::string hostName = dest.toString();
                 if (cmdRequest) {
-                    log() << "Discarding \"" << cmdRequest->getCommandName()
-                          << "\" command with arguments " << cmdRequest->body << " from "
-                          << hostName;
+                    LOGV2("Discarding \"{}\" command with arguments {} from {}", "cmdRequest_getCommandName"_attr = cmdRequest->getCommandName(), "cmdRequest_body"_attr = cmdRequest->body, "hostName"_attr = hostName);
                 } else {
-                    log() << "Discarding " << networkOpToString(request.operation()) << " from "
-                          << hostName;
+                    LOGV2("Discarding {} from {}", "networkOpToString_request_operation"_attr = networkOpToString(request.operation()), "hostName"_attr = hostName);
                 }
                 return {Message()};
             }
@@ -351,7 +347,7 @@ DbResponse ServiceEntryPointBridge::handleRequest(OperationContext* opCtx, const
         // reply with. If the message handling settings were since changed to close
         // connections from 'host', then do so now.
         if (hostSettings.state == HostSettings::State::kHangUp) {
-            log() << "Closing connection from " << dest << ", end connection " << source->remote();
+            LOGV2("Closing connection from {}, end connection {}", "dest"_attr = dest, "source_remote"_attr = source->remote());
             source->end();
             return {Message()};
         }
@@ -403,12 +399,12 @@ int bridgeMain(int argc, char** argv, char** envp) {
         opts, serviceContext->getServiceEntryPoint()));
     auto tl = serviceContext->getTransportLayer();
     if (!tl->setup().isOK()) {
-        log() << "Error setting up transport layer";
+        LOGV2("Error setting up transport layer");
         return EXIT_NET_ERROR;
     }
 
     if (!tl->start().isOK()) {
-        log() << "Error starting transport layer";
+        LOGV2("Error starting transport layer");
         return EXIT_NET_ERROR;
     }
 
diff --git a/src/mongo/transport/message_compressor_manager.cpp b/src/mongo/transport/message_compressor_manager.cpp
index 5f0c5cb4d2..10f6af7c9c 100644
--- a/src/mongo/transport/message_compressor_manager.cpp
+++ b/src/mongo/transport/message_compressor_manager.cpp
@@ -37,6 +37,7 @@
 #include "mongo/base/data_type_endian.h"
 #include "mongo/bson/bsonobj.h"
 #include "mongo/bson/bsonobjbuilder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/message.h"
 #include "mongo/transport/message_compressor_registry.h"
 #include "mongo/transport/session.h"
@@ -95,7 +96,7 @@ StatusWith<Message> MessageCompressorManager::compressMessage(
         return {msg};
     }
 
-    LOG(3) << "Compressing message with " << compressor->getName();
+    LOGV2_DEBUG(3, "Compressing message with {}", "compressor_getName"_attr = compressor->getName());
 
     auto inputHeader = msg.header();
     size_t bufferSize = compressor->getMaxCompressedSize(msg.dataSize()) +
@@ -105,8 +106,7 @@ StatusWith<Message> MessageCompressorManager::compressMessage(
         inputHeader.getNetworkOp(), inputHeader.dataLen(), compressor->getId());
 
     if (bufferSize > MaxMessageSizeBytes) {
-        LOG(3) << "Compressed message would be larger than " << MaxMessageSizeBytes
-               << ", returning original uncompressed message";
+        LOGV2_DEBUG(3, "Compressed message would be larger than {}, returning original uncompressed message", "MaxMessageSizeBytes"_attr = MaxMessageSizeBytes);
         return {msg};
     }
 
@@ -152,7 +152,7 @@ StatusWith<Message> MessageCompressorManager::decompressMessage(const Message& m
         *compressorId = compressor->getId();
     }
 
-    LOG(3) << "Decompressing message with " << compressor->getName();
+    LOGV2_DEBUG(3, "Decompressing message with {}", "compressor_getName"_attr = compressor->getName());
 
     if (compressionHeader.uncompressedSize < 0) {
         return {ErrorCodes::BadValue, "Decompressed message would be negative in size"};
@@ -191,7 +191,7 @@ StatusWith<Message> MessageCompressorManager::decompressMessage(const Message& m
 }
 
 void MessageCompressorManager::clientBegin(BSONObjBuilder* output) {
-    LOG(3) << "Starting client-side compression negotiation";
+    LOGV2_DEBUG(3, "Starting client-side compression negotiation");
 
     // We're about to update the compressor list with the negotiation result from the server.
     _negotiated.clear();
@@ -202,7 +202,7 @@ void MessageCompressorManager::clientBegin(BSONObjBuilder* output) {
 
     BSONArrayBuilder sub(output->subarrayStart("compression"));
     for (const auto e : _registry->getCompressorNames()) {
-        LOG(3) << "Offering " << e << " compressor to server";
+        LOGV2_DEBUG(3, "Offering {} compressor to server", "e"_attr = e);
         sub.append(e);
     }
     sub.doneFast();
@@ -210,7 +210,7 @@ void MessageCompressorManager::clientBegin(BSONObjBuilder* output) {
 
 void MessageCompressorManager::clientFinish(const BSONObj& input) {
     auto elem = input.getField("compression");
-    LOG(3) << "Finishing client-side compression negotiation";
+    LOGV2_DEBUG(3, "Finishing client-side compression negotiation");
 
     // We've just called clientBegin, so the list of compressors should be empty.
     invariant(_negotiated.empty());
@@ -219,22 +219,21 @@ void MessageCompressorManager::clientFinish(const BSONObj& input) {
     // supported by this server and just return. We've already disabled compression by clearing
     // out the _negotiated array above.
     if (elem.eoo()) {
-        LOG(3) << "No compression algorithms were sent from the server. "
-               << "This connection will be uncompressed";
+        LOGV2_DEBUG(3, "No compression algorithms were sent from the server. This connection will be uncompressed");
         return;
     }
 
-    LOG(3) << "Received message compressors from server";
+    LOGV2_DEBUG(3, "Received message compressors from server");
     for (const auto& e : elem.Obj()) {
         auto algoName = e.checkAndGetStringData();
         auto ret = _registry->getCompressor(algoName);
-        LOG(3) << "Adding compressor " << ret->getName();
+        LOGV2_DEBUG(3, "Adding compressor {}", "ret_getName"_attr = ret->getName());
         _negotiated.push_back(ret);
     }
 }
 
 void MessageCompressorManager::serverNegotiate(const BSONObj& input, BSONObjBuilder* output) {
-    LOG(3) << "Starting server-side compression negotiation";
+    LOGV2_DEBUG(3, "Starting server-side compression negotiation");
 
     auto elem = input.getField("compression");
     // If the "compression" field is missing, then this isMaster request is requesting information
@@ -250,7 +249,7 @@ void MessageCompressorManager::serverNegotiate(const BSONObj& input, BSONObjBuil
             }
             sub.doneFast();
         } else {
-            LOG(3) << "Compression negotiation not requested by client";
+            LOGV2_DEBUG(3, "Compression negotiation not requested by client");
         }
         return;
     }
@@ -263,7 +262,7 @@ void MessageCompressorManager::serverNegotiate(const BSONObj& input, BSONObjBuil
     BSONObj theirObj = elem.Obj();
 
     if (!theirObj.nFields()) {
-        LOG(3) << "No compressors provided";
+        LOGV2_DEBUG(3, "No compressors provided");
         return;
     }
 
@@ -273,10 +272,10 @@ void MessageCompressorManager::serverNegotiate(const BSONObj& input, BSONObjBuil
         // If the MessageCompressorRegistry knows about a compressor with that name, then it is
         // valid and we add it to our list of negotiated compressors.
         if ((cur = _registry->getCompressor(curName))) {
-            LOG(3) << cur->getName() << " is supported";
+            LOGV2_DEBUG(3, "{} is supported", "cur_getName"_attr = cur->getName());
             _negotiated.push_back(cur);
         } else {  // Otherwise the compressor is not supported and we skip over it.
-            LOG(3) << curName << " is not supported";
+            LOGV2_DEBUG(3, "{} is not supported", "curName"_attr = curName);
         }
     }
 
@@ -289,7 +288,7 @@ void MessageCompressorManager::serverNegotiate(const BSONObj& input, BSONObjBuil
         }
         sub.doneFast();
     } else {
-        LOG(3) << "Could not agree on compressor to use";
+        LOGV2_DEBUG(3, "Could not agree on compressor to use");
     }
 }
 
diff --git a/src/mongo/transport/service_entry_point_impl.cpp b/src/mongo/transport/service_entry_point_impl.cpp
index 5076b21b9d..aff1c3c248 100644
--- a/src/mongo/transport/service_entry_point_impl.cpp
+++ b/src/mongo/transport/service_entry_point_impl.cpp
@@ -37,6 +37,7 @@
 
 #include "mongo/db/auth/restriction_environment.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/service_state_machine.h"
 #include "mongo/transport/session.h"
 #include "mongo/util/log.h"
@@ -91,8 +92,7 @@ ServiceEntryPointImpl::ServiceEntryPointImpl(ServiceContext* svcCtx) : _svcCtx(s
 
         size_t max = (size_t)(limit.rlim_cur * .8);
 
-        LOG(1) << "fd limit"
-               << " hard:" << limit.rlim_max << " soft:" << limit.rlim_cur << " max conn: " << max;
+        LOGV2_DEBUG(1, "fd limit hard:{} soft:{} max conn: {}", "limit_rlim_max"_attr = limit.rlim_max, "limit_rlim_cur"_attr = limit.rlim_cur, "max"_attr = max);
 
         return std::min(max, serverGlobalParams.maxConns);
 #endif
@@ -101,7 +101,7 @@ ServiceEntryPointImpl::ServiceEntryPointImpl(ServiceContext* svcCtx) : _svcCtx(s
     // If we asked for more connections than supported, inform the user.
     if (supportedMax < serverGlobalParams.maxConns &&
         serverGlobalParams.maxConns != DEFAULT_MAX_CONN) {
-        log() << " --maxConns too high, can only handle " << supportedMax;
+        LOGV2(" --maxConns too high, can only handle {}", "supportedMax"_attr = supportedMax);
     }
 
     _maxNumConnections = supportedMax;
@@ -154,7 +154,7 @@ void ServiceEntryPointImpl::startSession(transport::SessionHandle session) {
     // while holding it.
     if (connectionCount > _maxNumConnections && !usingMaxConnOverride) {
         if (!quiet) {
-            log() << "connection refused because too many open connections: " << connectionCount;
+            LOGV2("connection refused because too many open connections: {}", "connectionCount"_attr = connectionCount);
         }
         return;
     } else if (usingMaxConnOverride && _adminInternalPool) {
@@ -163,8 +163,7 @@ void ServiceEntryPointImpl::startSession(transport::SessionHandle session) {
 
     if (!quiet) {
         const auto word = (connectionCount == 1 ? " connection"_sd : " connections"_sd);
-        log() << "connection accepted from " << session->remote() << " #" << session->id() << " ("
-              << connectionCount << word << " now open)";
+        LOGV2("connection accepted from {} #{} ({}{} now open)", "session_remote"_attr = session->remote(), "session_id"_attr = session->id(), "connectionCount"_attr = connectionCount, "word"_attr = word);
     }
 
     ssm->setCleanupHook([this, ssmIt, quiet, session = std::move(session)] {
@@ -180,7 +179,7 @@ void ServiceEntryPointImpl::startSession(transport::SessionHandle session) {
 
         if (!quiet) {
             const auto word = (connectionCount == 1 ? " connection"_sd : " connections"_sd);
-            log() << "end connection " << remote << " (" << connectionCount << word << " now open)";
+            LOGV2("end connection {} ({}{} now open)", "remote"_attr = remote, "connectionCount"_attr = connectionCount, "word"_attr = word);
         }
     });
 
@@ -223,14 +222,13 @@ bool ServiceEntryPointImpl::shutdown(Milliseconds timeout) {
     auto noWorkersLeft = [this] { return numOpenSessions() == 0; };
     while (timeSpent < timeout &&
            !_shutdownCondition.wait_for(lk, checkInterval.toSystemDuration(), noWorkersLeft)) {
-        log(LogComponent::kNetwork)
-            << "shutdown: still waiting on " << numOpenSessions() << " active workers to drain... ";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "shutdown: still waiting on {} active workers to drain... ", "numOpenSessions"_attr = numOpenSessions());
         timeSpent += checkInterval;
     }
 
     bool result = noWorkersLeft();
     if (result) {
-        log(LogComponent::kNetwork) << "shutdown: no running workers found...";
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(LogComponent::kNetwork).toInt(), "shutdown: no running workers found...");
     } else {
         log(LogComponent::kNetwork) << "shutdown: exhausted grace period for" << numOpenSessions()
                                     << " active workers to drain; continuing with shutdown... ";
diff --git a/src/mongo/transport/service_entry_point_utils.cpp b/src/mongo/transport/service_entry_point_utils.cpp
index 3db20b7da0..9749a58bf3 100644
--- a/src/mongo/transport/service_entry_point_utils.cpp
+++ b/src/mongo/transport/service_entry_point_utils.cpp
@@ -36,6 +36,7 @@
 #include <functional>
 #include <memory>
 
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/debug_util.h"
@@ -104,7 +105,7 @@ Status launchServiceWorkerThread(std::function<void()> task) {
         pthread_attr_destroy(&attrs);
 
         if (failed) {
-            log() << "pthread_create failed: " << errnoWithDescription(failed);
+            LOGV2("pthread_create failed: {}", "errnoWithDescription_failed"_attr = errnoWithDescription(failed));
             throw std::system_error(
                 std::make_error_code(std::errc::resource_unavailable_try_again));
         }
diff --git a/src/mongo/transport/service_executor_adaptive.cpp b/src/mongo/transport/service_executor_adaptive.cpp
index 32e8ef9b8b..541b83861d 100644
--- a/src/mongo/transport/service_executor_adaptive.cpp
+++ b/src/mongo/transport/service_executor_adaptive.cpp
@@ -36,6 +36,7 @@
 #include <array>
 #include <random>
 
+#include "mongo/logv2/log.h"
 #include "mongo/transport/service_entry_point_utils.h"
 #include "mongo/transport/service_executor_gen.h"
 #include "mongo/transport/service_executor_task_names.h"
@@ -79,8 +80,7 @@ struct ServerParameterOptions : public ServiceExecutorAdaptive::Options {
             value = ProcessInfo::getNumAvailableCores() / 2;
             value = std::max(value, 2);
             adaptiveServiceExecutorReservedThreads.store(value);
-            log() << "No thread count configured for executor. Using number of cores / 2: "
-                  << value;
+            LOGV2("No thread count configured for executor. Using number of cores / 2: {}", "value"_attr = value);
         }
         return value;
     }
@@ -101,9 +101,7 @@ struct ServerParameterOptions : public ServiceExecutorAdaptive::Options {
         static Nanoseconds minTimerResolution = getMinimumTimerResolution();
         Microseconds value{adaptiveServiceExecutorMaxQueueLatencyMicros.load()};
         if (value < minTimerResolution) {
-            log() << "Target MaxQueueLatencyMicros (" << value
-                  << ") is less than minimum timer resolution of OS (" << minTimerResolution
-                  << "). Using " << minTimerResolution;
+            LOGV2("Target MaxQueueLatencyMicros ({}) is less than minimum timer resolution of OS ({}). Using {}", "value"_attr = value, "minTimerResolution"_attr = minTimerResolution, "minTimerResolution"_attr = minTimerResolution);
             value = duration_cast<Microseconds>(minTimerResolution) + Microseconds{1};
             adaptiveServiceExecutorMaxQueueLatencyMicros.store(value.count());
         }
@@ -350,9 +348,7 @@ void ServiceExecutorAdaptive::_controllerThreadRoutine() {
                 // thread to unblock the executor for now.
                 stuckThreadTimeout /= 2;
                 stuckThreadTimeout = std::max(Milliseconds{10}, stuckThreadTimeout);
-                log() << "Detected blocked worker threads, "
-                      << "starting new thread to unblock service executor. "
-                      << "Stuck thread timeout now: " << stuckThreadTimeout;
+                LOGV2("Detected blocked worker threads, starting new thread to unblock service executor. Stuck thread timeout now: {}", "stuckThreadTimeout"_attr = stuckThreadTimeout);
                 _startWorkerThread(ThreadCreationReason::kStuckDetection);
 
                 // Since we've just started a worker thread, then we know that the executor isn't
@@ -365,15 +361,14 @@ void ServiceExecutorAdaptive::_controllerThreadRoutine() {
             auto newStuckThreadTimeout = stuckThreadTimeout + (stuckThreadTimeout / 2);
             newStuckThreadTimeout = std::min(_config->stuckThreadTimeout(), newStuckThreadTimeout);
             if (newStuckThreadTimeout != stuckThreadTimeout) {
-                LOG(1) << "Increasing stuck thread timeout to " << newStuckThreadTimeout;
+                LOGV2_DEBUG(1, "Increasing stuck thread timeout to {}", "newStuckThreadTimeout"_attr = newStuckThreadTimeout);
                 stuckThreadTimeout = newStuckThreadTimeout;
             }
         }
 
         auto threadsRunning = _threadsRunning.load();
         if (threadsRunning < _config->reservedThreads()) {
-            log() << "Starting " << _config->reservedThreads() - threadsRunning
-                  << " to replenish reserved worker threads";
+            LOGV2("Starting {} to replenish reserved worker threads", "_config_reservedThreads_threadsRunning"_attr = _config->reservedThreads() - threadsRunning);
             while (_threadsRunning.load() < _config->reservedThreads()) {
                 _startWorkerThread(ThreadCreationReason::kReserveMinimum);
             }
@@ -421,7 +416,7 @@ void ServiceExecutorAdaptive::_controllerThreadRoutine() {
         // number of tasks executing (the number of free threads), then start a new worker to
         // avoid starvation.
         if (_isStarved()) {
-            log() << "Starting worker thread to avoid starvation.";
+            LOGV2("Starting worker thread to avoid starvation.");
             _startWorkerThread(ThreadCreationReason::kStarvation);
         }
     }
@@ -528,7 +523,7 @@ void ServiceExecutorAdaptive::_workerThreadRoutine(
         setThreadName(threadName);
     }
 
-    log() << "Started new database worker thread " << threadId;
+    LOGV2("Started new database worker thread {}", "threadId"_attr = threadId);
 
     bool guardThreadsRunning = true;
     const auto guard = makeGuard([this, &guardThreadsRunning, state] {
@@ -605,8 +600,7 @@ void ServiceExecutorAdaptive::_workerThreadRoutine(
         } while (terminateThread &&
                  !_threadsRunning.compareAndSwap(&runningThreads, runningThreads - 1));
         if (terminateThread) {
-            log() << "Thread was only executing tasks " << pctExecuting << "% over the last "
-                  << runTime << ". Exiting thread.";
+            LOGV2("Thread was only executing tasks {}% over the last {}. Exiting thread.", "pctExecuting"_attr = pctExecuting, "runTime"_attr = runTime);
 
             // Because we've already modified _threadsRunning, make sure the thread guard also
             // doesn't do it.
diff --git a/src/mongo/transport/service_executor_adaptive_test.cpp b/src/mongo/transport/service_executor_adaptive_test.cpp
index f30679b408..ce491956c7 100644
--- a/src/mongo/transport/service_executor_adaptive_test.cpp
+++ b/src/mongo/transport/service_executor_adaptive_test.cpp
@@ -34,6 +34,7 @@
 #include "boost/optional.hpp"
 
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/service_executor_adaptive.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
@@ -122,7 +123,7 @@ protected:
         invariant(waitFor.load() != -1);
         waitFor.fetchAndSubtract(1);
         cond.notify_one();
-        log() << "Ran callback";
+        LOGV2("Ran callback");
     };
 
     void waitForCallback(int expected, boost::optional<Milliseconds> timeout = boost::none) {
@@ -146,7 +147,7 @@ protected:
             getGlobalServiceContext(), asioIoCtx, std::move(configOwned));
 
         ASSERT_OK(exec->start());
-        log() << "wait for executor to finish starting";
+        LOGV2("wait for executor to finish starting");
         waitFor.store(1);
         ASSERT_OK(exec->schedule(notifyCallback,
                                  ServiceExecutor::kEmptyFlags,
@@ -173,7 +174,7 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestStuckTask) {
         ASSERT_OK(exec->shutdown(config->workerThreadRunTime() * 2));
     });
 
-    log() << "Scheduling blocked task";
+    LOGV2("Scheduling blocked task");
     waitFor.store(3);
     ASSERT_OK(exec->schedule(
         [this, &blockedMutex] {
@@ -184,20 +185,20 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestStuckTask) {
         ServiceExecutor::kEmptyFlags,
         ServiceExecutorTaskName::kSSMProcessMessage));
 
-    log() << "Scheduling task stuck on blocked task";
+    LOGV2("Scheduling task stuck on blocked task");
     ASSERT_OK(exec->schedule(
         notifyCallback, ServiceExecutor::kEmptyFlags, ServiceExecutorTaskName::kSSMProcessMessage));
 
-    log() << "Waiting for second thread to start";
+    LOGV2("Waiting for second thread to start");
     waitForCallback(1);
     ASSERT_EQ(exec->threadsRunning(), 2);
 
-    log() << "Waiting for unstuck task to run";
+    LOGV2("Waiting for unstuck task to run");
     blockedLock.unlock();
     waitForCallback(0);
     ASSERT_EQ(exec->threadsRunning(), 2);
 
-    log() << "Waiting for second thread to idle out";
+    LOGV2("Waiting for second thread to idle out");
     stdx::this_thread::sleep_for(config->workerThreadRunTime().toSystemDuration() * 1.5);
     ASSERT_EQ(exec->threadsRunning(), config->reservedThreads());
 }
@@ -219,7 +220,7 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestStuckThreads) {
     });
 
     auto blockedTask = [this, &blockedMutex] {
-        log() << "waiting on blocked mutex";
+        LOGV2("waiting on blocked mutex");
         notifyCallback();
         stdx::unique_lock<Latch> lk(blockedMutex);
         notifyCallback();
@@ -227,17 +228,17 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestStuckThreads) {
 
     waitFor.store(6);
     auto tasks = waitFor.load() / 2;
-    log() << "Scheduling " << tasks << " blocked tasks";
+    LOGV2("Scheduling {} blocked tasks", "tasks"_attr = tasks);
     for (auto i = 0; i < tasks; i++) {
         ASSERT_OK(exec->schedule(blockedTask,
                                  ServiceExecutor::kEmptyFlags,
                                  ServiceExecutorTaskName::kSSMProcessMessage));
     }
 
-    log() << "Waiting for executor to start new threads";
+    LOGV2("Waiting for executor to start new threads");
     waitForCallback(3);
 
-    log() << "All threads blocked, wait for executor to detect block and start a new thread.";
+    LOGV2("All threads blocked, wait for executor to detect block and start a new thread.");
 
     // The controller thread in the adaptive executor runs on a stuckThreadTimeout in normal
     // operation where no starvation is detected (shouldn't be in this test as all threads should be
@@ -247,7 +248,7 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestStuckThreads) {
 
     ASSERT_EQ(exec->threadsRunning(), waitFor.load() + config->reservedThreads());
 
-    log() << "Waiting for unstuck task to run";
+    LOGV2("Waiting for unstuck task to run");
     blockedLock.unlock();
     waitForCallback(0);
 }
@@ -318,12 +319,12 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestRecursion) {
 
     task = [this, &task, &exec, &mutex, &cv, &remainingTasks] {
         if (remainingTasks.subtractAndFetch(1) == 0) {
-            log() << "Signaling job done";
+            LOGV2("Signaling job done");
             cv.notify_one();
             return;
         }
 
-        log() << "Starting task recursively";
+        LOGV2("Starting task recursively");
 
         ASSERT_OK(exec->schedule(
             task, ServiceExecutor::kMayRecurse, ServiceExecutorTaskName::kSSMProcessMessage));
@@ -331,7 +332,7 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestRecursion) {
         // Make sure we don't block too long because then the block detection logic would kick in.
         stdx::this_thread::sleep_for(config->stuckThreadTimeout().toSystemDuration() /
                                      (config->recursionLimit() * 2));
-        log() << "Completing task recursively";
+        LOGV2("Completing task recursively");
     };
 
     stdx::unique_lock<Latch> lock(mutex);
@@ -363,7 +364,7 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestDeferredTasks) {
     });
 
     waitFor.store(3);
-    log() << "Scheduling a blocking task";
+    LOGV2("Scheduling a blocking task");
     ASSERT_OK(exec->schedule(
         [this, &blockedMutex] {
             stdx::unique_lock<Latch> lk(blockedMutex);
@@ -372,7 +373,7 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestDeferredTasks) {
         ServiceExecutor::kEmptyFlags,
         ServiceExecutorTaskName::kSSMProcessMessage));
 
-    log() << "Scheduling deferred task";
+    LOGV2("Scheduling deferred task");
     ASSERT_OK(exec->schedule(notifyCallback,
                              ServiceExecutor::kDeferredTask,
                              ServiceExecutorTaskName::kSSMProcessMessage));
@@ -380,7 +381,7 @@ TEST_F(ServiceExecutorAdaptiveFixture, TestDeferredTasks) {
     ASSERT_THROWS(waitForCallback(1, config->stuckThreadTimeout()),
                   unittest::TestAssertionFailureException);
 
-    log() << "Scheduling non-deferred task";
+    LOGV2("Scheduling non-deferred task");
     ASSERT_OK(exec->schedule(
         notifyCallback, ServiceExecutor::kEmptyFlags, ServiceExecutorTaskName::kSSMProcessMessage));
     waitForCallback(1, config->stuckThreadTimeout());
diff --git a/src/mongo/transport/service_executor_reserved.cpp b/src/mongo/transport/service_executor_reserved.cpp
index 6dba2bafc3..4606cb5f4c 100644
--- a/src/mongo/transport/service_executor_reserved.cpp
+++ b/src/mongo/transport/service_executor_reserved.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/transport/service_executor_reserved.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/transport/service_entry_point_utils.h"
 #include "mongo/transport/service_executor_gen.h"
@@ -78,7 +79,7 @@ Status ServiceExecutorReserved::start() {
 }
 
 Status ServiceExecutorReserved::_startWorker() {
-    log() << "Starting new worker thread for " << _name << " service executor";
+    LOGV2("Starting new worker thread for {} service executor", "_name"_attr = _name);
     return launchServiceWorkerThread([this] {
         stdx::unique_lock<Latch> lk(_mutex);
         _numRunningWorkerThreads.addAndFetch(1);
@@ -134,13 +135,13 @@ Status ServiceExecutorReserved::_startWorker() {
             }
         }
 
-        LOG(3) << "Exiting worker thread in " << _name << " service executor";
+        LOGV2_DEBUG(3, "Exiting worker thread in {} service executor", "_name"_attr = _name);
     });
 }
 
 
 Status ServiceExecutorReserved::shutdown(Milliseconds timeout) {
-    LOG(3) << "Shutting down reserved executor";
+    LOGV2_DEBUG(3, "Shutting down reserved executor");
 
     stdx::unique_lock<Latch> lock(_mutex);
     _stillRunning.store(false);
diff --git a/src/mongo/transport/service_executor_synchronous.cpp b/src/mongo/transport/service_executor_synchronous.cpp
index 8fe383768e..adc4bea2e2 100644
--- a/src/mongo/transport/service_executor_synchronous.cpp
+++ b/src/mongo/transport/service_executor_synchronous.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/transport/service_executor_synchronous.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/transport/service_entry_point_utils.h"
 #include "mongo/transport/service_executor_gen.h"
@@ -63,7 +64,7 @@ Status ServiceExecutorSynchronous::start() {
 }
 
 Status ServiceExecutorSynchronous::shutdown(Milliseconds timeout) {
-    LOG(3) << "Shutting down passthrough executor";
+    LOGV2_DEBUG(3, "Shutting down passthrough executor");
 
     _stillRunning.store(false);
 
@@ -113,7 +114,7 @@ Status ServiceExecutorSynchronous::schedule(Task task,
 
     // First call to schedule() for this connection, spawn a worker thread that will push jobs
     // into the thread local job queue.
-    LOG(3) << "Starting new executor thread in passthrough mode";
+    LOGV2_DEBUG(3, "Starting new executor thread in passthrough mode");
 
     Status status = launchServiceWorkerThread([this, task = std::move(task)] {
         _numRunningWorkerThreads.addAndFetch(1);
diff --git a/src/mongo/transport/service_executor_test.cpp b/src/mongo/transport/service_executor_test.cpp
index 645752d90d..6a5c19fca8 100644
--- a/src/mongo/transport/service_executor_test.cpp
+++ b/src/mongo/transport/service_executor_test.cpp
@@ -34,6 +34,7 @@
 #include "boost/optional.hpp"
 
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/service_executor_adaptive.h"
 #include "mongo/transport/service_executor_synchronous.h"
 #include "mongo/transport/service_executor_task_names.h"
@@ -114,7 +115,7 @@ public:
     void drain() override final {
         _ioContext.restart();
         while (_ioContext.poll()) {
-            LOG(1) << "Draining remaining work in reactor.";
+            LOGV2_DEBUG(1, "Draining remaining work in reactor.");
         }
         _ioContext.stop();
     }
diff --git a/src/mongo/transport/service_state_machine.cpp b/src/mongo/transport/service_state_machine.cpp
index 68ff7e8c1d..e14b8e9bad 100644
--- a/src/mongo/transport/service_state_machine.cpp
+++ b/src/mongo/transport/service_state_machine.cpp
@@ -40,6 +40,7 @@
 #include "mongo/db/dbmessage.h"
 #include "mongo/db/stats/counters.h"
 #include "mongo/db/traffic_recorder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/message.h"
 #include "mongo/rpc/op_msg.h"
 #include "mongo/transport/message_compressor_manager.h"
@@ -399,16 +400,14 @@ void ServiceStateMachine::_sourceCallback(Status status) {
                                       transport::ServiceExecutorTaskName::kSSMProcessMessage);
     } else if (ErrorCodes::isInterruption(status.code()) ||
                ErrorCodes::isNetworkError(status.code())) {
-        LOG(2) << "Session from " << remote
-               << " encountered a network error during SourceMessage: " << status;
+        LOGV2_DEBUG(2, "Session from {} encountered a network error during SourceMessage: {}", "remote"_attr = remote, "status"_attr = status);
         _state.store(State::EndSession);
     } else if (status == TransportLayer::TicketSessionClosedStatus) {
         // Our session may have been closed internally.
-        LOG(2) << "Session from " << remote << " was closed internally during SourceMessage";
+        LOGV2_DEBUG(2, "Session from {} was closed internally during SourceMessage", "remote"_attr = remote);
         _state.store(State::EndSession);
     } else {
-        log() << "Error receiving request from client: " << status << ". Ending connection from "
-              << remote << " (connection id: " << _session()->id() << ")";
+        LOGV2("Error receiving request from client: {}. Ending connection from {} (connection id: {})", "status"_attr = status, "remote"_attr = remote, "_session_id"_attr = _session()->id());
         _state.store(State::EndSession);
     }
 
@@ -430,8 +429,7 @@ void ServiceStateMachine::_sinkCallback(Status status) {
     // Otherwise, update the current state depending on whether we're in exhaust or not, and call
     // scheduleNext() to unwind the stack and do the next step.
     if (!status.isOK()) {
-        log() << "Error sending response to client: " << status << ". Ending connection from "
-              << _session()->remote() << " (connection id: " << _session()->id() << ")";
+        LOGV2("Error sending response to client: {}. Ending connection from {} (connection id: {})", "status"_attr = status, "_session_remote"_attr = _session()->remote(), "_session_id"_attr = _session()->id());
         _state.store(State::EndSession);
         return _runNextInGuard(std::move(guard));
     } else if (_inExhaust) {
@@ -565,7 +563,7 @@ void ServiceStateMachine::_runNextInGuard(ThreadGuard guard) {
 
         return;
     } catch (const DBException& e) {
-        log() << "DBException handling request, closing client connection: " << redact(e);
+        LOGV2("DBException handling request, closing client connection: {}", "redact_e"_attr = redact(e));
     }
     // No need to catch std::exception, as std::terminate will be called when the exception bubbles
     // to the top of the stack
@@ -629,7 +627,7 @@ void ServiceStateMachine::terminateIfTagsDontMatch(transport::Session::TagMask t
     // If terminateIfTagsDontMatch gets called when we still are 'pending' where no tags have been
     // set, then skip the termination check.
     if ((sessionTags & tags) || (sessionTags & transport::Session::kPending)) {
-        log() << "Skip closing connection for connection # " << _session()->id();
+        LOGV2("Skip closing connection for connection # {}", "_session_id"_attr = _session()->id());
         return;
     }
 
@@ -667,7 +665,7 @@ void ServiceStateMachine::_cleanupExhaustResources() noexcept try {
         _sep->handleRequest(opCtx.get(), makeKillCursorsMessage(cursorId));
     }
 } catch (const DBException& e) {
-    log() << "Error cleaning up resources for exhaust requests: " << e.toStatus();
+    LOGV2("Error cleaning up resources for exhaust requests: {}", "e_toStatus"_attr = e.toStatus());
 }
 
 void ServiceStateMachine::_cleanupSession(ThreadGuard guard) {
diff --git a/src/mongo/transport/service_state_machine_test.cpp b/src/mongo/transport/service_state_machine_test.cpp
index 2cc54156c6..a90e8c219f 100644
--- a/src/mongo/transport/service_state_machine_test.cpp
+++ b/src/mongo/transport/service_state_machine_test.cpp
@@ -39,6 +39,7 @@
 #include "mongo/db/client.h"
 #include "mongo/db/dbmessage.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/op_msg.h"
 #include "mongo/transport/mock_session.h"
 #include "mongo/transport/service_entry_point.h"
@@ -73,7 +74,7 @@ public:
     void startSession(transport::SessionHandle session) override {}
 
     DbResponse handleRequest(OperationContext* opCtx, const Message& request) override {
-        log() << "In handleRequest";
+        LOGV2("In handleRequest");
         _ranHandler = true;
         ASSERT_TRUE(haveClient());
 
@@ -154,7 +155,7 @@ public:
             tl->_lastTicketSource = true;
 
             tl->_ranSource = true;
-            log() << "In sourceMessage";
+            LOGV2("In sourceMessage");
 
             if (tl->_waitHook)
                 tl->_waitHook();
@@ -178,7 +179,7 @@ public:
             ASSERT_EQ(tl->_ssm->state(), ServiceStateMachine::State::SinkWait);
             tl->_lastTicketSource = false;
 
-            log() << "In sinkMessage";
+            LOGV2("In sinkMessage");
             tl->_ranSink = true;
 
             if (tl->_waitHook)
@@ -367,7 +368,7 @@ protected:
 void ServiceStateMachineFixture::runPingTest(State first, State second) {
     ASSERT_FALSE(haveClient());
     ASSERT_EQ(_ssm->state(), State::Created);
-    log() << "run next";
+    LOGV2("run next");
     _ssm->runNext();
 
     ASSERT_EQ(_ssm->state(), first);
@@ -384,7 +385,7 @@ void ServiceStateMachineFixture::sourceAndSink(State afterSource, State afterSin
     invariant(_ssm->state() == State::Source || _ssm->state() == State::Created);
 
     // Source a new message from the network.
-    log() << "(sourceAndSink) runNext to source a message";
+    LOGV2("(sourceAndSink) runNext to source a message");
     _ssm->runNext();
     ASSERT_TRUE(_tl->ranSource());
     ASSERT_EQ(_ssm->state(), afterSource);
@@ -392,7 +393,7 @@ void ServiceStateMachineFixture::sourceAndSink(State afterSource, State afterSin
 
     // Let the message be processed by sending it to the database, receiving the response, and then
     // sinking it.
-    log() << "(sourceAndSink) runNext to process and sink the response message";
+    LOGV2("(sourceAndSink) runNext to process and sink the response message");
     _ssm->runNext();
     ASSERT_FALSE(haveClient());
     ASSERT_TRUE(_tl->ranSink());
@@ -476,7 +477,7 @@ TEST_F(ServiceStateMachineFixture, TestGetMoreWithExhaust) {
     // terminal getMore, indicating that the exhaust stream should be ended.
     _sep->setResponseMessage(getMoreTerminalRes);
 
-    log() << "runNext to terminate the exhaust stream";
+    LOGV2("runNext to terminate the exhaust stream");
     _ssm->runNext();
     ASSERT_FALSE(haveClient());
     ASSERT_EQ(_ssm->state(), State::Source);
@@ -686,7 +687,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStates) {
     SimpleEvent hookRan, okayToContinue;
 
     auto cleanupHook = [&hookRan] {
-        log() << "Cleaning up session";
+        LOGV2("Cleaning up session");
         hookRan.signal();
     };
 
@@ -695,8 +696,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStates) {
     State waitFor = State::Created;
     SimpleEvent atDesiredState;
     auto waitForHook = [this, &waitFor, &atDesiredState, &okayToContinue]() {
-        log() << "Checking for wakeup at " << stateToString(_ssm->state()) << ". Expecting "
-              << stateToString(waitFor);
+        LOGV2("Checking for wakeup at {}. Expecting {}", "stateToString__ssm_state"_attr = stateToString(_ssm->state()), "stateToString_waitFor"_attr = stateToString(waitFor));
         if (_ssm->state() == waitFor) {
             atDesiredState.signal();
             okayToContinue.wait();
@@ -715,7 +715,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStates) {
     // Run this same test for each state.
     auto states = {State::Source, State::SourceWait, State::Process, State::SinkWait};
     for (const auto testState : states) {
-        log() << "Testing termination during " << stateToString(testState);
+        LOGV2("Testing termination during {}", "stateToString_testState"_attr = stateToString(testState));
 
         // Reset the _ssm to a fresh SSM and reset our tracking variables.
         _ssm = ServiceStateMachine::create(
@@ -733,7 +733,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStates) {
 
         // Wait for the SSM to advance to the expected state
         atDesiredState.wait();
-        log() << "Terminating session at " << stateToString(_ssm->state());
+        LOGV2("Terminating session at {}", "stateToString__ssm_state"_attr = stateToString(_ssm->state()));
 
         // Terminate the SSM
         _ssm->terminate();
@@ -760,7 +760,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStatesWithScheduleFailure
     bool scheduleFailed = false;
 
     auto cleanupHook = [&hookRan] {
-        log() << "Cleaning up session";
+        LOGV2("Cleaning up session");
         hookRan.signal();
     };
 
@@ -769,8 +769,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStatesWithScheduleFailure
     State waitFor = State::Created;
     SimpleEvent atDesiredState;
     auto waitForHook = [this, &waitFor, &scheduleFailed, &okayToContinue, &atDesiredState]() {
-        log() << "Checking for wakeup at " << stateToString(_ssm->state()) << ". Expecting "
-              << stateToString(waitFor);
+        LOGV2("Checking for wakeup at {}. Expecting {}", "stateToString__ssm_state"_attr = stateToString(_ssm->state()), "stateToString_waitFor"_attr = stateToString(waitFor));
         if (_ssm->state() == waitFor) {
             atDesiredState.signal();
             okayToContinue.wait();
@@ -786,7 +785,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStatesWithScheduleFailure
 
     auto states = {State::Source, State::SourceWait, State::Process, State::SinkWait};
     for (const auto testState : states) {
-        log() << "Testing termination during " << stateToString(testState);
+        LOGV2("Testing termination during {}", "stateToString_testState"_attr = stateToString(testState));
         _ssm = ServiceStateMachine::create(
             getGlobalServiceContext(), _tl->createSession(), transport::Mode::kSynchronous);
         _tl->setSSM(_ssm.get());
@@ -804,7 +803,7 @@ TEST_F(ServiceStateMachineFixture, TerminateWorksForAllStatesWithScheduleFailure
         // Wait for the SSM to advance to the expected state
         atDesiredState.wait();
         ASSERT_EQ(_ssm->state(), testState);
-        log() << "Terminating session at " << stateToString(_ssm->state());
+        LOGV2("Terminating session at {}", "stateToString__ssm_state"_attr = stateToString(_ssm->state()));
 
         // Terminate the SSM
         _ssm->terminate();
@@ -834,7 +833,7 @@ TEST_F(ServiceStateMachineFixture, SSMRunsRecursively) {
     // The scheduleHook just runs the task, effectively making this a recursive executor.
     int recursionDepth = 0;
     _sexec->setScheduleHook([&recursionDepth](auto task) {
-        log() << "running task in executor. depth: " << ++recursionDepth;
+        LOGV2("running task in executor. depth: {}", "recursionDepth"_attr = ++recursionDepth);
         task();
         return true;
     });
diff --git a/src/mongo/transport/transport_layer_asio.cpp b/src/mongo/transport/transport_layer_asio.cpp
index a8d5957958..f20bf3b629 100644
--- a/src/mongo/transport/transport_layer_asio.cpp
+++ b/src/mongo/transport/transport_layer_asio.cpp
@@ -61,6 +61,7 @@
 #include "mongo/transport/baton_asio_linux.h"
 #endif
 
+#include "mongo/logv2/log.h"
 #include "mongo/transport/session_asio.h"
 
 namespace mongo {
@@ -82,7 +83,7 @@ public:
     void cancel(const BatonHandle& baton = nullptr) override {
         // If we have a baton try to cancel that.
         if (baton && baton->networking() && baton->networking()->cancelTimer(*this)) {
-            LOG(2) << "Canceled via baton, skipping asio cancel.";
+            LOGV2_DEBUG(2, "Canceled via baton, skipping asio cancel.");
             return;
         }
 
@@ -109,7 +110,7 @@ private:
             armTimer();
             return _timer->async_wait(UseFuture{}).tapError([timer = _timer](const Status& status) {
                 if (status != ErrorCodes::CallbackCanceled) {
-                    LOG(2) << "Timer received error: " << status;
+                    LOGV2_DEBUG(2, "Timer received error: {}", "status"_attr = status);
                 }
             });
 
@@ -160,7 +161,7 @@ public:
     void drain() override {
         _ioContext.restart();
         while (_ioContext.poll()) {
-            LOG(2) << "Draining remaining work in reactor.";
+            LOGV2_DEBUG(2, "Draining remaining work in reactor.");
         }
         _ioContext.stop();
     }
@@ -613,7 +614,7 @@ Future<SessionHandle> TransportLayerASIO::asyncConnect(HostAndPort peer,
         })
         .getAsync([connector](Status connectResult) {
             if (MONGO_unlikely(transportLayerASIOasyncConnectTimesOut.shouldFail())) {
-                log() << "asyncConnectTimesOut fail point is active. simulating timeout.";
+                LOGV2("asyncConnectTimesOut fail point is active. simulating timeout.");
                 return;
             }
 
@@ -786,7 +787,7 @@ void TransportLayerASIO::_runListener() noexcept {
         }
 
         _acceptConnection(acceptor.second);
-        log() << "Listening on " << acceptor.first.getAddr();
+        LOGV2("Listening on {}", "acceptor_first_getAddr"_attr = acceptor.first.getAddr());
     }
 
     const char* ssl = "";
@@ -795,7 +796,7 @@ void TransportLayerASIO::_runListener() noexcept {
         ssl = " ssl";
     }
 #endif
-    log() << "waiting for connections on port " << _listenerPort << ssl;
+    LOGV2("waiting for connections on port {}{}", "_listenerPort"_attr = _listenerPort, "ssl"_attr = ssl);
 
     _listener.active = true;
     _listener.cv.notify_all();
@@ -817,7 +818,7 @@ void TransportLayerASIO::_runListener() noexcept {
         auto& addr = acceptor.first;
         if (addr.getType() == AF_UNIX && !addr.isAnonymousUNIXSocket()) {
             auto path = addr.getAddr();
-            log() << "removing socket file: " << path;
+            LOGV2("removing socket file: {}", "path"_attr = path);
             if (::unlink(path.c_str()) != 0) {
                 const auto ewd = errnoWithDescription();
                 warning() << "Unable to remove UNIX socket " << path << ": " << ewd;
@@ -893,8 +894,7 @@ void TransportLayerASIO::_acceptConnection(GenericAcceptor& acceptor) {
         }
 
         if (ec) {
-            log() << "Error accepting new connection on "
-                  << endpointToHostAndPort(acceptor.local_endpoint()) << ": " << ec.message();
+            LOGV2("Error accepting new connection on {}: {}", "endpointToHostAndPort_acceptor_local_endpoint"_attr = endpointToHostAndPort(acceptor.local_endpoint()), "ec_message"_attr = ec.message());
             _acceptConnection(acceptor);
             return;
         }
diff --git a/src/mongo/transport/transport_layer_asio_integration_test.cpp b/src/mongo/transport/transport_layer_asio_integration_test.cpp
index a180b93359..6567ef59fc 100644
--- a/src/mongo/transport/transport_layer_asio_integration_test.cpp
+++ b/src/mongo/transport/transport_layer_asio_integration_test.cpp
@@ -36,6 +36,7 @@
 #include "mongo/db/client.h"
 #include "mongo/db/operation_context.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/transport/session.h"
 #include "mongo/transport/transport_layer.h"
@@ -58,11 +59,11 @@ TEST(TransportLayerASIO, HTTPRequestGetsHTTPError) {
     asio::ip::tcp::resolver resolver(ioContext);
     asio::ip::tcp::socket socket(ioContext);
 
-    log() << "Connecting to " << server;
+    LOGV2("Connecting to {}", "server"_attr = server);
     auto resolverIt = resolver.resolve(server.host(), std::to_string(server.port()));
     asio::connect(socket, resolverIt);
 
-    log() << "Sending HTTP request";
+    LOGV2("Sending HTTP request");
     std::string httpReq = str::stream() << "GET /\r\n"
                                            "Host: "
                                         << server
@@ -71,13 +72,13 @@ TEST(TransportLayerASIO, HTTPRequestGetsHTTPError) {
                                            "Accept: */*";
     asio::write(socket, asio::buffer(httpReq.data(), httpReq.size()));
 
-    log() << "Waiting for response";
+    LOGV2("Waiting for response");
     std::array<char, 256> httpRespBuf;
     std::error_code ec;
     auto size = asio::read(socket, asio::buffer(httpRespBuf.data(), httpRespBuf.size()), ec);
     StringData httpResp(httpRespBuf.data(), size);
 
-    log() << "Received response: \"" << httpResp << "\"";
+    LOGV2("Received response: \"{}\"", "httpResp"_attr = httpResp);
     ASSERT_TRUE(httpResp.startsWith("HTTP/1.0 200 OK"));
 
 // Why oh why can't ASIO unify their error codes
diff --git a/src/mongo/transport/transport_layer_asio_test.cpp b/src/mongo/transport/transport_layer_asio_test.cpp
index 53f979d9cd..2943fe539a 100644
--- a/src/mongo/transport/transport_layer_asio_test.cpp
+++ b/src/mongo/transport/transport_layer_asio_test.cpp
@@ -33,6 +33,7 @@
 #include "mongo/transport/transport_layer_asio.h"
 
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/rpc/op_msg.h"
 #include "mongo/transport/service_entry_point.h"
 #include "mongo/unittest/unittest.h"
@@ -50,12 +51,12 @@ public:
     void startSession(transport::SessionHandle session) override {
         stdx::unique_lock<Latch> lk(_mutex);
         _sessions.push_back(std::move(session));
-        log() << "started session";
+        LOGV2("started session");
         _cv.notify_one();
     }
 
     void endAllSessions(transport::Session::TagMask tags) override {
-        log() << "end all sessions";
+        LOGV2("end all sessions");
         std::vector<transport::SessionHandle> old_sessions;
         {
             stdx::unique_lock<Latch> lock(_mutex);
@@ -106,10 +107,10 @@ public:
             Socket s;
             SockAddr sa{"localhost", _port, AF_INET};
             s.connect(sa);
-            log() << "connection: port " << _port;
+            LOGV2("connection: port {}", "_port"_attr = _port);
             stdx::unique_lock<Latch> lk(_mutex);
             _cv.wait(lk, [&] { return _stop; });
-            log() << "connection: Rx stop request";
+            LOGV2("connection: Rx stop request");
         }};
     }
 
@@ -118,10 +119,10 @@ public:
             stdx::unique_lock<Latch> lk(_mutex);
             _stop = true;
         }
-        log() << "connection: Tx stop request";
+        LOGV2("connection: Tx stop request");
         _cv.notify_one();
         _thr.join();
-        log() << "connection: stopped";
+        LOGV2("connection: stopped");
     }
 
 private:
@@ -153,7 +154,7 @@ TEST(TransportLayerASIO, PortZeroConnect) {
     ASSERT_OK(tla.start());
     int port = tla.listenerPort();
     ASSERT_GT(port, 0);
-    log() << "TransportLayerASIO.listenerPort() is " << port;
+    LOGV2("TransportLayerASIO.listenerPort() is {}", "port"_attr = port);
 
     SimpleConnectionThread connect_thread(port);
     sepu.waitForConnect();
@@ -174,7 +175,7 @@ public:
     }
 
     bool shutdown(Milliseconds timeout) override {
-        log() << "Joining all worker threads";
+        LOGV2("Joining all worker threads");
         for (auto& thread : _workerThreads) {
             thread.join();
         }
@@ -235,17 +236,17 @@ public:
     TimeoutSyncSEP(Mode mode) : _mode(mode) {}
 
     void startSession(transport::SessionHandle session) override {
-        log() << "Accepted connection from " << session->remote();
+        LOGV2("Accepted connection from {}", "session_remote"_attr = session->remote());
         startWorkerThread([this, session = std::move(session)]() mutable {
-            log() << "waiting for message";
+            LOGV2("waiting for message");
             session->setTimeout(Milliseconds{500});
             auto status = session->sourceMessage().getStatus();
             if (_mode == kShouldTimeout) {
                 ASSERT_EQ(status, ErrorCodes::NetworkTimeout);
-                log() << "message timed out";
+                LOGV2("message timed out");
             } else {
                 ASSERT_OK(status);
-                log() << "message received okay";
+                LOGV2("message received okay");
             }
 
             session.reset();
@@ -331,9 +332,9 @@ TEST(TransportLayerASIO, SourceSyncTimeoutSucceeds) {
 class TimeoutSwitchModesSEP : public TimeoutSEP {
 public:
     void startSession(transport::SessionHandle session) override {
-        log() << "Accepted connection from " << session->remote();
+        LOGV2("Accepted connection from {}", "session_remote"_attr = session->remote());
         startWorkerThread([this, session = std::move(session)]() mutable {
-            log() << "waiting for message";
+            LOGV2("waiting for message");
             auto sourceMessage = [&] { return session->sourceMessage().getStatus(); };
 
             // the first message we source should time out.
@@ -341,13 +342,13 @@ public:
             ASSERT_EQ(sourceMessage(), ErrorCodes::NetworkTimeout);
             notifyComplete();
 
-            log() << "timed out successfully";
+            LOGV2("timed out successfully");
 
             // get the session back in a known state with the timeout still in place
             ASSERT_OK(sourceMessage());
             notifyComplete();
 
-            log() << "waiting for message without a timeout";
+            LOGV2("waiting for message without a timeout");
 
             // this should block and timeout the waitForComplete mutex, and the session should wait
             // for a while to make sure this isn't timing out and then send a message to unblock
@@ -357,7 +358,7 @@ public:
 
             session.reset();
             notifyComplete();
-            log() << "ending test";
+            LOGV2("ending test");
         });
     }
 };
diff --git a/src/mongo/unittest/benchmark_main.cpp b/src/mongo/unittest/benchmark_main.cpp
index 957e214033..1fafa902a0 100644
--- a/src/mongo/unittest/benchmark_main.cpp
+++ b/src/mongo/unittest/benchmark_main.cpp
@@ -36,6 +36,7 @@
 #include "mongo/base/initializer.h"
 #include "mongo/config.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/signal_handlers_synchronous.h"
 
@@ -53,9 +54,9 @@ int main(int argc, char** argv, char** envp) {
         return 1;
 
 #ifndef MONGO_CONFIG_OPTIMIZED_BUILD
-    ::mongo::log() << "***WARNING*** MongoDB was built with --opt=off. Function timings may be "
+    ::mongo::LOGV2("***WARNING*** MongoDB was built with --opt=off. Function timings may be "
                       "affected. Always verify any code change against the production environment "
-                      "(e.g. --opt=on).";
+                      "(e.g. --opt=on).");
 #endif
 
     ::benchmark::RunSpecifiedBenchmarks();
diff --git a/src/mongo/unittest/death_test.cpp b/src/mongo/unittest/death_test.cpp
index b584ec7859..f45cdbbc6f 100644
--- a/src/mongo/unittest/death_test.cpp
+++ b/src/mongo/unittest/death_test.cpp
@@ -45,6 +45,7 @@
 
 #include <sstream>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 #include "mongo/util/quick_exit.h"
@@ -63,10 +64,10 @@ namespace unittest {
 
 void DeathTestBase::_doTest() {
 #if defined(_WIN32)
-    log() << "Skipping death test on Windows";
+    LOGV2("Skipping death test on Windows");
     return;
 #elif defined(__APPLE__) && (TARGET_OS_TV || TARGET_OS_WATCH)
-    log() << "Skipping death test on tvOS/watchOS";
+    LOGV2("Skipping death test on tvOS/watchOS");
     return;
 #else
     int pipes[2];
@@ -78,14 +79,14 @@ void DeathTestBase::_doTest() {
         char buf[1000];
         std::ostringstream os;
         ssize_t bytesRead;
-        log() << "========== Beginning of interleaved output of death test ==========";
+        LOGV2("========== Beginning of interleaved output of death test ==========");
         while (0 < (bytesRead = read(pipes[0], buf, sizeof(buf)))) {
             std::cout.write(buf, bytesRead);
             invariant(std::cout);
             os.write(buf, bytesRead);
             invariant(os);
         }
-        log() << "========== End of interleaved output of death test ==========";
+        LOGV2("========== End of interleaved output of death test ==========");
         checkSyscall(bytesRead);
         pid_t pid;
         int stat;
@@ -127,7 +128,7 @@ void DeathTestBase::_doTest() {
         auto test = _doMakeTest();
         test->run();
     } catch (const TestAssertionFailureException& tafe) {
-        log() << "Caught test exception while expecting death: " << tafe;
+        LOGV2("Caught test exception while expecting death: {}", "tafe"_attr = tafe);
         // To fail the test, we must exit with a successful error code, because the parent process
         // is checking for the child to die with an exit code indicating an error.
         quickExit(EXIT_SUCCESS);
diff --git a/src/mongo/unittest/integration_test_main.cpp b/src/mongo/unittest/integration_test_main.cpp
index 123d421e79..1cc014c6ec 100644
--- a/src/mongo/unittest/integration_test_main.cpp
+++ b/src/mongo/unittest/integration_test_main.cpp
@@ -41,6 +41,7 @@
 #include "mongo/db/server_options_helpers.h"
 #include "mongo/db/service_context.h"
 #include "mongo/logger/logger.h"
+#include "mongo/logv2/log.h"
 #include "mongo/transport/transport_layer_asio.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
@@ -133,7 +134,7 @@ MONGO_STARTUP_OPTIONS_STORE(IntegrationTestOptions)(InitializerContext*) {
     }
 
     fixtureConnectionString = std::move(swConnectionString.getValue());
-    log() << "Using test fixture with connection string = " << connectionString;
+    LOGV2("Using test fixture with connection string = {}", "connectionString"_attr = connectionString);
 
 
     return Status::OK();
diff --git a/src/mongo/unittest/temp_dir.cpp b/src/mongo/unittest/temp_dir.cpp
index 8b370dfd86..61de4821ac 100644
--- a/src/mongo/unittest/temp_dir.cpp
+++ b/src/mongo/unittest/temp_dir.cpp
@@ -36,6 +36,7 @@
 #include <boost/filesystem.hpp>
 
 #include "mongo/base/init.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 #include "mongo/util/options_parser/startup_option_init.h"
@@ -90,7 +91,7 @@ TempDir::TempDir(const std::string& namePrefix) {
         fassertFailed(17147);
     }
 
-    ::mongo::unittest::log() << "Created temporary directory: " << _path;
+    ::mongo::unittest::LOGV2("Created temporary directory: {}", "_path"_attr = _path);
 }
 
 TempDir::~TempDir() {
diff --git a/src/mongo/unittest/unittest.cpp b/src/mongo/unittest/unittest.cpp
index 03c00dfd75..11fcb6ef16 100644
--- a/src/mongo/unittest/unittest.cpp
+++ b/src/mongo/unittest/unittest.cpp
@@ -48,6 +48,7 @@
 #include "mongo/logger/logger.h"
 #include "mongo/logger/message_event_utf8_encoder.h"
 #include "mongo/logger/message_log_domain.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
@@ -264,11 +265,11 @@ void Test::stopCapturingLogMessages() {
     _isCapturingLogMessages = false;
 }
 void Test::printCapturedLogLines() const {
-    log() << "****************************** Captured Lines (start) *****************************";
+    LOGV2("****************************** Captured Lines (start) *****************************");
     for (const auto& line : getCapturedLogMessages()) {
-        log() << line;
+        LOGV2("{}", "line"_attr = line);
     }
-    log() << "****************************** Captured Lines (end) ******************************";
+    LOGV2("****************************** Captured Lines (end) ******************************");
 }
 
 int64_t Test::countLogLinesContaining(const std::string& needle) {
@@ -291,13 +292,12 @@ std::unique_ptr<Result> Suite::run(const std::string& filter,
 
     for (const auto& tc : _tests) {
         if (filter.size() && tc.name.find(filter) == std::string::npos) {
-            LOG(1) << "\t skipping test: " << tc.name << " because it doesn't match filter";
+            LOGV2_DEBUG(1, "\t skipping test: {} because it doesn't match filter", "tc_name"_attr = tc.name);
             continue;
         }
 
         if (fileNameFilter.size() && tc.fileName.find(fileNameFilter) == std::string::npos) {
-            LOG(1) << "\t skipping test: " << tc.fileName
-                   << " because it doesn't match fileNameFilter";
+            LOGV2_DEBUG(1, "\t skipping test: {} because it doesn't match fileNameFilter", "tc_fileName"_attr = tc.fileName);
             continue;
         }
 
@@ -315,7 +315,7 @@ std::unique_ptr<Result> Suite::run(const std::string& filter,
                     runTimes << "  (" << x + 1 << "/" << runsPerTest << ")";
                 }
 
-                log() << "\t going to run test: " << tc.name << runTimes.str();
+                LOGV2("\t going to run test: {}{}", "tc_name"_attr = tc.name, "runTimes_str"_attr = runTimes.str());
                 TestSuiteEnvironment environment;
                 tc.fn();
             }
@@ -344,7 +344,7 @@ std::unique_ptr<Result> Suite::run(const std::string& filter,
 
     r->_millis = timer.millis();
 
-    log() << "\t DONE running tests";
+    LOGV2("\t DONE running tests");
 
     return r;
 }
@@ -354,14 +354,13 @@ int Suite::run(const std::vector<std::string>& suites,
                const std::string& fileNameFilter,
                int runsPerTest) {
     if (suitesMap().empty()) {
-        log() << "error: no suites registered.";
+        LOGV2("error: no suites registered.");
         return EXIT_FAILURE;
     }
 
     for (unsigned int i = 0; i < suites.size(); i++) {
         if (suitesMap().count(suites[i]) == 0) {
-            log() << "invalid test suite [" << suites[i] << "], use --list to see valid names"
-                  << std::endl;
+            LOGV2("invalid test suite [{}], use --list to see valid names", "suites_i"_attr = suites[i]);
             return EXIT_FAILURE;
         }
     }
@@ -380,11 +379,11 @@ int Suite::run(const std::vector<std::string>& suites,
         std::shared_ptr<Suite>& s = suitesMap()[name];
         fassert(16145, s != nullptr);
 
-        log() << "going to run suite: " << name << std::endl;
+        LOGV2("going to run suite: {}", "name"_attr = name);
         results.push_back(s->run(filter, fileNameFilter, runsPerTest));
     }
 
-    log() << "**************************************************" << std::endl;
+    LOGV2("**************************************************");
 
     int rc = 0;
 
@@ -420,14 +419,13 @@ int Suite::run(const std::vector<std::string>& suites,
 
     // summary
     if (!totals._fails.empty()) {
-        log() << "Failing tests:" << std::endl;
+        LOGV2("Failing tests:");
         for (const std::string& s : totals._fails) {
-            log() << "\t " << s << " Failed";
+            LOGV2("\t {} Failed", "s"_attr = s);
         }
-        log() << "FAILURE - " << totals._fails.size() << " tests in " << failedSuites.size()
-              << " suites failed";
+        LOGV2("FAILURE - {} tests in {} suites failed", "totals__fails_size"_attr = totals._fails.size(), "failedSuites_size"_attr = failedSuites.size());
     } else {
-        log() << "SUCCESS - All tests in all suites passed";
+        LOGV2("SUCCESS - All tests in all suites passed");
     }
 
     return rc;
diff --git a/src/mongo/unittest/unittest_test.cpp b/src/mongo/unittest/unittest_test.cpp
index 7a1c7b6233..19206a8b4b 100644
--- a/src/mongo/unittest/unittest_test.cpp
+++ b/src/mongo/unittest/unittest_test.cpp
@@ -38,6 +38,7 @@
 #include <string>
 
 #include "mongo/bson/bsonobjbuilder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/death_test.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/assert_util.h"
@@ -270,7 +271,7 @@ class DeathTestSelfTestFixture : public ::mongo::unittest::Test {
 public:
     void setUp() override {}
     void tearDown() override {
-        mongo::unittest::log() << "Died in tear-down";
+        mongo::unittest::LOGV2("Died in tear-down");
         invariant(false);
     }
 };
diff --git a/src/mongo/util/alarm_test.cpp b/src/mongo/util/alarm_test.cpp
index f450284fc2..72ccf88bee 100644
--- a/src/mongo/util/alarm_test.cpp
+++ b/src/mongo/util/alarm_test.cpp
@@ -30,6 +30,7 @@
 
 #include "mongo/platform/basic.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/chrono.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/alarm.h"
@@ -49,21 +50,21 @@ TEST(AlarmScheduler, BasicSingleThread) {
     auto alarm = scheduler->alarmAt(testStart + Milliseconds(10));
     bool firstTimerExpired = false;
     std::move(alarm.future).getAsync([&](Status status) {
-        log() << "Timer expired: " << status;
+        LOGV2("Timer expired: {}", "status"_attr = status);
         firstTimerExpired = true;
     });
 
     alarm = scheduler->alarmAt(testStart + Milliseconds(500));
     bool secondTimerExpired = false;
     std::move(alarm.future).getAsync([&](Status status) {
-        log() << "Second timer expired: " << status;
+        LOGV2("Second timer expired: {}", "status"_attr = status);
         secondTimerExpired = true;
     });
 
     alarm = scheduler->alarmAt(testStart + Milliseconds(515));
     bool thirdTimerExpired = false;
     std::move(alarm.future).getAsync([&](Status status) {
-        log() << "third timer expired: " << status;
+        LOGV2("third timer expired: {}", "status"_attr = status);
         thirdTimerExpired = true;
     });
     auto missingEvent = alarm.handle;
diff --git a/src/mongo/util/assert_util.cpp b/src/mongo/util/assert_util.cpp
index c441e9b670..55ab2990a4 100644
--- a/src/mongo/util/assert_util.cpp
+++ b/src/mongo/util/assert_util.cpp
@@ -43,6 +43,7 @@
 #include <exception>
 
 #include "mongo/config.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/debug_util.h"
 #include "mongo/util/debugger.h"
 #include "mongo/util/exit.h"
@@ -194,7 +195,7 @@ MONGO_COMPILER_NOINLINE void uassertedWithLocation(const Status& status,
                                                    const char* file,
                                                    unsigned line) {
     assertionCount.condrollover(assertionCount.user.addAndFetch(1));
-    LOG(1) << "User Assertion: " << redact(status) << ' ' << file << ' ' << std::dec << line;
+    LOGV2_DEBUG(1, "User Assertion: {} {} {}", "redact_status"_attr = redact(status), "file"_attr = file, "line"_attr = line);
     error_details::throwExceptionForStatus(status);
 }
 
diff --git a/src/mongo/util/background.cpp b/src/mongo/util/background.cpp
index 6951bf8668..06ce5586cd 100644
--- a/src/mongo/util/background.cpp
+++ b/src/mongo/util/background.cpp
@@ -36,6 +36,7 @@
 #include <functional>
 
 #include "mongo/config.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/stdx/condition_variable.h"
 #include "mongo/stdx/thread.h"
@@ -147,7 +148,7 @@ void BackgroundJob::jobBody() {
         setThreadName(threadName);
     }
 
-    LOG(1) << "BackgroundJob starting: " << threadName;
+    LOGV2_DEBUG(1, "BackgroundJob starting: {}", "threadName"_attr = threadName);
 
     run();
 
@@ -340,7 +341,7 @@ void PeriodicTaskRunner::_runTask(PeriodicTask* const task) {
 
     const int ms = timer.millis();
     const int kMinLogMs = 100;
-    LOG(ms <= kMinLogMs ? 3 : 0) << "task: " << taskName << " took: " << ms << "ms";
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(ms <= kMinLogMs ? 3 : 0).toInt(), "task: {} took: {}ms", "taskName"_attr = taskName, "ms"_attr = ms);
 }
 
 }  // namespace mongo
diff --git a/src/mongo/util/concurrency/spin_lock_test.cpp b/src/mongo/util/concurrency/spin_lock_test.cpp
index 62266221b2..5f2480d245 100644
--- a/src/mongo/util/concurrency/spin_lock_test.cpp
+++ b/src/mongo/util/concurrency/spin_lock_test.cpp
@@ -31,6 +31,7 @@
 
 #include <functional>
 
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/concurrency/spin_lock.h"
@@ -107,7 +108,7 @@ TEST(Concurrency, ConcurrentIncs) {
     }
 
     int ms = timer.millis();
-    mongo::unittest::log() << "spinlock ConcurrentIncs time: " << ms << std::endl;
+    mongo::unittest::LOGV2("spinlock ConcurrentIncs time: {}", "ms"_attr = ms);
 
     ASSERT_EQUALS(counter, threads * incs);
 }
diff --git a/src/mongo/util/concurrency/thread_name.cpp b/src/mongo/util/concurrency/thread_name.cpp
index 03a6ab181c..bb929124db 100644
--- a/src/mongo/util/concurrency/thread_name.cpp
+++ b/src/mongo/util/concurrency/thread_name.cpp
@@ -51,6 +51,7 @@
 
 #include "mongo/base/init.h"
 #include "mongo/config.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
@@ -132,7 +133,7 @@ void setThreadName(StringData name) {
     }
     int error = pthread_setname_np(threadNameCopy.c_str());
     if (error) {
-        log() << "Ignoring error from setting thread name: " << errnoWithDescription(error);
+        LOGV2("Ignoring error from setting thread name: {}", "errnoWithDescription_error"_attr = errnoWithDescription(error));
     }
 #elif defined(__linux__) && defined(MONGO_CONFIG_HAVE_PTHREAD_SETNAME_NP)
     // Do not set thread name on the main() thread. Setting the name on main thread breaks
@@ -153,7 +154,7 @@ void setThreadName(StringData name) {
         }
 
         if (error) {
-            log() << "Ignoring error from setting thread name: " << errnoWithDescription(error);
+            LOGV2("Ignoring error from setting thread name: {}", "errnoWithDescription_error"_attr = errnoWithDescription(error));
         }
     }
 #endif
diff --git a/src/mongo/util/concurrency/thread_pool.cpp b/src/mongo/util/concurrency/thread_pool.cpp
index ceaf9fcaf7..8efb1497c9 100644
--- a/src/mongo/util/concurrency/thread_pool.cpp
+++ b/src/mongo/util/concurrency/thread_pool.cpp
@@ -34,6 +34,7 @@
 #include "mongo/util/concurrency/thread_pool.h"
 
 #include "mongo/base/status.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
@@ -243,7 +244,7 @@ void ThreadPool::_workerThreadBody(ThreadPool* pool, const std::string& threadNa
     setThreadName(threadName);
     pool->_options.onCreateThread(threadName);
     const auto poolName = pool->_options.poolName;
-    LOG(1) << "starting thread in pool " << poolName;
+    LOGV2_DEBUG(1, "starting thread in pool {}", "poolName"_attr = poolName);
     pool->_consumeTasks();
 
     // At this point, another thread may have destroyed "pool", if this thread chose to detach
@@ -253,7 +254,7 @@ void ThreadPool::_workerThreadBody(ThreadPool* pool, const std::string& threadNa
     // This can happen if this thread decided to retire, got descheduled after removing itself
     // from _threads and calling detach(), and then the pool was deleted. When this thread resumes,
     // it is no longer safe to access "pool".
-    LOG(1) << "shutting down thread in pool " << poolName;
+    LOGV2_DEBUG(1, "shutting down thread in pool {}", "poolName"_attr = poolName);
 }
 
 void ThreadPool::_consumeTasks() {
@@ -274,8 +275,7 @@ void ThreadPool::_consumeTasks() {
                     break;
                 }
 
-                LOG(3) << "Not reaping because the earliest retirement date is "
-                       << nextThreadRetirementDate;
+                LOGV2_DEBUG(3, "Not reaping because the earliest retirement date is {}", "nextThreadRetirementDate"_attr = nextThreadRetirementDate);
                 MONGO_IDLE_THREAD_BLOCK;
                 _workAvailable.wait_until(lk, nextThreadRetirementDate.toSystemTimePoint());
             } else {
@@ -333,7 +333,7 @@ void ThreadPool::_consumeTasks() {
 
 void ThreadPool::_doOneTask(stdx::unique_lock<Latch>* lk) noexcept {
     invariant(!_pendingTasks.empty());
-    LOG(3) << "Executing a task on behalf of pool " << _options.poolName;
+    LOGV2_DEBUG(3, "Executing a task on behalf of pool {}", "_options_poolName"_attr = _options.poolName);
     Task task = std::move(_pendingTasks.front());
     _pendingTasks.pop_front();
     --_numIdleThreads;
@@ -355,8 +355,7 @@ void ThreadPool::_startWorkerThread_inlock() {
         case joinRequired:
         case joining:
         case shutdownComplete:
-            LOG(1) << "Not starting new thread in pool " << _options.poolName
-                   << " while shutting down";
+            LOGV2_DEBUG(1, "Not starting new thread in pool {} while shutting down", "_options_poolName"_attr = _options.poolName);
             return;
         case running:
             break;
@@ -364,8 +363,7 @@ void ThreadPool::_startWorkerThread_inlock() {
             MONGO_UNREACHABLE;
     }
     if (_threads.size() == _options.maxThreads) {
-        LOG(2) << "Not starting new thread in pool " << _options.poolName
-               << " because it already has " << _options.maxThreads << ", its maximum";
+        LOGV2_DEBUG(2, "Not starting new thread in pool {} because it already has {}, its maximum", "_options_poolName"_attr = _options.poolName, "_options_maxThreads"_attr = _options.maxThreads);
         return;
     }
     invariant(_threads.size() < _options.maxThreads);
diff --git a/src/mongo/util/concurrency/ticketholder.cpp b/src/mongo/util/concurrency/ticketholder.cpp
index a6abd154b2..a67311b5b8 100644
--- a/src/mongo/util/concurrency/ticketholder.cpp
+++ b/src/mongo/util/concurrency/ticketholder.cpp
@@ -35,6 +35,7 @@
 
 #include <iostream>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/str.h"
 
@@ -218,7 +219,7 @@ Status TicketHolder::resize(int newSize) {
            << "more than newSize(" << newSize << ")";
 
         std::string errmsg = ss.str();
-        log() << errmsg;
+        LOGV2("{}", "errmsg"_attr = errmsg);
         return Status(ErrorCodes::BadValue, errmsg);
     }
 
diff --git a/src/mongo/util/concurrency/with_lock_test.cpp b/src/mongo/util/concurrency/with_lock_test.cpp
index 5724f89947..45a41802fb 100644
--- a/src/mongo/util/concurrency/with_lock_test.cpp
+++ b/src/mongo/util/concurrency/with_lock_test.cpp
@@ -31,6 +31,7 @@
 
 #include "mongo/platform/basic.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/concurrency/with_lock.h"
@@ -63,7 +64,7 @@ private:
         return _blerp(lk, i);
     }
     int _blerp(WithLock, int i) {
-        log() << i << " bleep" << (i == 1 ? "\n" : "s\n");
+        LOGV2("{} bleep{}", "i"_attr = i, "i_1_n_s_n"_attr = (i == 1 ? "\n" : "s\n"));
         return i;
     }
     Mutex _m = MONGO_MAKE_LATCH("Beerp::_m");
diff --git a/src/mongo/util/diagnostic_info.cpp b/src/mongo/util/diagnostic_info.cpp
index c323dbfa52..3e9a88f966 100644
--- a/src/mongo/util/diagnostic_info.cpp
+++ b/src/mongo/util/diagnostic_info.cpp
@@ -40,6 +40,7 @@
 
 #include "mongo/base/init.h"
 #include "mongo/db/client.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/util/clock_source.h"
 #include "mongo/util/hierarchical_acquisition.h"
@@ -100,29 +101,29 @@ void BlockedOp::start(ServiceContext* serviceContext) {
     _latchState.thread = stdx::thread([this, serviceContext]() mutable {
         ThreadClient tc("DiagnosticCaptureTestLatch", serviceContext);
 
-        log() << "Entered currentOpSpawnsThreadWaitingForLatch thread";
+        LOGV2("Entered currentOpSpawnsThreadWaitingForLatch thread");
 
         stdx::lock_guard testLock(_latchState.mutex);
 
-        log() << "Joining currentOpSpawnsThreadWaitingForLatch thread";
+        LOGV2("Joining currentOpSpawnsThreadWaitingForLatch thread");
     });
 
     _interruptibleState.thread = stdx::thread([this, serviceContext]() mutable {
         ThreadClient tc("DiagnosticCaptureTestInterruptible", serviceContext);
         auto opCtx = tc->makeOperationContext();
 
-        log() << "Entered currentOpSpawnsThreadWaitingForLatch thread for interruptibles";
+        LOGV2("Entered currentOpSpawnsThreadWaitingForLatch thread for interruptibles");
         stdx::unique_lock lk(_interruptibleState.mutex);
         opCtx->waitForConditionOrInterrupt(
             _interruptibleState.cv, lk, [&] { return _interruptibleState.isDone; });
         _interruptibleState.isDone = false;
 
-        log() << "Joining currentOpSpawnsThreadWaitingForLatch thread for interruptibles";
+        LOGV2("Joining currentOpSpawnsThreadWaitingForLatch thread for interruptibles");
     });
 
 
     _cv.wait(lk, [this] { return _latchState.isContended && _interruptibleState.isWaiting; });
-    log() << "Started threads for currentOpSpawnsThreadWaitingForLatch";
+    LOGV2("Started threads for currentOpSpawnsThreadWaitingForLatch");
 }
 
 // This function unlocks testMutex and joins if there are no more callers of BlockedOp::start()
@@ -155,14 +156,14 @@ void BlockedOp::join() {
 }
 
 void BlockedOp::setIsContended(bool value) {
-    log() << "Setting isContended to " << (value ? "true" : "false");
+    LOGV2("Setting isContended to {}", "value_true_false"_attr = (value ? "true" : "false"));
     stdx::lock_guard lk(_m);
     _latchState.isContended = value;
     _cv.notify_one();
 }
 
 void BlockedOp::setIsWaiting(bool value) {
-    log() << "Setting isWaiting to " << (value ? "true" : "false");
+    LOGV2("Setting isWaiting to {}", "value_true_false"_attr = (value ? "true" : "false"));
     stdx::lock_guard lk(_m);
     _interruptibleState.isWaiting = value;
     _cv.notify_one();
diff --git a/src/mongo/util/duration.cpp b/src/mongo/util/duration.cpp
index b53e55b52a..44239275d4 100644
--- a/src/mongo/util/duration.cpp
+++ b/src/mongo/util/duration.cpp
@@ -31,130 +31,25 @@
 
 #include "mongo/util/duration.h"
 
-#include <iostream>
-
-#include "mongo/bson/util/builder.h"
+#include "mongo/bson/bsonobjbuilder.h"
 
 namespace mongo {
-namespace {
-template <typename Stream>
-Stream& streamPut(Stream& os, Nanoseconds ns) {
-    return os << ns.count() << "ns";
-}
-
-template <typename Stream>
-Stream& streamPut(Stream& os, Microseconds us) {
-    return os << us.count() << "\xce\xbcs";
-}
-
-template <typename Stream>
-Stream& streamPut(Stream& os, Milliseconds ms) {
-    return os << ms.count() << "ms";
-}
-
-template <typename Stream>
-Stream& streamPut(Stream& os, Seconds s) {
-    return os << s.count() << 's';
-}
-
-template <typename Stream>
-Stream& streamPut(Stream& os, Minutes min) {
-    return os << min.count() << "min";
-}
 
-template <typename Stream>
-Stream& streamPut(Stream& os, Hours hrs) {
-    return os << hrs.count() << "hr";
-}
-
-template <typename Stream>
-Stream& streamPut(Stream& os, Days days) {
-    return os << days.count() << "d";
-}
-
-}  // namespace
-
-std::ostream& operator<<(std::ostream& os, Nanoseconds ns) {
-    return streamPut(os, ns);
-}
-
-std::ostream& operator<<(std::ostream& os, Microseconds us) {
-    return streamPut(os, us);
-}
-
-std::ostream& operator<<(std::ostream& os, Milliseconds ms) {
-    return streamPut(os, ms);
-}
-std::ostream& operator<<(std::ostream& os, Seconds s) {
-    return streamPut(os, s);
+template <typename Period>
+BSONObj Duration<Period>::toBSON() const {
+    BSONObjBuilder builder;
+    builder.append("units", unit_short());
+    builder.append("value", count());
+    builder.done();
+    return builder.obj();
 }
 
-std::ostream& operator<<(std::ostream& os, Minutes m) {
-    return streamPut(os, m);
-}
-
-std::ostream& operator<<(std::ostream& os, Hours h) {
-    return streamPut(os, h);
-}
-
-std::ostream& operator<<(std::ostream& os, Days d) {
-    return streamPut(os, d);
-}
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Nanoseconds ns) {
-    return streamPut(os, ns);
-}
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Microseconds us) {
-    return streamPut(os, us);
-}
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Milliseconds ms) {
-    return streamPut(os, ms);
-}
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Seconds s) {
-    return streamPut(os, s);
-}
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Minutes m) {
-    return streamPut(os, m);
-}
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Hours h) {
-    return streamPut(os, h);
-}
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Days d) {
-    return streamPut(os, d);
-}
+template BSONObj Nanoseconds::toBSON() const;
+template BSONObj Microseconds::toBSON() const;
+template BSONObj Milliseconds::toBSON() const;
+template BSONObj Seconds::toBSON() const;
+template BSONObj Minutes::toBSON() const;
+template BSONObj Hours::toBSON() const;
+template BSONObj Days::toBSON() const;
 
-template StringBuilderImpl<StackAllocator>& operator<<(StringBuilderImpl<StackAllocator>&,
-                                                       Nanoseconds);
-template StringBuilderImpl<StackAllocator>& operator<<(StringBuilderImpl<StackAllocator>&,
-                                                       Microseconds);
-template StringBuilderImpl<StackAllocator>& operator<<(StringBuilderImpl<StackAllocator>&,
-                                                       Milliseconds);
-template StringBuilderImpl<StackAllocator>& operator<<(StringBuilderImpl<StackAllocator>&, Seconds);
-template StringBuilderImpl<StackAllocator>& operator<<(StringBuilderImpl<StackAllocator>&, Minutes);
-template StringBuilderImpl<StackAllocator>& operator<<(StringBuilderImpl<StackAllocator>&, Hours);
-template StringBuilderImpl<SharedBufferAllocator>& operator<<(
-    StringBuilderImpl<SharedBufferAllocator>&, Nanoseconds);
-template StringBuilderImpl<SharedBufferAllocator>& operator<<(
-    StringBuilderImpl<SharedBufferAllocator>&, Microseconds);
-template StringBuilderImpl<SharedBufferAllocator>& operator<<(
-    StringBuilderImpl<SharedBufferAllocator>&, Milliseconds);
-template StringBuilderImpl<SharedBufferAllocator>& operator<<(
-    StringBuilderImpl<SharedBufferAllocator>&, Seconds);
-template StringBuilderImpl<SharedBufferAllocator>& operator<<(
-    StringBuilderImpl<SharedBufferAllocator>&, Minutes);
-template StringBuilderImpl<SharedBufferAllocator>& operator<<(
-    StringBuilderImpl<SharedBufferAllocator>&, Hours);
 }  // namespace mongo
diff --git a/src/mongo/util/duration.h b/src/mongo/util/duration.h
index 65cfc59ae1..aeed4cbb35 100644
--- a/src/mongo/util/duration.h
+++ b/src/mongo/util/duration.h
@@ -30,6 +30,7 @@
 #pragma once
 
 #include <cstdint>
+#include <fmt/format.h>
 #include <iosfwd>
 #include <limits>
 #include <ratio>
@@ -43,6 +44,8 @@
 
 namespace mongo {
 
+class BSONObj;
+
 template <typename Allocator>
 class StringBuilderImpl;
 
@@ -65,36 +68,6 @@ using Days = Duration<std::ratio<86400>>;
 // 5min
 //
 
-std::ostream& operator<<(std::ostream& os, Nanoseconds ns);
-std::ostream& operator<<(std::ostream& os, Microseconds us);
-std::ostream& operator<<(std::ostream& os, Milliseconds ms);
-std::ostream& operator<<(std::ostream& os, Seconds s);
-std::ostream& operator<<(std::ostream& os, Minutes m);
-std::ostream& operator<<(std::ostream& os, Hours h);
-std::ostream& operator<<(std::ostream& os, Days h);
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Nanoseconds ns);
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Microseconds us);
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Milliseconds ms);
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Seconds s);
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Minutes m);
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Hours h);
-
-template <typename Allocator>
-StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Days h);
-
-
 template <typename Duration1, typename Duration2>
 using HigherPrecisionDuration =
     typename std::conditional<!Duration1::template IsLowerPrecisionThan<Duration2>::value,
@@ -155,6 +128,24 @@ inline long long durationCount(const stdx::chrono::duration<RepIn, PeriodIn>& d)
 template <typename Period>
 class Duration {
 public:
+    static constexpr StringData unit_short() {
+        if constexpr (std::is_same_v<Duration, Nanoseconds>) {
+            return "ns"_sd;
+        } else if constexpr (std::is_same_v<Duration, Microseconds>) {
+            return "\xce\xbcs"_sd;
+        } else if constexpr (std::is_same_v<Duration, Milliseconds>) {
+            return "ms"_sd;
+        } else if constexpr (std::is_same_v<Duration, Seconds>) {
+            return "s"_sd;
+        } else if constexpr (std::is_same_v<Duration, Minutes>) {
+            return "min"_sd;
+        } else if constexpr (std::is_same_v<Duration, Hours>) {
+            return "hr"_sd;
+        } else if constexpr (std::is_same_v<Duration, Days>) {
+            return "d"_sd;
+        }
+        return StringData{};
+    }
     MONGO_STATIC_ASSERT_MSG(Period::num > 0, "Duration::period's numerator must be positive");
     MONGO_STATIC_ASSERT_MSG(Period::den > 0, "Duration::period's denominator must be positive");
 
@@ -367,6 +358,13 @@ public:
         return *this;
     }
 
+    BSONObj toBSON() const;
+
+    std::string toString() const {
+        return fmt::format("{} {}", count(), unit_short());
+    }
+
+
 private:
     rep _count = {};
 };
@@ -451,4 +449,22 @@ Duration<Period> operator/(Duration<Period> d, const Rep2& scale) {
     return d;
 }
 
+template <typename Stream, typename Period>
+Stream& streamPut(Stream& os, const Duration<Period>& dp) {
+    MONGO_STATIC_ASSERT_MSG(!Duration<Period>::unit_short().empty(), "Only normal Durations can logged");
+    return os << dp.count() << dp.unit_short();
+}
+
+template <typename Period>
+std::ostream& operator<<(std::ostream& os, Duration<Period> dp) {
+    MONGO_STATIC_ASSERT_MSG(!Duration<Period>::unit_short().empty(), "Only normal Durations can logged");
+    return streamPut(os, dp);
+}
+
+template <typename Allocator, typename Period>
+StringBuilderImpl<Allocator>& operator<<(StringBuilderImpl<Allocator>& os, Duration<Period> dp) {
+    MONGO_STATIC_ASSERT_MSG(!Duration<Period>::unit_short().empty(), "Only normal Durations can logged");
+    return streamPut(os, dp);
+}
+
 }  // namespace mongo
diff --git a/src/mongo/util/exception_filter_win32.cpp b/src/mongo/util/exception_filter_win32.cpp
index bda23d4e12..c3273e87cf 100644
--- a/src/mongo/util/exception_filter_win32.cpp
+++ b/src/mongo/util/exception_filter_win32.cpp
@@ -42,6 +42,7 @@
 #include <ostream>
 
 #include "mongo/config.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/exit_code.h"
 #include "mongo/util/log.h"
@@ -63,7 +64,7 @@ void doMinidumpWithException(struct _EXCEPTION_POINTERS* exceptionInfo) {
     DWORD ret = GetModuleFileNameW(nullptr, &moduleFileName[0], ARRAYSIZE(moduleFileName));
     if (ret == 0) {
         int gle = GetLastError();
-        log() << "GetModuleFileName failed " << errnoWithDescription(gle);
+        LOGV2("GetModuleFileName failed {}", "errnoWithDescription_gle"_attr = errnoWithDescription(gle));
 
         // Fallback name
         wcscpy_s(moduleFileName, L"mongo");
@@ -88,8 +89,7 @@ void doMinidumpWithException(struct _EXCEPTION_POINTERS* exceptionInfo) {
         dumpName.c_str(), GENERIC_WRITE, 0, nullptr, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, nullptr);
     if (INVALID_HANDLE_VALUE == hFile) {
         DWORD lasterr = GetLastError();
-        log() << "failed to open minidump file " << toUtf8String(dumpName.c_str()) << " : "
-              << errnoWithDescription(lasterr);
+        LOGV2("failed to open minidump file {} : {}", "toUtf8String_dumpName_c_str"_attr = toUtf8String(dumpName.c_str()), "errnoWithDescription_lasterr"_attr = errnoWithDescription(lasterr));
         return;
     }
 
@@ -105,7 +105,7 @@ void doMinidumpWithException(struct _EXCEPTION_POINTERS* exceptionInfo) {
         static_cast<MINIDUMP_TYPE>(MiniDumpNormal | MiniDumpWithIndirectlyReferencedMemory |
                                    MiniDumpWithProcessThreadData);
 #endif
-    log() << "writing minidump diagnostic file " << toUtf8String(dumpName.c_str());
+    LOGV2("writing minidump diagnostic file {}", "toUtf8String_dumpName_c_str"_attr = toUtf8String(dumpName.c_str()));
 
     BOOL bstatus = MiniDumpWriteDump(GetCurrentProcess(),
                                      GetCurrentProcessId(),
@@ -116,7 +116,7 @@ void doMinidumpWithException(struct _EXCEPTION_POINTERS* exceptionInfo) {
                                      nullptr);
     if (FALSE == bstatus) {
         DWORD lasterr = GetLastError();
-        log() << "failed to create minidump : " << errnoWithDescription(lasterr);
+        LOGV2("failed to create minidump : {}", "errnoWithDescription_lasterr"_attr = errnoWithDescription(lasterr));
     }
 
     CloseHandle(hFile);
diff --git a/src/mongo/util/exit.cpp b/src/mongo/util/exit.cpp
index 66af99151f..079fbf5ca2 100644
--- a/src/mongo/util/exit.cpp
+++ b/src/mongo/util/exit.cpp
@@ -37,6 +37,7 @@
 #include <functional>
 #include <stack>
 
+#include "mongo/logv2/log.h"
 #include "mongo/platform/mutex.h"
 #include "mongo/stdx/condition_variable.h"
 #include "mongo/stdx/thread.h"
@@ -68,7 +69,7 @@ void runTasks(decltype(shutdownTasks) tasks, const ShutdownTaskArgs& shutdownArg
 // has its own 'quickExitMutex' to prohibit multiple threads from attempting to call _exit().
 MONGO_COMPILER_NORETURN void logAndQuickExit_inlock() {
     ExitCode code = shutdownExitCode.get();
-    log() << "shutting down with code:" << code;
+    LOGV2("shutting down with code:{}", "code"_attr = (int)code);
     quickExit(code);
 }
 
diff --git a/src/mongo/util/file.cpp b/src/mongo/util/file.cpp
index b3c85b4c34..18b5ba6ba8 100644
--- a/src/mongo/util/file.cpp
+++ b/src/mongo/util/file.cpp
@@ -43,6 +43,7 @@
 #include <sys/types.h>
 #endif
 
+#include "mongo/logv2/log.h"
 #include "mongo/platform/basic.h"
 #include "mongo/util/allocator.h"
 #include "mongo/util/assert_util.h"
@@ -72,16 +73,14 @@ intmax_t File::freeSpace(const std::string& path) {
         return avail.QuadPart;
     }
     DWORD dosError = GetLastError();
-    log() << "In File::freeSpace(), GetDiskFreeSpaceEx for '" << path << "' failed with "
-          << errnoWithDescription(dosError);
+    LOGV2("In File::freeSpace(), GetDiskFreeSpaceEx for '{}' failed with {}", "path"_attr = path, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
     return -1;
 }
 
 void File::fsync() const {
     if (FlushFileBuffers(_handle) == 0) {
         DWORD dosError = GetLastError();
-        log() << "In File::fsync(), FlushFileBuffers for '" << _name << "' failed with "
-              << errnoWithDescription(dosError);
+        LOGV2("In File::fsync(), FlushFileBuffers for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
     }
 }
 
@@ -96,8 +95,7 @@ fileofs File::len() {
     }
     _bad = true;
     DWORD dosError = GetLastError();
-    log() << "In File::len(), GetFileSizeEx for '" << _name << "' failed with "
-          << errnoWithDescription(dosError);
+    LOGV2("In File::len(), GetFileSizeEx for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
     return 0;
 }
 
@@ -113,8 +111,7 @@ void File::open(const char* filename, bool readOnly, bool direct) {
     _bad = !is_open();
     if (_bad) {
         DWORD dosError = GetLastError();
-        log() << "In File::open(), CreateFileW for '" << _name << "' failed with "
-              << errnoWithDescription(dosError);
+        LOGV2("In File::open(), CreateFileW for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
     }
 }
 
@@ -124,17 +121,14 @@ void File::read(fileofs o, char* data, unsigned len) {
     if (SetFilePointerEx(_handle, li, nullptr, FILE_BEGIN) == 0) {
         _bad = true;
         DWORD dosError = GetLastError();
-        log() << "In File::read(), SetFilePointerEx for '" << _name
-              << "' tried to set the file pointer to " << o << " but failed with "
-              << errnoWithDescription(dosError);
+        LOGV2("In File::read(), SetFilePointerEx for '{}' tried to set the file pointer to {} but failed with {}", "_name"_attr = _name, "o"_attr = o, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
         return;
     }
     DWORD bytesRead;
     if (!ReadFile(_handle, data, len, &bytesRead, 0)) {
         _bad = true;
         DWORD dosError = GetLastError();
-        log() << "In File::read(), ReadFile for '" << _name << "' failed with "
-              << errnoWithDescription(dosError);
+        LOGV2("In File::read(), ReadFile for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
     } else if (bytesRead != len) {
         _bad = true;
         msgasserted(10438,
@@ -153,16 +147,13 @@ void File::truncate(fileofs size) {
     if (SetFilePointerEx(_handle, li, nullptr, FILE_BEGIN) == 0) {
         _bad = true;
         DWORD dosError = GetLastError();
-        log() << "In File::truncate(), SetFilePointerEx for '" << _name
-              << "' tried to set the file pointer to " << size << " but failed with "
-              << errnoWithDescription(dosError);
+        LOGV2("In File::truncate(), SetFilePointerEx for '{}' tried to set the file pointer to {} but failed with {}", "_name"_attr = _name, "size"_attr = size, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
         return;
     }
     if (SetEndOfFile(_handle) == 0) {
         _bad = true;
         DWORD dosError = GetLastError();
-        log() << "In File::truncate(), SetEndOfFile for '" << _name << "' failed with "
-              << errnoWithDescription(dosError);
+        LOGV2("In File::truncate(), SetEndOfFile for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
     }
 }
 
@@ -172,18 +163,14 @@ void File::write(fileofs o, const char* data, unsigned len) {
     if (SetFilePointerEx(_handle, li, nullptr, FILE_BEGIN) == 0) {
         _bad = true;
         DWORD dosError = GetLastError();
-        log() << "In File::write(), SetFilePointerEx for '" << _name
-              << "' tried to set the file pointer to " << o << " but failed with "
-              << errnoWithDescription(dosError) << std::endl;
+        LOGV2("In File::write(), SetFilePointerEx for '{}' tried to set the file pointer to {} but failed with {}", "_name"_attr = _name, "o"_attr = o, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
         return;
     }
     DWORD bytesWritten;
     if (WriteFile(_handle, data, len, &bytesWritten, nullptr) == 0) {
         _bad = true;
         DWORD dosError = GetLastError();
-        log() << "In File::write(), WriteFile for '" << _name << "' tried to write " << len
-              << " bytes but only wrote " << bytesWritten << " bytes, failing with "
-              << errnoWithDescription(dosError);
+        LOGV2("In File::write(), WriteFile for '{}' tried to write {} bytes but only wrote {} bytes, failing with {}", "_name"_attr = _name, "len"_attr = len, "bytesWritten"_attr = bytesWritten, "errnoWithDescription_dosError"_attr = errnoWithDescription(dosError));
     }
 }
 
@@ -203,15 +190,13 @@ intmax_t File::freeSpace(const std::string& path) {
     if (statvfs(path.c_str(), &info) == 0) {
         return static_cast<intmax_t>(info.f_bavail) * info.f_frsize;
     }
-    log() << "In File::freeSpace(), statvfs for '" << path << "' failed with "
-          << errnoWithDescription();
+    LOGV2("In File::freeSpace(), statvfs for '{}' failed with {}", "path"_attr = path, "errnoWithDescription"_attr = errnoWithDescription());
     return -1;
 }
 
 void File::fsync() const {
     if (::fsync(_fd)) {
-        log() << "In File::fsync(), ::fsync for '" << _name << "' failed with "
-              << errnoWithDescription();
+        LOGV2("In File::fsync(), ::fsync for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription"_attr = errnoWithDescription());
     }
 }
 
@@ -225,7 +210,7 @@ fileofs File::len() {
         return o;
     }
     _bad = true;
-    log() << "In File::len(), lseek for '" << _name << "' failed with " << errnoWithDescription();
+    LOGV2("In File::len(), lseek for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription"_attr = errnoWithDescription());
     return 0;
 }
 
@@ -244,8 +229,7 @@ void File::open(const char* filename, bool readOnly, bool direct) {
                  S_IRUSR | S_IWUSR);
     _bad = !is_open();
     if (_bad) {
-        log() << "In File::open(), ::open for '" << _name << "' failed with "
-              << errnoWithDescription();
+        LOGV2("In File::open(), ::open for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription"_attr = errnoWithDescription());
     }
 }
 
@@ -253,8 +237,7 @@ void File::read(fileofs o, char* data, unsigned len) {
     ssize_t bytesRead = ::pread(_fd, data, len, o);
     if (bytesRead == -1) {
         _bad = true;
-        log() << "In File::read(), ::pread for '" << _name << "' failed with "
-              << errnoWithDescription();
+        LOGV2("In File::read(), ::pread for '{}' failed with {}", "_name"_attr = _name, "errnoWithDescription"_attr = errnoWithDescription());
     } else if (bytesRead != static_cast<ssize_t>(len)) {
         _bad = true;
         msgasserted(16569,
@@ -270,9 +253,7 @@ void File::truncate(fileofs size) {
     }
     if (ftruncate(_fd, size) != 0) {
         _bad = true;
-        log() << "In File::truncate(), ftruncate for '" << _name
-              << "' tried to set the file pointer to " << size << " but failed with "
-              << errnoWithDescription() << std::endl;
+        LOGV2("In File::truncate(), ftruncate for '{}' tried to set the file pointer to {} but failed with {}", "_name"_attr = _name, "size"_attr = size, "errnoWithDescription"_attr = errnoWithDescription());
         return;
     }
 }
@@ -281,9 +262,7 @@ void File::write(fileofs o, const char* data, unsigned len) {
     ssize_t bytesWritten = ::pwrite(_fd, data, len, o);
     if (bytesWritten != static_cast<ssize_t>(len)) {
         _bad = true;
-        log() << "In File::write(), ::pwrite for '" << _name << "' tried to write " << len
-              << " bytes but only wrote " << bytesWritten << " bytes, failing with "
-              << errnoWithDescription();
+        LOGV2("In File::write(), ::pwrite for '{}' tried to write {} bytes but only wrote {} bytes, failing with {}", "_name"_attr = _name, "len"_attr = len, "bytesWritten"_attr = bytesWritten, "errnoWithDescription"_attr = errnoWithDescription());
     }
 }
 
diff --git a/src/mongo/util/heap_profiler.cpp b/src/mongo/util/heap_profiler.cpp
index 2784eac8cf..e60d4fd65e 100644
--- a/src/mongo/util/heap_profiler.cpp
+++ b/src/mongo/util/heap_profiler.cpp
@@ -35,6 +35,7 @@
 #include "mongo/base/static_assert.h"
 #include "mongo/config.h"
 #include "mongo/db/commands/server_status.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/stacktrace.h"
 #include "mongo/util/tcmalloc_parameters_gen.h"
@@ -382,7 +383,7 @@ private:
     // disable profiling and then log an error message.
     void disable(const char* msg) {
         sampleIntervalBytes = 0;
-        log() << msg;
+        LOGV2("{}", "msg"_attr = msg);
     }
 
     //
@@ -506,7 +507,7 @@ private:
                 free(demangled);
         }
         stackInfo.stackObj = builder.obj();
-        log() << "heapProfile stack" << stackInfo.stackNum << ": " << stackInfo.stackObj;
+        LOGV2("heapProfile stack{}: {}", "stackInfo_stackNum"_attr = stackInfo.stackNum, "stackInfo_stackObj"_attr = stackInfo.stackObj);
     }
 
     //
@@ -537,7 +538,7 @@ private:
                   << "objTableSize " << objTableSize / MB << " MB; "
                   << "stackTableSize " << stackTableSize / MB << " MB";
             // print a stack trace to log somap for post-facto symbolization
-            log() << "following stack trace is for heap profiler informational purposes";
+            LOGV2("following stack trace is for heap profiler informational purposes");
             printStackTrace();
             logGeneralStats = false;
         }
@@ -597,7 +598,7 @@ private:
         // importantStacks grows monotonically, so it can accumulate unneeded stacks,
         // so we clear it periodically.
         if (++numImportantSamples >= kMaxImportantSamples) {
-            log() << "clearing importantStacks";
+            LOGV2("clearing importantStacks");
             importantStacks.clear();
             numImportantSamples = 0;
         }
diff --git a/src/mongo/util/log.cpp b/src/mongo/util/log.cpp
index 43f32c76be..3f4fbfbd71 100644
--- a/src/mongo/util/log.cpp
+++ b/src/mongo/util/log.cpp
@@ -41,6 +41,7 @@
 #include "mongo/logger/message_event_utf8_encoder.h"
 #include "mongo/logger/ramlog.h"
 #include "mongo/logger/rotatable_file_manager.h"
+#include "mongo/logv2/log.h"
 #include "mongo/logv2/log_domain.h"
 #include "mongo/logv2/log_domain_global.h"
 #include "mongo/logv2/log_manager.h"
@@ -84,12 +85,12 @@ Status logger::registerExtraLogContextFn(logger::ExtraLogContextFn contextFn) {
 
 bool rotateLogs(bool renameFiles, bool useLogV2) {
     if (useLogV2) {
-        log() << "Logv2 rotation initiated";
+        LOGV2("Logv2 rotation initiated");
         return logv2::LogManager::global().getGlobalDomainInternal().rotate().isOK();
     }
     using logger::RotatableFileManager;
     RotatableFileManager* manager = logger::globalRotatableFileManager();
-    log() << "Log rotation initiated";
+    LOGV2("Log rotation initiated");
     RotatableFileManager::FileNameStatusPairVector result(
         manager->rotateAll(renameFiles, "." + terseCurrentTime(false)));
     for (RotatableFileManager::FileNameStatusPairVector::iterator it = result.begin();
@@ -102,7 +103,7 @@ bool rotateLogs(bool renameFiles, bool useLogV2) {
 
 void logContext(const char* errmsg) {
     if (errmsg) {
-        log() << errmsg << std::endl;
+        LOGV2("{}", "errmsg"_attr = errmsg);
     }
     // NOTE: We disable long-line truncation for the stack trace, because the JSON representation of
     // the stack trace can sometimes exceed the long line limit.
diff --git a/src/mongo/util/lru_cache_test.cpp b/src/mongo/util/lru_cache_test.cpp
index b88e4297e4..96d239815d 100644
--- a/src/mongo/util/lru_cache_test.cpp
+++ b/src/mongo/util/lru_cache_test.cpp
@@ -33,6 +33,7 @@
 #include <type_traits>
 #include <utility>
 
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/type_traits.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/assert_util.h"
@@ -144,7 +145,7 @@ const std::array<int, 7> kTestSizes{1, 2, 3, 4, 5, 10, 1000};
 using SizedTest = std::function<void(int)>;
 void runWithDifferentSizes(SizedTest test) {
     for (auto size : kTestSizes) {
-        mongo::unittest::log() << "\t\tTesting cache size of " << size;
+        mongo::unittest::LOGV2("\t\tTesting cache size of {}", "size"_attr = size);
         test(size);
     }
 }
diff --git a/src/mongo/util/net/hostname_canonicalization.cpp b/src/mongo/util/net/hostname_canonicalization.cpp
index e371091289..5477dd8f9d 100644
--- a/src/mongo/util/net/hostname_canonicalization.cpp
+++ b/src/mongo/util/net/hostname_canonicalization.cpp
@@ -41,6 +41,7 @@
 #include <sys/types.h>
 #endif
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/sockaddr.h"
 #include "mongo/util/scopeguard.h"
@@ -90,8 +91,7 @@ std::vector<std::string> getHostFQDNs(std::string hostName, HostnameCanonicaliza
     int err;
     auto nativeHostName = shim_toNativeString(hostName.c_str());
     if ((err = shim_getaddrinfo(nativeHostName.c_str(), nullptr, &hints, &info)) != 0) {
-        LOG(3) << "Failed to obtain address information for hostname " << hostName << ": "
-               << getAddrInfoStrError(err);
+        LOGV2_DEBUG(3, "Failed to obtain address information for hostname {}: {}", "hostName"_attr = hostName, "getAddrInfoStrError_err"_attr = getAddrInfoStrError(err));
         return results;
     }
     const auto guard = makeGuard(shim_freeaddrinfo);
@@ -141,7 +141,7 @@ std::vector<std::string> getHostFQDNs(std::string hostName, HostnameCanonicaliza
     }
 
     if (encounteredErrors) {
-        LOG(3) << getNameInfoErrors.str() << " ]";
+        LOGV2_DEBUG(3, "{} ]", "getNameInfoErrors_str"_attr = getNameInfoErrors.str());
     }
 
     // Deduplicate the results list
diff --git a/src/mongo/util/net/openssl_init.cpp b/src/mongo/util/net/openssl_init.cpp
index 8f05d3c877..f0a9ca6934 100644
--- a/src/mongo/util/net/openssl_init.cpp
+++ b/src/mongo/util/net/openssl_init.cpp
@@ -33,6 +33,7 @@
 
 #include "mongo/base/init.h"
 #include "mongo/config.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/net/ssl_manager.h"
 #include "mongo/util/net/ssl_options.h"
@@ -152,7 +153,7 @@ void setupFIPS() {
                  << SSLManagerInterface::getSSLErrorMessage(ERR_get_error());
         fassertFailedNoTrace(16703);
     }
-    log() << "FIPS 140-2 mode activated";
+    LOGV2("FIPS 140-2 mode activated");
 #else
     severe() << "this version of mongodb was not compiled with FIPS support";
     fassertFailedNoTrace(17089);
diff --git a/src/mongo/util/net/sock.cpp b/src/mongo/util/net/sock.cpp
index 02e08eb7af..c414d8294e 100644
--- a/src/mongo/util/net/sock.cpp
+++ b/src/mongo/util/net/sock.cpp
@@ -57,6 +57,7 @@
 
 #include "mongo/config.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/background.h"
 #include "mongo/util/concurrency/value.h"
 #include "mongo/util/debug_util.h"
@@ -116,21 +117,21 @@ void setSockTimeouts(int sock, double secs) {
     int status =
         setsockopt(sock, SOL_SOCKET, SO_RCVTIMEO, reinterpret_cast<char*>(&timeout), sizeof(DWORD));
     if (report && (status == SOCKET_ERROR))
-        log() << "unable to set SO_RCVTIMEO: " << errnoWithDescription(WSAGetLastError());
+        LOGV2("unable to set SO_RCVTIMEO: {}", "errnoWithDescription_WSAGetLastError"_attr = errnoWithDescription(WSAGetLastError()));
     status =
         setsockopt(sock, SOL_SOCKET, SO_SNDTIMEO, reinterpret_cast<char*>(&timeout), sizeof(DWORD));
     if (kDebugBuild && report && (status == SOCKET_ERROR))
-        log() << "unable to set SO_SNDTIMEO: " << errnoWithDescription(WSAGetLastError());
+        LOGV2("unable to set SO_SNDTIMEO: {}", "errnoWithDescription_WSAGetLastError"_attr = errnoWithDescription(WSAGetLastError()));
 #else
     struct timeval tv;
     tv.tv_sec = (int)secs;
     tv.tv_usec = (int)((long long)(secs * 1000 * 1000) % (1000 * 1000));
     bool ok = setsockopt(sock, SOL_SOCKET, SO_RCVTIMEO, (char*)&tv, sizeof(tv)) == 0;
     if (report && !ok)
-        log() << "unable to set SO_RCVTIMEO";
+        LOGV2("unable to set SO_RCVTIMEO");
     ok = setsockopt(sock, SOL_SOCKET, SO_SNDTIMEO, (char*)&tv, sizeof(tv)) == 0;
     if (kDebugBuild && report && !ok)
-        log() << "unable to set SO_SNDTIMEO";
+        LOGV2("unable to set SO_SNDTIMEO");
 #endif
 }
 
@@ -537,18 +538,17 @@ void Socket::handleSendError(int ret, const char* context) {
     const int mongo_errno = errno;
     if ((mongo_errno == EAGAIN || mongo_errno == EWOULDBLOCK) && _timeout != 0) {
 #endif
-        LOG(_logLevel) << "Socket " << context << " send() timed out " << remoteString();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "Socket {} send() timed out {}", "context"_attr = context, "remoteString"_attr = remoteString());
         throwSocketError(SocketErrorKind::SEND_TIMEOUT, remoteString());
     } else if (mongo_errno != EINTR) {
-        LOG(_logLevel) << "Socket " << context << " send() " << errnoWithDescription(mongo_errno)
-                       << ' ' << remoteString();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "Socket {} send() {} {}", "context"_attr = context, "errnoWithDescription_mongo_errno"_attr = errnoWithDescription(mongo_errno), "remoteString"_attr = remoteString());
         throwSocketError(SocketErrorKind::SEND_ERROR, remoteString());
     }
 }  // namespace mongo
 
 void Socket::handleRecvError(int ret, int len) {
     if (ret == 0) {
-        LOG(3) << "Socket recv() conn closed? " << remoteString();
+        LOGV2_DEBUG(3, "Socket recv() conn closed? {}", "remoteString"_attr = remoteString());
         throwSocketError(SocketErrorKind::CLOSED, remoteString());
     }
 
@@ -571,11 +571,11 @@ void Socket::handleRecvError(int ret, int len) {
     if (e == EAGAIN && _timeout > 0) {
 #endif
         // this is a timeout
-        LOG(_logLevel) << "Socket recv() timeout  " << remoteString();
+        LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "Socket recv() timeout  {}", "remoteString"_attr = remoteString());
         throwSocketError(SocketErrorKind::RECV_TIMEOUT, remoteString());
     }
 
-    LOG(_logLevel) << "Socket recv() " << errnoWithDescription(e) << " " << remoteString();
+    LOGV2_DEBUG(::mongo::logger::LogSeverity(_logLevel).toInt(), "Socket recv() {} {}", "errnoWithDescription_e"_attr = errnoWithDescription(e), "remoteString"_attr = remoteString());
     throwSocketError(SocketErrorKind::RECV_ERROR, remoteString());
 }
 
@@ -628,8 +628,7 @@ bool Socket::isStillConnected() {
     // Poll( info[], size, timeout ) - timeout == 0 => nonblocking
     int nEvents = socketPoll(&pollInfo, 1, 0);
 
-    LOG(2) << "polling for status of connection to " << remoteString() << ", "
-           << (nEvents == 0 ? "no events" : nEvents == -1 ? "error detected" : "event detected");
+    LOGV2_DEBUG(2, "polling for status of connection to {}, {}", "remoteString"_attr = remoteString(), "nEvents_0_no_events_nEvents_1_error_detected_event_detected"_attr = (nEvents == 0 ? "no events" : nEvents == -1 ? "error detected" : "event detected"));
 
     if (nEvents == 0) {
         // No events incoming, return still connected AFAWK
@@ -680,20 +679,14 @@ bool Socket::isStillConnected() {
             dassert(false);
         } else {
             // recvd == 0, socket closed remotely, just return false
-            LOG(0) << "Socket closed remotely, no longer connected"
-                   << " (idle " << idleTimeSecs << " secs,"
-                   << " remote host " << remoteString() << ")";
+            LOGV2("Socket closed remotely, no longer connected (idle {} secs, remote host {})", "idleTimeSecs"_attr = idleTimeSecs, "remoteString"_attr = remoteString());
         }
     } else if (pollInfo.revents & POLLHUP) {
         // A hangup has occurred on this socket
-        LOG(0) << "Socket hangup detected, no longer connected"
-               << " (idle " << idleTimeSecs << " secs,"
-               << " remote host " << remoteString() << ")";
+        LOGV2("Socket hangup detected, no longer connected (idle {} secs, remote host {})", "idleTimeSecs"_attr = idleTimeSecs, "remoteString"_attr = remoteString());
     } else if (pollInfo.revents & POLLERR) {
         // An error has occurred on this socket
-        LOG(0) << "Socket error detected, no longer connected"
-               << " (idle " << idleTimeSecs << " secs,"
-               << " remote host " << remoteString() << ")";
+        LOGV2("Socket error detected, no longer connected (idle {} secs, remote host {})", "idleTimeSecs"_attr = idleTimeSecs, "remoteString"_attr = remoteString());
     } else if (pollInfo.revents & POLLNVAL) {
         // Socket descriptor itself is weird
         // Log and warn at runtime, log and abort at devtime
diff --git a/src/mongo/util/net/sockaddr.cpp b/src/mongo/util/net/sockaddr.cpp
index ed4135d1eb..4b42572d03 100644
--- a/src/mongo/util/net/sockaddr.cpp
+++ b/src/mongo/util/net/sockaddr.cpp
@@ -54,6 +54,7 @@
 #endif
 
 #include "mongo/bson/util/builder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/itoa.h"
 #include "mongo/util/log.h"
 
@@ -157,8 +158,7 @@ SockAddr::SockAddr(StringData target, int port, sa_family_t familyHint)
         // we were unsuccessful
         if (_hostOrIp != "0.0.0.0") {  // don't log if this as it is a
                                        // CRT construction and log() may not work yet.
-            log() << "getaddrinfo(\"" << _hostOrIp
-                  << "\") failed: " << getAddrInfoStrError(addrErr.err);
+            LOGV2("getaddrinfo(\"{}\") failed: {}", "_hostOrIp"_attr = _hostOrIp, "getAddrInfoStrError_addrErr_err"_attr = getAddrInfoStrError(addrErr.err));
             _isValid = false;
             return;
         }
@@ -187,7 +187,7 @@ std::vector<SockAddr> SockAddr::createAll(StringData target, int port, sa_family
 
     auto addrErr = resolveAddrInfo(hostOrIp, port, familyHint);
     if (addrErr.err) {
-        log() << "getaddrinfo(\"" << hostOrIp << "\") failed: " << getAddrInfoStrError(addrErr.err);
+        LOGV2("getaddrinfo(\"{}\") failed: {}", "hostOrIp"_attr = hostOrIp, "getAddrInfoStrError_addrErr_err"_attr = getAddrInfoStrError(addrErr.err));
         return {};
     }
 
diff --git a/src/mongo/util/net/socket_utils.cpp b/src/mongo/util/net/socket_utils.cpp
index f58ff484ec..29ca75e310 100644
--- a/src/mongo/util/net/socket_utils.cpp
+++ b/src/mongo/util/net/socket_utils.cpp
@@ -54,6 +54,7 @@
 #endif
 
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/concurrency/value.h"
 #include "mongo/util/errno_util.h"
 #include "mongo/util/log.h"
@@ -69,7 +70,7 @@ const struct WinsockInit {
     WinsockInit() {
         WSADATA d;
         if (WSAStartup(MAKEWORD(2, 2), &d) != 0) {
-            log() << "ERROR: wsastartup failed " << errnoWithDescription();
+            LOGV2("ERROR: wsastartup failed {}", "errnoWithDescription"_attr = errnoWithDescription());
             quickExit(EXIT_NTSERVICE_ERROR);
         }
     }
@@ -196,7 +197,7 @@ std::string getHostName() {
     char buf[256];
     int ec = gethostname(buf, 127);
     if (ec || *buf == 0) {
-        log() << "can't get this server's hostname " << errnoWithDescription();
+        LOGV2("can't get this server's hostname {}", "errnoWithDescription"_attr = errnoWithDescription());
         return "";
     }
     return buf;
diff --git a/src/mongo/util/net/ssl_manager.cpp b/src/mongo/util/net/ssl_manager.cpp
index 6831d4c9da..18228a8e89 100644
--- a/src/mongo/util/net/ssl_manager.cpp
+++ b/src/mongo/util/net/ssl_manager.cpp
@@ -42,6 +42,7 @@
 #include "mongo/bson/bsonobjbuilder.h"
 #include "mongo/config.h"
 #include "mongo/db/commands/server_status.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/overflow_arithmetic.h"
 #include "mongo/transport/session.h"
 #include "mongo/util/hex.h"
@@ -553,11 +554,11 @@ MONGO_INITIALIZER_WITH_PREREQUISITES(SSLManagerLogger, ("SSLManager", "GlobalLog
     if (!isSSLServer || (sslGlobalParams.sslMode.load() != SSLParams::SSLMode_disabled)) {
         const auto& config = theSSLManager->getSSLConfiguration();
         if (!config.clientSubjectName.empty()) {
-            LOG(1) << "Client Certificate Name: " << config.clientSubjectName;
+            LOGV2_DEBUG(1, "Client Certificate Name: {}", "config_clientSubjectName"_attr = config.clientSubjectName);
         }
         if (!config.serverSubjectName().empty()) {
-            LOG(1) << "Server Certificate Name: " << config.serverSubjectName();
-            LOG(1) << "Server Certificate Expiration: " << config.serverCertificateExpirationDate;
+            LOGV2_DEBUG(1, "Server Certificate Name: {}", "config_serverSubjectName"_attr = config.serverSubjectName());
+            LOGV2_DEBUG(1, "Server Certificate Expiration: {}", "config_serverCertificateExpirationDate"_attr = config.serverCertificateExpirationDate);
         }
     }
 
@@ -594,8 +595,7 @@ Status SSLX509Name::normalizeStrings() {
                     break;
                 }
                 default:
-                    LOG(1) << "Certificate subject name contains unknown string type: "
-                           << entry.type << " (string value is \"" << entry.value << "\")";
+                    LOGV2_DEBUG(1, "Certificate subject name contains unknown string type: {} (string value is \"{}\")", "entry_type"_attr = entry.type, "entry_value"_attr = entry.value);
                     break;
             }
         }
@@ -1112,8 +1112,7 @@ void recordTLSVersion(TLSVersion version, const HostAndPort& hostForLogging) {
     }
 
     if (!versionString.empty()) {
-        log() << "Accepted connection with TLS Version " << versionString << " from connection "
-              << hostForLogging;
+        LOGV2("Accepted connection with TLS Version {} from connection {}", "versionString"_attr = versionString, "hostForLogging"_attr = hostForLogging);
     }
 }
 
diff --git a/src/mongo/util/net/ssl_manager_apple.cpp b/src/mongo/util/net/ssl_manager_apple.cpp
index 99fc341ca3..6eac53e70f 100644
--- a/src/mongo/util/net/ssl_manager_apple.cpp
+++ b/src/mongo/util/net/ssl_manager_apple.cpp
@@ -43,6 +43,7 @@
 #include "mongo/base/status_with.h"
 #include "mongo/crypto/sha1_block.h"
 #include "mongo/crypto/sha256_block.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/random.h"
 #include "mongo/util/base64.h"
 #include "mongo/util/concurrency/mutex.h"
@@ -1539,7 +1540,7 @@ StatusWith<SSLPeerInfo> SSLManagerApple::parseAndValidatePeerCertificate(
         return swPeerSubjectName.getStatus();
     }
     const auto peerSubjectName = std::move(swPeerSubjectName.getValue());
-    LOG(2) << "Accepted TLS connection from peer: " << peerSubjectName;
+    LOGV2_DEBUG(2, "Accepted TLS connection from peer: {}", "peerSubjectName"_attr = peerSubjectName);
 
     // Server side.
     if (remoteHost.empty()) {
diff --git a/src/mongo/util/net/ssl_manager_openssl.cpp b/src/mongo/util/net/ssl_manager_openssl.cpp
index a7524ce57e..ee60109bc7 100644
--- a/src/mongo/util/net/ssl_manager_openssl.cpp
+++ b/src/mongo/util/net/ssl_manager_openssl.cpp
@@ -48,6 +48,7 @@
 #include "mongo/base/secure_allocator.h"
 #include "mongo/bson/bsonobjbuilder.h"
 #include "mongo/config.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/transport/session.h"
 #include "mongo/util/concurrency/mutex.h"
@@ -630,7 +631,7 @@ SSLConnectionOpenSSL::SSLConnectionOpenSSL(SSL_CTX* context,
     if (len > 0) {
         int toBIO = BIO_write(networkBIO, initialBytes, len);
         if (toBIO != len) {
-            LOG(3) << "Failed to write initial network data to the SSL BIO layer";
+            LOGV2_DEBUG(3, "Failed to write initial network data to the SSL BIO layer");
             throwSocketError(SocketErrorKind::RECV_ERROR, socket->remoteString());
         }
     }
@@ -1107,8 +1108,7 @@ bool SSLManagerOpenSSL::_setupCRL(SSL_CTX* context, const std::string& crlFile)
                 << getSSLErrorMessage(ERR_get_error());
         return false;
     }
-    log() << "ssl imported " << status << " revoked certificate" << ((status == 1) ? "" : "s")
-          << " from the revocation list.";
+    LOGV2("ssl imported {} revoked certificate{} from the revocation list.", "status"_attr = status, "status_1_s"_attr = ((status == 1) ? "" : "s"));
     return true;
 }
 
@@ -1155,7 +1155,7 @@ void SSLManagerOpenSSL::_flushNetworkBIO(SSLConnectionOpenSSL* conn) {
 
         int toBIO = BIO_write(conn->networkBIO, buffer, numRead);
         if (toBIO != numRead) {
-            LOG(3) << "Failed to write network data to the SSL BIO layer";
+            LOGV2_DEBUG(3, "Failed to write network data to the SSL BIO layer");
             throwSocketError(SocketErrorKind::RECV_ERROR, conn->socket->remoteString());
         }
     }
@@ -1637,7 +1637,7 @@ StatusWith<SSLPeerInfo> SSLManagerOpenSSL::parseAndValidatePeerCertificate(
 
     // TODO: check optional cipher restriction, using cert.
     auto peerSubject = getCertificateSubjectX509Name(peerCert);
-    LOG(2) << "Accepted TLS connection from peer: " << peerSubject;
+    LOGV2_DEBUG(2, "Accepted TLS connection from peer: {}", "peerSubject"_attr = peerSubject);
 
     StatusWith<stdx::unordered_set<RoleName>> swPeerCertificateRoles = _parsePeerRoles(peerCert);
     if (!swPeerCertificateRoles.isOK()) {
diff --git a/src/mongo/util/net/ssl_manager_test.cpp b/src/mongo/util/net/ssl_manager_test.cpp
index a733597012..2ee3183d4e 100644
--- a/src/mongo/util/net/ssl_manager_test.cpp
+++ b/src/mongo/util/net/ssl_manager_test.cpp
@@ -38,6 +38,7 @@
 #include "mongo/util/log.h"
 
 #if MONGO_CONFIG_SSL_PROVIDER == MONGO_CONFIG_SSL_PROVIDER_OPENSSL
+#include "mongo/logv2/log.h"
 #include "mongo/util/net/dh_openssl.h"
 #endif
 
@@ -78,10 +79,9 @@ TEST(SSLManager, matchHostname) {
     for (const auto& test : tests) {
         if (bool(test.expected) != hostNameMatchForX509Certificates(test.hostname, test.certName)) {
             failure = true;
-            LOG(1) << "Failure for Hostname: " << test.hostname
-                   << " Certificate: " << test.certName;
+            LOGV2_DEBUG(1, "Failure for Hostname: {} Certificate: {}", "test_hostname"_attr = test.hostname, "test_certName"_attr = test.certName);
         } else {
-            LOG(1) << "Passed for Hostname: " << test.hostname << " Certificate: " << test.certName;
+            LOGV2_DEBUG(1, "Passed for Hostname: {} Certificate: {}", "test_hostname"_attr = test.hostname, "test_certName"_attr = test.certName);
         }
     }
     ASSERT_FALSE(failure);
@@ -358,7 +358,7 @@ TEST(SSLManager, DNParsingAndNormalization) {
           {"2.5.4.7", ", "}}}};
 
     for (const auto& test : tests) {
-        log() << "Testing DN \"" << test.first << "\"";
+        LOGV2("Testing DN \"{}\"", "test_first"_attr = test.first);
         auto swDN = parseDN(test.first);
         ASSERT_OK(swDN.getStatus());
         ASSERT_OK(swDN.getValue().normalizeStrings());
@@ -370,7 +370,7 @@ TEST(SSLManager, DNParsingAndNormalization) {
 TEST(SSLManager, BadDNParsing) {
     std::vector<std::string> tests = {"CN=#12345", R"(CN=\B)", R"(CN=<", "\)"};
     for (const auto& test : tests) {
-        log() << "Testing bad DN: \"" << test << "\"";
+        LOGV2("Testing bad DN: \"{}\"", "test"_attr = test);
         auto swDN = parseDN(test);
         ASSERT_NOT_OK(swDN.getStatus());
     }
diff --git a/src/mongo/util/net/ssl_manager_windows.cpp b/src/mongo/util/net/ssl_manager_windows.cpp
index 4106f1f8ba..6ae5fba01b 100644
--- a/src/mongo/util/net/ssl_manager_windows.cpp
+++ b/src/mongo/util/net/ssl_manager_windows.cpp
@@ -47,6 +47,7 @@
 #include "mongo/bson/util/builder.h"
 #include "mongo/config.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/atomic_word.h"
 #include "mongo/util/concurrency/mutex.h"
 #include "mongo/util/debug_util.h"
@@ -1929,7 +1930,7 @@ StatusWith<SSLPeerInfo> SSLManagerWindows::parseAndValidatePeerCertificate(
         return SSLPeerInfo(sni);
     }
 
-    LOG(2) << "Accepted TLS connection from peer: " << peerSubjectName;
+    LOGV2_DEBUG(2, "Accepted TLS connection from peer: {}", "peerSubjectName"_attr = peerSubjectName);
 
     // If this is a server and client and server certificate are the same, log a warning.
     if (remoteHost.empty() && _sslConfiguration.serverSubjectName() == peerSubjectName) {
diff --git a/src/mongo/util/net/ssl_options_server.cpp b/src/mongo/util/net/ssl_options_server.cpp
index dba0e0f94f..55916d04bb 100644
--- a/src/mongo/util/net/ssl_options_server.cpp
+++ b/src/mongo/util/net/ssl_options_server.cpp
@@ -38,6 +38,7 @@
 #include "mongo/base/status.h"
 #include "mongo/config.h"
 #include "mongo/db/server_options.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/options_parser/startup_option_init.h"
 #include "mongo/util/options_parser/startup_options.h"
@@ -337,8 +338,8 @@ MONGO_STARTUP_OPTIONS_VALIDATE(SSLServerOptions)(InitializerContext*) {
 MONGO_INITIALIZER_WITH_PREREQUISITES(ImplicitDisableTLS10Warning, ("ServerLogRedirection"))
 (InitializerContext*) {
     if (gImplicitDisableTLS10) {
-        log() << "Automatically disabling TLS 1.0, to force-enable TLS 1.0 "
-                 "specify --sslDisabledProtocols 'none'";
+        LOGV2("Automatically disabling TLS 1.0, to force-enable TLS 1.0 "
+                 "specify --sslDisabledProtocols 'none'");
     }
     return Status::OK();
 }
diff --git a/src/mongo/util/ntservice.cpp b/src/mongo/util/ntservice.cpp
index 512200c274..751c99ea00 100644
--- a/src/mongo/util/ntservice.cpp
+++ b/src/mongo/util/ntservice.cpp
@@ -37,6 +37,7 @@
 
 #include "mongo/util/ntservice.h"
 
+#include "mongo/logv2/log.h"
 #include "mongo/stdx/chrono.h"
 #include "mongo/stdx/future.h"
 #include "mongo/stdx/thread.h"
@@ -108,38 +109,38 @@ void configureService(ServiceCallback serviceCallback,
 
     if (params.count("install")) {
         if (badOption != -1) {
-            log() << "--install cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--install cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         if (!params.count("systemLog.destination") ||
             params["systemLog.destination"].as<std::string>() != "file") {
-            log() << "--install has to be used with a log file for server output";
+            LOGV2("--install has to be used with a log file for server output");
             quickExit(EXIT_BADOPTIONS);
         }
         installService = true;
     }
     if (params.count("reinstall")) {
         if (badOption != -1) {
-            log() << "--reinstall cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--reinstall cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         if (!params.count("systemLog.destination") ||
             params["systemLog.destination"].as<std::string>() != "file") {
-            log() << "--reinstall has to be used with a log file for server output";
+            LOGV2("--reinstall has to be used with a log file for server output");
             quickExit(EXIT_BADOPTIONS);
         }
         reinstallService = true;
     }
     if (params.count("remove")) {
         if (badOption != -1) {
-            log() << "--remove cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--remove cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         removeService = true;
     }
     if (params.count("service")) {
         if (badOption != -1) {
-            log() << "--service cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--service cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         _startService = true;
@@ -147,7 +148,7 @@ void configureService(ServiceCallback serviceCallback,
 
     if (params.count("processManagement.windowsService.serviceName")) {
         if (badOption != -1) {
-            log() << "--serviceName cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--serviceName cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         _serviceName = toWideString(
@@ -155,7 +156,7 @@ void configureService(ServiceCallback serviceCallback,
     }
     if (params.count("processManagement.windowsService.displayName")) {
         if (badOption != -1) {
-            log() << "--serviceDisplayName cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--serviceDisplayName cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         windowsServiceDisplayName = toWideString(
@@ -163,7 +164,7 @@ void configureService(ServiceCallback serviceCallback,
     }
     if (params.count("processManagement.windowsService.description")) {
         if (badOption != -1) {
-            log() << "--serviceDescription cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--serviceDescription cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         windowsServiceDescription = toWideString(
@@ -171,7 +172,7 @@ void configureService(ServiceCallback serviceCallback,
     }
     if (params.count("processManagement.windowsService.serviceUser")) {
         if (badOption != -1) {
-            log() << "--serviceUser cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--serviceUser cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         windowsServiceUser = toWideString(
@@ -179,7 +180,7 @@ void configureService(ServiceCallback serviceCallback,
     }
     if (params.count("processManagement.windowsService.servicePassword")) {
         if (badOption != -1) {
-            log() << "--servicePassword cannot be used with --" << disallowedOptions[badOption];
+            LOGV2("--servicePassword cannot be used with --{}", "disallowedOptions_badOption"_attr = disallowedOptions[badOption]);
             quickExit(EXIT_BADOPTIONS);
         }
         windowsServicePassword = toWideString(
@@ -274,7 +275,7 @@ void installServiceOrDie(const wstring& serviceName,
                          const wstring& servicePassword,
                          const std::vector<std::string>& argv,
                          const bool reinstall) {
-    log() << "Trying to install Windows service '" << toUtf8String(serviceName) << "'";
+    LOGV2("Trying to install Windows service '{}'", "toUtf8String_serviceName"_attr = toUtf8String(serviceName));
 
     std::vector<std::string> serviceArgv = constructServiceArgv(argv);
 
@@ -287,7 +288,7 @@ void installServiceOrDie(const wstring& serviceName,
     SC_HANDLE schSCManager = ::OpenSCManager(nullptr, nullptr, SC_MANAGER_ALL_ACCESS);
     if (schSCManager == nullptr) {
         DWORD err = ::GetLastError();
-        log() << "Error connecting to the Service Control Manager: " << windows::GetErrMsg(err);
+        LOGV2("Error connecting to the Service Control Manager: {}", "windows_GetErrMsg_err"_attr = windows::GetErrMsg(err));
         quickExit(EXIT_NTSERVICE_ERROR);
     }
 
@@ -300,8 +301,7 @@ void installServiceOrDie(const wstring& serviceName,
         // Services MMC snap-ins.
         schService = ::OpenService(schSCManager, serviceName.c_str(), SERVICE_ALL_ACCESS);
         if (schService != nullptr) {
-            log() << "There is already a service named '" << toUtf8String(serviceName)
-                  << (retryCount > 0 ? "', sleeping and retrying" : "', aborting");
+            LOGV2("There is already a service named '{}{}", "toUtf8String_serviceName"_attr = toUtf8String(serviceName), "retryCount_0_sleeping_and_retrying_aborting"_attr = (retryCount > 0 ? "', sleeping and retrying" : "', aborting"));
             ::CloseServiceHandle(schService);
 
             // If we are reinstalling the service, but SCM thinks it is installed, then wait
@@ -336,17 +336,16 @@ void installServiceOrDie(const wstring& serviceName,
                                   nullptr);                   // user account password
     if (schService == nullptr) {
         DWORD err = ::GetLastError();
-        log() << "Error creating service: " << windows::GetErrMsg(err);
+        LOGV2("Error creating service: {}", "windows_GetErrMsg_err"_attr = windows::GetErrMsg(err));
         ::CloseServiceHandle(schSCManager);
         quickExit(EXIT_NTSERVICE_ERROR);
     }
 
-    log() << "Service '" << toUtf8String(serviceName) << "' (" << toUtf8String(displayName)
-          << ") installed with command line '" << commandLine << "'";
+    LOGV2("Service '{}' ({}) installed with command line '{}'", "toUtf8String_serviceName"_attr = toUtf8String(serviceName), "toUtf8String_displayName"_attr = toUtf8String(displayName), "commandLine"_attr = commandLine);
     string typeableName((serviceName.find(L' ') != wstring::npos)
                             ? "\"" + toUtf8String(serviceName) + "\""
                             : toUtf8String(serviceName));
-    log() << "Service can be started from the command line with 'net start " << typeableName << "'";
+    LOGV2("Service can be started from the command line with 'net start {}'", "typeableName"_attr = typeableName);
 
     bool serviceInstalled;
 
@@ -359,7 +358,7 @@ void installServiceOrDie(const wstring& serviceName,
             actualServiceUser = serviceUser;
         }
 
-        log() << "Setting service login credentials for user: " << toUtf8String(actualServiceUser);
+        LOGV2("Setting service login credentials for user: {}", "toUtf8String_actualServiceUser"_attr = toUtf8String(actualServiceUser));
         serviceInstalled = ::ChangeServiceConfig(schService,                 // service handle
                                                  SERVICE_NO_CHANGE,          // service type
                                                  SERVICE_NO_CHANGE,          // start type
@@ -372,7 +371,7 @@ void installServiceOrDie(const wstring& serviceName,
                                                  servicePassword.c_str(),  // user account password
                                                  nullptr);                 // service display name
         if (!serviceInstalled) {
-            log() << "Setting service login failed, service has 'LocalService' permissions";
+            LOGV2("Setting service login failed, service has 'LocalService' permissions");
         }
     }
 
@@ -410,7 +409,7 @@ void installServiceOrDie(const wstring& serviceName,
 
     } else {
 #endif
-        log() << "Could not set service description. Check the Windows Event Log for more details.";
+        LOGV2("Could not set service description. Check the Windows Event Log for more details.");
     }
 
     // Set the pre-shutdown notification with a timeout of 10 minutes.
@@ -436,18 +435,18 @@ void installServiceOrDie(const wstring& serviceName,
 }
 
 void removeServiceOrDie(const wstring& serviceName) {
-    log() << "Trying to remove Windows service '" << toUtf8String(serviceName) << "'";
+    LOGV2("Trying to remove Windows service '{}'", "toUtf8String_serviceName"_attr = toUtf8String(serviceName));
 
     SC_HANDLE schSCManager = ::OpenSCManager(nullptr, nullptr, SC_MANAGER_ALL_ACCESS);
     if (schSCManager == nullptr) {
         DWORD err = ::GetLastError();
-        log() << "Error connecting to the Service Control Manager: " << windows::GetErrMsg(err);
+        LOGV2("Error connecting to the Service Control Manager: {}", "windows_GetErrMsg_err"_attr = windows::GetErrMsg(err));
         quickExit(EXIT_NTSERVICE_ERROR);
     }
 
     SC_HANDLE schService = ::OpenService(schSCManager, serviceName.c_str(), SERVICE_ALL_ACCESS);
     if (schService == nullptr) {
-        log() << "Could not find a service named '" << toUtf8String(serviceName) << "' to remove";
+        LOGV2("Could not find a service named '{}' to remove", "toUtf8String_serviceName"_attr = toUtf8String(serviceName));
         ::CloseServiceHandle(schSCManager);
         quickExit(EXIT_NTSERVICE_ERROR);
     }
@@ -456,8 +455,7 @@ void removeServiceOrDie(const wstring& serviceName) {
 
     // stop service if its running
     if (::ControlService(schService, SERVICE_CONTROL_STOP, &serviceStatus)) {
-        log() << "Service " << toUtf8String(serviceName)
-              << " is currently running, stopping service";
+        LOGV2("Service {} is currently running, stopping service", "toUtf8String_serviceName"_attr = toUtf8String(serviceName));
         while (::QueryServiceStatus(schService, &serviceStatus)) {
             if (serviceStatus.dwCurrentState == SERVICE_STOP_PENDING) {
                 Sleep(1000);
@@ -465,7 +463,7 @@ void removeServiceOrDie(const wstring& serviceName) {
                 break;
             }
         }
-        log() << "Service '" << toUtf8String(serviceName) << "' stopped";
+        LOGV2("Service '{}' stopped", "toUtf8String_serviceName"_attr = toUtf8String(serviceName));
     }
 
     bool serviceRemoved = ::DeleteService(schService);
@@ -474,9 +472,9 @@ void removeServiceOrDie(const wstring& serviceName) {
     ::CloseServiceHandle(schSCManager);
 
     if (serviceRemoved) {
-        log() << "Service '" << toUtf8String(serviceName) << "' removed";
+        LOGV2("Service '{}' removed", "toUtf8String_serviceName"_attr = toUtf8String(serviceName));
     } else {
-        log() << "Failed to remove service '" << toUtf8String(serviceName) << "'";
+        LOGV2("Failed to remove service '{}'", "toUtf8String_serviceName"_attr = toUtf8String(serviceName));
     }
 
     if (!serviceRemoved)
@@ -546,7 +544,7 @@ static void serviceStop() {
     // We periodically check if we are done exiting by polling at half of each wait interval
     while (exitedCleanly.wait_for(timeout.toSystemDuration()) != stdx::future_status::ready) {
         reportStatus(SERVICE_STOP_PENDING, kStopWaitHintMillis);
-        log() << "Service Stop is waiting for storage engine to finish shutdown";
+        LOGV2("Service Stop is waiting for storage engine to finish shutdown");
     }
 }
 
@@ -571,9 +569,8 @@ static void WINAPI initService(DWORD argc, LPTSTR* argv) {
 static void serviceShutdown(const char* controlCodeName) {
     setThreadName("serviceShutdown");
 
-    log() << "got " << controlCodeName << " request from Windows Service Control Manager, "
-          << (globalInShutdownDeprecated() ? "already in shutdown"
-                                           : "will terminate after current cmd ends");
+    LOGV2("got {} request from Windows Service Control Manager, {}", "controlCodeName"_attr = controlCodeName, "globalInShutdownDeprecated_already_in_shutdown_will_terminate_after_current_cmd_ends"_attr = (globalInShutdownDeprecated() ? "already in shutdown"
+                                           : "will terminate after current cmd ends"));
 
     reportStatus(SERVICE_STOP_PENDING, kStopWaitHintMillis);
 
@@ -617,7 +614,7 @@ void startService() {
         {const_cast<LPWSTR>(_serviceName.c_str()), (LPSERVICE_MAIN_FUNCTION)initService},
         {nullptr, nullptr}};
 
-    log() << "Trying to start Windows service '" << toUtf8String(_serviceName) << "'";
+    LOGV2("Trying to start Windows service '{}'", "toUtf8String__serviceName"_attr = toUtf8String(_serviceName));
     if (StartServiceCtrlDispatcherW(dispTable)) {
         quickExit(EXIT_CLEAN);
     } else {
diff --git a/src/mongo/util/options_parser/options_parser.cpp b/src/mongo/util/options_parser/options_parser.cpp
index 99231dd132..b83c469ebc 100644
--- a/src/mongo/util/options_parser/options_parser.cpp
+++ b/src/mongo/util/options_parser/options_parser.cpp
@@ -56,6 +56,7 @@
 #include "mongo/crypto/sha256_block.h"
 #include "mongo/db/jsobj.h"
 #include "mongo/db/json.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/hex.h"
 #include "mongo/util/log.h"
@@ -594,9 +595,9 @@ StatusWith<YAML::Node> runYAMLExpansion(const YAML::Node& node,
         prefix += '.';
     }
 
-    log() << "Processing " << expansion.getExpansionName() << " config expansion for: " << nodeName;
+    LOGV2("Processing {} config expansion for: {}", "expansion_getExpansionName"_attr = expansion.getExpansionName(), "nodeName"_attr = nodeName);
     const auto action = expansion.getAction();
-    LOG(2) << prefix << expansion.getExpansionName() << ": " << action;
+    LOGV2_DEBUG(2, "{}{}: {}", "prefix"_attr = prefix, "expansion_getExpansionName"_attr = expansion.getExpansionName(), "action"_attr = action);
 
     if (expansion.isRestExpansion()) {
         return expansion.process(runYAMLRestExpansion(action, configExpand.timeout));
diff --git a/src/mongo/util/perfctr_collect_test.cpp b/src/mongo/util/perfctr_collect_test.cpp
index 869f72f9e2..e5e428160f 100644
--- a/src/mongo/util/perfctr_collect_test.cpp
+++ b/src/mongo/util/perfctr_collect_test.cpp
@@ -38,6 +38,7 @@
 
 #include "mongo/bson/bsonobj.h"
 #include "mongo/bson/bsonobjbuilder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 
diff --git a/src/mongo/util/periodic_runner_impl.cpp b/src/mongo/util/periodic_runner_impl.cpp
index dc9f091505..42c69a1165 100644
--- a/src/mongo/util/periodic_runner_impl.cpp
+++ b/src/mongo/util/periodic_runner_impl.cpp
@@ -35,6 +35,7 @@
 
 #include "mongo/db/client.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/clock_source.h"
 #include "mongo/util/log.h"
 #include "mongo/util/scopeguard.h"
@@ -114,7 +115,7 @@ void PeriodicRunnerImpl::PeriodicJobImpl::_run() {
 }
 
 void PeriodicRunnerImpl::PeriodicJobImpl::start() {
-    LOG(2) << "Starting periodic job " << _job.name;
+    LOGV2_DEBUG(2, "Starting periodic job {}", "_job_name"_attr = _job.name);
 
     _run();
 }
@@ -148,7 +149,7 @@ void PeriodicRunnerImpl::PeriodicJobImpl::stop() {
 
     // Only join once
     if (lastExecStatus != ExecutionStatus::CANCELED) {
-        LOG(2) << "Stopping periodic job " << _job.name;
+        LOGV2_DEBUG(2, "Stopping periodic job {}", "_job_name"_attr = _job.name);
 
         _condvar.notify_one();
         _thread.join();
diff --git a/src/mongo/util/platform_init.cpp b/src/mongo/util/platform_init.cpp
index 335cd5c7bf..70c6f61d53 100644
--- a/src/mongo/util/platform_init.cpp
+++ b/src/mongo/util/platform_init.cpp
@@ -39,6 +39,7 @@
 #endif
 
 #include "mongo/base/init.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/stacktrace.h"
 
@@ -71,8 +72,7 @@ extern "C" {
 int __cdecl crtDebugCallback(int nRptType, char* originalMessage, int* returnValue) noexcept {
     *returnValue = 0;  // Returned by _CrtDbgReport. (1: starts the debugger).
     bool die = (nRptType != _CRT_WARN);
-    log() << "*** C runtime " << severity(nRptType) << ": " << firstLine(originalMessage)
-          << (die ? ", terminating"_sd : ""_sd);
+    LOGV2("*** C runtime {}: {}{}", "severity_nRptType"_attr = severity(nRptType), "firstLine_originalMessage"_attr = firstLine(originalMessage), "die_terminating__sd__sd"_attr = (die ? ", terminating"_sd : ""_sd));
     if (die) {
         fassertFailed(17006);
     }
diff --git a/src/mongo/util/processinfo.cpp b/src/mongo/util/processinfo.cpp
index 3428d0907d..d651417d42 100644
--- a/src/mongo/util/processinfo.cpp
+++ b/src/mongo/util/processinfo.cpp
@@ -39,6 +39,7 @@
 #include <fstream>
 #include <iostream>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 
 namespace mongo {
@@ -61,11 +62,9 @@ public:
         if (!out.good()) {
             auto errAndStr = errnoAndDescription();
             if (errAndStr.first == 0) {
-                log() << "ERROR: Cannot write pid file to " << path.string()
-                      << ": Unable to determine OS error";
+                LOGV2("ERROR: Cannot write pid file to {}: Unable to determine OS error", "path_string"_attr = path.string());
             } else {
-                log() << "ERROR: Cannot write pid file to " << path.string() << ": "
-                      << errAndStr.second;
+                LOGV2("ERROR: Cannot write pid file to {}: {}", "path_string"_attr = path.string(), "errAndStr_second"_attr = errAndStr.second);
             }
         } else {
             boost::system::error_code ec;
@@ -75,8 +74,7 @@ public:
                     boost::filesystem::group_read | boost::filesystem::others_read,
                 ec);
             if (ec) {
-                log() << "Could not set permissions on pid file " << path.string() << ": "
-                      << ec.message();
+                LOGV2("Could not set permissions on pid file {}: {}", "path_string"_attr = path.string(), "ec_message"_attr = ec.message());
                 return false;
             }
         }
diff --git a/src/mongo/util/processinfo_freebsd.cpp b/src/mongo/util/processinfo_freebsd.cpp
index f3b60f426e..970a94c0c4 100644
--- a/src/mongo/util/processinfo_freebsd.cpp
+++ b/src/mongo/util/processinfo_freebsd.cpp
@@ -44,6 +44,7 @@
 #include <vm/vm_param.h>
 
 #include "mongo/util/log.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/scopeguard.h"
 #include "processinfo.h"
 
@@ -130,13 +131,11 @@ void ProcessInfo::SystemInfo::collectSystemInfo() {
 
     int status = getSysctlByNameWithDefault("kern.version", std::string("unknown"), &osVersion);
     if (status != 0)
-        log() << "Unable to collect OS Version. (errno: " << status << " msg: " << strerror(status)
-              << ")";
+        LOGV2("Unable to collect OS Version. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
 
     status = getSysctlByNameWithDefault("hw.machine_arch", std::string("unknown"), &cpuArch);
     if (status != 0)
-        log() << "Unable to collect Machine Architecture. (errno: " << status
-              << " msg: " << strerror(status) << ")";
+        LOGV2("Unable to collect Machine Architecture. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
     addrSize = cpuArch.find("64") != std::string::npos ? 64 : 32;
 
     uintptr_t numBuffer;
@@ -145,14 +144,12 @@ void ProcessInfo::SystemInfo::collectSystemInfo() {
     memSize = numBuffer;
     memLimit = memSize;
     if (status != 0)
-        log() << "Unable to collect Physical Memory. (errno: " << status
-              << " msg: " << strerror(status) << ")";
+        LOGV2("Unable to collect Physical Memory. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
 
     status = getSysctlByNameWithDefault("hw.ncpu", defaultNum, &numBuffer);
     numCores = numBuffer;
     if (status != 0)
-        log() << "Unable to collect Number of CPUs. (errno: " << status
-              << " msg: " << strerror(status) << ")";
+        LOGV2("Unable to collect Number of CPUs. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
 
     pageSize = static_cast<unsigned long long>(sysconf(_SC_PAGESIZE));
 
@@ -172,7 +169,7 @@ bool ProcessInfo::blockCheckSupported() {
 bool ProcessInfo::blockInMemory(const void* start) {
     char x = 0;
     if (mincore(alignToStartOfPage(start), getPageSize(), &x)) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return 1;
     }
     return x & 0x1;
@@ -182,7 +179,7 @@ bool ProcessInfo::pagesInMemory(const void* start, size_t numPages, std::vector<
     out->resize(numPages);
     // int mincore(const void *addr, size_t len, char *vec);
     if (mincore(alignToStartOfPage(start), numPages * getPageSize(), &(out->front()))) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return false;
     }
     for (size_t i = 0; i < numPages; ++i) {
diff --git a/src/mongo/util/processinfo_linux.cpp b/src/mongo/util/processinfo_linux.cpp
index 9c2db3c416..0361d1bb2a 100644
--- a/src/mongo/util/processinfo_linux.cpp
+++ b/src/mongo/util/processinfo_linux.cpp
@@ -54,6 +54,7 @@
 #include <boost/none.hpp>
 #include <boost/optional.hpp>
 
+#include "mongo/logv2/log.h"
 #include "mongo/util/file.h"
 #include "mongo/util/log.h"
 
@@ -407,7 +408,7 @@ public:
             if (mongo::NumberParser{}(meminfo, &systemMem).isOK()) {
                 return systemMem * 1024;  // convert from kB to bytes
             } else
-                log() << "Unable to collect system memory information";
+                LOGV2("Unable to collect system memory information");
         }
         return 0;
     }
@@ -521,7 +522,7 @@ void ProcessInfo::SystemInfo::collectSystemInfo() {
     LinuxSysHelper::getLinuxDistro(distroName, distroVersion);
 
     if (uname(&unameData) == -1) {
-        log() << "Unable to collect detailed system information: " << strerror(errno);
+        LOGV2("Unable to collect detailed system information: {}", "strerror_errno"_attr = strerror(errno));
     }
 
     osType = "Linux";
@@ -573,8 +574,7 @@ bool ProcessInfo::checkNumaEnabled() {
         hasMultipleNodes = boost::filesystem::exists("/sys/devices/system/node/node1");
         hasNumaMaps = boost::filesystem::exists("/proc/self/numa_maps");
     } catch (boost::filesystem::filesystem_error& e) {
-        log() << "WARNING: Cannot detect if NUMA interleaving is enabled. "
-              << "Failed to probe \"" << e.path1().string() << "\": " << e.code().message();
+        LOGV2("WARNING: Cannot detect if NUMA interleaving is enabled. Failed to probe \"{}\": {}", "e_path1_string"_attr = e.path1().string(), "e_code_message"_attr = e.code().message());
         return false;
     }
 
@@ -600,7 +600,7 @@ bool ProcessInfo::blockCheckSupported() {
 bool ProcessInfo::blockInMemory(const void* start) {
     unsigned char x = 0;
     if (mincore(const_cast<void*>(alignToStartOfPage(start)), getPageSize(), &x)) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return 1;
     }
     return x & 0x1;
@@ -611,7 +611,7 @@ bool ProcessInfo::pagesInMemory(const void* start, size_t numPages, std::vector<
     if (mincore(const_cast<void*>(alignToStartOfPage(start)),
                 numPages * getPageSize(),
                 reinterpret_cast<unsigned char*>(&out->front()))) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return false;
     }
     for (size_t i = 0; i < numPages; ++i) {
diff --git a/src/mongo/util/processinfo_openbsd.cpp b/src/mongo/util/processinfo_openbsd.cpp
index 34dade8a88..fe75779aa4 100644
--- a/src/mongo/util/processinfo_openbsd.cpp
+++ b/src/mongo/util/processinfo_openbsd.cpp
@@ -43,6 +43,7 @@
 #include <unistd.h>
 
 #include "mongo/util/log.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/scopeguard.h"
 #include "processinfo.h"
 
@@ -105,7 +106,7 @@ int ProcessInfo::getVirtualMemorySize() {
     int cnt = 0;
     char err[_POSIX2_LINE_MAX] = {0};
     if ((kd = kvm_openfiles(NULL, NULL, NULL, KVM_NO_FILES, err)) == NULL) {
-        log() << "Unable to get virt mem size: " << err;
+        LOGV2("Unable to get virt mem size: {}", "err"_attr = err);
         return -1;
     }
 
@@ -121,7 +122,7 @@ int ProcessInfo::getResidentSize() {
     int cnt = 0;
     char err[_POSIX2_LINE_MAX] = {0};
     if ((kd = kvm_openfiles(NULL, NULL, NULL, KVM_NO_FILES, err)) == NULL) {
-        log() << "Unable to get res mem size: " << err;
+        LOGV2("Unable to get res mem size: {}", "err"_attr = err);
         return -1;
     }
     kinfo_proc* task = kvm_getprocs(kd, KERN_PROC_PID, _pid.toNative(), sizeof(kinfo_proc), &cnt);
@@ -143,15 +144,13 @@ void ProcessInfo::SystemInfo::collectSystemInfo() {
     mib[1] = KERN_VERSION;
     int status = getSysctlByIDWithDefault(mib, 2, std::string("unknown"), &osVersion);
     if (status != 0)
-        log() << "Unable to collect OS Version. (errno: " << status << " msg: " << strerror(status)
-              << ")";
+        LOGV2("Unable to collect OS Version. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
 
     mib[0] = CTL_HW;
     mib[1] = HW_MACHINE;
     status = getSysctlByIDWithDefault(mib, 2, std::string("unknown"), &cpuArch);
     if (status != 0)
-        log() << "Unable to collect Machine Architecture. (errno: " << status
-              << " msg: " << strerror(status) << ")";
+        LOGV2("Unable to collect Machine Architecture. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
     addrSize = cpuArch.find("64") != std::string::npos ? 64 : 32;
 
     uintptr_t numBuffer;
@@ -162,16 +161,14 @@ void ProcessInfo::SystemInfo::collectSystemInfo() {
     memSize = numBuffer;
     memLimit = memSize;
     if (status != 0)
-        log() << "Unable to collect Physical Memory. (errno: " << status
-              << " msg: " << strerror(status) << ")";
+        LOGV2("Unable to collect Physical Memory. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
 
     mib[0] = CTL_HW;
     mib[1] = HW_NCPU;
     status = getSysctlByIDWithDefault(mib, 2, defaultNum, &numBuffer);
     numCores = numBuffer;
     if (status != 0)
-        log() << "Unable to collect Number of CPUs. (errno: " << status
-              << " msg: " << strerror(status) << ")";
+        LOGV2("Unable to collect Number of CPUs. (errno: {} msg: {})", "status"_attr = status, "strerror_status"_attr = strerror(status));
 
     pageSize = static_cast<unsigned long long>(sysconf(_SC_PAGESIZE));
 
@@ -191,7 +188,7 @@ bool ProcessInfo::blockCheckSupported() {
 bool ProcessInfo::blockInMemory(const void* start) {
     char x = 0;
     if (mincore((void*)alignToStartOfPage(start), getPageSize(), &x)) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return 1;
     }
     return x & 0x1;
@@ -201,7 +198,7 @@ bool ProcessInfo::pagesInMemory(const void* start, size_t numPages, std::vector<
     out->resize(numPages);
     // int mincore(const void *addr, size_t len, char *vec);
     if (mincore((void*)alignToStartOfPage(start), numPages * getPageSize(), &(out->front()))) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return false;
     }
     for (size_t i = 0; i < numPages; ++i) {
diff --git a/src/mongo/util/processinfo_osx.cpp b/src/mongo/util/processinfo_osx.cpp
index 45fc77f68f..e80254ccb9 100644
--- a/src/mongo/util/processinfo_osx.cpp
+++ b/src/mongo/util/processinfo_osx.cpp
@@ -48,6 +48,7 @@
 #include <sys/types.h>
 
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/processinfo.h"
 
@@ -153,7 +154,7 @@ Variant getSysctlByName(const char* sysctlName) {
     } while (status == -1 && errno == ENOMEM);
     if (status == -1) {
         // unrecoverable error from sysctlbyname
-        log() << sysctlName << " unavailable";
+        LOGV2("{} unavailable", "sysctlName"_attr = sysctlName);
         return "";
     }
 
@@ -169,11 +170,10 @@ long long getSysctlByName<NumberVal>(const char* sysctlName) {
     long long value = 0;
     size_t len = sizeof(value);
     if (sysctlbyname(sysctlName, &value, &len, nullptr, 0) < 0) {
-        log() << "Unable to resolve sysctl " << sysctlName << " (number) ";
+        LOGV2("Unable to resolve sysctl {} (number) ", "sysctlName"_attr = sysctlName);
     }
     if (len > 8) {
-        log() << "Unable to resolve sysctl " << sysctlName << " as integer.  System returned "
-              << len << " bytes.";
+        LOGV2("Unable to resolve sysctl {} as integer.  System returned {} bytes.", "sysctlName"_attr = sysctlName, "len"_attr = len);
     }
     return value;
 }
@@ -223,7 +223,7 @@ bool ProcessInfo::blockCheckSupported() {
 bool ProcessInfo::blockInMemory(const void* start) {
     char x = 0;
     if (mincore(alignToStartOfPage(start), getPageSize(), &x)) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return 1;
     }
     return x & 0x1;
@@ -232,7 +232,7 @@ bool ProcessInfo::blockInMemory(const void* start) {
 bool ProcessInfo::pagesInMemory(const void* start, size_t numPages, std::vector<char>* out) {
     out->resize(numPages);
     if (mincore(alignToStartOfPage(start), numPages * getPageSize(), &out->front())) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return false;
     }
     for (size_t i = 0; i < numPages; ++i) {
diff --git a/src/mongo/util/processinfo_solaris.cpp b/src/mongo/util/processinfo_solaris.cpp
index c12ce0e6da..f8b9b1e753 100644
--- a/src/mongo/util/processinfo_solaris.cpp
+++ b/src/mongo/util/processinfo_solaris.cpp
@@ -46,6 +46,7 @@
 #include <vector>
 
 #include "mongo/util/file.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/log.h"
 #include "mongo/util/processinfo.h"
 #include "mongo/util/scopeguard.h"
@@ -139,7 +140,7 @@ void ProcessInfo::getExtraInfo(BSONObjBuilder& info) {
 void ProcessInfo::SystemInfo::collectSystemInfo() {
     struct utsname unameData;
     if (uname(&unameData) == -1) {
-        log() << "Unable to collect detailed system information: " << strerror(errno);
+        LOGV2("Unable to collect detailed system information: {}", "strerror_errno"_attr = strerror(errno));
     }
 
     char buf_64[32];
@@ -148,7 +149,7 @@ void ProcessInfo::SystemInfo::collectSystemInfo() {
         sysinfo(SI_ARCHITECTURE_NATIVE, buf_native, sizeof(buf_native)) != -1) {
         addrSize = str::equals(buf_64, buf_native) ? 64 : 32;
     } else {
-        log() << "Unable to determine system architecture: " << strerror(errno);
+        LOGV2("Unable to determine system architecture: {}", "strerror_errno"_attr = strerror(errno));
     }
 
     osType = unameData.sysname;
@@ -223,7 +224,7 @@ bool ProcessInfo::blockInMemory(const void* start) {
     char x = 0;
     if (mincore(
             static_cast<char*>(const_cast<void*>(alignToStartOfPage(start))), getPageSize(), &x)) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return 1;
     }
     return x & 0x1;
@@ -234,7 +235,7 @@ bool ProcessInfo::pagesInMemory(const void* start, size_t numPages, std::vector<
     if (mincore(static_cast<char*>(const_cast<void*>(alignToStartOfPage(start))),
                 numPages * getPageSize(),
                 &out->front())) {
-        log() << "mincore failed: " << errnoWithDescription();
+        LOGV2("mincore failed: {}", "errnoWithDescription"_attr = errnoWithDescription());
         return false;
     }
     for (size_t i = 0; i < numPages; ++i) {
diff --git a/src/mongo/util/procparser_test.cpp b/src/mongo/util/procparser_test.cpp
index 1fba705f92..2922b81af2 100644
--- a/src/mongo/util/procparser_test.cpp
+++ b/src/mongo/util/procparser_test.cpp
@@ -38,6 +38,7 @@
 
 #include "mongo/bson/bsonobj.h"
 #include "mongo/bson/bsonobjbuilder.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/log.h"
 
@@ -222,7 +223,7 @@ TEST(FTDCProcStat, TestLocalStat) {
 
     BSONObj obj = builder.obj();
     auto stringMap = toStringMap(obj);
-    log() << "OBJ:" << obj;
+    LOGV2("OBJ:{}", "obj"_attr = obj);
     ASSERT_KEY("user_ms");
     ASSERT_KEY("nice_ms");
     ASSERT_KEY("idle_ms");
@@ -335,7 +336,7 @@ TEST(FTDCProcMemInfo, TestLocalMemInfo) {
 
     BSONObj obj = builder.obj();
     auto stringMap = toStringMap(obj);
-    log() << "OBJ:" << obj;
+    LOGV2("OBJ:{}", "obj"_attr = obj);
     ASSERT_KEY("MemTotal_kb");
     ASSERT_KEY("MemFree_kb");
     // Needs in 3.15+ - ASSERT_KEY("MemAvailable_kb");
@@ -474,7 +475,7 @@ TEST(FTDCProcNetstat, TestLocalNetstat) {
 
     BSONObj obj = builder.obj();
     auto stringMap = toStringMap(obj);
-    log() << "OBJ:" << obj;
+    LOGV2("OBJ:{}", "obj"_attr = obj);
     ASSERT_KEY("TcpExt:TCPTimeouts");
     ASSERT_KEY("TcpExt:TCPPureAcks");
     ASSERT_KEY("TcpExt:TCPAbortOnTimeout");
@@ -498,7 +499,7 @@ TEST(FTDCProcNetstat, TestLocalNetSnmp) {
 
     BSONObj obj = builder.obj();
     auto stringMap = toStringMap(obj);
-    log() << "OBJ:" << obj;
+    LOGV2("OBJ:{}", "obj"_attr = obj);
     ASSERT_KEY("Ip:InReceives");
     ASSERT_KEY("Ip:OutRequests");
     ASSERT_KEY("Tcp:InSegs");
@@ -612,7 +613,7 @@ TEST(FTDCProcDiskStats, TestLocalDiskStats) {
 
     std::vector<StringData> disks2;
     for (const auto& disk : disks) {
-        log() << "DISK:" << disk;
+        LOGV2("DISK:{}", "disk"_attr = disk);
         disks2.emplace_back(disk);
     }
 
@@ -624,7 +625,7 @@ TEST(FTDCProcDiskStats, TestLocalDiskStats) {
 
     BSONObj obj = builder.obj();
     auto stringMap = toNestedStringMap(obj);
-    log() << "OBJ:" << obj;
+    LOGV2("OBJ:{}", "obj"_attr = obj);
 
     bool foundDisk = false;
 
diff --git a/src/mongo/util/signal_handlers.cpp b/src/mongo/util/signal_handlers.cpp
index 33ab8afb92..c042264390 100644
--- a/src/mongo/util/signal_handlers.cpp
+++ b/src/mongo/util/signal_handlers.cpp
@@ -43,6 +43,7 @@
 #include "mongo/db/log_process_details.h"
 #include "mongo/db/server_options.h"
 #include "mongo/db/service_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/process_id.h"
 #include "mongo/stdx/thread.h"
 #include "mongo/util/assert_util.h"
@@ -78,24 +79,24 @@ namespace {
 #ifdef _WIN32
 void consoleTerminate(const char* controlCodeName) {
     setThreadName("consoleTerminate");
-    log() << "got " << controlCodeName << ", will terminate after current cmd ends";
+    LOGV2("got {}, will terminate after current cmd ends", "controlCodeName"_attr = controlCodeName);
     exitCleanly(EXIT_KILL);
 }
 
 BOOL WINAPI CtrlHandler(DWORD fdwCtrlType) {
     switch (fdwCtrlType) {
         case CTRL_C_EVENT:
-            log() << "Ctrl-C signal";
+            LOGV2("Ctrl-C signal");
             consoleTerminate("CTRL_C_EVENT");
             return TRUE;
 
         case CTRL_CLOSE_EVENT:
-            log() << "CTRL_CLOSE_EVENT signal";
+            LOGV2("CTRL_CLOSE_EVENT signal");
             consoleTerminate("CTRL_CLOSE_EVENT");
             return TRUE;
 
         case CTRL_BREAK_EVENT:
-            log() << "CTRL_BREAK_EVENT signal";
+            LOGV2("CTRL_BREAK_EVENT signal");
             consoleTerminate("CTRL_BREAK_EVENT");
             return TRUE;
 
@@ -104,7 +105,7 @@ BOOL WINAPI CtrlHandler(DWORD fdwCtrlType) {
             return FALSE;
 
         case CTRL_SHUTDOWN_EVENT:
-            log() << "CTRL_SHUTDOWN_EVENT signal";
+            LOGV2("CTRL_SHUTDOWN_EVENT signal");
             consoleTerminate("CTRL_SHUTDOWN_EVENT");
             return TRUE;
 
@@ -139,7 +140,7 @@ void eventProcessingThread() {
 
     setThreadName("eventTerminate");
 
-    log() << "shutdown event signaled, will terminate after current cmd ends";
+    LOGV2("shutdown event signaled, will terminate after current cmd ends");
     exitCleanly(EXIT_CLEAN);
 }
 
@@ -189,19 +190,19 @@ struct LogRotationState {
 
 void handleOneSignal(const SignalWaitResult& waited, LogRotationState* rotation) {
     int sig = waited.sig;
-    log() << "got signal " << sig << " (" << strsignal(sig) << ")";
+    LOGV2("got signal {} ({})", "sig"_attr = sig, "strsignal_sig"_attr = strsignal(sig));
 #ifdef __linux__
     const siginfo_t& si = waited.si;
     switch (si.si_code) {
         case SI_USER:
         case SI_QUEUE:
-            log() << "kill from pid:" << si.si_pid << " uid:" << si.si_uid;
+            LOGV2("kill from pid:{} uid:{}", "si_si_pid"_attr = si.si_pid, "si_si_uid"_attr = si.si_uid);
             break;
         case SI_TKILL:
-            log() << "tgkill";
+            LOGV2("tgkill");
             break;
         case SI_KERNEL:
-            log() << "kernel";
+            LOGV2("kernel");
             break;
     }
 #endif  // __linux__
@@ -231,7 +232,7 @@ void handleOneSignal(const SignalWaitResult& waited, LogRotationState* rotation)
     }
 #endif
     // interrupt/terminate signal
-    log() << "will terminate after current cmd ends";
+    LOGV2("will terminate after current cmd ends");
     exitCleanly(EXIT_CLEAN);
 }
 
diff --git a/src/mongo/util/stacktrace_libunwind_test.cpp b/src/mongo/util/stacktrace_libunwind_test.cpp
index 363b041460..2bfcc7684d 100644
--- a/src/mongo/util/stacktrace_libunwind_test.cpp
+++ b/src/mongo/util/stacktrace_libunwind_test.cpp
@@ -40,6 +40,7 @@
 
 #include <libunwind.h>
 
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/unittest.h"
 #include "mongo/util/stacktrace.h"
 #include "mongo/util/stacktrace_libunwind_test_functions.h"
@@ -186,7 +187,7 @@ TEST(Unwind, Linkage) {
                 << "--- END ACTUAL BACKTRACE ---";
             FAIL("name '{}' is missing or out of order in sample backtrace"_format(name));
         }
-        unittest::log() << "removing prefix `" << std::string(remainder.substr(0, pos)) << "`";
+        unittest::LOGV2("removing prefix `{}`", "std_string_remainder_substr_0_pos"_attr = std::string(remainder.substr(0, pos)));
         remainder.remove_prefix(pos);
     }
 }
diff --git a/src/mongo/util/version.cpp b/src/mongo/util/version.cpp
index 494fbabf33..1bdaaee31d 100644
--- a/src/mongo/util/version.cpp
+++ b/src/mongo/util/version.cpp
@@ -46,6 +46,7 @@
 #include <sstream>
 
 #include "mongo/db/jsobj.h"
+#include "mongo/logv2/log.h"
 #include "mongo/util/assert_util.h"
 #include "mongo/util/log.h"
 
@@ -195,17 +196,17 @@ std::string VersionInfoInterface::openSSLVersion(StringData prefix, StringData s
 }
 
 void VersionInfoInterface::logTargetMinOS() const {
-    log() << "targetMinOS: " << targetMinOS();
+    LOGV2("targetMinOS: {}", "targetMinOS"_attr = targetMinOS());
 }
 
 void VersionInfoInterface::logBuildInfo() const {
-    log() << "git version: " << gitVersion();
+    LOGV2("git version: {}", "gitVersion"_attr = gitVersion());
 
 #if defined(MONGO_CONFIG_SSL) && MONGO_CONFIG_SSL_PROVIDER == MONGO_CONFIG_SSL_PROVIDER_OPENSSL
-    log() << openSSLVersion("OpenSSL version: ");
+    LOGV2("{}", "openSSLVersion_OpenSSL_version"_attr = openSSLVersion("OpenSSL version: "));
 #endif
 
-    log() << "allocator: " << allocator();
+    LOGV2("allocator: {}", "allocator"_attr = allocator());
 
     std::stringstream ss;
     ss << "modules: ";
@@ -217,15 +218,15 @@ void VersionInfoInterface::logBuildInfo() const {
             ss << m << " ";
         }
     }
-    log() << ss.str();
+    LOGV2("{}", "ss_str"_attr = ss.str());
 
-    log() << "build environment:";
+    LOGV2("build environment:");
     for (auto&& envDataEntry : buildInfo()) {
         if (std::get<3>(envDataEntry)) {
             auto val = std::get<1>(envDataEntry);
             if (val.size() == 0)
                 continue;
-            log() << "    " << std::get<0>(envDataEntry) << ": " << std::get<1>(envDataEntry);
+            LOGV2("    {}: {}", "std_get_0_envDataEntry"_attr = std::get<0>(envDataEntry), "std_get_1_envDataEntry"_attr = std::get<1>(envDataEntry));
         }
     }
 }
diff --git a/src/mongo/watchdog/watchdog.cpp b/src/mongo/watchdog/watchdog.cpp
index accc1b3b06..db9147e5df 100644
--- a/src/mongo/watchdog/watchdog.cpp
+++ b/src/mongo/watchdog/watchdog.cpp
@@ -45,6 +45,7 @@
 #include "mongo/base/static_assert.h"
 #include "mongo/db/client.h"
 #include "mongo/db/operation_context.h"
+#include "mongo/logv2/log.h"
 #include "mongo/platform/process_id.h"
 #include "mongo/util/concurrency/idle_thread_block.h"
 #include "mongo/util/exit.h"
@@ -165,7 +166,7 @@ void WatchdogPeriodicThread::doLoop() {
 
                 // This interruption ends the WatchdogPeriodicThread. This means it is possible to
                 // killOp this operation and stop it for the lifetime of the process.
-                LOG(1) << "WatchdogPeriodicThread interrupted by: " << e;
+                LOGV2_DEBUG(1, "WatchdogPeriodicThread interrupted by: {}", "e"_attr = e);
                 return;
             }
 
@@ -202,8 +203,7 @@ void WatchdogCheckThread::run(OperationContext* opCtx) {
         check->run(opCtx);
         Microseconds micros = timer.elapsed();
 
-        LOG(1) << "Watchdog test '" << check->getDescriptionForLogging() << "' took "
-               << duration_cast<Milliseconds>(micros);
+        LOGV2_DEBUG(1, "Watchdog test '{}' took {}", "check_getDescriptionForLogging"_attr = check->getDescriptionForLogging(), "duration_cast_Milliseconds_micros"_attr = duration_cast<Milliseconds>(micros));
 
         // We completed a check, bump the generation counter.
         _checkGeneration.fetchAndAdd(1);
@@ -250,7 +250,7 @@ WatchdogMonitor::WatchdogMonitor(std::vector<std::unique_ptr<WatchdogCheck>> che
 }
 
 void WatchdogMonitor::start() {
-    log() << "Starting Watchdog Monitor";
+    LOGV2("Starting Watchdog Monitor");
 
     // Start the threads.
     _watchdogCheckThread.start();
@@ -279,12 +279,12 @@ void WatchdogMonitor::setPeriod(Milliseconds duration) {
             _watchdogCheckThread.setPeriod(_checkPeriod);
             _watchdogMonitorThread.setPeriod(duration);
 
-            log() << "WatchdogMonitor period changed to " << duration_cast<Seconds>(duration);
+            LOGV2("WatchdogMonitor period changed to {}", "duration_cast_Seconds_duration"_attr = duration_cast<Seconds>(duration));
         } else {
             _watchdogMonitorThread.setPeriod(duration);
             _watchdogCheckThread.setPeriod(duration);
 
-            log() << "WatchdogMonitor disabled";
+            LOGV2("WatchdogMonitor disabled");
         }
     }
 }
diff --git a/src/mongo/watchdog/watchdog_test.cpp b/src/mongo/watchdog/watchdog_test.cpp
index bc8bac2cc7..220048326e 100644
--- a/src/mongo/watchdog/watchdog_test.cpp
+++ b/src/mongo/watchdog/watchdog_test.cpp
@@ -38,6 +38,7 @@
 #include "mongo/db/client.h"
 #include "mongo/db/service_context.h"
 #include "mongo/db/service_context_test_fixture.h"
+#include "mongo/logv2/log.h"
 #include "mongo/unittest/death_test.h"
 #include "mongo/unittest/temp_dir.h"
 #include "mongo/unittest/unittest.h"
@@ -300,7 +301,7 @@ class WatchdogMonitorThreadTest : public ServiceContextTest {};
 TEST_F(WatchdogMonitorThreadTest, Basic) {
     ManualResetEvent deathEvent;
     WatchdogDeathCallback deathCallback = [&deathEvent]() {
-        log() << "Death signalled";
+        LOGV2("Death signalled");
         deathEvent.set();
     };
 
@@ -345,7 +346,7 @@ private:
 TEST_F(WatchdogMonitorThreadTest, SleepyHungCheck) {
     ManualResetEvent deathEvent;
     WatchdogDeathCallback deathCallback = [&deathEvent]() {
-        log() << "Death signalled";
+        LOGV2("Death signalled");
         deathEvent.set();
     };
 
@@ -375,7 +376,7 @@ class WatchdogMonitorTest : public ServiceContextTest {};
 TEST_F(WatchdogMonitorTest, SleepyHungCheck) {
     ManualResetEvent deathEvent;
     WatchdogDeathCallback deathCallback = [&deathEvent]() {
-        log() << "Death signalled";
+        LOGV2("Death signalled");
         deathEvent.set();
     };
 
@@ -412,7 +413,7 @@ DEATH_TEST(WatchdogMonitorTest, Death, "") {
 TEST_F(WatchdogMonitorTest, PauseAndResume) {
 
     WatchdogDeathCallback deathCallback = []() {
-        log() << "Death signalled, it should not have been";
+        LOGV2("Death signalled, it should not have been");
         invariant(false);
     };
 
-- 
2.17.2

